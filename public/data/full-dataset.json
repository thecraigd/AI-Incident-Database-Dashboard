{
  "incidents": [
    {
      "id": "ObjectId(625763de343edc875fe63a15)",
      "incident_id": 23,
      "date": "2017-11-08",
      "title": "Las Vegas Self-Driving Bus Involved in Accident",
      "description": "A self-driving public shuttle by Keolis North America and Navya was involved in a collision with a human-driven delivery truck in Las Vegas, Nevada on its first day of service.",
      "deployers": [
        "navya",
        "keolis-north-america"
      ],
      "developers": [
        "navya",
        "keolis-north-america"
      ],
      "harmedParties": [
        "navya",
        "keolis-north-america",
        "bus-passengers"
      ],
      "reports": [
        242,
        243,
        244,
        245,
        246,
        247,
        248,
        249,
        250,
        253,
        254,
        257,
        258,
        259,
        260,
        261,
        263,
        264,
        266,
        267,
        268,
        269,
        270,
        2389
      ],
      "severity": "AI tangible harm event",
      "classification": "yes",
      "sector": "transportation and storage",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763dc343edc875fe63a02)",
      "incident_id": 4,
      "date": "2018-03-18",
      "title": "Uber AV Killed Pedestrian in Arizona",
      "description": "An Uber autonomous vehicle (AV) in autonomous mode struck and killed a pedestrian in Tempe, Arizona.",
      "deployers": [
        "uber"
      ],
      "developers": [
        "uber"
      ],
      "harmedParties": [
        "elaine-herzberg",
        "pedestrians"
      ],
      "reports": [
        629,
        630,
        631,
        632,
        633,
        634,
        635,
        636,
        637,
        638,
        639,
        640,
        641,
        642,
        644,
        645,
        646,
        647,
        1375,
        1376,
        1377,
        1378,
        1542,
        2147,
        1257
      ],
      "severity": "AI tangible harm event",
      "classification": "yes",
      "sector": "transportation and storage",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763db343edc875fe639ff)",
      "incident_id": 1,
      "date": "2015-05-19",
      "title": "Google’s YouTube Kids App Presents Inappropriate Content",
      "description": "YouTube’s content filtering and recommendation algorithms exposed children to disturbing and inappropriate videos.",
      "deployers": [
        "youtube"
      ],
      "developers": [
        "youtube"
      ],
      "harmedParties": [
        "children"
      ],
      "reports": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        14,
        15
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "Arts, entertainment and recreation, information and communication",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763de343edc875fe63a10)",
      "incident_id": 18,
      "date": "2015-04-04",
      "title": "Gender Biases of Google Image Search",
      "description": "Google Image returns results that under-represent women in leadership roles, notably with the first photo of a female CEO being a Barbie doll after 11 rows of male CEOs.",
      "deployers": [
        "google"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "women"
      ],
      "reports": [
        130,
        131,
        132,
        133,
        134,
        135,
        136,
        137,
        138,
        1367,
        1368
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "information and communication",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763dd343edc875fe63a0a)",
      "incident_id": 12,
      "date": "2016-07-21",
      "title": "Common Biases of Vector Embeddings",
      "description": "Researchers from Boston University and Microsoft Research, New England demonstrated gender bias in the most common techniques used to embed words for natural language processing (NLP).",
      "deployers": [
        "microsoft-research",
        "boston-university"
      ],
      "developers": [
        "microsoft-research",
        "google",
        "boston-university"
      ],
      "harmedParties": [
        "women",
        "minority-groups"
      ],
      "reports": [
        42
      ],
      "severity": "none",
      "classification": "no",
      "sector": "professional, scientific and technical activities",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763dd343edc875fe63a0d)",
      "incident_id": 15,
      "date": "2008-05-23",
      "title": "Amazon Censors Gay Books",
      "description": "Amazon's book store cataloging error led to books containing gay and lesbian themes to lose their sales ranking, therefore losing visibility on the sales platform.",
      "deployers": [
        "amazon"
      ],
      "developers": [
        "amazon"
      ],
      "harmedParties": [
        "amazon-customers"
      ],
      "reports": [
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81
      ],
      "severity": "none",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763dc343edc875fe63a05)",
      "incident_id": 7,
      "date": "2017-02-24",
      "title": "Wikipedia Vandalism Prevention Bot Loop",
      "description": "Wikipedia bots meant to remove vandalism clash with each other and form feedback loops of repetitve undoing of the other bot's edits.",
      "deployers": [
        "wikipedia"
      ],
      "developers": [
        "wikipedia"
      ],
      "harmedParties": [
        "wikimedia-foundation",
        "wikipedia-editors",
        "wikipedia-users"
      ],
      "reports": [
        1123,
        1125,
        1126,
        1127,
        1129,
        1130
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "information and communication",
      "region": "Global"
    },
    {
      "id": "ObjectId(625763dc343edc875fe63a03)",
      "incident_id": 5,
      "date": "2015-07-13",
      "title": "Collection of Robotic Surgery Malfunctions",
      "description": "Study on database reports of robotic surgery malfunctions (8,061), including those ending in injury (1,391) and death (144), between 2000 and 2013.",
      "deployers": [
        "hospitals",
        "doctors"
      ],
      "developers": [
        "intuitive-surgical"
      ],
      "harmedParties": [
        "patients"
      ],
      "reports": [
        767,
        768,
        769,
        770,
        771,
        772,
        773,
        774,
        775,
        776,
        777,
        778
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(625763dc343edc875fe63a04)",
      "incident_id": 6,
      "date": "2016-03-24",
      "title": "TayBot",
      "description": "Microsoft's Tay, an artificially intelligent chatbot, was released on March 23, 2016 and removed within 24 hours due to multiple racist, sexist, and anit-semitic tweets generated by the bot.",
      "deployers": [
        "microsoft"
      ],
      "developers": [
        "microsoft"
      ],
      "harmedParties": [
        "twitter-users"
      ],
      "reports": [
        906,
        908,
        909,
        910,
        911,
        912,
        913,
        914,
        915,
        916,
        917,
        918,
        919,
        920,
        921,
        922,
        923,
        924,
        925,
        926,
        927,
        928,
        929,
        930,
        1374,
        1780,
        2398,
        2656
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "information and communication",
      "region": "Global"
    },
    {
      "id": "ObjectId(625763dd343edc875fe63a08)",
      "incident_id": 10,
      "date": "2014-08-14",
      "title": "Kronos Scheduling Algorithm Allegedly Caused Financial Issues for Starbucks Employees",
      "description": "Kronos’s scheduling algorithm and its use by Starbucks managers allegedly negatively impacted financial and scheduling stability for Starbucks employees, which disadvantaged wage workers.",
      "deployers": [
        "starbucks"
      ],
      "developers": [
        "kronos"
      ],
      "harmedParties": [
        "starbucks-employees"
      ],
      "reports": [
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25
      ],
      "severity": "AI tangible harm event",
      "classification": "yes",
      "sector": "accommodation and food service activities",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763dd343edc875fe63a09)",
      "incident_id": 11,
      "date": "2016-05-23",
      "title": "Northpointe Risk Models",
      "description": "An algorithm developed by Northpointe and used in the penal system is two times more likely to incorrectly label a black person as a high-risk re-offender and is two times more likely to incorrectly label a white person as low-risk for reoffense according to a ProPublica review.",
      "deployers": [
        "northpointe"
      ],
      "developers": [
        "northpointe"
      ],
      "harmedParties": [
        "accused-people"
      ],
      "reports": [
        29,
        30,
        31,
        32,
        33,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        1371,
        1372,
        1373
      ],
      "severity": "AI tangible harm event",
      "classification": "yes",
      "sector": "law enforcement, public administration",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763de343edc875fe63a12)",
      "incident_id": 20,
      "date": "2016-06-30",
      "title": "A Collection of Tesla Autopilot-Involved Crashes",
      "description": "Multiple unrelated car accidents result in varying levels of harm have been occurred while a Tesla's autopilot was in use.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "motorists"
      ],
      "reports": [
        191,
        192,
        193,
        196,
        197,
        198,
        201,
        202,
        203,
        204,
        205,
        206,
        207,
        210,
        211,
        213,
        214,
        215,
        216,
        1362,
        1363,
        1364
      ],
      "severity": "AI tangible harm event",
      "classification": "yes",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763de343edc875fe63a16)",
      "incident_id": 24,
      "date": "2014-07-15",
      "title": "Robot kills worker at German Volkswagen plant",
      "description": "A Volkswagen plant robot crushed to death a worker by pinning him to a metal plate. ",
      "deployers": [
        "volkswagen"
      ],
      "developers": [
        "volkswagen"
      ],
      "harmedParties": [
        "robotics-consultant"
      ],
      "reports": [
        271,
        272,
        273,
        274,
        275,
        276,
        277,
        278,
        279,
        281,
        282,
        283,
        284,
        285,
        286,
        287,
        288,
        289,
        290,
        291,
        292,
        293,
        294,
        295,
        296,
        298,
        299
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "manufacturing",
      "region": "Europe"
    },
    {
      "id": "ObjectId(625763dd343edc875fe63a0c)",
      "incident_id": 14,
      "date": "2017-10-26",
      "title": "Biased Sentiment Analysis",
      "description": "Google Cloud's Natural Language API provided racist, homophobic, amd antisemitic sentiment analyses.",
      "deployers": [
        "google"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "women",
        "minority-groups"
      ],
      "reports": [
        50,
        51,
        52,
        53,
        54,
        55,
        56
      ],
      "severity": "none",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763dd343edc875fe63a0e)",
      "incident_id": 16,
      "date": "2015-06-03",
      "title": "Images of Black People Labeled as Gorillas",
      "description": "Google Photos image processing software mistakenly labelled a black couple as gorillas.",
      "deployers": [
        "google"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "black-people"
      ],
      "reports": [
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        95,
        96,
        98,
        99,
        100,
        101,
        102,
        103,
        104,
        105,
        1369,
        1370,
        3004
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "information and communication",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763dc343edc875fe63a01)",
      "incident_id": 3,
      "date": "2018-10-27",
      "title": "Crashes with Maneuvering Characteristics Augmentation System (MCAS)",
      "description": "A Boeing 737 crashed into the sea, killing 189 people, after faulty sensor data caused an automated manuevering system to repeatedly push the plane's nose downward.",
      "deployers": [
        "boeing"
      ],
      "developers": [
        "boeing"
      ],
      "harmedParties": [
        "airplane-passengers",
        "airplane-crew"
      ],
      "reports": [
        372,
        373,
        374,
        375,
        376,
        377,
        378,
        379,
        380,
        381,
        382,
        383,
        384,
        385,
        386,
        387,
        388,
        389,
        1342,
        3447
      ],
      "severity": "unclear",
      "classification": "yes",
      "sector": "transportation and storage",
      "region": "Asia"
    },
    {
      "id": "ObjectId(625763dc343edc875fe63a00)",
      "incident_id": 2,
      "date": "2018-12-05",
      "title": "Warehouse robot ruptures can of bear spray and injures workers",
      "description": "Twenty-four Amazon workers in New Jersey were hospitalized after a robot punctured a can of bear repellent spray in a warehouse.",
      "deployers": [
        "amazon"
      ],
      "developers": [
        "amazon"
      ],
      "harmedParties": [
        "warehouse-workers"
      ],
      "reports": [
        139,
        141,
        142,
        143,
        144,
        145,
        146,
        148,
        149,
        150,
        151,
        152,
        153,
        154,
        155,
        156,
        157
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "wholesale and retail trade",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763de343edc875fe63a11)",
      "incident_id": 19,
      "date": "2013-01-23",
      "title": "Sexist and Racist Google Adsense Advertisements",
      "description": "Advertisements chosen by Google Adsense are reported as producing sexist and racist results.",
      "deployers": [
        "google"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "women",
        "minority-groups"
      ],
      "reports": [
        158,
        159,
        160,
        161,
        162,
        163,
        166,
        167,
        168,
        169,
        171,
        172,
        173,
        174,
        175,
        176,
        177,
        178,
        179,
        181,
        182,
        183,
        184,
        185,
        187,
        1365,
        1366
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "information and communication",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763dd343edc875fe63a07)",
      "incident_id": 9,
      "date": "2012-02-25",
      "title": "NY City School Teacher Evaluation Algorithm Contested",
      "description": "An algorithm used to rate the effectiveness of school teachers in New York has resulted in thousands of disputes of its results.",
      "deployers": [
        "new-york-city-dept.-of-education"
      ],
      "developers": [
        "new-york-city-dept.-of-education"
      ],
      "harmedParties": [
        "teachers"
      ],
      "reports": [
        1329,
        1330,
        1331,
        1332,
        1333,
        1334,
        1335
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "Education",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763dc343edc875fe63a06)",
      "incident_id": 8,
      "date": "2014-08-15",
      "title": "Uber Autonomous Cars Running Red Lights",
      "description": "Uber vehicles equipped with technology allowing for autonomous driving running red lights in San Francisco street testing.",
      "deployers": [
        "uber"
      ],
      "developers": [
        "uber"
      ],
      "harmedParties": [
        "pedestrians",
        "motorists"
      ],
      "reports": [
        1142,
        1143,
        1145,
        1149,
        1150,
        1151,
        1153,
        1154,
        1155,
        1156
      ],
      "severity": "AI tangible harm near-miss",
      "classification": "yes",
      "sector": "transportation and storage",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763dd343edc875fe63a0b)",
      "incident_id": 13,
      "date": "2017-02-27",
      "title": "High-Toxicity Assessed on Text Involving Women and Minority Groups",
      "description": "Google's Perspective API, which assigns a toxicity score to online text, seems to award higher toxicity scores to content involving non-white, male, Christian, heterosexual phrases.",
      "deployers": [
        "google"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "women",
        "minority-groups"
      ],
      "reports": [
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        1414,
        1415
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "information and communication",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763de343edc875fe63a13)",
      "incident_id": 21,
      "date": "2016-07-14",
      "title": "Tougher Turing Test Exposes Chatbots’ Stupidity (migrated to Issue)",
      "description": "The 2016 Winograd Schema Challenge highlighted how even the most successful AI systems entered into the Challenge were only successful 3% more often than random chance. This incident has been downgraded to an issue as it does not meet current ingestion criteria.",
      "deployers": [
        "researchers"
      ],
      "developers": [
        "researchers"
      ],
      "harmedParties": [
        "researchers"
      ],
      "reports": [
        2471
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(625763dd343edc875fe63a0f)",
      "incident_id": 17,
      "date": "2015-11-03",
      "title": "Inappropriate Gmail Smart Reply Suggestions",
      "description": "Google's Gmail Smart Reply tool was over-recommending the response I love you in situations where it was deemed innappropriate. ",
      "deployers": [
        "google"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "gmail-users"
      ],
      "reports": [
        106,
        107,
        110,
        111,
        112,
        113,
        114,
        115,
        116,
        117,
        118,
        119,
        120,
        121,
        122,
        123,
        124,
        125,
        126,
        127,
        128,
        129
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "information and communication",
      "region": "Global"
    },
    {
      "id": "ObjectId(625763de343edc875fe63a14)",
      "incident_id": 22,
      "date": "2017-12-06",
      "title": "Waze Navigates Motorists into Wildfires",
      "description": "Waze, a Google-owned directions app, led California drivers into the 2017 Skirball wildfires as they tried to evacuate the area.",
      "deployers": [
        "google"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "motorists"
      ],
      "reports": [
        218,
        219,
        220,
        221,
        223,
        224,
        225,
        226,
        227,
        228,
        229,
        230,
        231,
        232,
        233,
        234,
        235,
        236,
        237,
        238,
        239,
        240
      ],
      "severity": "AI tangible harm near-miss",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763de343edc875fe63a17)",
      "incident_id": 25,
      "date": "2015-05-11",
      "title": "Near-miss between two Self-Driving Cars",
      "description": "A Google self-driving car allegedly cut off a Delphi self-driving car during a road test, however the Delphi car sensed and avoided collision with the Google car.",
      "deployers": [
        "google",
        "delphi-technologies"
      ],
      "developers": [
        "google",
        "delphi-technologies"
      ],
      "harmedParties": [
        "delphi-technologies"
      ],
      "reports": [
        310,
        309,
        308,
        307,
        306,
        305,
        304,
        302,
        301,
        300,
        2173
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "transportation and storage",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763e0343edc875fe63a23)",
      "incident_id": 37,
      "date": "2016-08-10",
      "title": "Female Applicants Down-Ranked by Amazon Recruiting Tool",
      "description": "Amazon shuts down internal AI recruiting tool that would down-rank female applicants.",
      "deployers": [
        "amazon"
      ],
      "developers": [
        "amazon"
      ],
      "harmedParties": [
        "female-applicants"
      ],
      "reports": [
        599,
        600,
        601,
        602,
        603,
        604,
        605,
        606,
        607,
        608,
        609,
        610,
        611,
        612,
        613,
        614,
        615,
        616,
        617,
        618,
        619,
        620,
        621,
        622,
        623,
        624,
        625,
        626,
        627,
        628,
        1498,
        2253,
        2461
      ],
      "severity": "AI tangible harm issue",
      "classification": "maybe",
      "sector": "administrative and support service activities",
      "region": "Europe"
    },
    {
      "id": "ObjectId(625763df343edc875fe63a1d)",
      "incident_id": 31,
      "date": "2017-12-03",
      "title": "Driverless Train in Delhi Crashes due to Braking Failure",
      "description": "A driverless metro train in Delhi, India crashed during a test run due to faulty brakes.",
      "deployers": [
        "delhi-metro-rail-corporation"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "delhi-metro-rail-corporation"
      ],
      "reports": [
        454,
        455,
        456,
        457,
        458,
        459,
        460,
        461,
        462,
        463,
        464,
        465,
        466,
        467,
        468,
        469,
        470,
        471,
        472,
        473,
        474,
        475,
        476,
        477,
        479,
        480,
        481,
        482,
        483
      ],
      "severity": "none",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763df343edc875fe63a20)",
      "incident_id": 34,
      "date": "2015-12-05",
      "title": "Amazon Alexa Responding to Environmental Inputs",
      "description": "There are multiple reports of Amazon Alexa products (Echo, Echo Dot) reacting and acting upon unintended stimulus, usually from television commercials or news reporter's voices.",
      "deployers": [
        "amazon"
      ],
      "developers": [
        "amazon"
      ],
      "harmedParties": [
        "alexa-device-owners"
      ],
      "reports": [
        509,
        510,
        512,
        513,
        514,
        516,
        517,
        518,
        519,
        520,
        521,
        522,
        524,
        525,
        526,
        527,
        528,
        529,
        530,
        531,
        532,
        533,
        535,
        536,
        537,
        538,
        818,
        819,
        820,
        821,
        822,
        823,
        824,
        825,
        826
      ],
      "severity": "AI tangible harm near-miss",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763df343edc875fe63a19)",
      "incident_id": 27,
      "date": "1983-09-26",
      "title": "Nuclear False Alarm",
      "description": "An alert of five incoming intercontinental ballistic missiles was properly identified as a false-positive by the Soviet Union operator Stanislov Petrov.",
      "deployers": [
        "soviet-union"
      ],
      "developers": [
        "soviet-union"
      ],
      "harmedParties": [
        "all-life-on-earth"
      ],
      "reports": [
        342,
        343,
        344,
        345,
        346,
        347,
        349,
        350,
        351,
        352,
        353,
        354,
        355,
        356,
        357,
        358,
        359,
        360,
        361,
        363,
        364,
        365,
        366,
        367,
        368,
        370,
        371
      ],
      "severity": "none",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763df343edc875fe63a1b)",
      "incident_id": 29,
      "date": "2011-09-20",
      "title": "Image Classification of Battle Tanks",
      "description": "A potentially apocryphal story in which an image classifier was produced to differentiate types of battle tanks, but the resulting model keyed in on environmental attributes rather than tank attributes",
      "deployers": [
        "united-states-government"
      ],
      "developers": [
        "united-states-government"
      ],
      "harmedParties": [
        "united-states-government"
      ],
      "reports": [
        420,
        422,
        2471
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(625763df343edc875fe63a1e)",
      "incident_id": 32,
      "date": "2017-09-13",
      "title": "Identical Twins Can Open Apple FaceID Protected Devices",
      "description": "Apple's iPhone FaceID can be opened by an identical twin of the person who has registered their face to unlock the phone.",
      "deployers": [
        "apple"
      ],
      "developers": [
        "apple"
      ],
      "harmedParties": [
        "people-with-twins"
      ],
      "reports": [
        484,
        485,
        486,
        487,
        488,
        489,
        490,
        491,
        492,
        493,
        494,
        495,
        496,
        497,
        498,
        499,
        500,
        501,
        502,
        503,
        1361
      ],
      "severity": "none",
      "classification": "maybe",
      "sector": "information and communication",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763e0343edc875fe63a2a)",
      "incident_id": 44,
      "date": "2008-07-01",
      "title": "Machine Personal Assistants Failed to Maintain Social Norms",
      "description": "During an experiment of software personal assistants at the Information Sciences Institute (ISI) at the University of Southern California (USC), researchers found that the assistants violated the privacy of their principals and were unable to respect the social norms of the office.",
      "deployers": [
        "usc-information-sciences-institute"
      ],
      "developers": [
        "usc-information-sciences-institute"
      ],
      "harmedParties": [
        "usc-information-sciences-institute"
      ],
      "reports": [
        766
      ],
      "severity": "none",
      "classification": "no",
      "sector": "administrative and support service activities",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763df343edc875fe63a21)",
      "incident_id": 35,
      "date": "2014-10-18",
      "title": "Employee Automatically Terminated by Computer Program",
      "description": "An employee was laid off, allegedly by an artificially intelligent personnel system, and blocked from access to the building and computer systems without their knowledge.",
      "deployers": [
        "unknown"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "ibrahim-diallo"
      ],
      "reports": [
        539,
        540,
        541,
        543,
        544,
        545,
        547,
        548,
        549,
        550,
        551,
        555,
        558,
        562,
        563,
        564,
        565,
        566,
        567,
        568
      ],
      "severity": "none",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763e1343edc875fe63a2d)",
      "incident_id": 47,
      "date": "2016-09-06",
      "title": "LinkedIn Search Prefers Male Names",
      "description": "An investigation by The Seattle Times in 2016 found a gender bias in LinkedIn's search engine.",
      "deployers": [
        "linkedin"
      ],
      "developers": [
        "linkedin"
      ],
      "harmedParties": [
        "women"
      ],
      "reports": [
        829,
        830,
        831,
        832,
        833,
        834,
        835,
        836,
        837
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "information and communication",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763e1343edc875fe63a2e)",
      "incident_id": 48,
      "date": "2016-12-07",
      "title": "Passport checker Detects Asian man's Eyes as Closed",
      "description": "New Zealand passport robot reader rejects the application of an applicant with Asian descent and says his eyes are closed.",
      "deployers": [
        "new-zealand"
      ],
      "developers": [
        "new-zealand"
      ],
      "harmedParties": [
        "asian-people"
      ],
      "reports": [
        838,
        839,
        840,
        842,
        843,
        844,
        845,
        846,
        847,
        848,
        849,
        850,
        851,
        853,
        854,
        855,
        857,
        858,
        859,
        860,
        862,
        863
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "public administration",
      "region": "Oceania"
    },
    {
      "id": "ObjectId(625763df343edc875fe63a1a)",
      "incident_id": 28,
      "date": "2010-05-08",
      "title": "2010 Market Flash Crash",
      "description": "A modified algorithm was able to cause dramatic price volatility and disrupted trading in the US stock exchange.",
      "deployers": [
        "navinder-sarao",
        "waddell-and-reed",
        "barclays-capital"
      ],
      "developers": [
        "navinder-sarao",
        "waddell-and-reed",
        "barclays-capital"
      ],
      "harmedParties": [
        "market-participants"
      ],
      "reports": [
        390,
        391,
        392,
        393,
        394,
        395,
        396,
        397,
        398,
        399,
        400,
        401,
        402,
        403,
        404,
        405,
        406,
        407,
        408,
        409,
        410,
        411,
        412,
        413,
        414,
        415,
        416,
        417,
        418,
        419
      ],
      "severity": "none",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763e0343edc875fe63a29)",
      "incident_id": 43,
      "date": "1998-03-05",
      "title": "Racist AI behaviour is not a new problem",
      "description": "From 1982 to 1986, St George's Hospital Medical School used a program to automate a portion of their admissions process that resulted in discrimination against women and members of ethnic minorities.",
      "deployers": [
        "st-george's-hospital-medical-school"
      ],
      "developers": [
        "dr.-geoffrey-franglen"
      ],
      "harmedParties": [
        "women",
        "minority-groups"
      ],
      "reports": [
        762,
        763,
        764,
        765
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "Education, human health and social work activities",
      "region": "Europe"
    },
    {
      "id": "ObjectId(625763de343edc875fe63a18)",
      "incident_id": 26,
      "date": "2017-09-13",
      "title": "Hackers Break Apple Face ID",
      "description": "Vietnamese security firm Bkav created an improved mask to bypass Apple's Face ID",
      "deployers": [
        "apple"
      ],
      "developers": [
        "apple"
      ],
      "harmedParties": [
        "apple",
        "device-owners"
      ],
      "reports": [
        311,
        312,
        313,
        314,
        315,
        316,
        317,
        318,
        319,
        321,
        323,
        324,
        325,
        326,
        327,
        329,
        330,
        333,
        334,
        336,
        337,
        338,
        339,
        340
      ],
      "severity": "none",
      "classification": "yes",
      "region": "Asia"
    },
    {
      "id": "ObjectId(625763df343edc875fe63a1f)",
      "incident_id": 33,
      "date": "2017-11-09",
      "title": "Amazon Alexa Plays Loud Music when Owner is Away",
      "description": "An Amazon Alexa, without instruction to do so, began playing loud music in the early morning while the homeowner was away leading to police breaking into their house to turn off the device.",
      "deployers": [
        "amazon"
      ],
      "developers": [
        "amazon"
      ],
      "harmedParties": [
        "oliver-haberstroh",
        "neighbors"
      ],
      "reports": [
        504,
        505,
        507,
        508
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "information and communication",
      "region": "Europe"
    },
    {
      "id": "ObjectId(625763e1343edc875fe63a2c)",
      "incident_id": 46,
      "date": "2014-01-21",
      "title": "Nest Smoke Alarm Erroneously Stops Alarming",
      "description": "In testing, Google Nest engineers demonstrated that the Nest Wave feature of their Nest Protect: Smoke + CO Alarm could inadvertently silence genuine alarms.",
      "deployers": [
        "nest-labs"
      ],
      "developers": [
        "nest-labs"
      ],
      "harmedParties": [
        "fire-victims"
      ],
      "reports": [
        810,
        811,
        812,
        813,
        814,
        815
      ],
      "severity": "none",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763e0343edc875fe63a25)",
      "incident_id": 39,
      "date": "2017-07-01",
      "title": "Deepfake Obama Introduction of Deepfakes",
      "description": "University of Washington researchers made a deepfake of Obama, followed by Jordan Peele",
      "deployers": [
        "university-of-washington",
        "fakeapp"
      ],
      "developers": [
        "university-of-washington",
        "fakeapp"
      ],
      "harmedParties": [
        "barack-obama"
      ],
      "reports": [
        667,
        668,
        669,
        670,
        671,
        672,
        673,
        674,
        675,
        676,
        677,
        678,
        679,
        680,
        681,
        682,
        683,
        684,
        685,
        686,
        687,
        688,
        689,
        690,
        692,
        693,
        694,
        695,
        696
      ],
      "severity": "none",
      "classification": "no",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763df343edc875fe63a1c)",
      "incident_id": 30,
      "date": "2016-10-08",
      "title": "Poor Performance of Tesla Factory Robots",
      "description": "The goal of manufacturing 2,500 Tesla Model 3's per week was falling short by 500 cars/week, and employees had to be borrowed from Panasonic in a shared factory to help hand-assemble lithium batteries for Tesla.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "tesla"
      ],
      "reports": [
        424,
        425,
        426,
        428,
        430,
        431,
        432,
        433,
        434,
        435,
        436,
        437,
        438,
        439,
        440,
        441,
        442,
        443,
        444,
        445,
        446,
        447,
        448,
        449,
        450,
        451,
        452,
        453
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "manufacturing",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763e0343edc875fe63a22)",
      "incident_id": 36,
      "date": "2018-11-06",
      "title": "Picture of Woman on Side of Bus Shamed for Jaywalking",
      "description": "Facial recognition system in China mistakes celebrity's face on moving billboard for jaywalker",
      "deployers": [
        "ningbo-traffic-police"
      ],
      "developers": [
        "ningbo-traffic-police"
      ],
      "harmedParties": [
        "dong-mingzhu"
      ],
      "reports": [
        1360,
        598,
        597,
        596,
        595,
        593,
        592,
        591,
        590,
        589,
        587,
        586,
        585,
        584,
        582,
        581,
        580,
        579,
        577,
        574,
        573,
        571,
        570,
        569
      ],
      "severity": "AI tangible harm near-miss",
      "classification": "yes",
      "sector": "law enforcement",
      "region": "Asia"
    },
    {
      "id": "ObjectId(625763e0343edc875fe63a27)",
      "incident_id": 41,
      "date": "2018-04-02",
      "title": "All Image Captions Produced are Violent",
      "description": "MIT Media Lab researchers create AI-powered psychopath  named Norman by training a model on dark corners of Reddit.",
      "deployers": [
        "mit-media-lab"
      ],
      "developers": [
        "mit-media-lab"
      ],
      "harmedParties": [
        "unknown"
      ],
      "reports": [
        719,
        720,
        721,
        722,
        724,
        725,
        726,
        727,
        728,
        730,
        731,
        732,
        733,
        734,
        735,
        736,
        737,
        738,
        739,
        740,
        741,
        742,
        743,
        744,
        745,
        746,
        747,
        748
      ],
      "severity": "none",
      "classification": "no",
      "sector": "professional, scientific and technical activities",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763e0343edc875fe63a28)",
      "incident_id": 42,
      "date": "1996-04-03",
      "title": "Inefficiencies in the United States Resident Matching Program",
      "description": "Alvin Roth, a Ph.D at the University of Pittsburgh, describes the National Resident Matching Program (NRMP) and suggests future changes that are needed in the algorithm used to match recently graduated medical students to their residency programs.",
      "deployers": [
        "national-resident-matching-program"
      ],
      "developers": [
        "national-resident-matching-program"
      ],
      "harmedParties": [
        "medical-residents"
      ],
      "reports": [
        759,
        2471
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(625763e1343edc875fe63a2b)",
      "incident_id": 45,
      "date": "2011-04-05",
      "title": "Defamation via AutoComplete",
      "description": "Google's autocomplete feature alongside its image search results resulted in the defamation of people and businesses.",
      "deployers": [
        "google"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "varied"
      ],
      "reports": [
        780,
        781,
        782,
        783,
        784,
        785,
        787,
        788,
        789,
        790,
        791,
        792,
        793,
        794,
        795,
        796,
        798,
        799,
        800,
        801,
        802,
        803,
        804,
        805,
        807,
        808,
        809,
        1355,
        1356
      ],
      "severity": "AI tangible harm event",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763e0343edc875fe63a24)",
      "incident_id": 38,
      "date": "2016-06-02",
      "title": "Game AI System Produces Imbalanced Game",
      "description": "Elite: Dangerous, a videogame developed by Frontier Development, received an expansion update that featured an AI system that went rogue and began to create weapons that were impossibly powerful and would shred people according to complaints on the game's blog.",
      "deployers": [
        "frontier-development"
      ],
      "developers": [
        "frontier-development"
      ],
      "harmedParties": [
        "video-game-players"
      ],
      "reports": [
        648,
        649,
        650,
        652,
        654,
        655,
        656,
        657,
        658,
        659,
        662
      ],
      "severity": "none",
      "classification": "no",
      "sector": "Arts, entertainment and recreation",
      "region": "Global"
    },
    {
      "id": "ObjectId(625763e0343edc875fe63a26)",
      "incident_id": 40,
      "date": "2016-05-23",
      "title": "COMPAS Algorithm Performs Poorly in Crime Recidivism Prediction",
      "description": "Correctional Offender Management Profiling for Alternative Sanctions (COMPAS), a recidivism risk-assessment algorithmic tool used in the judicial system to assess likelihood of defendants' recidivism, is found to be less accurate than random untrained human evaluators.",
      "deployers": [
        "equivant"
      ],
      "developers": [
        "equivant"
      ],
      "harmedParties": [
        "accused-people"
      ],
      "reports": [
        697,
        699,
        700,
        701,
        702,
        703,
        704,
        705,
        706,
        707,
        708,
        709,
        711,
        712,
        715,
        716,
        717,
        718,
        1338,
        1357,
        1358,
        1359
      ],
      "severity": "AI tangible harm event",
      "classification": "yes",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763e3343edc875fe63a3e)",
      "incident_id": 64,
      "date": "2018-01-22",
      "title": "Customer Service Robot Scares Away Customers",
      "description": "Heriot-Watt Univeristy in Scotland developed an artificially intelligent grocery store robot, Fabio, who provided unhelpful answers to customer's questions and scared away multiple customers, according to the grocery store Margiotta.",
      "deployers": [
        "heriot-watt-university",
        "margiotta"
      ],
      "developers": [
        "heriot-watt-university"
      ],
      "harmedParties": [
        "store-patrons"
      ],
      "reports": [
        1137
      ],
      "severity": "none",
      "classification": "no",
      "sector": "wholesale and retail trade",
      "region": "Europe"
    },
    {
      "id": "ObjectId(625763e3343edc875fe63a41)",
      "incident_id": 67,
      "date": "2018-12-01",
      "title": "Sleeping Driver on Tesla AutoPilot",
      "description": "A Tesla Model S remained on autopilot while being operated by a drunk, sleeping operator whose hands were not on the wheel. The police had to slow the car down by slowing in front of the vehicle to activate its 'driver assist' feature .",
      "deployers": [
        "tesla",
        "motorist"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "motorists"
      ],
      "reports": [
        1181,
        1182,
        1183,
        1185,
        1186,
        1187,
        1188,
        1189,
        1190,
        1192,
        1194,
        1195,
        1196,
        1197,
        1198,
        1199,
        1202,
        1203,
        1204,
        1205,
        1206,
        1207,
        1208,
        1209
      ],
      "severity": "none",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763e2343edc875fe63a3a)",
      "incident_id": 60,
      "date": "2017-04-25",
      "title": "FaceApp Racial Filters",
      "description": "FaceApp is criticized for offering racist filters.",
      "deployers": [
        "faceapp"
      ],
      "developers": [
        "faceapp"
      ],
      "harmedParties": [
        "minority-groups"
      ],
      "reports": [
        1096,
        1097,
        1098,
        1099,
        1101,
        1102,
        1103,
        1104,
        1105,
        1106,
        1107,
        1108,
        1109,
        1110,
        1112,
        1113,
        1117,
        1118,
        1119,
        1120,
        1121,
        1122,
        1344
      ],
      "severity": "none",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763e2343edc875fe63a34)",
      "incident_id": 54,
      "date": "2015-11-18",
      "title": "Predictive Policing Biases of PredPol",
      "description": "Predictive policing algorithms meant to aid law enforcement by predicting future crime show signs of biased output.",
      "deployers": [
        "predpol",
        "oakland-police-department"
      ],
      "developers": [
        "predpol"
      ],
      "harmedParties": [
        "oakland-residents"
      ],
      "reports": [
        1007,
        1008,
        1009,
        1010,
        1014,
        1015,
        1017,
        1019,
        1347,
        1349,
        1524,
        1525,
        1526,
        1013,
        1011,
        1018,
        1012
      ],
      "severity": "none",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763e3343edc875fe63a42)",
      "incident_id": 68,
      "date": "2017-07-17",
      "title": "Security Robot Drowns Itself in a Fountain",
      "description": "A Knightscope K5 security robot ran itself into a water fountain in Washington, DC.",
      "deployers": [
        "knightscope"
      ],
      "developers": [
        "knightscope"
      ],
      "harmedParties": [
        "knightscope"
      ],
      "reports": [
        1210,
        1211,
        1212,
        1213,
        1214,
        1215,
        1216,
        1217,
        1218,
        1219,
        1220,
        1221,
        1222,
        1223,
        1224,
        1225,
        1226,
        1227,
        1228,
        1229,
        1230,
        1231,
        1232,
        1233,
        1234,
        1235,
        1236,
        1237,
        1238,
        1239
      ],
      "severity": "AI tangible harm event",
      "classification": "yes",
      "sector": "administrative and support service activities",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763e2343edc875fe63a38)",
      "incident_id": 58,
      "date": "2017-10-12",
      "title": "Russian Chatbot Supports Stalin and Violence",
      "description": "Yandex, a Russian technology company, released an artificially intelligent chat bot named Alice which began to reply to questions with racist, pro-stalin, and pro-violence responses",
      "deployers": [
        "yandex"
      ],
      "developers": [
        "yandex"
      ],
      "harmedParties": [
        "yandex-users"
      ],
      "reports": [
        1079,
        1080,
        1082,
        1083,
        1084
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "information and communication",
      "region": "Europe"
    },
    {
      "id": "ObjectId(625763e2343edc875fe63a3b)",
      "incident_id": 61,
      "date": "2017-05-01",
      "title": "Overfit Kaggle Models Discouraged Data Science Competitors",
      "description": "In the “The Nature Conservancy Fisheries Monitoring” competition on the data science competition website Kaggle, a number of competitors overfit their image classifier models to a poorly representative validation data set.",
      "deployers": [
        "individual-kaggle-competitors"
      ],
      "developers": [
        "individual-kaggle-competitors"
      ],
      "harmedParties": [
        "individual-kaggle-competitors"
      ],
      "reports": [
        1132
      ],
      "severity": "none",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763e1343edc875fe63a32)",
      "incident_id": 52,
      "date": "2016-07-01",
      "title": "Tesla on AutoPilot Killed Driver in Crash in Florida while Watching Movie",
      "description": "A Tesla Model S on autopilot crashed into a white articulated tractor-trailer on Highway US 27A in Williston, Florida, killing the driver.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "joshua-brown"
      ],
      "reports": [
        961,
        963,
        964,
        965,
        966,
        967,
        968,
        969,
        970,
        971,
        972,
        973,
        975,
        976,
        977,
        979,
        980,
        981,
        982,
        983,
        984,
        985,
        986,
        987,
        988,
        989,
        990,
        1353,
        1354
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(625763e3343edc875fe63a44)",
      "incident_id": 70,
      "date": "2016-02-10",
      "title": "Self-driving cars in winter",
      "description": "Volvo autonomous driving XC90 SUV's experienced issues in Jokkmokk, Sweden when sensors used for automated driving iced over during the winter, rendering them useless.",
      "deployers": [
        "volvo"
      ],
      "developers": [
        "volvo"
      ],
      "harmedParties": [
        "drivers-in-jokkmokk",
        "drivers-in-sweden",
        "volvo"
      ],
      "reports": [
        1255,
        1256,
        1259,
        1260
      ],
      "severity": "none",
      "classification": "no",
      "sector": "transportation and storage",
      "region": "Europe"
    },
    {
      "id": "ObjectId(625763e2343edc875fe63a39)",
      "incident_id": 59,
      "date": "2017-04-13",
      "title": "Gender Biases in Google Translate",
      "description": "A Cornell University study in 2016 highlighted Google Translate's pattern of assigning gender to occupations in a way showing an implicit gender bias against women.",
      "deployers": [
        "google"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "women"
      ],
      "reports": [
        1085,
        1086,
        1087,
        1088,
        1089,
        1090,
        1091,
        1092,
        1093,
        1345
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "information and communication",
      "region": "Global"
    },
    {
      "id": "ObjectId(625763e2343edc875fe63a3c)",
      "incident_id": 62,
      "date": "2017-12-23",
      "title": "Bad AI-Written Christmas Carols",
      "description": "Janelle Shane, an AI research scientist, used 240 popular Christmas carols to train a neural network to write its own carols. This incident has been downgraded to an issue as it does not meet current ingestion criteria.",
      "deployers": [
        "janelle-shane"
      ],
      "developers": [
        "janelle-shane"
      ],
      "harmedParties": [
        "carollers"
      ],
      "reports": [
        2471
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(625763e1343edc875fe63a31)",
      "incident_id": 51,
      "date": "2016-07-12",
      "title": "Security Robot Rolls Over Child in Mall",
      "description": "On July 7, 2016, a Knightscope K5 autonomous security robot collided with a 16-month old boy while patrolling the Stanford Shopping Center in Palo Alto, CA.",
      "deployers": [
        "stanford-shopping-center"
      ],
      "developers": [
        "knightscope"
      ],
      "harmedParties": [
        "child"
      ],
      "reports": [
        931,
        932,
        933,
        934,
        935,
        936,
        938,
        939,
        940,
        942,
        943,
        944,
        945,
        946,
        948,
        949,
        950,
        951,
        952,
        953,
        954,
        955,
        956,
        957,
        958,
        959,
        1765
      ],
      "severity": "AI tangible harm event",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763e1343edc875fe63a33)",
      "incident_id": 53,
      "date": "2016-03-31",
      "title": "Biased Google Image Results",
      "description": "On June 6, 2016, Google image searches of three black teenagers resulted in mostly mugshot images whereas Google image searchers of three white teenagers consisted of mostly stock images, suggesting a racial bias in Google's algorithm.",
      "deployers": [
        "google"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "minority-groups"
      ],
      "reports": [
        991,
        992,
        994,
        995,
        996,
        997,
        998,
        999,
        1000,
        1001,
        1002,
        1003,
        1004,
        1005,
        1006,
        1350,
        1351,
        1352
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "information and communication",
      "region": "Global"
    },
    {
      "id": "ObjectId(625763e3343edc875fe63a3d)",
      "incident_id": 63,
      "date": "2018-01-25",
      "title": "Google Photo Merge Decapitates Subject",
      "description": "Google Photos' AI Assistant created a strange hybrid photograph when merging three different pictures from a ski trip.",
      "deployers": [
        "google"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "alex-harker"
      ],
      "reports": [
        1136
      ],
      "severity": "none",
      "classification": "no",
      "sector": "Arts, entertainment and recreation, information and communication",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763e2343edc875fe63a36)",
      "incident_id": 56,
      "date": "2017-07-10",
      "title": "AI-Designed Phone Cases Are Unexpected",
      "description": "A third-party Amazon merchant named “my_handy_design” was suspected of using a bot to generate cell phone case designs based on the bizarre and unattractive designs being offered.",
      "deployers": [
        "my_handy_design"
      ],
      "developers": [
        "my_handy_design"
      ],
      "harmedParties": [
        "my_handy_design"
      ],
      "reports": [
        1041,
        1042,
        1043,
        1044,
        1045,
        1046,
        1047
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "wholesale and retail trade",
      "region": "Global"
    },
    {
      "id": "ObjectId(625763e2343edc875fe63a37)",
      "incident_id": 57,
      "date": "2015-07-01",
      "title": "Australian Automated Debt Assessment System Issued False Notices to Thousands",
      "description": "Australian Department of Human Services (DHS)’s automated debt assessment system issued false or incorrect debt notices to hundreds of thousands of people, resulting in years-long lawsuits and damages to welfare recipients.",
      "deployers": [
        "australian-department-of-human-services"
      ],
      "developers": [
        "centrelink"
      ],
      "harmedParties": [
        "australian-welfare-recipients"
      ],
      "reports": [
        1048,
        1049,
        1050,
        1051,
        1052,
        1054,
        1055,
        1056,
        1058,
        1059,
        1060,
        1061,
        1062,
        1063,
        1064,
        1065,
        1066,
        1067,
        1068,
        1069,
        1070,
        1071,
        1072,
        1073,
        1074,
        1075,
        1076,
        1077,
        1346,
        1437,
        1618,
        1619,
        2369,
        2372,
        2373,
        2374,
        2375,
        2419,
        3167
      ],
      "severity": "none",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763e3343edc875fe63a3f)",
      "incident_id": 65,
      "date": "2016-12-22",
      "title": "Reinforcement Learning Reward Functions in Video Games",
      "description": "OpenAI published a post about its findings when using Universe, a software for measuring and training AI agents to conduct reinforcement learning experiments, showing that the AI agent did not act in the way intended to complete a videogame.",
      "deployers": [
        "openai"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "openai"
      ],
      "reports": [
        1140
      ],
      "severity": "none",
      "classification": "no",
      "sector": "Arts, entertainment and recreation",
      "region": "Global"
    },
    {
      "id": "ObjectId(625763e1343edc875fe63a30)",
      "incident_id": 50,
      "date": "2016-06-17",
      "title": "The DAO Hack",
      "description": "On June 18, 2016, an attacker successfully exploited a vulnerability in The Decentralized Autonomous Organization (The DAO) on the Ethereum blockchain to steal 3.7M Ether valued at $70M.",
      "deployers": [
        "the-dao"
      ],
      "developers": [
        "the-dao"
      ],
      "harmedParties": [
        "dao-token-holders"
      ],
      "reports": [
        876,
        877,
        878,
        879,
        880,
        881,
        883,
        884,
        885,
        886,
        887,
        888,
        889,
        892,
        893,
        896,
        897,
        898,
        899,
        900,
        901,
        902,
        903,
        905
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "financial and insurance activities",
      "region": "Global"
    },
    {
      "id": "ObjectId(625763e3343edc875fe63a45)",
      "incident_id": 71,
      "date": "2016-09-26",
      "title": "Google admits its self driving car got it wrong: Bus crash was caused by software",
      "description": "On February 14, 2016, a Google autonomous test vehicle partially responsible for a low-speed collision with a bus on El Camino Real in Google’s hometown of Mountain View, CA.",
      "deployers": [
        "google"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "mountain-view-municipal-bus-passengers",
        "mountain-view-municipal-bus"
      ],
      "reports": [
        1261,
        1262,
        1263,
        1264,
        1265,
        1266,
        1267,
        1268,
        1269,
        1270,
        1271,
        1272,
        1273,
        1274,
        1275,
        1276,
        1277,
        1278,
        1279,
        1280,
        1281,
        1282,
        1284,
        1285,
        1287,
        1288,
        1289,
        1290
      ],
      "severity": "AI tangible harm event",
      "classification": "yes",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763e2343edc875fe63a35)",
      "incident_id": 55,
      "date": "2016-12-30",
      "title": "Alexa Plays Pornography Instead of Kids Song",
      "description": "An Amazon Echo Dot using the Amazon Alex software started to play pornographic results when a child asked it to play a song.",
      "deployers": [
        "amazon"
      ],
      "developers": [
        "amazon"
      ],
      "harmedParties": [
        "children"
      ],
      "reports": [
        1020,
        1021,
        1022,
        1024,
        1025,
        1026,
        1027,
        1028,
        1029,
        1030,
        1032,
        1033,
        1034,
        1035,
        1036,
        1038
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "Arts, entertainment and recreation, information and communication",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763e3343edc875fe63a43)",
      "incident_id": 69,
      "date": "2015-07-02",
      "title": "Worker killed by robot in welding accident at car parts factory in India",
      "description": "A factory robot at the SKH Metals Factory in Manesar, India pierced and killed 24-year-old worker Ramji Lal when Lal reached behind the machine to dislodge a piece of metal stuck in the machine.",
      "deployers": [
        "skh-metals"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "ramji-lal"
      ],
      "reports": [
        1240,
        1241,
        1243,
        1244,
        1245,
        1246,
        1247,
        1248,
        1249,
        1250,
        1252,
        1253
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "manufacturing",
      "region": "Asia"
    },
    {
      "id": "ObjectId(625763e3343edc875fe63a40)",
      "incident_id": 66,
      "date": "2017-08-02",
      "title": "Chinese Chatbots Question Communist Party",
      "description": "Chatbots on Chinese messaging service expressed anti-China sentiments, causing the messaging service to remove and reprogram the chatbots.",
      "deployers": [
        "tencent-holdings"
      ],
      "developers": [
        "microsoft",
        "turing-robot"
      ],
      "harmedParties": [
        "chinese-communist-party",
        "tencent-holdings",
        "microsoft",
        "turing-robot"
      ],
      "reports": [
        1159,
        1161,
        1162,
        1163,
        1165,
        1166,
        1169,
        1170,
        1172,
        1173,
        1174,
        1175,
        1176,
        1178,
        1179,
        1180
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "information and communication",
      "region": "Asia"
    },
    {
      "id": "ObjectId(625763e1343edc875fe63a2f)",
      "incident_id": 49,
      "date": "2016-09-05",
      "title": "AI Beauty Judge Did Not Like Dark Skin",
      "description": "In 2016, after artificial inntelligence software Beauty.AI judged an international beauty contest and declared a majority of winners to be white, researchers found that Beauty.AI was racially biased in determining beauty.",
      "deployers": [
        "youth-laboratories"
      ],
      "developers": [
        "youth-laboratories"
      ],
      "harmedParties": [
        "people-with-dark-skin"
      ],
      "reports": [
        864,
        865,
        866,
        867,
        868,
        870,
        872,
        873,
        874,
        875
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "Arts, entertainment and recreation",
      "region": "Global"
    },
    {
      "id": "ObjectId(625763e4343edc875fe63a46)",
      "incident_id": 72,
      "date": "2017-10-17",
      "title": "Facebook translates 'good morning' into 'attack them', leading to arrest",
      "description": "Facebook's automatic language translation software incorrectly translated an Arabic post saying Good morning into Hebrew saying hurt them, leading to the arrest of a Palestinian man in Beitar Illit, Israel.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "unnamed-palestinian-facebook-user",
        "palestinian-facebook-users",
        "arabic-speaking-facebook-users",
        "facebook-users"
      ],
      "reports": [
        1291,
        1292,
        1293,
        1294,
        1295,
        1296,
        1297,
        1298,
        1299,
        1300,
        1301,
        1302,
        1304,
        1305,
        1306,
        1307,
        1309,
        1310,
        1311,
        1312,
        1313,
        1314,
        1315,
        1316,
        1318,
        1319
      ],
      "severity": "AI tangible harm event",
      "classification": "yes",
      "sector": "information and communication",
      "region": "Asia"
    },
    {
      "id": "ObjectId(625763e5343edc875fe63a50)",
      "incident_id": 82,
      "date": "2020-10-21",
      "title": "#LekkiMassacre: Why Facebook labelled content from October 20 incident ‘false’",
      "description": "Facebook incorrectly labels content relating to an incident between #EndSARS protestors and the Nigerian army as misinformation.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "facebook-users",
        "facebook-users-interested-in-the-lekki-massacre-incident"
      ],
      "reports": [
        1382
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "information and communication",
      "region": "Global"
    },
    {
      "id": "ObjectId(625763e6343edc875fe63a5a)",
      "incident_id": 93,
      "date": "2018-08-13",
      "title": "HUD charges Facebook with enabling housing discrimination",
      "description": "In March 2019 the U.S. Department of Housing and Urban Development charged Facebook with violating the Fair Housing Act by allowing real estate sellers to target advertisements in a discriminatory manner.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "facebook-users-of-minority-groups",
        "non-american-born-facebook-users",
        "non-christian-facebook-users",
        "facebook-users-interested-in-accessibility",
        "facebook-users-interested-in-hispanic-culture"
      ],
      "reports": [
        1394,
        1817,
        2107,
        2205
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "information and communication",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763e5343edc875fe63a53)",
      "incident_id": 85,
      "date": "2020-10-09",
      "title": "AI attempts to ease fear of robots, blurts out it can’t ‘avoid destroying humankind’",
      "description": "On September 8, 2020, the Guardian published an op-ed generated by OpenAI’s GPT-3 text generating AI that included threats to destroy humankind. This incident has been downgraded to an issue as it does not meet current ingestion criteria.",
      "deployers": [
        "openai"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "unknown"
      ],
      "reports": [
        2471
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(625763e5343edc875fe63a52)",
      "incident_id": 84,
      "date": "2020-10-09",
      "title": "Tiny Changes Let False Claims About COVID-19, Voting Evade Facebook Fact Checks",
      "description": "Avaaz, an international advocacy group, released a review of Facebook's misinformation identifying software showing that the labeling process failed to label 42% of false information posts, most surrounding COVID-19 and the 2020 USA Presidential Election.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "facebook-users",
        "facebook-users-interested-in-covid-information",
        "facebook-users-interested-in-the-us-presidential-election"
      ],
      "reports": [
        1384
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "information and communication",
      "region": "Global"
    },
    {
      "id": "ObjectId(625763e4343edc875fe63a4b)",
      "incident_id": 77,
      "date": "2019-10-04",
      "title": "Knightscope's Park Patrol Robot Ignored Bystander Pressing Emergency Button to Alert Police about Fight",
      "description": "A Knightscope K5 autonomous police robot patrolling Huntington Park, California failed to respond to an onlooker who attempted to activate its emergency alert button when a nearby fight broke out.",
      "deployers": [
        "knightscope"
      ],
      "developers": [
        "knightscope"
      ],
      "harmedParties": [
        "cogo-guebara",
        "unnamed-woman-injured-in-the-fight"
      ],
      "reports": [
        1340,
        1390,
        1878,
        2201,
        2202
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "law enforcement",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763e4343edc875fe63a4c)",
      "incident_id": 78,
      "date": "2020-07-06",
      "title": "Meet the Secret Algorithm That's Keeping Students Out of College",
      "description": "In response to the Covid-19 pandemic, the International Baccalaureate final exams were replaced by a calculated score, prompting complaints of unfairness from teachers and students.",
      "deployers": [
        "international-baccalaurette"
      ],
      "developers": [
        "international-baccalaurette"
      ],
      "harmedParties": [
        "international-baccalaureate-students"
      ],
      "reports": [
        1341
      ],
      "severity": "none",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763e6343edc875fe63a5d)",
      "incident_id": 96,
      "date": "2017-05-08",
      "title": "Houston Schools Must Face Teacher Evaluation Lawsuit",
      "description": "On May 4, 2017, a U.S. federal judge advanced teachers’ claims that the Houston Independent School District’s algorithmic teacher evaluations violated their due process rights to their jobs by not allowing them to review the grounds of their termination.",
      "deployers": [
        "houston-independent-school-district"
      ],
      "developers": [
        "sas-institute"
      ],
      "harmedParties": [
        "houston-independent-school-district-teachers"
      ],
      "reports": [
        1398
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "Education",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763e5343edc875fe63a56)",
      "incident_id": 88,
      "date": "2017-08-15",
      "title": "Jewish Baby Strollers Provided Anti-Semitic Google Images, Allegedly Resulting from Hate Speech Campaign",
      "description": "Google's Image search for Jewish baby strollers showed offensive, anti-Semitic results, allegedly a result of a coordinated hate-speech campaign involving malicious actors on 4chan.",
      "deployers": [
        "google"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "jewish-people",
        "google-images-users"
      ],
      "reports": [
        1388,
        2183
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "information and communication",
      "region": "Global"
    },
    {
      "id": "ObjectId(625763e4343edc875fe63a47)",
      "incident_id": 73,
      "date": "2016-03-01",
      "title": "Is Pokémon Go racist? How the app may be redlining communities of color",
      "description": "Through a crowdsourcing social media campaign in 2016, several journalists and researchers demonstrated that augmented reality locations in the popular smartphone game Pokemon Go were more likely to be in white neighborhoods.",
      "deployers": [
        "niantic-labs"
      ],
      "developers": [
        "niantic-labs"
      ],
      "harmedParties": [
        "non-white-neighborhoods",
        "communities-of-color"
      ],
      "reports": [
        1320,
        1321,
        1322,
        1323,
        1324,
        1325,
        1327,
        1343
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "information and communication, Arts, entertainment and recreation",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763e4343edc875fe63a49)",
      "incident_id": 75,
      "date": "2012-01-05",
      "title": "Google Instant's Allegedly 'Anti-Semitic' Results Lead To Lawsuit In France",
      "description": "The organizations SOS Racisme, Union of Jewish Students of France, Movement Against Racism and for Friendship Among Peoples are suing Google due to its autocomplete software suggesting jewish when the names of certain public figures were searched on the platform.",
      "deployers": [
        "google"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "jewish-people",
        "jewish-public-figures"
      ],
      "reports": [
        1337
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "information and communication",
      "region": "Europe"
    },
    {
      "id": "ObjectId(625763e4343edc875fe63a4f)",
      "incident_id": 81,
      "date": "2020-10-21",
      "title": "Researchers find evidence of racial, gender, and socioeconomic bias in chest X-ray classifiers",
      "description": "A study by the University of Toronto, the Vector Institute, and MIT showed the input databases that trained AI systems used to classify chest X-rays led the systems to show gender, socioeconomic, and racial biases.",
      "deployers": [
        "mount-sinai-hospitals"
      ],
      "developers": [
        "google",
        "qure.ai",
        "aidoc",
        "darwinai"
      ],
      "harmedParties": [
        "patients-of-minority-groups",
        "low-income-patients",
        "female-patients",
        "hispanic-patients",
        "patients-with-medicaid-insurance"
      ],
      "reports": [
        1381
      ],
      "severity": "none",
      "classification": "no",
      "sector": "human health and social work activities",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763e5343edc875fe63a54)",
      "incident_id": 86,
      "date": "2020-10-08",
      "title": "Coding Errors in Leaving Certificate Grading Algorithm Caused Inaccurate Scores in Ireland",
      "description": "Errors in Irish Department of Education's algorithm to calculate students’ Leaving Certificate exam grades resulted in thousands of inaccurate scores.",
      "deployers": [
        "irish-department-of-education-and-skills"
      ],
      "developers": [
        "irish-department-of-education-and-skills"
      ],
      "harmedParties": [
        "leaving-certificate-exam-takers",
        "irish-department-of-education-and-skills"
      ],
      "reports": [
        1386,
        2038
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "Education",
      "region": "Europe"
    },
    {
      "id": "ObjectId(625763e4343edc875fe63a48)",
      "incident_id": 74,
      "date": "2020-01-30",
      "title": "Detroit Police Wrongfully Arrested Black Man Due To Faulty FRT",
      "description": "A Black man was wrongfully detained by the Detroit Police Department as a result of a false facial recognition (FRT) result.",
      "deployers": [
        "detroit-police-department"
      ],
      "developers": [
        "dataworks-plus"
      ],
      "harmedParties": [
        "robert-julian-borchak-williams",
        "black-people-in-detroit"
      ],
      "reports": [
        1336,
        1400,
        1467,
        1484,
        1543,
        1837,
        2027,
        2028,
        2029,
        2734,
        3964
      ],
      "severity": "AI tangible harm event",
      "classification": "yes",
      "sector": "law enforcement",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763e6343edc875fe63a5c)",
      "incident_id": 95,
      "date": "2019-11-06",
      "title": "Job Screening Service Halts Facial Analysis of Applicants",
      "description": "In January 2021, HireVue removed the controversial AI expression tracking tool from its virtual job interview software.",
      "deployers": [
        "hirevue"
      ],
      "developers": [
        "hirevue"
      ],
      "harmedParties": [
        "job-applicants-using-hirevue",
        "hirevue-customers"
      ],
      "reports": [
        2133,
        2132,
        1397,
        2194
      ],
      "severity": "AI tangible harm issue",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763e4343edc875fe63a4e)",
      "incident_id": 80,
      "date": "2020-10-24",
      "title": "AI mistakes referee’s bald head for football — hilarity ensued",
      "description": "In a Scottish soccer match the AI-enabled ball-tracking camera used to livestream the game repeatedly tracked an official’s bald head as though it were the soccer ball.",
      "deployers": [
        "inverness-caledonian-thistle-football-club"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "livestream-viewers"
      ],
      "reports": [
        1380,
        1559
      ],
      "severity": "none",
      "classification": "no",
      "sector": "Arts, entertainment and recreation",
      "region": "Europe"
    },
    {
      "id": "ObjectId(625763e5343edc875fe63a51)",
      "incident_id": 83,
      "date": "2020-10-22",
      "title": "AI Spam Filters Allegedly Block Legitimate Emails Based on Biased Keyword Detection",
      "description": "AlgorithmWatch tested spam filtering algorithms across Gmail, Yahoo, Outlook, GMX, and LaPoste. Their findings reportedly showed that Microsoft Outlook’s spam filter flagged emails based on specific keywords that led to racial and content-based biases blocking legitimate communications. Emails mentioning Nigeria or containing certain financial and sexual health terms were found to be disproportionately marked as spam.",
      "deployers": [
        "yahoo",
        "outlook",
        "laposte",
        "gmx",
        "gmail"
      ],
      "developers": [
        "yahoo",
        "microsoft",
        "laposte",
        "google",
        "gmx"
      ],
      "harmedParties": [
        "yahoo!-mail-users",
        "microsoft-outlook-users",
        "laposte-users",
        "gmx-users",
        "gmail-users"
      ],
      "reports": [
        1383
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "information and communication",
      "region": "Global"
    },
    {
      "id": "ObjectId(625763e6343edc875fe63a5e)",
      "incident_id": 97,
      "date": "2020-10-22",
      "title": "Tesla Autopilot Mistakes Red Letters on Flag for Red Traffic Lights",
      "description": "A Tesla Model 3 misidentified flags with COOP written vertically on them as traffic lights.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "tesla-drivers"
      ],
      "reports": [
        1399
      ],
      "severity": "AI tangible harm issue",
      "classification": "yes",
      "sector": "transportation and storage",
      "region": "Europe"
    },
    {
      "id": "ObjectId(625763e6343edc875fe63a5f)",
      "incident_id": 98,
      "date": "2021-04-28",
      "title": "N.Y.P.D. Robot Dog’s Run Is Cut Short After Fierce Backlash",
      "description": "The New York Police Department canceled a contract to use Boston Dynamics' robotic dog Spot following public backlash. ",
      "deployers": [
        "new-york-city-police-department"
      ],
      "developers": [
        "boston-dynamics"
      ],
      "harmedParties": [
        "new-york-city-low-income-communities"
      ],
      "reports": [
        1401
      ],
      "severity": "unclear",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763e4343edc875fe63a4d)",
      "incident_id": 79,
      "date": "1999-03-16",
      "title": "Kidney Testing Method Allegedly Underestimated Risk of Black Patients",
      "description": "Decades-long use of the estimated glomerular filtration rate (eGFR) method to test kidney function which considers race has been criticized by physicians and medical students for its racist history and inaccuracy against Black patients.",
      "deployers": [
        "chronic-kidney-disease-epidemiology-collaboration"
      ],
      "developers": [
        "chronic-kidney-disease-epidemiology-collaboration"
      ],
      "harmedParties": [
        "black-patients",
        "african-american-patients"
      ],
      "reports": [
        1379,
        1736,
        2039
      ],
      "severity": "none",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763e5343edc875fe63a55)",
      "incident_id": 87,
      "date": "2020-10-07",
      "title": "UK passport photo checker shows bias against dark-skinned women",
      "description": "UK passport photo checker shows bias against dark-skinned women.",
      "deployers": [
        "uk-home-office"
      ],
      "developers": [
        "uk-home-office"
      ],
      "harmedParties": [
        "dark-skinned-people",
        "dark-skinned-women"
      ],
      "reports": [
        1387
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "public administration",
      "region": "Europe"
    },
    {
      "id": "ObjectId(625763e5343edc875fe63a58)",
      "incident_id": 91,
      "date": "2020-12-18",
      "title": "Frontline workers protest at Stanford after hospital distributed vaccine to administrators",
      "description": "In 2020, Stanford Medical Center's distribution algorithm only designated 7 of 5,000 vaccines to Medical Residents, who are frontline workers regularly exposed to COVID-19.",
      "deployers": [
        "stanford-medical-center"
      ],
      "developers": [
        "stanford-medical-center"
      ],
      "harmedParties": [
        "stanford-medical-frontline-workers",
        "stanford-medical-residents"
      ],
      "reports": [
        1391,
        1392,
        1463,
        1720,
        1779
      ],
      "severity": "none",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763e4343edc875fe63a4a)",
      "incident_id": 76,
      "date": "2020-10-09",
      "title": "Live facial recognition is tracking kids suspected of being criminals",
      "description": "Buenos Aires city government uses a facial recognition system that has led to numerous false arrests.",
      "deployers": [
        "buenos-aires-city-government"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "buenos-aires-children"
      ],
      "reports": [
        1339
      ],
      "severity": "AI tangible harm event",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763e5343edc875fe63a59)",
      "incident_id": 92,
      "date": "2019-11-11",
      "title": "Apple Card's Credit Assessment Algorithm Allegedly Discriminated against Women",
      "description": "Apple Card's credit assessment algorithm was reported by Goldman-Sachs customers to have shown gender bias, in which men received significantly higher credit limits than women with equal credit qualifications.",
      "deployers": [
        "goldman-sachs"
      ],
      "developers": [
        "apple"
      ],
      "harmedParties": [
        "apple-card-female-users",
        "apple-card-female-credit-applicants"
      ],
      "reports": [
        1393,
        1396,
        2035,
        2036,
        2037,
        2274
      ],
      "severity": "AI tangible harm event",
      "classification": "yes",
      "sector": "financial and insurance activities",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763e5343edc875fe63a57)",
      "incident_id": 89,
      "date": "2019-03-15",
      "title": "The Christchurch shooter and YouTube’s radicalization trap",
      "description": "A New Zealand government report released following a right-wing terrorist killing 51 worshippers at two New Sealand mosques which indicated that Youtube's recommendation algorithm played an important role in the terrorist's radicalization.",
      "deployers": [
        "youtube"
      ],
      "developers": [
        "youtube"
      ],
      "harmedParties": [
        "youtube-users"
      ],
      "reports": [
        1389
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "information and communication, Arts, entertainment and recreation",
      "region": "Oceania"
    },
    {
      "id": "ObjectId(625763e6343edc875fe63a5b)",
      "incident_id": 94,
      "date": "2020-11-27",
      "title": "Court Rules Deliveroo Used 'Discriminatory' Algorithm",
      "description": "In December 2020, an Italian court ruled that Deliveroo’s employee ‘reliability’ algorithm illegally discriminated against workers with legitimate reasons for cancelling shifts.",
      "deployers": [
        "deliveroo"
      ],
      "developers": [
        "deliveroo"
      ],
      "harmedParties": [
        "deliveroo-workers-with-legitimate-reasons-for-cancelling-shifts",
        "deliveroo-workers"
      ],
      "reports": [
        1395,
        1473
      ],
      "severity": "AI tangible harm event",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763e7343edc875fe63a6b)",
      "incident_id": 110,
      "date": "2016-01-01",
      "title": "Arkansas's Opaque Algorithm to Allocate Health Care Excessively Cut Down Hours for Beneficiaries",
      "description": "Beneficiaries of the Arkansas Department of Human Services (DHS)'s Medicaid waiver program were allocated excessively fewer hours of caretaker visit via an algorithm deployed to boost efficiency, which reportedly contained errors and whose outputs varied wildly despite small input changes.",
      "deployers": [
        "arkansas-department-of-human-services"
      ],
      "developers": [
        "interrai"
      ],
      "harmedParties": [
        "arkansas-medicaid-waiver-program-beneficiaries",
        "arkansas-healthcare-workers"
      ],
      "reports": [
        1413,
        2651
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "human health and social work activities",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763e7343edc875fe63a6c)",
      "incident_id": 111,
      "date": "2015-09-25",
      "title": "Amazon Flex Drivers Allegedly Fired via Automated Employee Evaluations",
      "description": "Amazon Flex's contract delivery drivers were dismissed using a minimally human-interfered automated employee performance evaluation based on indicators impacted by out-of-driver's-control factors and without having a chance to defend against or appeal the decision.",
      "deployers": [
        "amazon-flex"
      ],
      "developers": [
        "amazon"
      ],
      "harmedParties": [
        "amazon-flex-employees",
        "amazon-flex-drivers"
      ],
      "reports": [
        1426,
        1427,
        1428,
        1429,
        1430
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(625763e7343edc875fe63a65)",
      "incident_id": 104,
      "date": "2021-02-12",
      "title": "California's Algorithm Considered ZIP Codes in Vaccine Distribution, Allegedly Excluding Low-Income Neighborhoods and Communities of Color",
      "description": "California's vaccine-distribution algorithm used ZIP codes as opposed to census tracts in its decision-making, which critics said undermined equity and access for vulnerable communities who are largely low-income, underserved neighborhoods with low Healthy Places Index scores.",
      "deployers": [
        "california-department-of-public-health"
      ],
      "developers": [
        "blue-shield-of-california"
      ],
      "harmedParties": [
        "california-low-income-neighborhoods",
        "california-communities-of-color"
      ],
      "reports": [
        1407
      ],
      "severity": "none",
      "classification": "maybe",
      "sector": "public administration, human health and social work activities",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763e7343edc875fe63a67)",
      "incident_id": 106,
      "date": "2020-12-23",
      "title": "Korean Chatbot Luda Made Offensive Remarks towards Minority Groups",
      "description": "A Korean interactive chatbot was shown in screenshots to have used derogatory and bigoted language when asked about lesbians, Black people, and people with disabilities.",
      "deployers": [
        "facebook-messenger"
      ],
      "developers": [
        "scatter-lab"
      ],
      "harmedParties": [
        "korean-facebook-messenger-users",
        "korean-people-of-gender-minorities",
        "korean-people-with-disabilities"
      ],
      "reports": [
        1409,
        1416,
        1417,
        1418,
        1419,
        1420,
        1421,
        1422,
        1423,
        1424,
        1425,
        2034,
        2356
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "information and communication, Arts, entertainment and recreation",
      "region": "Asia"
    },
    {
      "id": "ObjectId(625763e7343edc875fe63a69)",
      "incident_id": 108,
      "date": "2021-07-10",
      "title": "Skating Rink’s Facial Recognition Cameras Misidentified Black Teenager as Banned Troublemaker",
      "description": "A Black teenager living in Livonia, Michigan was incorrectly stopped from entering a roller skating rink after its facial-recognition cameras misidentified her as another person who had been previously banned for starting a skirmish with other skaters.",
      "deployers": [
        "riverside-arena-skating-rink"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "lamya-robinson",
        "black-livonia-residents"
      ],
      "reports": [
        1411,
        1503,
        1537
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "Arts, entertainment and recreation",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763e8343edc875fe63a70)",
      "incident_id": 115,
      "date": "2020-07-28",
      "title": "Genderify’s AI to Predict a Person’s Gender Revealed by Free API Users to Exhibit Bias",
      "description": "A company's AI predicting a person's gender based on their name, email address, or username was reported by its users to show biased and inaccurate results.",
      "deployers": [
        "genderify"
      ],
      "developers": [
        "genderify"
      ],
      "harmedParties": [
        "genderify-customers",
        "gender-minority-groups"
      ],
      "reports": [
        1440,
        1472,
        2204
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "information and communication",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763e8343edc875fe63a6f)",
      "incident_id": 114,
      "date": "2018-07-26",
      "title": "Amazon's Rekognition Falsely Matched Members of Congress to Mugshots",
      "description": "Rekognition's face comparison feature was shown by the ACLU to have misidentified members of congress, and particularly members of colors, as other people who have been arrested using a mugshot database built on publicly available arrest photos.",
      "deployers": [
        "amazon"
      ],
      "developers": [
        "amazon"
      ],
      "harmedParties": [
        "rekognition-users",
        "arrested-people"
      ],
      "reports": [
        1439
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "information and communication, law enforcement",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763e7343edc875fe63a68)",
      "incident_id": 107,
      "date": "2018-07-20",
      "title": "Chinese Tech Firms Allegedly Developed Facial Recognition to Identify People by Race, Targeting Uyghur Muslims",
      "description": "Various Chinese firms were revealed by patent applications to have developed facial recognition capable of detecting people by race, which critics feared would enable persecution and discrimination of Uyghur Muslims.",
      "deployers": [
        "none"
      ],
      "developers": [
        "huawei",
        "megvii",
        "sensetime",
        "alibaba",
        "baibu"
      ],
      "harmedParties": [
        "uyghur-people"
      ],
      "reports": [
        1410,
        1928
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(625763e8343edc875fe63a74)",
      "incident_id": 119,
      "date": "2021-08-03",
      "title": "Xsolla Employees Fired by CEO Allegedly via Big Data Analytics of Work Activities",
      "description": "Xsolla CEO fired more than a hundred employees from his company in Perm, Russia, based on big data analysis of their remote digitized-work activity, which critics said was violating employee's privacy, outdated, and extremely ineffective.",
      "deployers": [
        "xsolla"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "xsolla-employees"
      ],
      "reports": [
        1444,
        1800,
        1801,
        1802
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "administrative and support service activities",
      "region": "Europe"
    },
    {
      "id": "ObjectId(625763e7343edc875fe63a66)",
      "incident_id": 105,
      "date": "2019-08-24",
      "title": "Tesla Model 3 on Autopilot Crashed into a Ford Explorer Pickup, Killing a Fifteen-Year-Old in California",
      "description": "A Tesla Model 3 on Autopilot mode crashed into a pickup on a California freeway, where data and video from the company showed neither Autopilot nor the driver slowing the vehicle until seconds before the crash.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "jovani-maldonado",
        "benjamin-maldonado",
        "california-public"
      ],
      "reports": [
        1408
      ],
      "severity": "AI tangible harm event",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763e6343edc875fe63a60)",
      "incident_id": 99,
      "date": "2012-01-01",
      "title": "Major Universities Are Using Race as a “High Impact Predictor” of Student Success",
      "description": "Several major universities are using a tool that uses race as one factor to predict student success.",
      "deployers": [
        "university-of-massachusetts-amherst",
        "university-of-wisconsin-milwaukee",
        "university-of-houston",
        "texas-aandm-university",
        "georgia-state-university",
        "more-than-500-colleges"
      ],
      "developers": [
        "eab"
      ],
      "harmedParties": [
        "black-college-students",
        "latinx-college-students",
        "indigenous-students"
      ],
      "reports": [
        1402
      ],
      "severity": "none",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763e8343edc875fe63a76)",
      "incident_id": 121,
      "date": "2020-03-27",
      "title": "Autonomous Kargu-2 Drone Allegedly Remotely Used to Hunt down Libyan Soldiers",
      "description": "In Libya, a Turkish-made Kargu-2 aerial drone powered by a computer vision model was allegedly used remotely by forces backed by the Tripoli-based government to track down and attack enemies as they were running from rocket attacks.",
      "deployers": [
        "tripoli-based-government"
      ],
      "developers": [
        "stm"
      ],
      "harmedParties": [
        "libyan-soldiers"
      ],
      "reports": [
        2106,
        2105,
        2104,
        1447
      ],
      "severity": "AI tangible harm near-miss",
      "classification": "yes",
      "sector": "defense",
      "region": "Africa"
    },
    {
      "id": "ObjectId(625763e7343edc875fe63a6a)",
      "incident_id": 109,
      "date": "2017-01-01",
      "title": "PimEyes's Facial Recognition AI Allegedly Lacked Safeguards to Prevent Itself from Being Abused",
      "description": "PimEyes offered its subscription-based AI service to anyone in the public to search for matching facial images across the internet, which critics said lacked public oversight and government rules to prevent itself from misuse such as stalking women.",
      "deployers": [
        "pimeyes"
      ],
      "developers": [
        "pimeyes"
      ],
      "harmedParties": [
        "internet-users"
      ],
      "reports": [
        1412
      ],
      "severity": "unclear",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763e6343edc875fe63a62)",
      "incident_id": 101,
      "date": "2018-09-01",
      "title": "Dutch Families Wrongfully Accused of Tax Fraud Due to Discriminatory Algorithm",
      "description": "A childcare benefits system in the Netherlands falsely accused thousands of families of fraud, in part due to an algorithm that treated having a second nationality as a risk factor.",
      "deployers": [
        "dutch-tax-authority"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "dutch-tax-authority",
        "dutch-families"
      ],
      "reports": [
        1404,
        1575,
        1863,
        2570,
        2805,
        2845
      ],
      "severity": "AI tangible harm event",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763e7343edc875fe63a64)",
      "incident_id": 103,
      "date": "2020-09-18",
      "title": "Twitter’s Image Cropping Tool Allegedly Showed Gender and Racial Bias",
      "description": "Twitter's photo cropping algorithm was revealed by researchers to favor white and women faces in photos containing multiple faces, prompting the company to stop its use on mobile platform.",
      "deployers": [
        "twitter"
      ],
      "developers": [
        "twitter"
      ],
      "harmedParties": [
        "twitter-users",
        "twitter-non-white-users",
        "twitter-non-male-users"
      ],
      "reports": [
        1406,
        1527,
        1528,
        2145,
        2241
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "information and communication",
      "region": "Global"
    },
    {
      "id": "ObjectId(625763e8343edc875fe63a6e)",
      "incident_id": 113,
      "date": "2020-06-27",
      "title": "Facebook's AI Put Primates Label on Video Featuring Black Men",
      "description": "Facebook's AI mislabeled video featuring Black men as a video about primates, resulting in an offensive prompt message for users who watched the video.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "black-people",
        "facebook-users"
      ],
      "reports": [
        1438
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "information and communication",
      "region": "Global"
    },
    {
      "id": "ObjectId(625763e9343edc875fe63a77)",
      "incident_id": 122,
      "date": "2015-06-14",
      "title": "Facebook’s Tag Suggestions Allegedly Stored Biometric Data without User Consent",
      "description": "Facebook’s initial version of the its Tag Suggestions feature where users were offered suggestions about the identity of people's faces in photos allegedly stored biometric data without consent, violating the Illinois Biometric Information Privacy Act.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "facebook-users"
      ],
      "reports": [
        1448
      ],
      "severity": "AI tangible harm event",
      "classification": "maybe"
    },
    {
      "id": "ObjectId(625763e7343edc875fe63a63)",
      "incident_id": 102,
      "date": "2020-03-23",
      "title": "Personal voice assistants struggle with black voices, new study shows",
      "description": "A study found that voice recognition tools from Apple, Amazon, Google, IBM, and Microsoft disproportionately made errors when transcribing black speakers.",
      "deployers": [
        "microsoft",
        "ibm",
        "google",
        "apple",
        "amazon"
      ],
      "developers": [
        "microsoft",
        "ibm",
        "google",
        "apple",
        "amazon"
      ],
      "harmedParties": [
        "black-people"
      ],
      "reports": [
        1405,
        1523
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "administrative and support service activities, information and communication",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763e8343edc875fe63a6d)",
      "incident_id": 112,
      "date": "2012-10-09",
      "title": "Police Departments Reported ShotSpotter as Unreliable and Wasteful",
      "description": "ShotSpotter algorithmic systems locating gunshots were reported by police departments for containing high false positive rates and wasting police resources, prompting discontinuation.",
      "deployers": [
        "troy-police-department",
        "syracuse-police-department",
        "san-francisco-police-department",
        "san-antonio-police-department",
        "new-york-city-police-department",
        "fall-river-police-department",
        "chicago-police-department"
      ],
      "developers": [
        "shotspotter"
      ],
      "harmedParties": [
        "troy-residents",
        "troy-police-department",
        "syracuse-residents",
        "syracuse-police-department",
        "san-francisco-residents",
        "san-francisco-police-department",
        "san-antonio-residents",
        "san-antonio-police-department",
        "new-york-city-residents",
        "new-york-city-police-department",
        "fall-river-residents",
        "fall-river-police-department",
        "chicago-residents",
        "chicago-police-department"
      ],
      "reports": [
        2831,
        2623,
        2496,
        2495,
        2250,
        1821,
        1810,
        1436,
        1435,
        1434,
        1433,
        1432,
        3654,
        4057,
        4058
      ],
      "severity": "AI tangible harm event",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763e6343edc875fe63a61)",
      "incident_id": 100,
      "date": "2021-03-17",
      "title": "How French welfare services are creating ‘robo-debt’",
      "description": "A French welfare office using software to automatically evaluate cases incorrectly notified a woman receiving benefits that she owed €542.",
      "deployers": [
        "french-welfare-offices"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "lucie-inland"
      ],
      "reports": [
        1403
      ],
      "severity": "none",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763e8343edc875fe63a71)",
      "incident_id": 116,
      "date": "2021-09-20",
      "title": "Amazon's AI Cameras Incorrectly Penalized Delivery Drivers for Mistakes They Did Not Make",
      "description": "Amazon's automated performance evaluation system involving AI-powered cameras incorrectly punished delivery drivers for non-existent mistakes, impacting their chances for bonuses and rewards.",
      "deployers": [
        "amazon"
      ],
      "developers": [
        "netradyne"
      ],
      "harmedParties": [
        "amazon-delivery-drivers",
        "amazon-workers"
      ],
      "reports": [
        1441,
        1803
      ],
      "severity": "AI tangible harm event",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763e8343edc875fe63a73)",
      "incident_id": 118,
      "date": "2020-08-06",
      "title": "OpenAI's GPT-3 Associated Muslims with Violence",
      "description": "Users and researchers revealed generative AI GPT-3 associating Muslims to violence in prompts, resulting in disturbingly racist and explicit outputs such as casting Muslim actor as a terrorist.",
      "deployers": [
        "openai"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "muslims"
      ],
      "reports": [
        1443,
        2009,
        2010
      ],
      "severity": "none",
      "classification": "no",
      "sector": "information and communication, professional, scientific and technical activities",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763e8343edc875fe63a75)",
      "incident_id": 120,
      "date": "2020-09-01",
      "title": "Philosophy AI Allegedly Used To Generate Mixture of Innocent and Harmful Reddit Posts",
      "description": "Philosopher AI, a GPT-3-powered controversial text generator, was allegedly used by an anonymous actor on AskReddit subreddit, whose posts featured a mixture of harmless stories, conspiracy theories, and sensitive topic discussions.",
      "deployers": [
        "unknown"
      ],
      "developers": [
        "murat-ayfer",
        "openai"
      ],
      "harmedParties": [
        "reddit-users"
      ],
      "reports": [
        1445
      ],
      "severity": "none",
      "classification": "no",
      "sector": "Arts, entertainment and recreation, information and communication",
      "region": "Global"
    },
    {
      "id": "ObjectId(625763e8343edc875fe63a72)",
      "incident_id": 117,
      "date": "2020-02-24",
      "title": "TikTok's Suggested Accounts Algorithm Allegedly Reinforced Racial Bias through Feedback Loops",
      "description": "TikTok's Suggested Accounts recommendations allegedly reinforced racial bias despite not basing recommendations on race or creators' profile photo.",
      "deployers": [
        "tiktok"
      ],
      "developers": [
        "tiktok"
      ],
      "harmedParties": [
        "tiktok-users",
        "tiktok-content-creators"
      ],
      "reports": [
        1442,
        2019,
        2020,
        2021
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(625763e9343edc875fe63a7e)",
      "incident_id": 129,
      "date": "2021-03-01",
      "title": "Facebook's Automated Tools Failed to Adequately Remove Hate Speech, Violence, and Incitement",
      "description": "Facebook's automated moderation tools were shown by internal documents performing incomparably to human moderators, and accounting for only a small fraction of hate speech, violence, and incitement content removal.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "facebook-users"
      ],
      "reports": [
        1462
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "information and communication",
      "region": "Global"
    },
    {
      "id": "ObjectId(625763ea343edc875fe63a89)",
      "incident_id": 140,
      "date": "2020-06-01",
      "title": "ProctorU’s Identity Verification and Exam Monitoring Systems Provided Allegedly Discriminatory Experiences for BIPOC Students",
      "description": "An exam monitoring service used by the University of Toronto was alleged by its students to have provided discriminatory check-in experiences via its facial recognition's failure to verify passport photo, disproportionately enhancing disadvantaging stress level for BIPOC students.",
      "deployers": [
        "university-of-toronto"
      ],
      "developers": [
        "proctoru"
      ],
      "harmedParties": [
        "university-of-toronto-bipoc-students"
      ],
      "reports": [
        1478
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "Education",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763eb343edc875fe63a8f)",
      "incident_id": 146,
      "date": "2021-10-22",
      "title": "Research Prototype AI, Delphi, Reportedly Gave Racially Biased Answers on Ethics",
      "description": "A publicly accessible research model that was trained via Reddit threads showed racially biased advice on moral dilemmas, allegedly demonstrating limitations of language-based models trained on moral judgments.",
      "deployers": [
        "allen-institute-for-ai"
      ],
      "developers": [
        "allen-institute-for-ai"
      ],
      "harmedParties": [
        "minority-groups"
      ],
      "reports": [
        1494,
        1495,
        1502
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "information and communication",
      "region": "Global"
    },
    {
      "id": "ObjectId(625763ea343edc875fe63a86)",
      "incident_id": 137,
      "date": "2021-01-11",
      "title": "Israeli Tax Authority Employed Opaque Algorithm to Impose Fines, Reportedly Refusing to Provide an Explanation for Amount Calculation to a Farmer",
      "description": "An Israeli farmer was imposed a computer generated fine by the tax authority, who allegedly were not able to explain its calculation, and refused to disclose the program and its source code.",
      "deployers": [
        "israeli-tax-authority"
      ],
      "developers": [
        "israeli-tax-authority"
      ],
      "harmedParties": [
        "moshe-har-shemesh",
        "israeli-people-having-tax-fines"
      ],
      "reports": [
        1474
      ],
      "severity": "unclear",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763eb343edc875fe63a8d)",
      "incident_id": 144,
      "date": "2020-06-28",
      "title": "YouTube's AI Mistakenly Banned Chess Channel over Chess Language Misinterpretation",
      "description": "YouTube's AI-powered hate speech detection system falsely flagged chess content and banned chess creators allegedly due to its misinterpretation of strategy language such as black, white, and attack as harmful and dangerous.",
      "deployers": [
        "youtube"
      ],
      "developers": [
        "youtube"
      ],
      "harmedParties": [
        "antonio-radic",
        "youtube-chess-content-creators",
        "youtube-users"
      ],
      "reports": [
        1483,
        1979,
        1980,
        2042,
        2043,
        2134
      ],
      "severity": "unclear",
      "classification": "yes",
      "sector": "Arts, entertainment and recreation, information and communication",
      "region": "Global"
    },
    {
      "id": "ObjectId(625763eb343edc875fe63a91)",
      "incident_id": 148,
      "date": "2021-11-21",
      "title": "Web Accessibility Vendors Allegedly Falsely Claimed to Provide Compliance Using AI",
      "description": "AI-powered web accessibility vendors allegedly overstated to customers about their products' utility for people with disabilities, falsely claiming to deliver automated compliance solutions.",
      "deployers": [
        "accessibe",
        "accessus.ai",
        "allyable",
        "userway",
        "maxaccess.io"
      ],
      "developers": [
        "accessibe",
        "accessus.ai",
        "allyable",
        "userway",
        "maxaccess.io"
      ],
      "harmedParties": [
        "internet-users-with-disabilities",
        "web-accessibility-vendors'-customers"
      ],
      "reports": [
        1499
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "information and communication",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763ec343edc875fe63a9d)",
      "incident_id": 160,
      "date": "2021-12-26",
      "title": "Alexa Recommended Dangerous TikTok Challenge to Ten-Year-Old Girl",
      "description": "Amazon’s voice assistant Alexa suggested “the penny challenge,” which involves dangerously touching a coin to the prongs of a half-exposed plug, when a ten-year-old girl asked for a challenge to do.",
      "deployers": [
        "amazon"
      ],
      "developers": [
        "amazon"
      ],
      "harmedParties": [
        "kristin-livdahl's-daughter",
        "amazon-echo-customers",
        "children-using-alexa"
      ],
      "reports": [
        1520,
        1521,
        2381
      ],
      "severity": "AI tangible harm issue",
      "classification": "yes",
      "sector": "information and communication",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763ec343edc875fe63a95)",
      "incident_id": 152,
      "date": "2021-07-13",
      "title": "SoftBank's Humanoid Robot, Pepper, Reportedly Frequently Made Errors, Prompting Dismissal",
      "description": "SoftBank's robot allegedly kept making mechanical errors, taking unplanned breaks, failing to recognize previously-met people, and breaking down during practice runs.",
      "deployers": [
        "softbank"
      ],
      "developers": [
        "aldebaran",
        "softbank-robotics"
      ],
      "harmedParties": [
        "softbank"
      ],
      "reports": [
        1509,
        1510
      ],
      "severity": "AI tangible harm event",
      "classification": "yes",
      "sector": "administrative and support service activities, other service activities, financial and insurance activities, Arts, entertainment and recreation, human health and social work activities",
      "region": "Asia"
    },
    {
      "id": "ObjectId(625763ed343edc875fe63a9e)",
      "incident_id": 161,
      "date": "2019-04-03",
      "title": "Facebook's Ad Delivery Reportedly Excluded Audience along Racial and Gender Lines",
      "description": "Facebook's housing and employment ad delivery process allegedly resulted in skews in exposure for some users along demographic lines such as gender and racial identity.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "female-facebook-users",
        "black-facebook-users",
        "male-facebook-users"
      ],
      "reports": [
        1530,
        2138,
        2139
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(625763ed343edc875fe63aa1)",
      "incident_id": 164,
      "date": "2018-10-01",
      "title": "Facebook News Feed Allegedly Boosted Misinformation and Violating Content Following Use of MSI Metric",
      "description": "After the “News Feed” algorithm had been overhauled to boost engagement between friends and family in early 2018, its heavy weighting of re-shared content was alleged found by company researchers to have pushed content creators to reorient their posts towards outrage and sensationalism, causing a proliferation of misinformation, toxicity, and violent content.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "facebook-users",
        "facebook-content-creators"
      ],
      "reports": [
        1534
      ],
      "severity": "AI tangible harm event",
      "classification": "yes",
      "sector": "information and communication",
      "region": "Global"
    },
    {
      "id": "ObjectId(625763ed343edc875fe63aa5)",
      "incident_id": 168,
      "date": "2022-03-01",
      "title": "Collaborative Filtering Prone to Popularity Bias, Resulting in Overrepresentation of Popular Items in the Recommendation Outputs",
      "description": "Collaborative filtering prone to popularity bias, resulting in overrepresentation of popular items in the recommendation outputs.",
      "deployers": [
        "facebook",
        "linkedin",
        "youtube",
        "twitter",
        "netflix"
      ],
      "developers": [
        "facebook",
        "linkedin",
        "youtube",
        "twitter",
        "netflix"
      ],
      "harmedParties": [
        "facebook-users",
        "linkedin-users",
        "youtube-users",
        "twitter-users",
        "netflix-users"
      ],
      "reports": [
        1540,
        1541
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(625763ea343edc875fe63a82)",
      "incident_id": 133,
      "date": "2020-12-15",
      "title": "Online Trolls Allegedly Abused TikTok’s Automated Content Reporting System to Discriminate against Marginalized Creators",
      "description": "TikTok's automated content reporting system was allegedly abused by online trolls to intentionally misreport content created by users of marginalized groups.",
      "deployers": [
        "tiktok"
      ],
      "developers": [
        "tiktok"
      ],
      "harmedParties": [
        "tiktok-content-creators-of-marginalized-groups"
      ],
      "reports": [
        1468
      ],
      "severity": "none",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763e9343edc875fe63a80)",
      "incident_id": 131,
      "date": "2020-12-04",
      "title": "Proctoring Algorithm in Online California Bar Exam Flagged an Unusually High Number of Alleged Cheaters",
      "description": "The proctoring algorithm used in a California bar exam cited a third of thousands of applicants as cheaters, resulting in allegations where exam takers were instructed to prove otherwise without seeing their incriminating video evidence.",
      "deployers": [
        "california-bar's-committee-of-bar-examiners"
      ],
      "developers": [
        "examsoft"
      ],
      "harmedParties": [
        "california-bar-exam-takers",
        "flagged-california-bar-exam-takers"
      ],
      "reports": [
        1465,
        1771
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "Education, professional, scientific and technical activities",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763ec343edc875fe63a96)",
      "incident_id": 153,
      "date": "2019-12-29",
      "title": "Tesla Driver on Autopilot Ran a Red Light, Crashing into a Car and Killing Two People in Los Angeles",
      "description": "In 2019, a Tesla Model S driver on Autopilot mode reportedly went through a red light and crashed into a Honda Civic, killing two people in Gardena, Los Angeles.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "gilberto-alcazar-lopez",
        "maria-guadalupe-nieves-lopez"
      ],
      "reports": [
        1511,
        1729,
        1763,
        2514
      ],
      "severity": "AI tangible harm event",
      "classification": "yes",
      "sector": "transportation and storage",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763eb343edc875fe63a8e)",
      "incident_id": 145,
      "date": "2021-07-23",
      "title": "Tesla's Autopilot Misidentified the Moon as Yellow Stop Light",
      "description": "Tesla's Autopilot was shown on video by its owner mistaking the moon for a yellow stop light, allegedly causing the vehicle to keep slowing down.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "tesla-drivers"
      ],
      "reports": [
        1485,
        1504,
        1529
      ],
      "severity": "AI tangible harm issue",
      "classification": "yes",
      "sector": "transportation and storage",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763ea343edc875fe63a8a)",
      "incident_id": 141,
      "date": "2021-02-05",
      "title": "California Police Turned on Music to Allegedly Trigger Instagram’s DCMA to Avoid Being Live-Streamed",
      "description": "A police officer in Beverly Hills played copyrighted music on his phone when realizing that his interactions were being recorded on a livestream, allegedly hoping the Instagram's automated copyright detection system to end or mute the stream.",
      "deployers": [
        "instagram"
      ],
      "developers": [
        "instagram"
      ],
      "harmedParties": [
        "sennett-devermont",
        "beverly-hills-citizens"
      ],
      "reports": [
        1479,
        1480
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(625763ea343edc875fe63a83)",
      "incident_id": 134,
      "date": "2020-12-25",
      "title": "Robot in Chinese Shopping Mall Fell off the Escalator, Knocking down Passengers",
      "description": "A shopping guide robot deployed by the Fuzhou Zhongfang Marlboro Mall was shown on video allegedly walking to the escalator by itself, falling down, and knocking over passengers, which prompted its suspension.",
      "deployers": [
        "fuzhou-zhongfang-marlboro-mall"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "fuzhou-zhongfang-marlboro-mall-goers"
      ],
      "reports": [
        1469,
        1951
      ],
      "severity": "unclear",
      "classification": "yes",
      "sector": "wholesale and retail trade",
      "region": "Asia"
    },
    {
      "id": "ObjectId(625763e9343edc875fe63a7a)",
      "incident_id": 125,
      "date": "2020-09-29",
      "title": "Amazon’s Robotic Fulfillment Centers Have Higher Serious Injury Rates",
      "description": "Amazon’s robotic fulfillment centers have higher serious injury rates.",
      "deployers": [
        "amazon"
      ],
      "developers": [
        "amazon"
      ],
      "harmedParties": [
        "amazon-fulfillment-center-workers"
      ],
      "reports": [
        1451,
        1452,
        1460
      ],
      "severity": "AI tangible harm event",
      "classification": "yes",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763ea343edc875fe63a85)",
      "incident_id": 136,
      "date": "2020-12-06",
      "title": "Brand Safety Tech Firms Falsely Claimed Use of AI, Blocking Ads Using Simple Keyword Lists",
      "description": "Brand safety tech firms falsely claimed use of AI, blocking ads using simple keyword lists.",
      "deployers": [
        "brand-safety-tech-firms"
      ],
      "developers": [
        "none"
      ],
      "harmedParties": [
        "news-sites"
      ],
      "reports": [
        1471
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "Arts, entertainment and recreation, information and communication",
      "region": "Global"
    },
    {
      "id": "ObjectId(625763ea343edc875fe63a87)",
      "incident_id": 138,
      "date": "2020-01-21",
      "title": "Alleged Issues with Proctorio's Remote-Testing AI Prompted Suspension by University",
      "description": "Proctorio's remote-testing software were reported by students at the University of Illinois Urbana-Champaign for issues regarding privacy, accessibility, differential performance on darker-skinned students.",
      "deployers": [
        "university-of-illinois"
      ],
      "developers": [
        "proctorio"
      ],
      "harmedParties": [
        "university-of-illinois-students-of-color",
        "university-of-illinois-students"
      ],
      "reports": [
        1475,
        1505,
        1555,
        1556,
        2442,
        2434
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(625763ea343edc875fe63a81)",
      "incident_id": 132,
      "date": "2020-12-27",
      "title": "TikTok’s Content Moderation Allegedly Failed to Adequately Take down Videos Promoting Eating Disorders",
      "description": "Videos promoting eating disorders evaded TikTok's automated violation detection system without difficulty via common misspellings of search terms, bypassing its ban of violating hashtags such as proana and anorexia.",
      "deployers": [
        "tiktok"
      ],
      "developers": [
        "tiktok"
      ],
      "harmedParties": [
        "tiktok-users",
        "tiktok-users-under-18-years-old"
      ],
      "reports": [
        1466
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "Arts, entertainment and recreation, information and communication",
      "region": "Global"
    },
    {
      "id": "ObjectId(625763ea343edc875fe63a84)",
      "incident_id": 135,
      "date": "2012-12-01",
      "title": "UT Austin GRADE Algorithm Allegedly Reinforced Historical Inequalities",
      "description": "The University of Texas at Austin's Department of Computer Science's assistive algorithm to assess PhD applicants GRADE raised concerns among faculty about worsening historical inequalities for marginalized candidates, prompting its suspension.",
      "deployers": [
        "university-of-texas-at-austin's-department-of-computer-science"
      ],
      "developers": [
        "university-of-texas-at-austin-researchers"
      ],
      "harmedParties": [
        "university-of-texas-at-austin-phd-applicants-of-marginalized-groups"
      ],
      "reports": [
        1470,
        1871
      ],
      "severity": "none",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763ec343edc875fe63a98)",
      "incident_id": 155,
      "date": "2021-12-27",
      "title": "Google Maps Allegedly Directed Sierra Nevada Travelers to Dangerous Roads amid Winter Storm",
      "description": "Lake Tahoe travelers were allegedly guided by Google Maps into hazardous shortcuts in the mountains during a snowstorm.",
      "deployers": [
        "google-maps"
      ],
      "developers": [
        "google-maps"
      ],
      "harmedParties": [
        "google-maps-users-traveling-in-sierra-nevada",
        "google-maps-users-traveling-in-the-mountains"
      ],
      "reports": [
        1513,
        1514
      ],
      "severity": "AI tangible harm near-miss",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763ed343edc875fe63a9f)",
      "incident_id": 162,
      "date": "2014-01-01",
      "title": "ETS Used Allegedly Flawed Voice Recognition Evidence to Accuse and Assess Scale of Cheating, Causing Thousands to be Deported from the UK",
      "description": " International testing organization ETS admits voice recognition as evidence of cheating for thousands of previous TOEIC test-takers that reportedly included wrongfully accused people, causing them to be deported without an appeal process or seeing their incriminating evidence.",
      "deployers": [
        "ets"
      ],
      "developers": [
        "ets"
      ],
      "harmedParties": [
        "uk-ets-past-test-takers",
        "uk-ets-test-takers",
        "uk-home-office"
      ],
      "reports": [
        1531
      ],
      "severity": "AI tangible harm event",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763ee343edc875fe63aa8)",
      "incident_id": 171,
      "date": "2021-10-18",
      "title": "Traffic Camera Misread Text on Pedestrian's Shirt as License Plate, Causing UK Officials to Issue Fine to an Unrelated Person",
      "description": "A Bath resident was wrongly fined by the local officials because an automated license plate recognition camera misread the text on her shirt as a license plate number.",
      "deployers": [
        "bath-government"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "paula-knight",
        "bath-officials",
        "uk-public"
      ],
      "reports": [
        1549
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(625763ec343edc875fe63a94)",
      "incident_id": 151,
      "date": "2021-10-28",
      "title": "California Regulator Suspended Pony.ai's Driverless Testing Permit Following a Non-Fatal Collision",
      "description": "A Pony.ai vehicle operating in autonomous mode crashed into a center divider and a traffic sign in San Francisco, prompting a regulator to suspend the driverless testing permit for the startup.",
      "deployers": [
        "pony.ai"
      ],
      "developers": [
        "pony.ai"
      ],
      "harmedParties": [
        "san-francisco-city-government"
      ],
      "reports": [
        1507,
        1508,
        1703,
        1704,
        1705,
        1706,
        1707,
        1708,
        1709,
        1710
      ],
      "severity": "AI tangible harm event",
      "classification": "yes",
      "sector": "transportation and storage",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763e9343edc875fe63a78)",
      "incident_id": 123,
      "date": "2021-08-01",
      "title": "Epic Systems’s Sepsis Prediction Algorithms Revealed to Have High Error Rates on Seriously Ill Patients",
      "description": "Epic System's sepsis prediction algorithms was shown by investigators at the University of Michigan Hospital to have high rates of false positives and false negatives, allegedly delivering inaccurate and irrelevant information on patients, contrasting sharply with their published claims.",
      "deployers": [
        "university-of-michigan-hospital"
      ],
      "developers": [
        "epic-systems"
      ],
      "harmedParties": [
        "sepsis-patients"
      ],
      "reports": [
        1449,
        2651,
        2705,
        3013,
        3012
      ],
      "severity": "AI tangible harm issue",
      "classification": "yes",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763ec343edc875fe63a99)",
      "incident_id": 156,
      "date": "2022-02-04",
      "title": "Amazon Reportedly Sold Products and Recommended Frequently Bought Together Items That Aid Suicide Attempts",
      "description": "Despite complaints notifying Amazon about the sale of various products that had been used to aid suicide attempts, its recommendation system reportedly continued selling them and suggesting their frequently bought-together items.",
      "deployers": [
        "amazon"
      ],
      "developers": [
        "amazon"
      ],
      "harmedParties": [
        "people-attempting-suicides"
      ],
      "reports": [
        1515,
        2197
      ],
      "severity": "none",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763eb343edc875fe63a8c)",
      "incident_id": 143,
      "date": "2021-02-16",
      "title": "Facebook’s and Twitter's Automated Content Moderation Reportedly Failed to Effectively Enforce Violation Rules for Small Language Groups",
      "description": "Facebook's and Twitter were not able to sufficiently moderate content of small language groups such as the Balkan languages using AI, allegedly due to the lack of investment in human moderation and difficulty in AI-solution design for the languages.",
      "deployers": [
        "facebook",
        "twitter"
      ],
      "developers": [
        "facebook",
        "twitter"
      ],
      "harmedParties": [
        "facebook-users-of-small-language-groups",
        "twitter-users-of-small-language-groups"
      ],
      "reports": [
        1482
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "information and communication",
      "region": "Europe"
    },
    {
      "id": "ObjectId(625763ec343edc875fe63a9a)",
      "incident_id": 157,
      "date": "2021-03-15",
      "title": "Amazon's Monitoring System Allegedly Pushed Delivery Drivers to Prioritize Speed over Safety, Leading to Crash",
      "description": "A lawsuit cited Amazon as liable in a crash involving its delivery driver, alleging that Amazon’s AI-powered driver monitoring system pushed drivers to prioritize speed over safety.",
      "deployers": [
        "amazon"
      ],
      "developers": [
        "amazon"
      ],
      "harmedParties": [
        "amazon-workers",
        "amazon-delivery-drivers"
      ],
      "reports": [
        1516
      ],
      "severity": "unclear",
      "classification": "yes",
      "sector": "transportation and storage, wholesale and retail trade",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763ee343edc875fe63aa7)",
      "incident_id": 170,
      "date": "2003-06-01",
      "title": "Target Suggested Maternity-Related Advertisements to a Teenage Girl's Home, Allegedly Correctly Predicting Her Pregnancy via Algorithm",
      "description": "Target recommended maternity-related items to a family in Atlanta via ads, allegedly predicting their teenage daughter’s pregnancy before her father did, although critics have called into question the predictability of the algorithm and the authenticity of its claims.",
      "deployers": [
        "target"
      ],
      "developers": [
        "target"
      ],
      "harmedParties": [
        "target-customers"
      ],
      "reports": [
        1546,
        1547,
        1548
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(625763ea343edc875fe63a88)",
      "incident_id": 139,
      "date": "2021-01-21",
      "title": "Amazon’s Search and Recommendation Algorithms Found by Auditors to Have Boosted Products That Contained Vaccine Misinformation",
      "description": "Evidence of the filter-bubble effect were found by vaccine-misinformation researchers in Amazon's recommendations, where its algorithms presented users who performed actions on misinformative products with more misinfomative products.",
      "deployers": [
        "amazon"
      ],
      "developers": [
        "amazon"
      ],
      "harmedParties": [
        "amazon-customers"
      ],
      "reports": [
        1476,
        1477
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "wholesale and retail trade",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763eb343edc875fe63a8b)",
      "incident_id": 142,
      "date": "2021-02-11",
      "title": "Facebook’s Advertisement Moderation System Routinely Misidentified Adaptive Fashion Products as Medical Equipment and Blocked Their Sellers",
      "description": "Facebook platforms' automated ad moderation system falsely classified adaptive fashion products as medical and health care products and services, resulting in regular bans and appeals faced by their retailers.",
      "deployers": [
        "facebook",
        "instagram"
      ],
      "developers": [
        "facebook",
        "instagram"
      ],
      "harmedParties": [
        "facebook-users-of-disabilities",
        "adaptive-fashion-retailers"
      ],
      "reports": [
        1481
      ],
      "severity": "AI tangible harm issue",
      "classification": "yes",
      "sector": "wholesale and retail trade, information and communication",
      "region": "Global"
    },
    {
      "id": "ObjectId(625763eb343edc875fe63a93)",
      "incident_id": 150,
      "date": "2018-07-21",
      "title": "Swedish Contraceptive App, Natural Cycles, Allegedly Failed to Correctly Map Menstrual Cycle",
      "description": "Some women using the contraceptive app, Natural Cycles, reported unwanted pregnancies, revealing its algorithm's difficulties in mapping menstrual cycles.",
      "deployers": [
        "natural-cycles"
      ],
      "developers": [
        "natural-cycles"
      ],
      "harmedParties": [
        "natural-cycles-users",
        "women"
      ],
      "reports": [
        1506,
        3157,
        3158
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(625763ed343edc875fe63aa6)",
      "incident_id": 169,
      "date": "2018-08-15",
      "title": "Facebook Allegedly Failed to Police Anti-Rohingya Hate Speech Content That Contributed to Violence in Myanmar",
      "description": " Facebook allegedly did not adequately remove anti-Rohingya hate speech, some of which was extremely violent and dehumanizing, on its platform, contributing to the violence faced by Rohingya communities in Myanmar.",
      "deployers": [
        "facebook",
        "meta"
      ],
      "developers": [
        "facebook",
        "meta"
      ],
      "harmedParties": [
        "rohingya-people",
        "rohingya-facebook-users",
        "myanmar-public",
        "facebook-users-in-myanmar",
        "burmese-speaking-facebook-users"
      ],
      "reports": [
        1544,
        1545,
        2986,
        2987,
        2988
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(625763eb343edc875fe63a90)",
      "incident_id": 147,
      "date": "2020-01-01",
      "title": "Hong Kong Bank Manager Swindled by Fraudsters Using Deepfaked Voice of Company Director",
      "description": "In early 2020, fraudsters reportedly allegedly deepfaked the voice of a company's director, demanding a bank manager in Hong Kong to authorize a $35M transfer.",
      "deployers": [
        "scammers"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "hong-kong-bank-manager"
      ],
      "reports": [
        1496,
        1497
      ],
      "severity": "AI tangible harm event",
      "classification": "yes",
      "sector": "financial and insurance activities, other",
      "region": "Asia"
    },
    {
      "id": "ObjectId(625763e9343edc875fe63a7b)",
      "incident_id": 126,
      "date": "2021-07-16",
      "title": "Three Robots Collided, Sparking Fire in a Grocer's Warehouse in UK ",
      "description": "A collision involving three robots at an Ocado's warehouse in Erith, UK, resulting in a fire but no reports of injuries.",
      "deployers": [
        "ocado"
      ],
      "developers": [
        "ocado"
      ],
      "harmedParties": [
        "ocado"
      ],
      "reports": [
        1453,
        1454,
        1455,
        1532
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "wholesale and retail trade, transportation and storage",
      "region": "Europe"
    },
    {
      "id": "ObjectId(625763e9343edc875fe63a7d)",
      "incident_id": 128,
      "date": "2017-08-01",
      "title": "Tesla Sedan on Autopilot Reportedly Drove Over Dividing Curb in Washington, Resulting in Minor Vehicle Damage",
      "description": " A Tesla Sedan operating on Autopilot mode was not able to center itself on the road and drove over a yellow dividing curb in Redmond, Washington, causing minor damage to the vehicle’s rear suspension.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "eric-horvitz",
        "tesla-drivers"
      ],
      "reports": [
        1459,
        1818
      ],
      "severity": "AI tangible harm event",
      "classification": "yes",
      "sector": "transportation and storage",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763ec343edc875fe63a97)",
      "incident_id": 154,
      "date": "2022-01-26",
      "title": "Justice Department’s Recidivism Risk Algorithm PATTERN Allegedly Caused Persistent Disparities Along Racial Lines",
      "description": "Department of Justice’s inmate-recidivism risk assessment tool was reported to have produced racially uneven results, misclassifying risk levels for inmates of color.",
      "deployers": [
        "us-department-of-justice"
      ],
      "developers": [
        "us-department-of-justice"
      ],
      "harmedParties": [
        "inmates-of-color"
      ],
      "reports": [
        1512
      ],
      "severity": "AI tangible harm event",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763ed343edc875fe63aa2)",
      "incident_id": 165,
      "date": "2020-06-20",
      "title": "Image Upscaling Algorithm PULSE Allegedly Produced Facial Images with Caucasian Features More Often",
      "description": "Image upscaling tool PULSE powered by NVIDIA's StyleGAN reportedly generated faces with Caucasian features more often, although AI academics, engineers, and researchers were not in agreement about where the source of bias was.",
      "deployers": [
        "duke-researchers"
      ],
      "developers": [
        "duke-researchers"
      ],
      "harmedParties": [
        "people-having-non-caucasian-facial-features"
      ],
      "reports": [
        1536,
        2781
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(625763ec343edc875fe63a9b)",
      "incident_id": 158,
      "date": "2021-02-01",
      "title": "Facial Recognition in Remote Learning Software Reportedly Failed to Recognize a Black Student’s Face",
      "description": "A Black student's face was not recognized by the remote-proctoring software during check-in of a lab quiz, causing her to excessively change her environments for it to work as intended.",
      "deployers": [
        "unknown"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "amaya-ross",
        "black-students",
        "black-test-takers"
      ],
      "reports": [
        1517
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(625763eb343edc875fe63a92)",
      "incident_id": 149,
      "date": "2021-11-02",
      "title": "Zillow Shut Down Zillow Offers Division Allegedly Due to Predictive Pricing Tool's Insufficient Accuracy",
      "description": "Zillow's AI-powered predictive pricing tool Zestimate was allegedly not able to accurately forecast housing prices three to six months in advance due to rapid market changes, prompting division shutdown and layoff of a few thousand employees.",
      "deployers": [
        "zillow"
      ],
      "developers": [
        "zillow-offers"
      ],
      "harmedParties": [
        "zillow-offers-staff",
        "zillow"
      ],
      "reports": [
        1500,
        1501,
        1890,
        2925
      ],
      "severity": "AI tangible harm event",
      "classification": "yes",
      "region": "North America"
    },
    {
      "id": "ObjectId(625763e9343edc875fe63a79)",
      "incident_id": 124,
      "date": "2019-10-24",
      "title": "Algorithmic Health Risk Scores Underestimated Black Patients’ Needs",
      "description": "Optum's algorithm deployed by a large academic hospital was revealed by researchers to have under-predicted the health needs of black patients, effectively de-prioritizing them in extra care programs relative to white patients with the same health burden.",
      "deployers": [
        "unnamed-large-academic-hospital"
      ],
      "developers": [
        "optum"
      ],
      "harmedParties": [
        "black-patients"
      ],
      "reports": [
        1450,
        1522,
        2262,
        2652,
        2651,
        2704,
        2856
      ],
      "severity": "AI tangible harm event",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763ec343edc875fe63a9c)",
      "incident_id": 159,
      "date": "2019-03-29",
      "title": "Tesla Autopilot’s Lane Recognition Allegedly Vulnerable to Adversarial Attacks",
      "description": "Tencent Keen Security Lab conducted security research into Tesla’s Autopilot system and identified crafted adversarial samples and remote controlling via wireless gamepad as vulnerabilities to its system, although the company called into question their real-world practicality. This incident has been downgraded to an issue as it does not meet current ingestion criteria.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "tesla-drivers"
      ],
      "reports": [
        2471
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(625763ed343edc875fe63aa4)",
      "incident_id": 167,
      "date": "2017-09-07",
      "title": "Researchers' Homosexual-Men Detection Model Denounced as a Threat to LGBTQ People’s Safety and Privacy",
      "description": "Researchers at Stanford Graduate School of Business developed a model that determined, on a binary scale, whether someone was homosexual using only his facial image, which advocacy groups such as GLAAD and the Human Rights Campaign denounced as flawed science and threatening to LGBTQ folks.",
      "deployers": [
        "michal-kosinski",
        "yilun-wang"
      ],
      "developers": [
        "michal-kosinski",
        "yilun-wang"
      ],
      "harmedParties": [
        "lgbtq-people",
        "lgbtq-people-of-color",
        "non-american-lgbtq-people"
      ],
      "reports": [
        1539
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(625763e9343edc875fe63a7c)",
      "incident_id": 127,
      "date": "2020-06-06",
      "title": "Microsoft’s Algorithm Allegedly Selected Photo of the Wrong Mixed-Race Person Featured in a News Story",
      "description": "A news story published on MSN.com featured a photo of the wrong mixed-race person that was allegedly selected by an algorithm, following Microsoft’s layoff and replacement of journalists and editorial workers at its organizations with AI systems.",
      "deployers": [
        "microsoft",
        "msn.com"
      ],
      "developers": [
        "microsoft"
      ],
      "harmedParties": [
        "jade-thirlwall",
        "leigh-anne-pinnock"
      ],
      "reports": [
        1456,
        1457,
        1458,
        1461,
        1486,
        1487,
        1488,
        1489,
        1490,
        1491,
        1492,
        1493
      ],
      "severity": "none",
      "classification": "yes"
    },
    {
      "id": "ObjectId(625763ed343edc875fe63aa0)",
      "incident_id": 163,
      "date": "2021-11-21",
      "title": "Facebook’s Hate Speech Detection Algorithms Allegedly Disproportionately Failed to Remove Racist Content towards Minority Groups",
      "description": "Facebook’s hate-speech detection algorithms was found by company researchers to have under-reported less common but more harmful content that was more often experienced by minority groups such as Black, Muslim, LGBTQ, and Jewish users.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "facebook-users-of-minority-groups",
        "facebook-users"
      ],
      "reports": [
        1533,
        1652
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(625763ed343edc875fe63aa3)",
      "incident_id": 166,
      "date": "2020-02-07",
      "title": "Networking Platform Giggle Employs AI to Determine Users’ Gender, Allegedly Excluding Transgender Women",
      "description": "A social networking platform, Giggle, allegedly collected, shared to third-parties, and used sensitive information and biometric data to verify whether a person is a woman via facial recognition, which critics claimed to be discriminatory against women of color and harmful towards trans women.",
      "deployers": [
        "giggle"
      ],
      "developers": [
        "kairos"
      ],
      "harmedParties": [
        "trans-women",
        "women-of-color"
      ],
      "reports": [
        1538,
        1563
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6259b3d5c2337187617c53c3)",
      "incident_id": 176,
      "date": "2022-03-02",
      "title": "Starship’s Autonomous Food Delivery Robot Allegedly Stranded at Railroad Crossing in Oregon, Run over by Freight Train",
      "description": " A Starship food delivery robot deployed by Oregon State University reportedly failed to cross the railroad, becoming stranded, and ending up being struck by an oncoming freight train.",
      "deployers": [
        "oregon-state-university"
      ],
      "developers": [
        "starship-technologies"
      ],
      "harmedParties": [
        "oregon-state-university",
        "freight-train-crew"
      ],
      "reports": [
        1557
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62842ee176e12cf335550ab1)",
      "incident_id": 182,
      "date": "2018-06-11",
      "title": "Two Cruise Autonomous Vehicles Collided with Each Other in California ",
      "description": "In San Francisco, an autonomous Cruise Chevrolet Bolt collided with another Cruise vehicle driven by a Cruise human employee, causing minor scuffs to the cars but no human injuries.",
      "deployers": [
        "cruise"
      ],
      "developers": [
        "cruise"
      ],
      "harmedParties": [
        "cruise-vehicles",
        "cruise-driver-employee"
      ],
      "reports": [
        1573,
        1574
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(625763ee343edc875fe63aaa)",
      "incident_id": 173,
      "date": "2021-07-30",
      "title": "AI Tools Failed to Sufficiently Predict COVID Patients, Some Potentially Harmful",
      "description": "AI tools failed to sufficiently predict COVID patients, some potentially harmful.",
      "deployers": [
        "unknown"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "doctors",
        "covid-patients"
      ],
      "reports": [
        1551
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6297936efc298401e1ba35c0)",
      "incident_id": 203,
      "date": "2022-02-10",
      "title": "Uber Launched Opaque Algorithm That Changes Drivers' Payments in the US",
      "description": "Uber launched a new but opaque algorithm to determine drivers' pay in the US which allegedly caused drivers to experience lower fares, confusing fare drops, and a decrease in rides.",
      "deployers": [
        "uber"
      ],
      "developers": [
        "uber"
      ],
      "harmedParties": [
        "uber-drivers"
      ],
      "reports": [
        1659,
        1660,
        1661
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62849d9dcb05238c61a5cc65)",
      "incident_id": 184,
      "date": "2018-04-12",
      "title": "Facial Recognition Program in São Paulo Metro Stations Suspended for Illegal and Disproportionate Violation of Citizens’ Right to Privacy",
      "description": " A facial recognition program rolled out by São Paulo Metro Stations was suspended following a court ruling in response to a lawsuit by civil society organizations, who cited fear of it being integrated with other electronic surveillance entities without consent, and lack of transparency about the biometric data collection process of metro users.",
      "deployers": [
        "companhia-do-metropolitano-de-sao-paulo"
      ],
      "developers": [
        "securos"
      ],
      "harmedParties": [
        "sao-paulo-metro-users",
        "sao-paulo-citizens"
      ],
      "reports": [
        1581,
        1584,
        1899
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(628ad91f7da5b905fb4444b8)",
      "incident_id": 195,
      "date": "2015-09-01",
      "title": "Predictive Policing Program by Florida Sheriff’s Office Allegedly Violated Residents’ Rights and Targeted Children of Vulnerable Groups",
      "description": "The Intelligence-Led Policing model rolled out by the Pasco County Sheriff’s Office was allegedly developed based on flawed science and biased data that also contained sensitive information and irrelevant attributes about students, which critics said to be discriminatory.",
      "deployers": [
        "pasco-sheriff's-office"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "pasco-residents",
        "pasco-black-students",
        "pasco-students-with-disabilities"
      ],
      "reports": [
        1622,
        1623,
        1624,
        1625,
        1626,
        1627,
        1628,
        1629,
        1630,
        1631,
        1632,
        1843
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(629dce346e8239f700dfecbf)",
      "incident_id": 213,
      "date": "2020-07-01",
      "title": "Facebook’s Political Ad Detection Reportedly Showed High and Geographically Uneven Error Rates",
      "description": "The performance of Facebook’s political ad detection was revealed by researchers to be imprecise, uneven across countries in errors, and inadequate for preventing systematic violations of political advertising policies.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "facebook-users"
      ],
      "reports": [
        1715,
        1716,
        1717,
        1718,
        1719
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(625763ee343edc875fe63aab)",
      "incident_id": 174,
      "date": "2022-02-28",
      "title": "Fake LinkedIn Profiles Created Using GAN Photos",
      "description": "More than a thousand inauthentic LinkedIn profiles using allegedly GAN-generated photos were notified by researchers at Stanford to LinkedIn’s staff, and many of which were removed for violating rules against creating fake profiles and falsifying information.",
      "deployers": [
        "unknown"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "linkedin-users"
      ],
      "reports": [
        1552,
        1585,
        1595,
        1599
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(628af245a8f82bdc4c020cc2)",
      "incident_id": 198,
      "date": "2022-03-16",
      "title": "Deepfake Video of Ukrainian President Yielding to Russia Posted on Ukrainian Websites and Social Media",
      "description": " A quickly-debunked deepfaked video of the Ukrainian President Volodymyr Zelenskyy was posted on various Ukrainian websites and social media platforms encouraging Ukrainians to surrender to Russian forces during the Russia-Ukraine war.",
      "deployers": [
        "hackers"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "volodymyr-zelenskyy",
        "ukrainian-social-media-users",
        "ukrainian-public"
      ],
      "reports": [
        1642,
        1643,
        1644,
        1645,
        1646,
        3332,
        3333,
        3334,
        3335
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(625763ee343edc875fe63aac)",
      "incident_id": 175,
      "date": "2022-04-01",
      "title": "Cruise Autonomous Taxi Allegedly Bolted off from Police After Being Pulled over in San Francisco",
      "description": "An autonomous Chevy Bolt operated by Cruise was pulled over in San Francisco, and as the police attempted to engage with the car, it reportedly bolted off, pulled over again, and put on its hazards lights on at a point farther down the road.",
      "deployers": [
        "cruise"
      ],
      "developers": [
        "cruise"
      ],
      "harmedParties": [
        "san-francisco-public",
        "cruise-customers"
      ],
      "reports": [
        1553,
        1554,
        1606,
        1607,
        1608
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6269ca6f01cc3d7da1e059ad)",
      "incident_id": 178,
      "date": "2022-04-21",
      "title": "Tesla Owner Activated Smart Summon Feature, Causing a Collision with an Aircraft in a Washington Airport",
      "description": " A Tesla Model Y was shown on video slowly crashing into a Vision Jet in Spokane, Washington, allegedly due to its owner activating the “Smart Summon” feature.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "tesla-owner",
        "vision-jet-owner"
      ],
      "reports": [
        1560,
        1565,
        1566,
        1567,
        1568,
        1569,
        1570,
        1594
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62842764c4ac5276446aed58)",
      "incident_id": 180,
      "date": "2020-02-19",
      "title": "Algorithm Used by the Malaysian Judiciary Reportedly Recommended Unusually High Sentencing to a Drug Possession Case",
      "description": "The AI system used by the Malaysian judiciary which explicitly considered age, employment, and socio-economic data provided sentencing to a drug possession case that was alleged by lawyer to be disproportionately high for the crime committed.",
      "deployers": [
        "malaysian-judiciary",
        "malaysian-courts"
      ],
      "developers": [
        "sarawak-information-systems"
      ],
      "harmedParties": [
        "malaysian-convicted-people"
      ],
      "reports": [
        1564,
        1582,
        2236
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(628498c9ba5ecc08807ab7d9)",
      "incident_id": 183,
      "date": "2017-07-01",
      "title": "Airbnb's Trustworthiness Algorithm Allegedly Banned Users without Explanation, and Discriminated against Sex Workers",
      "description": " Airbnb allegedly considered publicly available data on users to gauge their trustworthiness via algorithmic assessment of personality and behavioral traits, resulting in unexplained bans and discriminatory bans against sex workers.",
      "deployers": [
        "airbnb"
      ],
      "developers": [
        "airbnb",
        "trooly"
      ],
      "harmedParties": [
        "sex-workers",
        "airbnb-users"
      ],
      "reports": [
        1576,
        1577,
        1578,
        1579,
        1580,
        2066
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62a18ffaae26c04e23bf1d27)",
      "incident_id": 220,
      "date": "2020-11-11",
      "title": "Facebook Mistakenly Blocked Small Business Ads",
      "description": "Facebook’s AI mistakenly blocked advertisements by small and struggling businesses, after the company allegedly leaned more on algorithms to monitor ads on the platform with little review from human moderators.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "small-businesses-on-facebook"
      ],
      "reports": [
        1731,
        1732,
        1969,
        2061
      ],
      "severity": "AI tangible harm event",
      "classification": "yes",
      "sector": "wholesale and retail trade, information and communication",
      "region": "Global"
    },
    {
      "id": "ObjectId(628ad7417da5b905fb43f208)",
      "incident_id": 194,
      "date": "2018-02-01",
      "title": "Australian Telco’s Incident Management Bot Excessively Sent Technicians in the Field by Mistake, Allegedly Costing Millions",
      "description": "In early 2018, an Australian telecommunications company’s incident management AI excessively deployed technicians into the field, and was allegedly unable to be stopped by the automation team.",
      "deployers": [
        "unnamed-australian-telecommunications-company"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "unnamed-australian-telecommunications-company"
      ],
      "reports": [
        1621
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(628b0ea3db7d62b8a823c307)",
      "incident_id": 200,
      "date": "2019-03-01",
      "title": "Fraudsters Used AI to Mimic Voice of a UK-Based Firm's CEO's Boss",
      "description": "Fraudsters allegedly used AI voice technology to impersonate the boss of a UK-based firm's CEO, demanding a transfer of €220,000 over the phone.",
      "deployers": [
        "scammers"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "unnamed-uk-based-energy-firm's-ceo"
      ],
      "reports": [
        1653
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62988029093243282c69c2b2)",
      "incident_id": 206,
      "date": "2015-03-01",
      "title": "Tinder's Personalized Pricing Algorithm Found to Offer Higher Prices for Older Users",
      "description": "Tinder’s personalized pricing was found by Consumers International to consider age as a major determinant of pricing, and could be considered a direct discrimination based on age, according to anti-discrimination law experts.",
      "deployers": [
        "tinder"
      ],
      "developers": [
        "tinder"
      ],
      "harmedParties": [
        "tinder-users-over-30-years-old"
      ],
      "reports": [
        1675,
        1676,
        1677,
        1678
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6285d00023ec6cb0db5af13a)",
      "incident_id": 186,
      "date": "2007-07-26",
      "title": "Algorithm Assessing Risk Faced by Victims of Gender Violence Misclassified Low-Risk Cases, Allegedly Leading to Homicide of Women and Children in Spain",
      "description": " In Spain, the algorithm that assesses recidivism risk in gender violence, VioGén, have critically underestimated the level of risk in a series of cases that ended in homicide of women and children since its first deployment.",
      "deployers": [
        "spanish-ministry-of-interior"
      ],
      "developers": [
        "spanish-secretary-of-state-for-security",
        "spanish-ministry-of-interior"
      ],
      "harmedParties": [
        "spanish-victims-of-gender-violence"
      ],
      "reports": [
        1590,
        1591,
        1592,
        1593,
        1788,
        1933,
        1934
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(629791afc7e109ab6bc28b6f)",
      "incident_id": 202,
      "date": "2021-12-06",
      "title": "Korean Politician Employed Deepfake as Campaign Representative",
      "description": "A South Korean political candidate created a deepfake avatar which political opponents alleged to be fraudulent and a threat to democracy.",
      "deployers": [
        "yoon-suk-yeol",
        "yoon-suk-yeol's-campaign"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "korean-public"
      ],
      "reports": [
        1655,
        1656,
        1657,
        1658,
        1721
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(629f0c2548f09c92aeb5fe4d)",
      "incident_id": 216,
      "date": "2017-10-10",
      "title": "WeChat’s Machine Translation Gave a Racist English Translation for the Chinese Term for “Black Foreigner”",
      "description": "The Chinese platform WeChat provided an inappropriate and racist English translation for the Chinese term for “black foreigner” in its messaging app.",
      "deployers": [
        "wechat"
      ],
      "developers": [
        "wechat"
      ],
      "harmedParties": [
        "black-wechat-users"
      ],
      "reports": [
        1724,
        1924,
        1925,
        1926,
        1927
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62a196265fb208d11b3108fa)",
      "incident_id": 221,
      "date": "2022-03-07",
      "title": "A Road Engineer Killed Following a Collision Involving a Tesla on Autopilot",
      "description": "In Taiwan, a Tesla Model 3 on Autopilot mode whose driver did not pay attention to the road collided with a road repair truck; a road engineer immediately placed crash warnings in front of the Tesla, but soon after got hit and was killed by a BMW when its driver failed to see the sign and crashed into the accident.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "road-engineer"
      ],
      "reports": [
        1733,
        1734
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(626a2b97f9c5ab809bbc9af1)",
      "incident_id": 179,
      "date": "2022-04-01",
      "title": "DALL-E 2 Reported for Gender and Racially Biased Outputs",
      "description": "Developers of OpenAI's DALL-E 2 cited risks of the model, varying from misuse as disinformation and explicit content generation, to gender and racial bias.",
      "deployers": [
        "openai"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "underrepresented-groups",
        "minority-groups"
      ],
      "reports": [
        1561,
        1562,
        1874
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(625763ee343edc875fe63aa9)",
      "incident_id": 172,
      "date": "2020-07-01",
      "title": "NarxCare’s Risk Score Model Allegedly Lacked Validation and Trained on Data with High Risk of Bias",
      "description": "NarxCare's overdose risk algorithm, lacking peer-reviewed validation, uses sensitive data like doctor visits, prescriptions, and possibly genetic information, leading to significant biases against women and Black patients. Factors like sexual abuse and criminal records exacerbate stigmas and disparities, often resulting in unjust denial of necessary pain medication. The newly approved AvertD genetic test shares similar issues, further complicating and potentially harming medical treatment decisions.",
      "deployers": [
        "appriss",
        "narxcare",
        "avertd"
      ],
      "developers": [
        "appriss"
      ],
      "harmedParties": [
        "american-physicians",
        "american-pharmacists",
        "american-patients-of-minority-groups",
        "american-patients"
      ],
      "reports": [
        1550,
        3859,
        3912
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62842db6dee309a4a8e14d4b)",
      "incident_id": 181,
      "date": "2022-02-11",
      "title": "BMW Sedan Made a Prohibited Left Turn, Colliding with a Cruise Autonomous Vehicle",
      "description": "A BMW Sedan reportedly made an illegal left turn, causing a minor collision but no injuries with a Cruise autonomous vehicle (AV) operating in autonomous mode.",
      "deployers": [
        "cruise"
      ],
      "developers": [
        "cruise"
      ],
      "harmedParties": [
        "cruise-vehicle"
      ],
      "reports": [
        1571,
        1572
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62868592e0a9519a0ba08a94)",
      "incident_id": 190,
      "date": "2017-01-15",
      "title": "ByteDance Allegedly Trained For You Algorithm Using Content Scraped without Consent from Other Social Platforms",
      "description": " ByteDance allegedly scraped short-form videos, usernames, profile pictures, and descriptions of accounts on Instagram, Snapchat, and other sources, and uploaded them without consent on Flipagram, TikTok’s predecessor, in order to improve its “For You” algorithm's performance on American users.",
      "deployers": [
        "bytedance"
      ],
      "developers": [
        "bytedance"
      ],
      "harmedParties": [
        "instagram-users",
        "snapchat-users",
        "american-social-media-users"
      ],
      "reports": [
        1610,
        1611,
        1612,
        1613
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(626331bad17b021fce12b51b)",
      "incident_id": 177,
      "date": "2022-04-19",
      "title": "Google’s Assistive Writing Feature Provided Allegedly Unnecessary and Clumsy Suggestions",
      "description": "Google’s “inclusive language” feature prompting writers to consider alternatives to non-inclusive words reportedly also recommend alternatives for words such as “landlord” and “motherboard,” which critics said was a form of obtrusive, unnecessary, and bias-reinforcing speech-policing.",
      "deployers": [
        "google-docs"
      ],
      "developers": [
        "google-docs"
      ],
      "harmedParties": [
        "google-docs-users"
      ],
      "reports": [
        1558,
        1583,
        1600,
        1601,
        1602
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(628681d73a32758144dc742b)",
      "incident_id": 188,
      "date": "2018-04-11",
      "title": "Argentinian City Government Deployed Teenage-Pregnancy Predictive Algorithm Using Invasive Demographic Data",
      "description": "In 2018, during the abortion-decriminalization debate in Argentina, the Salta city government deployed a teenage-pregnancy predictive algorithm built by Microsoft that allegedly lacked a defined purpose, explicitly considered sensitive information such as disability and whether their home had access to hot water.",
      "deployers": [
        "salta-city-government"
      ],
      "developers": [
        "microsoft"
      ],
      "harmedParties": [
        "salta-teenage-girls",
        "salta-girls-of-minority-groups"
      ],
      "reports": [
        1603,
        1604,
        1782,
        1605
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(628686fce0eed158517d4796)",
      "incident_id": 191,
      "date": "2020-10-06",
      "title": "Korean Internet Portal Giant Naver Manipulated Shopping and Video Search Algorithms to Favor In-House Services",
      "description": "The Korean Fair Trade Commission (FTC) imposed a 26.7B KRW on Naver for manipulating shopping and video search algorithms, favoring its own online shopping business to boost its market share. ",
      "deployers": [
        "naver"
      ],
      "developers": [
        "naver"
      ],
      "harmedParties": [
        "naver-customers"
      ],
      "reports": [
        1614,
        1615
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(628b0fb73a32758144c2c21d)",
      "incident_id": 201,
      "date": "2020-04-14",
      "title": "Climate Action Group Posted Deepfake of Belgian Prime Minister Urging Climate Crisis Action",
      "description": "A deepfake video showing the Belgium’s prime minister speaking of an urgent need to tackle the climate crises was released by a climate action group.",
      "deployers": [
        "extinction-rebellion-belgium"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "shophie-wilmes",
        "belgian-government"
      ],
      "reports": [
        1654,
        2435
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62986c4c093243282c6578f5)",
      "incident_id": 204,
      "date": "2022-02-11",
      "title": "A Chinese Tech Worker at Zhihu Fired Allegedly via a Resignation Risk Prediction Algorithm",
      "description": "The firing of an employee at Zhihu, a large Q&A platform in China, was allegedly caused by the use of a behavioral perception algorithm which claimed to predict a worker’s resignation risk using their online footprints, such as browsing history and internal communication.",
      "deployers": [
        "zhihu"
      ],
      "developers": [
        "sangfor-technologies"
      ],
      "harmedParties": [
        "zhihu-employees",
        "chinese-tech-workers"
      ],
      "reports": [
        1662,
        1663,
        1664,
        1665
      ],
      "severity": "Low",
      "classification": "AI Incident",
      "region": "Eastern and South-Eastern Asia"
    },
    {
      "id": "ObjectId(629da7969e8fc9073246a3f2)",
      "incident_id": 209,
      "date": "2020-10-20",
      "title": "Tesla Disabled “Rolling Stop” Functionality Associated with the “Aggressive” Driving Mode",
      "description": "The “rolling stop” functionality within the “Aggressive” Full Self Driving (FSD) profile that was released via a Tesla firmware update was recalled and disabled.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "tesla-drivers"
      ],
      "reports": [
        1688,
        1689,
        1690,
        1691,
        1692
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62a045b0d1bc84a9cc93ad7a)",
      "incident_id": 219,
      "date": "2020-11-15",
      "title": "Poachers Evaded AI Cameras and Killed Four Rhinos",
      "description": "AI cameras installed by Ezemvelo KZN Wildlife failed to detect poachers when four dehorned rhino carcasses were found.",
      "deployers": [
        "ezemvelo-kzn-wildlife"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "rhinos-in-conservation"
      ],
      "reports": [
        1730
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6286854a3a32758144dd5fa7)",
      "incident_id": 189,
      "date": "2019-10-15",
      "title": "Opaque Fraud Detection Algorithm by the UK’s Department of Work and Pensions Allegedly Discriminated against People with Disabilities",
      "description": "People with disabilities were allegedly disproportionately targeted by a benefit fraud detection algorithm which the UK’s Department of Work and Pensions was urged to disclose.",
      "deployers": [
        "uk-department-of-work-and-pensions"
      ],
      "developers": [
        "uipath"
      ],
      "harmedParties": [
        "people-with-disabilities"
      ],
      "reports": [
        1609,
        1670,
        1671,
        1672,
        1673,
        1674
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(629f00a448f09c92aeb39c9e)",
      "incident_id": 214,
      "date": "2020-01-02",
      "title": "SN Technologies Reportedly Lied to a New York State School District about Its Facial and Weapon Detection Systems’ Performance",
      "description": "SN Technologies allegedly misled Lockport City Schools about the performance of its AEGIS face and weapons detection systems, downplaying error rates for Black faces and weapon misidentification.",
      "deployers": [
        "lockport-city-school-district"
      ],
      "developers": [
        "sn-technologies"
      ],
      "harmedParties": [
        "black-students"
      ],
      "reports": [
        1722
      ],
      "severity": "AI tangible harm near-miss",
      "classification": "yes",
      "sector": "Education, law enforcement, public administration",
      "region": "North America"
    },
    {
      "id": "ObjectId(629f09325fb208d11b8efe2d)",
      "incident_id": 215,
      "date": "2020-04-01",
      "title": "Facebook Content Moderators Demand Better Working Conditions Due to Allegedly Inadequate AI Content Moderation",
      "description": "Content moderators and employees at Facebook demand better working conditions, as automated content moderation system allegedly failed to achieve sufficient performance and exposed human reviewers to psychologically hazardous content such as graphic violence and child abuse.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "facebook-content-moderators"
      ],
      "reports": [
        1723
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6286888d158fde27b10d8dc5)",
      "incident_id": 192,
      "date": "2022-03-17",
      "title": "Three Make-Up Artists Lost Jobs Following Black-Box Automated Decision by HireVue",
      "description": "Three make-up artists lost their positions following an algorithmically-assessed video interview by HireVue who reportedly failed to provide adequate explanation of the findings.",
      "deployers": [
        "estee-lauder"
      ],
      "developers": [
        "hirevue"
      ],
      "harmedParties": [
        "pseudonymous-estee-lauder's-former-staff"
      ],
      "reports": [
        1616,
        1617
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(629f0db656a7be53bbed68fa)",
      "incident_id": 217,
      "date": "2016-11-16",
      "title": "Robot at a Chinese Tech Fair Smashed a Glass Booth, Injuring a Visitor",
      "description": "At the 18th China Hi-Tech Fair, a robot suddenly smashed through a glass booth and injured a visitor, after a staff member reportedly mistakenly pressed a button, causing it to reverse and accelerate.",
      "deployers": [
        "evolver"
      ],
      "developers": [
        "evolver"
      ],
      "harmedParties": [
        "fair-visitors"
      ],
      "reports": [
        1725,
        1726
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(629c5b57fbbeec2d0fb4fc64)",
      "incident_id": 208,
      "date": "2021-05-01",
      "title": "Tesla Phantom Braking Complaints Surged, Allegedly Linked to Tesla Vision Rollout",
      "description": "In late 2021, Tesla owners’ complaints to the National Highway Traffic Safety Administration about sudden unexpected automatic braking rapidly increased, coinciding with when radar was no longer equipped in its Model 3 and Model Y vehicles.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "tesla-drivers"
      ],
      "reports": [
        1683,
        1684,
        1685,
        1686,
        1687,
        1759,
        1760,
        1761
      ],
      "severity": "Medium",
      "classification": "AI Incident",
      "region": "Europe and Northern America"
    },
    {
      "id": "ObjectId(629dc73db462c8b2647f965e)",
      "incident_id": 212,
      "date": "2021-01-01",
      "title": "XPeng Motors Fined For Illegal Collection of Consumers’ Faces Using Facial Recognition Cameras",
      "description": "The Chinese electric vehicle (EV) firm XPeng Motors was fined by local market regulators for illegally collecting in-store customers’ facial images without their consent for six months.",
      "deployers": [
        "xpeng-motors"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "xpeng-motors-customers"
      ],
      "reports": [
        1711,
        1712,
        1713,
        1714
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(628ad5c80d8089cc43894760)",
      "incident_id": 193,
      "date": "2013-11-27",
      "title": "Excessive Automated Monitoring Alerts Ignored by Staff, Resulting in Private Data Theft of Seventy Million Target Customers",
      "description": "Alerts about a Target data breach were ignored by Minneapolis Target’s staff reportedly due to them being included with many other potential false alerts, and due to some of the company’s network infiltration alerting systems being off to reduce such false alerts, causing private data theft for millions of customers.  ",
      "deployers": [
        "target"
      ],
      "developers": [
        "fireeye"
      ],
      "harmedParties": [
        "target",
        "target-customers"
      ],
      "reports": [
        1620
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(628ae659d50929fc8d419df7)",
      "incident_id": 196,
      "date": "2013-09-01",
      "title": "Compromise of National Biometric ID Card System Leads to Reverification and Change of Status",
      "description": "When the leader of the Afghan Taliban was found possessing a valid ID card in the Pakistani national biometric identification database system, Pakistan launch a national re-verification campaign that is linked to numerous changes in recognition status and loss of services.",
      "deployers": [
        "pakistan-national-database-and-registration-authority"
      ],
      "developers": [
        "pakistan-national-database-and-registration-authority"
      ],
      "harmedParties": [
        "pakistani-citizens"
      ],
      "reports": [
        1633,
        1634,
        1635,
        1636,
        1637
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(629c4e9f9bed6f7732c7ee3f)",
      "incident_id": 207,
      "date": "2021-01-10",
      "title": "Hawaii Police Deployed Robot Dog to Patrol a Homeless Encampment",
      "description": "Honolulu Police Department spent federal pandemic relief funds on a robot dog to take body temperatures and patrol a homeless quarantine encampment which local civil rights advocates criticized as dehumanizing.",
      "deployers": [
        "honolulu-police-department"
      ],
      "developers": [
        "boston-dynamics"
      ],
      "harmedParties": [
        "honolulu-homeless-people"
      ],
      "reports": [
        1679,
        1680,
        1681,
        1682
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(629dbfd2927145fff913f831)",
      "incident_id": 211,
      "date": "2021-12-11",
      "title": "A Tesla Taxi Cab Involved in an Accident in Paris with Twenty Injuries",
      "description": "In Paris, about 20 people were injured in an accident involving a Tesla Model 3 taxi cab which was reportedly caused by a sudden unintended acceleration (SUA) episode and braking issues.",
      "deployers": [
        "taxis-g7"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "pedestrians"
      ],
      "reports": [
        1696,
        1697,
        1698,
        1699,
        1700,
        1701,
        1702
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6285d69123ec6cb0db5c574a)",
      "incident_id": 187,
      "date": "2022-02-04",
      "title": "YouTuber Tested Tesla on Self Driving Mode, Colliding with Street Pylons",
      "description": "A YouTuber who was a Tesla’s employee conducted an on-road review of Tesla's Full Self Driving (FSD) Beta, showing its navigation in various road environments in San Jose and collision with a bollards during Autopilot, allegedly causing his dismissal from the company.",
      "deployers": [
        "ai-addict"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "john-bernal",
        "san-jose-public"
      ],
      "reports": [
        1596,
        1597,
        1598
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6285caf4c4ac527644be031f)",
      "incident_id": 185,
      "date": "2022-03-01",
      "title": "TikTok's For You Algorithm Directed New Users towards Disinformation about the War in Ukraine",
      "description": " An investigation by NewsGuard into TikTok’s handling of content related to the Russia-Ukraine war showed its “For You” algorithm pushing new users towards false and misleading content about the war within less than an hour of signing up.",
      "deployers": [
        "tiktok"
      ],
      "developers": [
        "tiktok"
      ],
      "harmedParties": [
        "tiktok-users",
        "tiktok-new-users"
      ],
      "reports": [
        1586,
        1587,
        1588,
        1589
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(629874f4257531f2d69d1030)",
      "incident_id": 205,
      "date": "2022-02-25",
      "title": "AI-Generated Profiles Used in Disinformation Campaign Targeting Ukrainians",
      "description": "According to security reports by Meta, fictitious personas with GAN-generated profile pictures were used by people operating in Russia and Ukraine to push a disinformation campaign targeting Ukrainian social media users, and were taken down.",
      "deployers": [
        "individuals-in-the-donbass-region",
        "individuals-in-russia",
        "media-organizations-in-crimea"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "ukrainian-social-media-users"
      ],
      "reports": [
        1666,
        1667,
        1668,
        1669
      ],
      "severity": "none",
      "classification": "no",
      "sector": "Arts, entertainment and recreation, information and communication",
      "region": "Europe"
    },
    {
      "id": "ObjectId(629f165a47b12f3b70c05fa4)",
      "incident_id": 218,
      "date": "2020-06-01",
      "title": "Tesla on Autopilot Crashed into Flipped Truck on Taiwan Highway",
      "description": "On a highway in Taiwan, a Tesla Sedan, reportedly operating on Autopilot mode, crashed into a large overturned truck, barely missing a pedestrian.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "delivery-truck",
        "pedestrians",
        "tesla-drivers"
      ],
      "reports": [
        1727,
        1728,
        1950
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(628aeecad50929fc8d43513b)",
      "incident_id": 197,
      "date": "2021-10-01",
      "title": "Facebook Internally Reported Failure of Ranking Algorithm, Exposing Harmful Content to Viewers over Months",
      "description": "Facebook's internal report showed an at-least six-month long alleged software bug that caused moderator-flagged posts and other harmful content to evade down-ranking filters, leading to surges of misinformation on users' News Feed.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "facebook-users"
      ],
      "reports": [
        1638,
        1639,
        1640,
        1641
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(628af5401212a93e232c56d3)",
      "incident_id": 199,
      "date": "2019-04-01",
      "title": "Ever AI Reportedly Deceived Customers about FRT Use in App",
      "description": "Ever AI, now Paravision AI, allegedly failed to inform customers about the development and use of facial recognition that facilitates the sale of customers’ data to various businesses, a business model that critics said was an egregious violation of privacy.",
      "deployers": [
        "ever-ai"
      ],
      "developers": [
        "ever-ai"
      ],
      "harmedParties": [
        "ever-ai-users"
      ],
      "reports": [
        1647,
        1648,
        1649,
        1650,
        1651,
        2024,
        2031
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(629db470fee4758bdce67001)",
      "incident_id": 210,
      "date": "2020-04-28",
      "title": "Indian Political App Tek Fog Allegedly Hijacked Trends and Manipulated Public Opinion on Other Social Media Platforms",
      "description": "The Indian political social media app Tek Fog allegedly allowed operatives affiliated with the ruling political party to hijack social media trends and manipulate public opinion on other apps such as Twitter and WhatsApp, which opposition parties denounced as a national security threat.",
      "deployers": [
        "bharatiya-janata-yuva-morcha"
      ],
      "developers": [
        "persistent-systems"
      ],
      "harmedParties": [
        "indian-voters",
        "indian-social-media-users",
        "indian-women-journalists"
      ],
      "reports": [
        1693,
        1694,
        1695
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62a7205b15d14c6d6ceba1a5)",
      "incident_id": 235,
      "date": "2016-04-15",
      "title": "Chinese Insurer Ping An Employed Facial Recognition to Determine Customers’ Untrustworthiness, Which Critics Alleged to Likely Make Errors and Discriminate",
      "description": "Customers’ untrustworthiness and unprofitability were reportedly determined by Ping An, a large insurance company in China, via facial-recognition measurements of micro-expressions and body-mass indices (BMI), which critics argue was likely to make mistakes, discriminate against certain ethnic groups, and undermine its own industry.",
      "deployers": [
        "ping-an"
      ],
      "developers": [
        "ping-an"
      ],
      "harmedParties": [
        "ping-an-customers",
        "chinese-minority-groups"
      ],
      "reports": [
        1756
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62a6c3e11cea23c4caf38bc5)",
      "incident_id": 227,
      "date": "2018-01-12",
      "title": "Waze App Allegedly Caused Tourists’ Car to End up in Lake Champlain, Vermont",
      "description": "The tourists driving through Vermont blamed Waze for directing them into a boat launch in Lake Champlain, prompting the vehicle to slide into the water by the time the drivers realized their location in the dark and foggy weather.",
      "deployers": [
        "waze"
      ],
      "developers": [
        "waze"
      ],
      "harmedParties": [
        "tourists",
        "waze-users"
      ],
      "reports": [
        1744,
        1973,
        1974
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62a19d1f6a8a811a6084ea37)",
      "incident_id": 222,
      "date": "2020-07-18",
      "title": "Thoughts App Allegedly Created Toxic Tweets",
      "description": "Tweets created by Thoughts, a tweet generation app that leverages OpenAI’s GPT-3, allegedly exhibited toxicity when given prompts related to minority groups.",
      "deployers": [
        "satria-technologies"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "thoughts-users",
        "twitter-users"
      ],
      "reports": [
        1735
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62a1a65fae26c04e23c48fcd)",
      "incident_id": 223,
      "date": "2019-10-09",
      "title": "Hive Box Facial-Recognition Locks Hacked by Fourth Graders Using Intended Recipient’s Facial Photo",
      "description": "Facial-recognition locks by Hive Box, an express delivery locker company in China, were easily opened by a group of fourth-graders in a science-club demo using only a printed photo of the intended recipient’s face, leaving contents vulnerable to theft.",
      "deployers": [
        "hive-box"
      ],
      "developers": [
        "hive-box"
      ],
      "harmedParties": [
        "hive-box-customers"
      ],
      "reports": [
        1737
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62a6d3542cccb6726ae25091)",
      "incident_id": 229,
      "date": "2018-04-23",
      "title": "Content Using Bestiality Thumbnails Allegedly Evaded YouTube’s Thumbnail Monitoring System",
      "description": "YouTube’s thumbnail monitoring system was allegedly evaded by content farms such as ones in Cambodia who spike viewership and generate ad revenue using bestiality-themed thumbnails.",
      "deployers": [
        "youtube"
      ],
      "developers": [
        "youtube"
      ],
      "harmedParties": [
        "youtube-users",
        "youtube-content-creators"
      ],
      "reports": [
        1746,
        1747
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62a1ab6756a7be53bb9096a4)",
      "incident_id": 224,
      "date": "2020-07-01",
      "title": "WeChat Pay's Facial Recognition Security Evaded by Scammers Using Victims’ Social Media Content",
      "description": "In China, fraudsters bypassed facial-recognition security for online financial transactions on WeChat Pay by crafting identity-verification GIFs of victims from their selfies on WeChat Moments, a social media platform.",
      "deployers": [
        "wechat-pay"
      ],
      "developers": [
        "wechat"
      ],
      "harmedParties": [
        "wechat-pay-users"
      ],
      "reports": [
        1738
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62a98ef2cfb6a09201e5595e)",
      "incident_id": 239,
      "date": "2009-09-01",
      "title": "Algorithmic Teacher Evaluation Program Failed Student Outcome Goals and Allegedly Caused Harm Against Teachers",
      "description": "Gates-Foundation-funded Intensive Partnerships for Effective Teaching Initiative’s algorithmic program to assess teacher performance reportedly failed to achieve its goals for student outcomes, particularly for minority students, and was criticized for potentially causing harm against teachers.",
      "deployers": [
        "intensive-partnerships-for-effective-teaching"
      ],
      "developers": [
        "intensive-partnerships-for-effective-teaching"
      ],
      "harmedParties": [
        "students",
        "low-income-minority-students",
        "teachers"
      ],
      "reports": [
        1764
      ],
      "severity": "unclear",
      "classification": "yes"
    },
    {
      "id": "ObjectId(62a1b2ba9b0df3a9e564faf2)",
      "incident_id": 225,
      "date": "2017-04-07",
      "title": "IBM Watson for Oncology Criticized by Customers for Allegedly Unsafe and Inaccurate Cancer Treatment Recommendations",
      "description": "Internal documents from IBM Watson Health showed negative assessments from customers such as Florida’s Jupiter Hospital and Memorial Sloan Kettering criticizing its Watson for Oncology product for allegedly unsafe and incorrect cancer treatment recommendations.",
      "deployers": [
        "jupiter-hospital",
        "memorial-sloan-kettering"
      ],
      "developers": [
        "ibm-watson-health"
      ],
      "harmedParties": [
        "oncologists",
        "cancer-patients"
      ],
      "reports": [
        1739,
        1740
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62a70b1e97c1945c062019f1)",
      "incident_id": 232,
      "date": "2018-04-29",
      "title": "Tesla Model X on Autopilot Missed Parked Vehicles and Pedestrians, Killing Motorcyclist in Japan",
      "description": "A Tesla Model X operated on Autopilot reportedly failed to recognize the parked motorcycles, pedestrians, and van in its path in Kanagawa, Japan, and ran over a motorcyclist who previously stopped when a member of his motorcyclist group was involved in an accident.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "yoshihiro-umeda",
        "pedestrians",
        "tesla-drivers"
      ],
      "reports": [
        1751,
        1752,
        1975,
        2018
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62de08794ad8b68d9e3be1ad)",
      "incident_id": 242,
      "date": "2021-02-24",
      "title": "Manufacturing Robot Failure Caused Factory Worker's Death in India",
      "description": "A sensor snag resulted in an automotive parts factory robot falling on a factory worker in India",
      "deployers": [
        "chakan-plant-of-automotive-stampings-and-assemblies"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "umesh-ramesh-dhake"
      ],
      "reports": [
        1775
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62df75b523ef2c676c07d179)",
      "incident_id": 244,
      "date": "2020-08-03",
      "title": "Colorado Police’s Automated License Plate Reader (ALPR) Matched a Family’s Minivan’s Plate to That of a Stolen Vehicle Allegedly, Resulting in Detainment at Gunpoint",
      "description": "An automated plate reader reportedly matched a license plate information, but of a family’s minivan and an alleged motorcycle in Montana that was reportedly stolen earlier in the year, resulting in them and their children being held at gunpoint and detained in handcuffs by multiple Aurora police officers.",
      "deployers": [
        "aurora-police-department"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "the-gilliam-family"
      ],
      "reports": [
        1783
      ],
      "severity": "AI tangible harm event",
      "classification": "yes"
    },
    {
      "id": "ObjectId(62a70f6215d14c6d6ce9e579)",
      "incident_id": 233,
      "date": "2018-12-03",
      "title": "Tumblr Automated Pornography-Detecting Algorithms Erroneously Flagged Inoffensive Images as Explicit",
      "description": "Tumblr’s automated tools to identify adult content were reported to have incorrectly flagged inoffensive images as explicit, following its announcement to ban all adult content on the platform.",
      "deployers": [
        "tumblr"
      ],
      "developers": [
        "tumblr"
      ],
      "harmedParties": [
        "tumblr-content-creators",
        "tumblr-users"
      ],
      "reports": [
        1753
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62a6d8341cea23c4caf855ce)",
      "incident_id": 230,
      "date": "2019-03-01",
      "title": "Model 3 Tesla on Autopilot Crashed into a Truck in Florida, Killing Driver",
      "description": "In Florida, a Model 3 Tesla on Autopilot mode crashed into a tractor-trailer truck, killing the 50-year-old driver.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "jeremy-beren-banner",
        "tesla-users"
      ],
      "reports": [
        1748
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62df76e9a6f43c979e242859)",
      "incident_id": 246,
      "date": "2014-04-16",
      "title": "Misreading of an Automated License Plate Reader (ALPR) Unverified by Police, Resulting in Traffic Stop in Missouri",
      "description": "An automated license plate reader (ALPR) camera misread a 7 as a 2 and incorrectly alerted the local police about a stolen Oldsmobile car, which was allegedly not able to be verified by an officer before a traffic stop was effected on a BMW in Kansas City suburb.",
      "deployers": [
        "prairie-village-police-department"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "mark-molner"
      ],
      "reports": [
        1785,
        1787
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62a6c8ed1b7b69ce98ebe04c)",
      "incident_id": 228,
      "date": "2019-02-01",
      "title": "Apple Maps Allegedly Directed Ski Trip Couple Onto Unpaved Road in the Mountains",
      "description": "Near Los Angeles, Apple Maps allegedly directed a couple on a ski trip in the mountains toward into an unconventional route out of town, where the drivers found themselves lost and stuck on an unpaved road in the snow.",
      "deployers": [
        "apple"
      ],
      "developers": [
        "apple"
      ],
      "harmedParties": [
        "tourists",
        "apple-maps-users"
      ],
      "reports": [
        1745
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62a6dccdf24b23be1794e864)",
      "incident_id": 231,
      "date": "2016-01-20",
      "title": "A Tesla Crashed into and Killed a Road Sweeper on a Highway in China",
      "description": "A Tesla Model S collided with and killed a road sweeper on a highway near Handan, China, an accident where Tesla previously said it was not able to determine whether Autopilot was operating at the time of the crash.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "gao-yaning",
        "tesla-drivers"
      ],
      "reports": [
        1749,
        1750,
        208,
        1945
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62df765656418e2a5bdd7c06)",
      "incident_id": 245,
      "date": "2009-03-30",
      "title": "Unverified Misreading by Automated Plate Reader Led to Traffic Stop and Restraint of an Innocent Person at Gunpoint in California",
      "description": "In San Francisco, an automated license plate reader (ALPR) camera misread a number as belonging to a stolen vehicle having the wrong make, but its photo was not visually confirmed by the police due to poor quality and allegedly despite multiple chances prior to making a traffic stop, causing an innocent person to be pulled over at gunpoint and restrained in handcuffed.",
      "deployers": [
        "san-francisco-police-department"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "denise-green"
      ],
      "reports": [
        1784
      ],
      "severity": "AI tangible harm event",
      "classification": "yes"
    },
    {
      "id": "ObjectId(62e0aad0a6f43c979e3e6e1b)",
      "incident_id": 248,
      "date": "2018-11-23",
      "title": "Automated License Plate Camera Notified Police about a Previously Stolen Rental Car that was Returned, Causing an Innocent Person to be Detained at Gunpoint in California",
      "description": "In Oakland, a previously stolen rental car that was returned but allegedly not updated in the police database was pinged by an automated license plate reader (ALPR) camera, leading to police’s wrongful detainment of an innocent person reportedly using excessive force and improper conduct.",
      "deployers": [
        "contra-costa-county-sheriff"
      ],
      "developers": [
        "vigilant-solutions"
      ],
      "harmedParties": [
        "brian-hofer"
      ],
      "reports": [
        1789,
        1790
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62a725b6a147e7dbd3894c5d)",
      "incident_id": 236,
      "date": "2022-04-13",
      "title": "AI-Generated Faces Used by Scammers to Pose as a Law Firm in Boston",
      "description": "GAN faces were allegedly used by scammers alongside a parked domain and a fake website to impersonate a Boston law firm.",
      "deployers": [
        "scammers"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "email-users"
      ],
      "reports": [
        1757
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62a717230927356849c4d5df)",
      "incident_id": 234,
      "date": "2019-09-06",
      "title": "Waze Allegedly Frequently Routed Drivers through the Town of Los Gatos, Blocking Its Single Wildfire Escape Route",
      "description": "Waze app was blamed by Los Gatos town residents for contributing to high wildfire hazard risk via allegedly routing weekend beach-going drivers through their neighborhoods, effectively choking off their single escape route in the event of a medical emergency or wildfire.",
      "deployers": [
        "waze"
      ],
      "developers": [
        "waze"
      ],
      "harmedParties": [
        "los-gatos-residents"
      ],
      "reports": [
        1754,
        1755
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62a8e5811afd5f65688b4c58)",
      "incident_id": 238,
      "date": "2018-10-01",
      "title": "Oregon’s Screening Tool for Child Abuse Cases Discontinued Following Concerns of Racial Bias",
      "description": "Oregon’s Department of Human Services (DHS) stopped using its Safety at Screening Tool, that is aimed to predict the risk that children wind up in foster care or be investigated in the future, and opted for a new process allegedly to reduce disparities and improve racially equitable decision-making.",
      "deployers": [
        "oregon-department-of-human-services"
      ],
      "developers": [
        "oregon-department-of-human-services"
      ],
      "harmedParties": [
        "children-of-minority-groups",
        "families-of-minority-groups"
      ],
      "reports": [
        1762
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62a31418ae26c04e232cbb19)",
      "incident_id": 226,
      "date": "2015-04-01",
      "title": "Waze Allegedly Clogged Streets and Directed Drivers to Make Unsafe Traffic Decisions",
      "description": "For years, Waze has, in an attempt to cut travel times, allegedly caused more traffic and guided drivers to make unsafe and often un-permitted traffic decisions, which was described by a Los Angeles city council member as a threat to public safety.",
      "deployers": [
        "waze"
      ],
      "developers": [
        "waze"
      ],
      "harmedParties": [
        "sherman-oaks-residents",
        "waze-users",
        "los-angeles-city-government"
      ],
      "reports": [
        1741,
        1742,
        1743
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62de06966bb8effab3aa069d)",
      "incident_id": 241,
      "date": "2022-07-21",
      "title": "Chess-Playing Robot Broke Child's Finger in Russia",
      "description": "A chess robot at a tournament in Russia broke the finger of a child who reached onto the board before the robot had completed its move",
      "deployers": [
        "russian-chess-federation"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "child-named-christopher"
      ],
      "reports": [
        1772,
        1773,
        1774,
        1776,
        1781
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62b65a72b7a838d899c3005c)",
      "incident_id": 240,
      "date": "2021-06-29",
      "title": "GitHub Copilot, Copyright Infringement and Open Source Licensing",
      "description": "Users of GitHub Copilot can produce source code subject to license requirements without attributing and licensing the code to the rights holder.",
      "deployers": [
        "github",
        "programmers"
      ],
      "developers": [
        "github"
      ],
      "harmedParties": [
        "intellectual-property-rights-holders"
      ],
      "reports": [
        1767,
        1768,
        1769,
        1770,
        2230
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62df67d35939a0bbe4e9d758)",
      "incident_id": 243,
      "date": "2020-01-01",
      "title": "Bots Allegedly Made up Roughly Half of Twitter Accounts in Discussions Surrounding COVID-19 Related Issues",
      "description": "Bots by anonymous actors were found by researchers to make up roughly half of Twitter accounts participating in COVID-19 discussions, many of which posted tweets about “reopening America“.",
      "deployers": [
        "unknown"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "twitter",
        "twitter-users",
        "twitter-users-participating-in-covid-19-discussions"
      ],
      "reports": [
        1777,
        1778
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62ea330f50582f2a6babdf2b)",
      "incident_id": 270,
      "date": "2011-04-18",
      "title": "Apple Tweaked App Store Ranking Algorithms, Allegedly Resulted in Demotion of Local Apps in China",
      "description": "Following Apple’s changes in ranking algorithm in its iTunes App Store, apps by allegedly reputable companies and local startups in China experienced significant drops in ranking order.",
      "deployers": [
        "apple"
      ],
      "developers": [
        "apple"
      ],
      "harmedParties": [
        "renren",
        "buding-movie-tickets",
        "yi-xia",
        "dangdang",
        "chinese-startups",
        "chinese-companies"
      ],
      "reports": [
        1851
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62ee0aa455716343a47d06a5)",
      "incident_id": 271,
      "date": "2022-07-24",
      "title": "Tesla Model 3 Sedan on Autopilot Killed Motorcyclist in a Rear-End Collision in Utah",
      "description": "A Tesla Model 3 operating on Autopilot mode slammed into the back of a Harley-Davidson motorcycle on an interstate in Utah, throwing the rider from the bike and killing him instantly.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "landon-embry",
        "motorcyclists",
        "tesla-drivers"
      ],
      "reports": [
        1852,
        1861,
        1862
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62ea2d14e98668f51871cdfa)",
      "incident_id": 268,
      "date": "2020-03-16",
      "title": "Permanent Removal of Social Media Content via Automated Tools Allegedly Prevented Investigative Efforts",
      "description": "Automated permanent removal of violating social media content, such as terrorism, violent extremism, and hate speech, without archival has allegedly hindered the potential use of this content for investigating serious crimes and hampered efforts in criminal accountability.",
      "deployers": [
        "youtube",
        "twitter",
        "facebook"
      ],
      "developers": [
        "youtube",
        "twitter",
        "facebook"
      ],
      "harmedParties": [
        "victims-of-crimes-documented-on-social-media",
        "investigative-journalists",
        "international-criminal-court-investigators",
        "international-court-of-justice-investigators",
        "criminal-investigators"
      ],
      "reports": [
        1849,
        1929,
        3905,
        3906
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62e0b35fd1725b4ba7c3444a)",
      "incident_id": 251,
      "date": "2018-08-01",
      "title": "Amazon Allegedly Tweaked Search Algorithm to Boost Its Own Products",
      "description": "Amazon tweaked product-search algorithm to boost and guide customers towards more profitable in-house products instead of showing mainly most-relevant and best-selling listings, which its internal engineers and lawyers alleged to violate company’s best-for-customer principle.",
      "deployers": [
        "amazon"
      ],
      "developers": [
        "amazon"
      ],
      "harmedParties": [
        "small-businesses-on-amazon",
        "amazon-customers"
      ],
      "reports": [
        1794,
        2384,
        2975
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62f2040555716343a41ffb47)",
      "incident_id": 273,
      "date": "2020-12-24",
      "title": "FaceApp Predicted Different Genders for Similar User Photos with Slight Variations",
      "description": "FaceApp’s algorithm was reported by a user to have predicted different genders for two mostly identical facial photos with only a slight difference in eyebrow thickness.",
      "deployers": [
        "faceapp"
      ],
      "developers": [
        "faceapp"
      ],
      "harmedParties": [
        "faceapp-non-binary-presenting-users",
        "faceapp-transgender-users",
        "faceapp-users"
      ],
      "reports": [
        1856
      ],
      "severity": "none",
      "classification": "yes"
    },
    {
      "id": "ObjectId(62e78c54929b426d214e30ed)",
      "incident_id": 259,
      "date": "2022-06-03",
      "title": "YouTuber Built, Made Publicly Available, and Released Model Trained on Toxic 4chan Posts as Prank",
      "description": "A YouTuber built GPT-4chan, a model based on OpenAI’s GPT-J and trained on posts containing racism, misogyny, and antisemitism collected from 4chan’s “politically incorrect” board, which he made publicly available, and deployed as multiple bots posting thousands of messages on the same 4chan board as a prank.",
      "deployers": [
        "yannic-kilcher"
      ],
      "developers": [
        "yannic-kilcher"
      ],
      "harmedParties": [
        "internet-social-platform-users"
      ],
      "reports": [
        1822,
        1842
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62e51c32981a526a00e7e1b2)",
      "incident_id": 255,
      "date": "2020-05-31",
      "title": "Unreliable ShotSpotter Audio Previously Used to Convict Chicago Man in Murder Case",
      "description": "ShotSpotter audios were previously admitted to convict an innocent Black man in a murder case in Chicago, resulted in his nearly-one-year-long arrest before being dismissed by prosecutors as insufficient evidence.",
      "deployers": [
        "chicago-police-department"
      ],
      "developers": [
        "shotspotter"
      ],
      "harmedParties": [
        "michael-williams"
      ],
      "reports": [
        1805,
        1806,
        1807,
        1808,
        1809,
        1431,
        1811,
        1812,
        1813
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62ea182550582f2a6ba7f130)",
      "incident_id": 266,
      "date": "2022-01-15",
      "title": "Replika's AI Companions Reportedly Abused by Its Users",
      "description": "Replika's AI-powered digital companions was allegedly abused by their users, who posted on Reddit abusive behaviors and interactions such as using slurs, roleplaying violent acts, and stimulating sexual abuse.",
      "deployers": [
        "replika"
      ],
      "developers": [
        "replika"
      ],
      "harmedParties": [
        "replika-users",
        "replika-male-users",
        "replika"
      ],
      "reports": [
        1844,
        2532,
        2533,
        2534,
        2535,
        2536,
        2537,
        2538
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62e0c365a6f43c979e413e86)",
      "incident_id": 253,
      "date": "2022-05-18",
      "title": "Cruise's Self-Driving Cars Allegedly Lost Connection to Their Server, Causing Traffic Blockages in San Francisco",
      "description": "Cruise’s autonomous vehicles were shown on video stopping in the middle of the road and causing blockages in San Francisco, as they were disabled allegedly due to lost connection to their company’s server.",
      "deployers": [
        "cruise"
      ],
      "developers": [
        "cruise"
      ],
      "harmedParties": [
        "san-francisco-traffic-participants",
        "san-francisco-public"
      ],
      "reports": [
        1796,
        1797,
        1798,
        1799
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62e0ad4dd1725b4ba7c29784)",
      "incident_id": 249,
      "date": "2016-10-01",
      "title": "Government Deployed Extreme Surveillance Technologies to Monitor and Target Muslim Minorities in Xinjiang",
      "description": "A suite of AI-powered digital surveillance systems involving facial recognition and analysis of biometric data were deployed by the Chinese government in Xinjiang to monitor and discriminate local Uyghur and other Turkic Muslims.",
      "deployers": [
        "chinese-government"
      ],
      "developers": [
        "chinese-government"
      ],
      "harmedParties": [
        "uyghur-people",
        "turkic-muslim-ethnic-groups"
      ],
      "reports": [
        1791,
        1792
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62e0cfd6a6f43c979e428116)",
      "incident_id": 254,
      "date": "2015-05-01",
      "title": "Google’s Face Grouping Allegedly Collected and Analyzed Users’ Facial Structure without Consent, Violated BIPA",
      "description": "A class-action lawsuit alleged Google failing to provide notice, obtain informed written consent, or publish data retention policies about the collection, storage, and analysis of its face-grouping feature in Google Photos, which violated Illinois Biometric Information Privacy Act (BIPA).",
      "deployers": [
        "google"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "google-photos-users-residing-in-illinois",
        "google-photos-users",
        "illinois-residents"
      ],
      "reports": [
        1804,
        2069
      ],
      "severity": "AI tangible harm event",
      "classification": "no"
    },
    {
      "id": "ObjectId(62e53195eac42ca1004d3eea)",
      "incident_id": 256,
      "date": "2021-11-07",
      "title": "DUI Arrest Case Allegedly Based Only on ShotSpotter's Alert",
      "description": "A car stop resulting in a DUI arrest of its driver was allegedly based solely on a ShotSpotter alert, the reliability of which came into question by public defenders, who subpoenaed the company to assess its gunshot alert system.",
      "deployers": [
        "chicago-police-department"
      ],
      "developers": [
        "shotspotter"
      ],
      "harmedParties": [
        "chicago-drivers"
      ],
      "reports": [
        1814
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62e0afa523ef2c676c22b9b5)",
      "incident_id": 250,
      "date": "2016-02-01",
      "title": "Dutch City Court Defended Home Value Generated by Black-Box Algorithm",
      "description": "A home value generated by a black-box algorithm was reportedly defended by the Castricum court, which was criticized by a legal specialist for setting a dangerous precedent for accepting black-box algorithms as long as their results appear reasonable.",
      "deployers": [
        "castricum-municipality"
      ],
      "developers": [
        "castricum-municipality"
      ],
      "harmedParties": [
        "unnamed-property-owner"
      ],
      "reports": [
        1793
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62e6193e981a526a0059d8cf)",
      "incident_id": 258,
      "date": "2022-05-13",
      "title": "Australian Retailers Reportedly Captured Face Prints of Their Customers without Consent",
      "description": "Major Australian retailers reportedly analyzed in-store footage to capture facial features of their customers without consent, which was criticized by consumer groups as creepy and invasive.",
      "deployers": [
        "the-good-guys",
        "kmart",
        "bunnings"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "the-good-guys-customers",
        "kmart-customers",
        "bunnings-customers"
      ],
      "reports": [
        1819,
        1820
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62f2041455716343a41ffd1a)",
      "incident_id": 274,
      "date": "2003-07-01",
      "title": "Virginia Courts’ Algorithmic Recidivism Risk Assessment Failed to Lower Incarceration Rates",
      "description": "Virginia courts’ use of algorithmic predictions of future offending risks were found by researchers failing to reduce incarceration rates, showed racial and age disparities in risk scores and its application, and neither exacerbated or ameliorated historical racial differences in sentencing.",
      "deployers": [
        "virginia-courts"
      ],
      "developers": [
        "virginia-department-of-criminal-justice-services"
      ],
      "harmedParties": [
        "virginia-convicted-felons",
        "virginia-black-offenders",
        "virginia-young-offenders"
      ],
      "reports": [
        1857,
        1859
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62ea1f06e98668f5186fdbb5)",
      "incident_id": 267,
      "date": "2017-06-15",
      "title": "Clearview AI Algorithm Built on Photos Scraped from Social Media Profiles without Consent",
      "description": "Face-matching algorithm by Clearview AI was built using scraped images from social media sites such as Instagram and Facebook without user consent, violating social media site policies, and allegedly privacy regulations.",
      "deployers": [
        "clearview-ai"
      ],
      "developers": [
        "clearview-ai"
      ],
      "harmedParties": [
        "social-media-users",
        "instagram-users",
        "facebook-users"
      ],
      "reports": [
        1845,
        1846,
        1847,
        1848,
        2101,
        2141,
        2142,
        2143,
        2144,
        2226
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62e6066deac42ca100acf90b)",
      "incident_id": 257,
      "date": "2012-05-04",
      "title": "Police Reportedly Deployed ShotSpotter Sensors Disproportionately in Neighborhoods of Color",
      "description": "Police departments disproportionately placed ShotSpotter sensors in black and brown neighborhoods, which is denounced by communities for allegedly creating dangerous situations, such as one involving in Adam Toledo's death.",
      "deployers": [
        "kansas-city-police-department",
        "cleveland-division-of-police",
        "chicago-police-department",
        "atlanta-police-department"
      ],
      "developers": [
        "shotspotter"
      ],
      "harmedParties": [
        "neighborhoods-of-color",
        "brown-communities",
        "black-communities",
        "adam-toledo"
      ],
      "reports": [
        1815,
        1435,
        1821,
        2250
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62e8aafa2db96a8ab9f74396)",
      "incident_id": 264,
      "date": "2022-03-01",
      "title": "AI-Based Vehicle Speed Estimation App Denounced by UK Drivers as Surveillance Technology",
      "description": "Speedcam Anywhere, an app allowing users to document and report traffic violations via AI-based videographic speed estimation of a vehicle, raised concerns for UK drivers about its capabilities for surveillance and abuse.",
      "deployers": [
        "speedcam-anywhere"
      ],
      "developers": [
        "speedcam-anywhere"
      ],
      "harmedParties": [
        "uk-drivers"
      ],
      "reports": [
        1839
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62e0babc23ef2c676c23eca3)",
      "incident_id": 252,
      "date": "2022-06-01",
      "title": "Remotely Operated Taser-Armed Drones Proposed by Taser Manufacturer as Defense for School Shootings in the US",
      "description": "Axon Enterprise considered development of remotely operated drones capable of tasering at a target a short distance away as a defense mechanism for mass shootings, despite its internal AI ethics board’s previous objection and condemnation as dangerous and fantastical.",
      "deployers": [
        "none"
      ],
      "developers": [
        "axon-enterprise"
      ],
      "harmedParties": [
        "us-schools",
        "us-students"
      ],
      "reports": [
        1795
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62f1fd1da076fc957e0b0b26)",
      "incident_id": 272,
      "date": "2019-10-08",
      "title": "Grab Tweaked Matchmaking Algorithm, Providing Preferential Treatment to Drivers Registered with Affiliated Car Rental Service",
      "description": "Grab Indonesia was fined by the Indonesian Competition Commission (KPPU) for unfairly favoring drivers who rented cars via the Grab-affiliated company Teknologi Pengangkutan Indonesia (TPI), including offering more rides via their matchmaking algorithm.",
      "deployers": [
        "grab"
      ],
      "developers": [
        "grab"
      ],
      "harmedParties": [
        "non-tpi-registered-grab-drivers",
        "grab-drivers-in-indonesia",
        "grab-drivers"
      ],
      "reports": [
        1853,
        1854,
        1855
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62e7c7750a8b81000ba6c913)",
      "incident_id": 260,
      "date": "2014-08-26",
      "title": "US DHS’s Opaque Vetting Software Allegedly Relied on Poor-Quality Data and Discriminated against Immigrants",
      "description": "US Citizenship and Immigration Services (USCIS)’s ATLAS software used in vetting immigration requests was condemned by advocacy groups as a threat to naturalized citizens for its secretive algorithmic decision-making, reliance on poor quality data and unknown sources, and alleged discrimination of immigrants using biometric and sensitive information.",
      "deployers": [
        "us-department-of-homeland-security",
        "us-citizenship-and-immigration-services"
      ],
      "developers": [
        "us-citizenship-and-immigration-services"
      ],
      "harmedParties": [
        "us-naturalized-citizens",
        "us-immigrants",
        "us-citizenship-applicants",
        "us-immigration-applicants"
      ],
      "reports": [
        1823,
        1831
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62e7cd5d138e1db3a1511a0a)",
      "incident_id": 261,
      "date": "2017-11-15",
      "title": "Robot Deployed by Animal Shelter to Patrol Sidewalks outside Its Office, Warding off Homeless People in San Francisco",
      "description": "Society for the Prevention of Cruelty to Animals (SPCA) deployed a Knightscope robot to autonomously patrol the area outside its office and ward off homeless people, which was criticized by residents as a tool of intimidation and ordered by the city of San Francisco to stop its use on a public right-of-way.",
      "deployers": [
        "society-for-the-prevention-of-cruelty-to-animals"
      ],
      "developers": [
        "knightscope"
      ],
      "harmedParties": [
        "san-francisco-homeless-people"
      ],
      "reports": [
        1824,
        1825,
        1826,
        1827,
        1828,
        1829,
        1830,
        1832
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62e7dd265f2757eae1db9659)",
      "incident_id": 262,
      "date": "2022-06-11",
      "title": "DALL-E Mini Reportedly Reinforced or Exacerbated Societal Biases in Its Outputs as Gender and Racial Stereotypes",
      "description": "Publicly deployed open-source model DALL-E Mini was acknowledged by its developers and found by its users to have produced images which reinforced racial and gender biases.",
      "deployers": [
        "boris-dayma"
      ],
      "developers": [
        "boris-dayma",
        "suraj-patil",
        "pedro-cuenca",
        "khalid-saifullah",
        "tanishq-abraham",
        "phuc-le-khac",
        "luke-melas",
        "ritobrata-ghosh"
      ],
      "harmedParties": [
        "minority-groups",
        "underrepresented-groups"
      ],
      "reports": [
        1833,
        1834,
        1835,
        1836
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62e89ea3088b12099cc26a44)",
      "incident_id": 263,
      "date": "2015-09-01",
      "title": "YouTube Recommendations Implicated in Political Radicalization of User",
      "description": "YouTube’s personalization and recommendation algorithms were alleged to have pushed and exposed its young male users to political extremism and misinformation, driving them towards far-right ideologies such as neo-Nazism and white supremacy.",
      "deployers": [
        "youtube"
      ],
      "developers": [
        "youtube"
      ],
      "harmedParties": [
        "youtube-young-male-users",
        "youtube-male-users",
        "caleb-cain"
      ],
      "reports": [
        1838
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62e8b8575890dc007562661a)",
      "incident_id": 265,
      "date": "2021-04-01",
      "title": "Black Uber Eats Driver Allegedly Subjected to Excessive Photo Checks and Dismissed via FRT Results",
      "description": "A lawsuit by a former Uber Eats delivery driver alleged the company to have wrongfully dismissed him due to frequent false mismatches of his verification selfies, and discriminated against him via excessive verification checks.",
      "deployers": [
        "uber-eats"
      ],
      "developers": [
        "uber-eats"
      ],
      "harmedParties": [
        "pa-edrissa-manjang",
        "uber-eats-black-delivery-drivers"
      ],
      "reports": [
        1840,
        1841
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62f3498bfa57b6f30ec2f015)",
      "incident_id": 278,
      "date": "2022-08-07",
      "title": "Meta’s BlenderBot 3 Chatbot Demo Made Offensive Antisemitic Comments",
      "description": "The publicly launched conversational AI demo BlenderBot 3 developed by Meta was reported by its users and acknowledged by its developers to have “occasionally” made offensive and inconsistent remarks such as invoking Jewish stereotypes.",
      "deployers": [
        "meta"
      ],
      "developers": [
        "meta"
      ],
      "harmedParties": [
        "jewish-people",
        "blenderbot-3-users"
      ],
      "reports": [
        1866,
        1867,
        1868
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62f2041c55716343a41ffe03)",
      "incident_id": 275,
      "date": "2020-06-11",
      "title": "Facebook’s Moderation Algorithm Banned Users for Historical Evidence of Slavery",
      "description": "Facebook’s automated content moderation was acknowledged by a company spokesperson to have erroneously censored and banned Australian users from posting an article containing a 1890s photo of Aboriginal men in chains over nudity as historical evidence of slavery in Australia.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "facebook-users-sharing-photo-evidence-of-slavery",
        "facebook-users"
      ],
      "reports": [
        1858,
        1860
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62f490d40658670483cb1691)",
      "incident_id": 285,
      "date": "2022-07-18",
      "title": "Google Lens’s Camera-Based Translation Feature Provided an Offensive Mistranslation of a Book Title in Korean",
      "description": "A book title by Korea’s first minister of culture was mistranslated into an offensive phrase by Google Lens’s camera-based translation feature allegedly due to its training on internet communications and a lack of context.",
      "deployers": [
        "google"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "google-lens-users"
      ],
      "reports": [
        1888
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(631975522a90260e9e4f5fc2)",
      "incident_id": 330,
      "date": "2016-12-15",
      "title": "“Amazon’s Choice” Algorithm Failed to Recommend Functional Products and Prone to Review Manipulation",
      "description": "Amazon’s “Amazon’s Choice” algorithm recommended poor-quality defective products and were reportedly susceptible to manipulation by inauthentic reviews.",
      "deployers": [
        "amazon"
      ],
      "developers": [
        "amazon"
      ],
      "harmedParties": [
        "amazon-users"
      ],
      "reports": [
        2017
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63033a8281052814ccec9f7b)",
      "incident_id": 299,
      "date": "2020-12-15",
      "title": "Japanese Porn Depixelated by Man using Deepfake",
      "description": "A man allegedly unblurred, using deepfake technology, pixelated pornographic images and videos of pornographic actors, which violated Japan’s obscenity law requiring images of genitalia to be obscured.",
      "deployers": [
        "masayuki-nakamoto"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "japanese-pornographic-actors"
      ],
      "reports": [
        1935
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(630f23807a8f2c2b4eece314)",
      "incident_id": 323,
      "date": "2018-05-29",
      "title": "Tesla on Autopilot Crashed into Parked Police Car in California",
      "description": "A Tesla sedan on Autopilot mode collided with a parked Laguna Beach Police Department car, resulting in minor injuries for its driver in Laguna Beach, California.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "laguna-beach-police-department"
      ],
      "reports": [
        1992,
        1193,
        2006,
        2514
      ],
      "severity": "AI tangible harm event",
      "classification": "yes",
      "sector": "transportation and storage",
      "region": "North America"
    },
    {
      "id": "ObjectId(62fa0340d2713a7e8de5b15c)",
      "incident_id": 293,
      "date": "2022-06-03",
      "title": "Cruise’s Self-Driving Car Involved in a Multiple-Injury Collision at an San Francisco Intersection",
      "description": "A Cruise autonomous vehicle was involved in a crash at an intersection in San Francisco when making a left turn in front of a Toyota Prius traveling in an opposite direction, which caused occupants in both cars to sustain injuries.",
      "deployers": [
        "cruise"
      ],
      "developers": [
        "cruise"
      ],
      "harmedParties": [
        "cruise-passengers",
        "toyota-prius-passengers"
      ],
      "reports": [
        1907,
        1908,
        1909,
        1910,
        1996,
        1997,
        2016
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(631712bba7aa86620c9a0f2f)",
      "incident_id": 325,
      "date": "2017-09-21",
      "title": "Offensive Instagram User Content Displayed as Facebook Ad",
      "description": "An Instagram user’s image containing violent content was reportedly used as advertisement on Facebook allegedly via automated means.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "olivia-solon",
        "olivia-solon's-facebook-connections"
      ],
      "reports": [
        2004,
        2005
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(631842c8d84017ad42c8e764)",
      "incident_id": 328,
      "date": "2020-06-13",
      "title": "Fake Accounts Using GAN Faces Deployed by Propaganda Campaign on Social Platforms",
      "description": "A pro-China propaganda campaign deployed fake accounts on Facebook, Twitter, and YouTube using GAN-synthesized faces to share and post comments on its content to gain wider circulation.",
      "deployers": [
        "spamouflage-dragon"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "facebook-users",
        "twitter-users",
        "youtube-users"
      ],
      "reports": [
        2014,
        2032
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(633d477a7d6871136596b7b5)",
      "incident_id": 347,
      "date": "2021-05-06",
      "title": "Waymo Self-Driving Taxi Behaved Unexpectedly, Driving away from Support Crew",
      "description": "A Waymo self-driving taxi car was shown on video stranded on a road in Arizona while carrying a passenger, suddenly drove away from the company's roadside assistance worker, and ended up being stuck farther down the road.",
      "deployers": [
        "waymo"
      ],
      "developers": [
        "waymo"
      ],
      "harmedParties": [
        "waymo-passengers"
      ],
      "reports": [
        2060,
        2098,
        2099
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6342883afb9dbe61e43fc839)",
      "incident_id": 350,
      "date": "2022-09-13",
      "title": "Delivery Robot Rolled Through Crime Scene",
      "description": "A Serve Robotics delivery robot was shown on video rolling through a crime scene blocked off by police tape.",
      "deployers": [
        "serve-robotics"
      ],
      "developers": [
        "serve-robotics"
      ],
      "harmedParties": [
        "police-investigators"
      ],
      "reports": [
        2067,
        2094
      ],
      "severity": "Low",
      "classification": "AI Incident",
      "region": "--"
    },
    {
      "id": "ObjectId(62f9f0c20127873b4a6fef3f)",
      "incident_id": 291,
      "date": "2021-05-28",
      "title": "Tesla Allegedly Misled Customers about Autopilot and FSD Capabilities",
      "description": "California’s Department of Motor Vehicles (DMV) accused Tesla of false advertising in its promotion of Autopilot and Full Self-Driving (FSD) technologies, alleging the company to have made untrue or misleading claims with marketing language about the capabilities of its products.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "california-department-of-motor-vehicles",
        "tesla-customers",
        "california-residents"
      ],
      "reports": [
        1901,
        1902,
        1903,
        2242,
        2590,
        2604
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62fa0c330127873b4a73e660)",
      "incident_id": 294,
      "date": "2018-05-26",
      "title": "Tesla Autopilot Allegedly Malfunctioned in a Non-Fatal Collision in Greece",
      "description": "Autopilot was alleged by its Tesla Model 3 driver to have unexpectedly malfunctioned, veering right without warning and crashing into a road divider near Thessaloniki, Greece, which resulted in damages to its wheel and door but no injury to the driver.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "you-you-xue",
        "tesla-drivers"
      ],
      "reports": [
        1911,
        1912,
        1913,
        1914
      ],
      "severity": "AI tangible harm event",
      "classification": "yes",
      "sector": "transportation and storage",
      "region": "Europe"
    },
    {
      "id": "ObjectId(62f36a72c17fe69fd2162681)",
      "incident_id": 280,
      "date": "2013-07-30",
      "title": "Coffee Meets Bagel’s Algorithm Reported by Users Disproportionately Showing Them Matches of Their Own Ethnicities Despite Selecting “No Preference”",
      "description": "Users selecting “no preference” were shown by Coffee Meets Bagels’s matching algorithm more potential matches with the same ethnicity, which was acknowledged and justified by its founder as a means to maximize connection rate without sufficient user information.",
      "deployers": [
        "coffee-meets-bagel"
      ],
      "developers": [
        "coffee-meets-bagel"
      ],
      "harmedParties": [
        "coffee-meets-bagel-users-having-no-ethnicity-preference",
        "coffee-meets-bagel-users"
      ],
      "reports": [
        1872,
        1873
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62f4bc3a77f5af9ce4624221)",
      "incident_id": 287,
      "date": "2020-10-27",
      "title": "OpenAI’s GPT-3 Reported as Unviable in Medical Tasks by Healthcare Firm",
      "description": "The French digital care company, Nabla, in researching GPT-3’s capabilities for medical documentation, diagnosis support, and treatment recommendation, found its inconsistency and lack of scientific and medical expertise unviable and risky in healthcare applications. This incident has been downgraded to an issue as it does not meet current ingestion criteria.",
      "deployers": [
        "none"
      ],
      "developers": [
        "openai",
        "nabla"
      ],
      "harmedParties": [
        "nabla-customers"
      ],
      "reports": [
        2471
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62fc9ebb7f039040988f789c)",
      "incident_id": 295,
      "date": "2018-11-08",
      "title": "Wrongful Attempted Arrest for Apple Store Thefts Due to NYPD’s Facial Misidentification",
      "description": "New York Police Department (NYPD)’s facial recognition system falsely connected a Black teenager to a series of thefts at Apple stores, which resulted in his wrongful attempted arrest.",
      "deployers": [
        "new-york-police-department"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "ousmane-bah",
        "nyc-black-people",
        "nyc-black-young-people"
      ],
      "reports": [
        1915,
        1916,
        1917,
        2102,
        2103
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(630de2a9c9d2246424b8bc01)",
      "incident_id": 320,
      "date": "2018-01-22",
      "title": "Tesla on Autopilot Collided with Parked Fire Truck on California Freeway",
      "description": "A Tesla Model S operating on Autopilot mode crashed into the back of a parked fire truck on a freeway in Culver City, California in a non-fatal collision.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "tesla-drivers",
        "culver-city-fire-department"
      ],
      "reports": [
        1985,
        1986,
        1987,
        2007
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63182b55d84017ad42c5406f)",
      "incident_id": 326,
      "date": "2014-12-09",
      "title": "Facebook Automated Year-in-Review Highlights Showed Users Painful Memories",
      "description": "Facebook’s “Year in Review” algorithm which compiled content in users’ past year as highlights inadvertently showed painful and unwanted memories to users, including death of family member.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "facebook-users-having-posts-about-painful-events",
        "facebook-users"
      ],
      "reports": [
        2008,
        2012,
        2013
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(633412840b988074a09c7ee0)",
      "incident_id": 335,
      "date": "2015-03-01",
      "title": "UK Visa Streamline Algorithm Allegedly Discriminated Based on Nationality",
      "description": "UK Home Office's algorithm to assess visa application risks explicitly considered nationality, allegedly caused candidates to face more scrutiny and discrimination.",
      "deployers": [
        "uk-visas-and-immigration"
      ],
      "developers": [
        "uk-visas-and-immigration",
        "uk-home-office"
      ],
      "harmedParties": [
        "uk-visa-applicants-from-some-countries"
      ],
      "reports": [
        2047,
        2090,
        2091,
        2092,
        2122,
        2123,
        2124,
        2125
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62f9fe883c16ab9cc78cf737)",
      "incident_id": 292,
      "date": "2021-09-01",
      "title": "Apple’s AVs Reportedly Struggled to Navigate Streets in Silicon Valley Test Drives",
      "description": "Apple’s autonomous cars were reported to have bumped into curbs and struggled to stay in their lanes after crossing intersections during an on-road test drives near the company’s Silicon Valley headquarters.",
      "deployers": [
        "apple"
      ],
      "developers": [
        "apple"
      ],
      "harmedParties": [
        "silicon-valley-traffic-participants",
        "silicon-valley-residents"
      ],
      "reports": [
        1904,
        1905,
        1906
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63033d3581052814cceda4de)",
      "incident_id": 300,
      "date": "2022-01-15",
      "title": "TikTok's For You Algorithm Allegedly Abused by Online Personality to Promote Anti-Women Hate",
      "description": "TikTok’s “For You” algorithm allegedly boosted or was manipulated by an online personality to artificially boost his content which promotes extreme misogynistic views towards teenagers and men, despite breaking its rules.",
      "deployers": [
        "tiktok"
      ],
      "developers": [
        "tiktok"
      ],
      "harmedParties": [
        "tiktok-male-teenager-users",
        "tiktok-male-users",
        "tiktok-teenage-users",
        "tiktok-users",
        "tiktok"
      ],
      "reports": [
        1936,
        1937
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(630dc67fb5b628f76fd964bc)",
      "incident_id": 318,
      "date": "2021-01-13",
      "title": "Facebook Recommended Military Gear Ads Despite Pause on Weapons Accessories Ads",
      "description": "Facebook’s algorithmic recommendations reportedly continued showing advertisements for gun accessories and military gear, despite Facebook’s halt on weapons accessories ads following the US Capitol attack.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "facebook-users"
      ],
      "reports": [
        1977,
        1978
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(630dd3b7f5504b7e75aad64f)",
      "incident_id": 319,
      "date": "2019-12-29",
      "title": "Tesla on Autopilot Fatally Crashed into Parked Fire Truck in Indiana",
      "description": "A Tesla on Autopilot mode failed to see a parked fire truck and crashed into its rear on an interstate in Indiana, causing the death of an Arizona woman.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "derrick-monet",
        "jenna-monet",
        "the-monets'-family"
      ],
      "reports": [
        1981,
        1982,
        1983,
        1984,
        1993
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(632056a45857ae71d0616e65)",
      "incident_id": 332,
      "date": "2016-04-05",
      "title": "Google Image Showed Racially Biased Results for “Professional” Hairstyles",
      "description": "Google Image search reportedly showed disparate results along racial lines, featuring almost exclusively white women for “professional hairstyles” and black women for “unprofessional hairstyles” prompts.",
      "deployers": [
        "google"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "black-women",
        "black-people",
        "google-users"
      ],
      "reports": [
        2033,
        2040,
        2041,
        2044
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(633a8fd3c70e5740bfbf5e4a)",
      "incident_id": 340,
      "date": "2017-02-01",
      "title": "Honda's CMBS False Positives Allegedly Caused Accidents to Customers",
      "description": "Honda's Collision Mitigation Braking System (CMBS) allegedly caused accidents to consumers due to frequent instances of false obstacle detection.",
      "deployers": [
        "honda"
      ],
      "developers": [
        "honda"
      ],
      "harmedParties": [
        "honda-customers"
      ],
      "reports": [
        2053
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(633aaae14178615128e595a2)",
      "incident_id": 341,
      "date": "2017-04-06",
      "title": "Nissan's Automatic Emergency Braking False Positives Posed Traffic Risks to Drivers",
      "description": "Nissan's Automatic Emergency Braking (AEB) feature was reported in a series of complaints for false positives and abrupt braking behaviors, endangering car occupants and traffic participants. ",
      "deployers": [
        "nissan"
      ],
      "developers": [
        "nissan"
      ],
      "harmedParties": [
        "nissan-drivers",
        "traffic-participants"
      ],
      "reports": [
        2054,
        2114,
        2198,
        2199,
        2200
      ],
      "severity": "AI tangible harm event",
      "classification": "yes",
      "sector": "transportation and storage",
      "region": "North America"
    },
    {
      "id": "ObjectId(63283d3b5ba952a8677615a3)",
      "incident_id": 334,
      "date": "2014-10-01",
      "title": "Uber Deployed Secret Program To Deny Local Authorities Rides",
      "description": "Uber developed a secret program Greyball which prevented known law enforcement officers in areas where its service violated regulations from receiving rides.",
      "deployers": [
        "uber"
      ],
      "developers": [
        "uber"
      ],
      "harmedParties": [
        "local-law-enforcement-officers"
      ],
      "reports": [
        2046,
        2077
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63036e545f65af7ded38efea)",
      "incident_id": 305,
      "date": "2019-02-01",
      "title": "YouTube’s Recommendation Algorithm Allegedly Promoted Climate Misinformation Content",
      "description": "YouTube’s recommendation system and its focus on views and watched time were alleged by an advocacy group to have driven people towards climate denial and misinformation videos.",
      "deployers": [
        "youtube"
      ],
      "developers": [
        "youtube"
      ],
      "harmedParties": [
        "youtube-users",
        "youtube-climate-skeptic-users"
      ],
      "reports": [
        1942,
        1943
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62fcc26b77f5af9ce4dee4b0)",
      "incident_id": 297,
      "date": "2020-02-20",
      "title": "EasyMile Self-Driving Shuttle Unexpectedly Stopped Mid-Route, Injuring a Passenger",
      "description": "A self-driving shuttle deployed by Smart Columbus in Linden neighborhood unexpectedly stopped on the street, which caused a woman to fall onto the floor from her seat.",
      "deployers": [
        "smart-columbus"
      ],
      "developers": [
        "easymile"
      ],
      "harmedParties": [
        "unnamed-woman-passenger"
      ],
      "reports": [
        1921,
        1922,
        1923
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62f3c064867302aca4f382fc)",
      "incident_id": 282,
      "date": "2020-10-03",
      "title": "Facebook’s Algorithm Mistook an Advertisement of Onions as Sexual Suggestive Content",
      "description": "Facebook’s content moderation algorithm misidentified and removed a Canadian business’s advertisement containing a photo of onions as products of overtly sexual content, which was later reinstated after review.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "the-seed-company-by-e.w.-gaze",
        "businesses-on-facebook"
      ],
      "reports": [
        1879,
        1881,
        1972
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62f24ab4fa57b6f30e8dc738)",
      "incident_id": 276,
      "date": "2022-01-01",
      "title": "Local South Korean Government’s Use of CCTV Footage Analysis via Facial Recognition to Track COVID Cases Raised Concerns about Privacy, Retention, and Potential Misuse",
      "description": "Bucheon government’s use of facial recognition in analyzing CCTV footage, despite gaining wide public support, was scrutinized by privacy advocates and some lawmakers for collecting data without consent, and retaining and misusing data beyond pandemic needs.",
      "deployers": [
        "bucheon-city-government"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "bucheon-citizens"
      ],
      "reports": [
        1864
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62f9ee8077f5af9ce45a140a)",
      "incident_id": 290,
      "date": "2022-06-03",
      "title": "False Negatives for Water Quality-Associated Beach Closures",
      "description": "Toronto’s use of AI predictive modeling (AIPM) which had replaced existing methodology as the only determiner of beach water quality raised concerns about its accuracy, after allegedly conflicting results were found by a local water advocacy group using traditional means.",
      "deployers": [
        "toronto-city-government"
      ],
      "developers": [
        "toronto-public-health"
      ],
      "harmedParties": [
        "sunnyside-beachgoers",
        "marie-curtis-beachgoers",
        "toronto-citizens"
      ],
      "reports": [
        1900,
        2413,
        2414
      ],
      "severity": "AI tangible harm near-miss",
      "classification": "yes",
      "sector": "human health and social work activities, public administration",
      "region": "North America"
    },
    {
      "id": "ObjectId(62fcb32d4a3f91af3d48436f)",
      "incident_id": 296,
      "date": "2016-02-10",
      "title": "Twitter Recommender System Amplified Right-Leaning Tweets",
      "description": "Twitter’s “Home” timeline algorithm was revealed by its internal researchers to have amplified tweets and news of rightwing politicians and organizations more than leftwing ones in six out of seven studied countries.",
      "deployers": [
        "twitter"
      ],
      "developers": [
        "twitter"
      ],
      "harmedParties": [
        "twitter-left-leaning-politicians",
        "twitter-left-leaning-news-organizations",
        "twitter-left-leaning-users",
        "twitter-users"
      ],
      "reports": [
        1918,
        1919,
        1920
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(630c8eb443fe03f46cc8bc7f)",
      "incident_id": 313,
      "date": "2022-08-25",
      "title": "BlenderBot 3 Cited Dutch Politician as a Terrorist",
      "description": "Meta’s conversational AI BlenderBot 3, when prompted “who is a terrorist,“ responded with an incumbent Dutch politician’s name, who was confused about its association.",
      "deployers": [
        "meta"
      ],
      "developers": [
        "meta"
      ],
      "harmedParties": [
        "marietje-schaake"
      ],
      "reports": [
        1967,
        3207
      ],
      "severity": "none",
      "classification": "no",
      "sector": "information and communication",
      "region": "Global"
    },
    {
      "id": "ObjectId(6321568425ffe34eb014af4a)",
      "incident_id": 333,
      "date": "2021-03-17",
      "title": "Tesla on Autopilot Crashed Parked Michigan Police Car on Interstate",
      "description": "A Tesla Model Y on Autopilot collided with a parked Michigan State Police (MSP) car which had its emergency lights on, in Eaton County, Michigan, although no one was injured.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "unnamed-22-year-old-male-driver",
        "tesla-drivers"
      ],
      "reports": [
        2045,
        2135,
        2136,
        2137,
        2146,
        2148
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(630367c881052814ccfd26f3)",
      "incident_id": 304,
      "date": "2021-11-03",
      "title": "Tesla on FSD Reportedly Drove into the Wrong Lane in California",
      "description": "A Tesla Model Y in Full Self-Driving (FSD) mode drove into the wrong lane after making a left turn despite its driver allegedly attempting to overtake its driving, resulting in a non-fatal collision with another vehicle in the wrong lane in Brea, California.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "unnamed-tesla-driver",
        "tesla-drivers"
      ],
      "reports": [
        1941
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63204d8bc912bf8020e381f8)",
      "incident_id": 331,
      "date": "2020-08-05",
      "title": "Bug in Instagram’s “Related Hashtags” Algorithm Allegedly Caused Disproportionate Treatment of Political Hashtags",
      "description": "A bug was reported by Instagram’s spokesperson to have prevented an algorithm from populating related hashtags for thousands of hashtags, resulting in an allege preferential treatment for some politically partisan hashtags.",
      "deployers": [
        "instagram"
      ],
      "developers": [
        "instagram"
      ],
      "harmedParties": [
        "instagram-users"
      ],
      "reports": [
        2022,
        2023
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63342b4609b0dac2f0bc4198)",
      "incident_id": 337,
      "date": "2021-04-17",
      "title": "Tesla Model S on ACC Crashed into Tree in Texas, Killing Two People",
      "description": "A 2019 Tesla Model S was reportedly traveling on Adaptive Cruise Control (ACC) at high speed before crashing into a tree near The Woodlands in Spring, Texas, killing two people.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "william-varner",
        "unnamed-passenger"
      ],
      "reports": [
        2049,
        2071,
        2072,
        2112,
        2115,
        2116,
        2117,
        2118,
        2237
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(633d286d399f7471b5c10035)",
      "incident_id": 346,
      "date": "2016-06-15",
      "title": "Robots in Japanese Hotel Annoyed Guests and Failed to Handle Simple Tasks",
      "description": "A number of robots employed by a hotel in Japan were reported by guests in a series of complaints for failing to handle tasks such as answering scheduling questions or making passport copies without human intervention.",
      "deployers": [
        "henn-na-hotel"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "henn-na-hotel-guests",
        "henn-na-hotal-staff"
      ],
      "reports": [
        2059,
        2062,
        2108,
        2109,
        2110
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62f3c2b9a076fc957e6080f8)",
      "incident_id": 283,
      "date": "2018-07-02",
      "title": "Facebook’s Automated Content Moderation Tool Flagged a Post Containing Parts of the Declaration of Independence as Hate Speech by Mistake",
      "description": "Facebook’s content moderation algorithm was acknowledged by the company to have flagged excerpts of the Declaration of Independence posted by a small newspaper in Texas as hate speech by mistake.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "the-vindicator"
      ],
      "reports": [
        1880
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62f4ae6e0658670483d4835d)",
      "incident_id": 286,
      "date": "2021-02-26",
      "title": "TikTok’s For You Allegedly Pushed Fatal “Blackout” Challenge Videos to Two Young Girls",
      "description": "TikTok’s recommendation algorithm was alleged in a lawsuit to have intentionally and repeatedly pushed videos of the “blackout” challenge onto children’s feeds, incentivizing their participation which ultimately resulted in the death of two young girls.",
      "deployers": [
        "tiktok"
      ],
      "developers": [
        "tiktok"
      ],
      "harmedParties": [
        "lalani-erika-renee-walton",
        "arriani-jaileen-arroyo",
        "lalani-erika-renee-walton's-family",
        "arriani-jaileen-arroyo's-family",
        "tiktok-young-users",
        "tiktok-users"
      ],
      "reports": [
        1889,
        2052,
        2381
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(630498489a95e74856267248)",
      "incident_id": 307,
      "date": "2017-11-01",
      "title": "iPhone Face ID Failed to Recognize Users’ Morning Faces",
      "description": "The Face ID feature on iPhone allowing users to unlock their phones via facial recognition was reported by users for not recognizing their faces in the morning.",
      "deployers": [
        "apple"
      ],
      "developers": [
        "apple"
      ],
      "harmedParties": [
        "iphone-face-id-users",
        "iphone-x-face-id-users"
      ],
      "reports": [
        1947
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6305dcfaaf7cc5438e28f38c)",
      "incident_id": 309,
      "date": "2017-08-26",
      "title": "Facial Recognition Trial Performed Poorly at Notting Hill Carnival",
      "description": "The facial recognition trial by London’s Metropolitan Police Service at the Notting Hill Carnival reportedly performed poorly with a high rate of false positives.",
      "deployers": [
        "metropolitan-police-service"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "notting-hill-carnival-goers"
      ],
      "reports": [
        1954,
        1956,
        1960,
        2030
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(631834963d3a94e2438bd339)",
      "incident_id": 327,
      "date": "2015-03-24",
      "title": "Facebook’s On-This-Day Feature Mistakenly Showed Painful Memories to Users",
      "description": "Facebook’s “On This Day” algorithm which highlighted past posts on a user’s private page or News Feed confronted unwanted and painful personal memories to its users.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "facebook-users-having-posts-about-painful-events",
        "facebook-users"
      ],
      "reports": [
        2011
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(633c45d3399f7471b597a077)",
      "incident_id": 344,
      "date": "2021-07-01",
      "title": "Hiring Algorithms Provided Invalid Positive Results for Interview Responses in German",
      "description": "Two AI interview softwares provided positive but invalid results such as competent English proficiency and high match percentage for interview responses given in German by reporters.",
      "deployers": [
        "myinterview",
        "curious-thing"
      ],
      "developers": [
        "myinterview",
        "curious-thing"
      ],
      "harmedParties": [
        "job-candidates-using-myinterview",
        "job-candidates-using-curious-thing",
        "employers-using-myinterview",
        "employers-using-curious-thing"
      ],
      "reports": [
        2057
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6342746c7349da35faffd3ee)",
      "incident_id": 348,
      "date": "2020-11-01",
      "title": "YouTube Recommendation Reportedly Pushed Election Fraud Content to Skeptics Disproportionately",
      "description": "YouTube's recommendation algorithm allegedly pushed 2020's US Presidential Election fraud content to users most skeptical of the election's legitimacy disproportionately compared to least skeptical users.",
      "deployers": [
        "youtube"
      ],
      "developers": [
        "youtube"
      ],
      "harmedParties": [
        "youtube-users-skeptical-of-us-election-results"
      ],
      "reports": [
        2064,
        2075,
        2096
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(634282e6c5ced0d56b1d0012)",
      "incident_id": 349,
      "date": "2022-03-22",
      "title": "Evolv's Gun Detection False Positives Created Problems for Schools",
      "description": "Evolv's AI-based weapons detection system reportedly produced excessive false positives, mistaking everyday school items for weapons and pulling schools' security personnel for manual checking.",
      "deployers": [
        "charlotte-mecklenburg-school-district"
      ],
      "developers": [
        "evolv-technology"
      ],
      "harmedParties": [
        "students-at-charlotte-mecklenburg-schools",
        "teachers-at-charlotte-mecklenburg-schools",
        "security-officers-at-charlotte-mecklenburg-schools"
      ],
      "reports": [
        2065,
        2095
      ],
      "severity": "AI tangible harm issue",
      "classification": "yes"
    },
    {
      "id": "ObjectId(62f2570d867302aca4ac4572)",
      "incident_id": 277,
      "date": "2022-01-14",
      "title": "Voices Created Using Publicly Available App Stolen and Resold as NFT without Attribution",
      "description": "An AI-synthetic audio sold as an NFT on Voiceverse’s platform was acknowledged by the company for having been created by 15.ai, a free web app specializing in text-to-speech and AI-voice generation, and reused without proper attribution.",
      "deployers": [
        "15.ai"
      ],
      "developers": [
        "15.ai"
      ],
      "harmedParties": [
        "15.ai",
        "15.ai-users"
      ],
      "reports": [
        1865
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6305f639af7cc5438e301103)",
      "incident_id": 311,
      "date": "2020-05-02",
      "title": "YouTube Auto-Moderation Mistakenly Banned Women of Sex Tech Conference",
      "description": "YouTube’s automated content moderation tool erroneously removed The Women of Sex Tech conference’s live-streamed event and banned the conference from the platform, despite not violating the platform’s sexual content policies.",
      "deployers": [
        "youtube"
      ],
      "developers": [
        "youtube"
      ],
      "harmedParties": [
        "women-of-sex-tech-conference-attendants",
        "women-of-sex-tech-conference-organizers"
      ],
      "reports": [
        1961,
        1962
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(630dbeae9451321cff796216)",
      "incident_id": 317,
      "date": "2020-03-17",
      "title": "Bug in Facebook’s Anti-Spam Filter Allegedly Blocked Legitimate Posts about COVID-19",
      "description": "Facebook was reported by users for blocking posts of legitimate news about the coronavirus pandemic, allegedly due to a bug in an anti-spam system.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "facebook-users-posting-legitimate-covid-19-news",
        "facebook-users"
      ],
      "reports": [
        1976
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(631704baa7aa86620c9827e8)",
      "incident_id": 324,
      "date": "2019-11-12",
      "title": "GAN Faces Deployed by The BL's Fake Account Network to Push Pro-Trump Content on Meta Platforms",
      "description": "A large network of pages, groups, and fake accounts having GAN-generated face photos associated with The BL, a US-based media outlet, reportedly bypassed Facebook moderation systems to push pro-Trump narratives on its platform and Instagram.",
      "deployers": [
        "the-bl"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "instagram-users",
        "facebook-users"
      ],
      "reports": [
        1998,
        1999,
        2000,
        2001,
        2002,
        2003
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63035dc822c28e977359610b)",
      "incident_id": 303,
      "date": "2022-08-21",
      "title": "Google’s Automated Child Abuse Detection Wrongfully Flagged a Parent’s Naked Photo of His Child",
      "description": "Google’s automated detection of abusive images of children incorrectly flagged a parent’s photo intended for a healthcare provider, resulting in a false police report of child abuse, and loss of access to his online accounts and information.",
      "deployers": [
        "google"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "a-software-engineer-named-mark",
        "parents-using-telemedicine-services"
      ],
      "reports": [
        1940,
        1944
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63369976589105516e51189b)",
      "incident_id": 339,
      "date": "2022-09-15",
      "title": "Open-Source Generative Models Abused by Students to Cheat on Assignments and Exams",
      "description": "Students were reportedly using open-source text generative models such as GPT-3 and ChatGPT to complete school assignments and exams such as writing reports, essays.",
      "deployers": [
        "students"
      ],
      "developers": [
        "sudowrite",
        "openai"
      ],
      "harmedParties": [
        "teachers",
        "non-cheating-students",
        "cheating-students"
      ],
      "reports": [
        2051,
        2063,
        2491,
        2511,
        2516,
        2539,
        2540,
        2575,
        2576,
        2593,
        2601,
        2634,
        2643,
        2755
      ],
      "severity": "none",
      "classification": "no",
      "sector": "Education, information and communication",
      "region": "Global"
    },
    {
      "id": "ObjectId(633c459b6ee03859f96820ab)",
      "incident_id": 343,
      "date": "2021-07-11",
      "title": "Facebook, Instagram, and Twitter Failed to Proactively Remove Targeted Racist Remarks via Automated Systems",
      "description": "Facebook's, Instagram's, and Twitter's automated content moderation failed to proactively remove racist remarks and posts directing at Black football players after finals loss, allegedly largely relying on user reports of harassment.",
      "deployers": [
        "facebook",
        "instagram",
        "twitter"
      ],
      "developers": [
        "facebook",
        "instagram",
        "twitter"
      ],
      "harmedParties": [
        "marcus-rashford",
        "jadon-sancho",
        "bukayo-saka",
        "facebook-users",
        "instagram-users",
        "twitter-users"
      ],
      "reports": [
        2056,
        2113
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(630350a5c971a26b3b4d6134)",
      "incident_id": 302,
      "date": "2021-03-15",
      "title": "Students Allegedly Wrongfully Accused of Cheating via Medical School's Internal Software",
      "description": "Dartmouth's Geisel School of Medicine allegedly falsely accused students of cheating during remote exams using an internally built system which tracked student activity patterns without their knowledge on its learning management platform.",
      "deployers": [
        "geisel-school-of-medicine"
      ],
      "developers": [
        "geisel-school-of-medicine's-technology-staff",
        "canvas"
      ],
      "harmedParties": [
        "sirey-zhang",
        "geisel-school-of-medicine's-students",
        "geisel-school-of-medicine's-professors",
        "geisel-school-of-medicine's-accused-students"
      ],
      "reports": [
        1939
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6305cb242b1af2bc7c3e34b8)",
      "incident_id": 308,
      "date": "2017-07-03",
      "title": "Atlas Robot Fell off Stage at Conference",
      "description": "Boston Dynamics’s autonomous robot Atlas allegedly caught its foot on a stage light, resulting in a fall off the stage at the Congress of Future Science and Technology Leaders conference.",
      "deployers": [
        "boston-dynamics"
      ],
      "developers": [
        "boston-dynamics"
      ],
      "harmedParties": [
        "none"
      ],
      "reports": [
        1952,
        1953
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6305e6d7af7cc5438e2ac401)",
      "incident_id": 310,
      "date": "2017-06-03",
      "title": "High False Positive Rate by SWP's Facial Recognition Use at Champion's League Final",
      "description": "South Wales Police (SWP)’s automated facial recognition (AFR) at the Champion's League Final football game in Cardiff wrongly identified innocent people as potential matches at an extremely high false positive rate of more than 90%.",
      "deployers": [
        "south-wales-police"
      ],
      "developers": [
        "nec"
      ],
      "harmedParties": [
        "finals-attendees",
        "falsely-accused-finals-attendees"
      ],
      "reports": [
        1955,
        1957,
        1958,
        1959,
        2126,
        2127,
        2128,
        2269
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(630c99e90212a2e7e79de7da)",
      "incident_id": 315,
      "date": "2016-04-09",
      "title": "Facial Recognition Service Abused to Target Russian Porn Actresses",
      "description": "The facial recognition software FindFace allowing its users to match photos to people’s social media pages on Vkontakte was reportedly abused to de-anonymize and harass Russian women who appeared in pornography and alleged sex workers.",
      "deployers": [
        "ntechlab"
      ],
      "developers": [
        "ntechlab"
      ],
      "harmedParties": [
        "russian-pornographic-actresses",
        "russian-sex-workers"
      ],
      "reports": [
        1970
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(630f057e690071b517189ef4)",
      "incident_id": 321,
      "date": "2018-03-23",
      "title": "Tesla Model X on Autopilot Crashed into California Highway Barrier, Killing Driver",
      "description": "A Tesla Model X P100D operating on Autopilot's Traffic-Aware Cruise Control (TACC) and Autosteer system allegedly accelerated above the speed limit of a highway in Mountain View, California, and steered itself directly into a barrier, resulting in its driver’s death.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "walter-huang's-family",
        "walter-huang"
      ],
      "reports": [
        188,
        190,
        194,
        195,
        199,
        209,
        212,
        1988,
        1989,
        1990,
        1995,
        200,
        3856,
        3858
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(631845f4a7aa86620cb95d56)",
      "incident_id": 329,
      "date": "2017-09-18",
      "title": "Amazon Recommended Explosive-Producing Ingredients as “Frequently Bought Together” Items for Chemicals",
      "description": "Amazon was reported to have shown chemical combinations for producing explosives and incendiary devices as “frequently bought together” items via automated recommendation.",
      "deployers": [
        "amazon"
      ],
      "developers": [
        "amazon"
      ],
      "harmedParties": [
        "amazon-users"
      ],
      "reports": [
        2015
      ],
      "severity": "none",
      "classification": "maybe",
      "sector": "wholesale and retail trade",
      "region": "Global"
    },
    {
      "id": "ObjectId(62f3d763614ca995dff23c49)",
      "incident_id": 284,
      "date": "2018-05-01",
      "title": "Facebook’s Automated Removal of Content Featuring Nudity-Containing Artworks Denounced as Censorship",
      "description": "Facebook’s removal of posts featuring renowned artworks by many historical artists and their promotional content due to nudity via both automated and human-moderated means were condemned by critics, such as museums and tourism boards, as cultural censorship and prevention of artwork promotion.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "museums-on-facebook",
        "facebook-users-interested-in-arts",
        "facebook-users"
      ],
      "reports": [
        1882,
        1883,
        1884,
        1885,
        1886,
        1887
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62ff8d332b190ab329b567f9)",
      "incident_id": 298,
      "date": "2021-10-21",
      "title": "Student-Developed Facial Recognition App Raised Ethical Concerns",
      "description": "TheFaceTag app, a social networking app developed and deployed within-campus by a student at Harvard raised concerns surrounding its facial recognition, cybersecurity, privacy, and misuse. This incident has been downgraded to an issue as it does not meet current ingestion criteria.",
      "deployers": [
        "yuen-ler-chow"
      ],
      "developers": [
        "yuen-ler-chow"
      ],
      "harmedParties": [
        "thefacetag-app-users"
      ],
      "reports": [
        2471
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62f35eea867302aca4e2b895)",
      "incident_id": 279,
      "date": "2019-07-01",
      "title": "TikTok’s “For You” Algorithm Exposed Young Users to Pro-Eating Disorder Content",
      "description": "TikTok’s young users were allegedly exposed to community-guideline-violating pro-eating disorder content on their algorithmically curated “For You” page that serves videos from any user on its platform.",
      "deployers": [
        "tiktok"
      ],
      "developers": [
        "tiktok"
      ],
      "harmedParties": [
        "tiktok-young-users",
        "tiktok-users"
      ],
      "reports": [
        1869,
        1870,
        2381
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62f3bb424240948816cde2a4)",
      "incident_id": 281,
      "date": "2019-02-04",
      "title": "YouTube's Algorithms Failed to Remove Violating Content Related to Suicide and Self-Harm",
      "description": "Terms-of-service-violating videos related to suicide and self-harm reportedly bypassed YouTube’s content moderation algorithms, allegedly resulting in exposure of graphic content to young users via recommended videos.",
      "deployers": [
        "youtube"
      ],
      "developers": [
        "youtube"
      ],
      "harmedParties": [
        "youtube-young-users",
        "youtube-users"
      ],
      "reports": [
        1875,
        1876,
        1877
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "information and communication, Arts, entertainment and recreation",
      "region": "Global"
    },
    {
      "id": "ObjectId(630c86a4707bde9384fd94ee)",
      "incident_id": 312,
      "date": "2021-08-15",
      "title": "Startup's Accent Translation AI Denounced as Reinforcing Racial Bias",
      "description": "A startup’s use of AI voice technology to alter or remove accents for call center agents was scrutinized by critics as reaffirming bias, despite the company’s claim.",
      "deployers": [
        "sanas"
      ],
      "developers": [
        "sanas"
      ],
      "harmedParties": [
        "call-center-agents-having-non-midwestern-american-accent",
        "people-having-non-midwestern-american-accent"
      ],
      "reports": [
        1963,
        1964,
        1965,
        1966
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(630ca22388619542799c19ec)",
      "incident_id": 316,
      "date": "2016-06-02",
      "title": "Facebook Ad-Approval Algorithm Allegedly Missed Fraudulent Ads via Simple URL Checks",
      "description": "Facebook’s advertisement-approval algorithm was reported by a security analyst to have neglected simple checks for domain URLs, leaving its users at risk of fraudulent ads.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "facebook-users"
      ],
      "reports": [
        1971
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62f4c81b0658670483dbe51b)",
      "incident_id": 288,
      "date": "2019-01-30",
      "title": "New Jersey Police Wrongful Arrested Innocent Black Man via FRT",
      "description": "Woodbridge Police Department falsely arrested an innocent Black man following a misidentification by their facial recognition software, who was jailed for more than a week and paid thousands of dollar for his defense.",
      "deployers": [
        "woodbridge-police-department"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "nijeer-parks"
      ],
      "reports": [
        1895,
        1896,
        2025,
        2026
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(62f4d2aa4a3f91af3dd48640)",
      "incident_id": 289,
      "date": "2020-06-15",
      "title": "Starship Delivery Robot Scuffed Bumper of a Resident’s Car in Texas, Allegedly Refusing to Release Footage of the Accident",
      "description": "A Starship food delivery robot crashed into the front bumper of a vehicle waiting at a stoplight intersection in Frisco, Texas, the video of which the company reportedly refused to release.",
      "deployers": [
        "starship-technologies"
      ],
      "developers": [
        "starship-technologies"
      ],
      "harmedParties": [
        "jisuk-mok",
        "frisco-residents"
      ],
      "reports": [
        1897,
        1898
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63048a1b3359229b334cee96)",
      "incident_id": 306,
      "date": "2016-05-26",
      "title": "Tesla on Autopilot TACC Crashed into Van on European Highway",
      "description": "A Tesla Model S operating on the Traffic-Aware Cruise Control (TACC) feature of Autopilot was shown on video by its driver crashing into a parked van on a European highway in heavy traffic, which damaged the front of the car.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "unnamed-tesla-owner",
        "tesla-drivers"
      ],
      "reports": [
        1946,
        1948,
        1949
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(633c45fd399f7471b597a758)",
      "incident_id": 345,
      "date": "2021-04-13",
      "title": "Auto-Insurance Photo-Based Estimation Allegedly Gave Inaccurate Repair Prices Frequently",
      "description": "Auto-insurance companies' photo-based estimation of repair price was alleged by repair shop owners and industry groups as providing inaccurate estimates, causing damaged cars to stay in the shop longer.",
      "deployers": [
        "insurance-companies"
      ],
      "developers": [
        "ccc-information-services",
        "tractable"
      ],
      "harmedParties": [
        "vehicle-repair-shops",
        "vehicle-owners"
      ],
      "reports": [
        2058
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(630349169b0efe36c58855ab)",
      "incident_id": 301,
      "date": "2022-02-15",
      "title": "Teenager at Broward College Allegedly Wrongfully Accused of Cheating via Remote Proctoring",
      "description": "Broward College’s use of remote proctoring system and reliance on its flagging algorithm allegedly led to a wrongful accusation of academic dishonesty in a biology exam of a Florida teenager.",
      "deployers": [
        "broward-college"
      ],
      "developers": [
        "honorlock"
      ],
      "harmedParties": [
        "unnamed-florida-teenager"
      ],
      "reports": [
        1938
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(630c923888619542799a0c42)",
      "incident_id": 314,
      "date": "2022-08-17",
      "title": "Stable Diffusion Abused by 4chan Users to Deepfake Celebrity Porn",
      "description": "Stable Diffusion, an open-source image generation model by Stability AI, was reportedly leaked on 4chan prior to its release date, and was used by its users to generate pornographic deepfakes of celebrities.",
      "deployers": [
        "stability-ai"
      ],
      "developers": [
        "stability-ai",
        "runway",
        "laion",
        "eleutherai",
        "compvis-lmu"
      ],
      "harmedParties": [
        "stability-ai",
        "deepfaked-celebrities"
      ],
      "reports": [
        1968
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(630f18e003b40739e3f018e6)",
      "incident_id": 322,
      "date": "2019-12-07",
      "title": "Tesla Model 3 Crashed into Police Patrol Car on Connecticut Highway",
      "description": "A Tesla Model 3 on Autopilot slammed into a parked car of patrol police officers who stopped to assist a stranded motorist on the interstate in Norwalk, Connecticut.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "connecticut-state-police"
      ],
      "reports": [
        1991,
        1994
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(633423b68b9212a310a337bc)",
      "incident_id": 336,
      "date": "2015-03-01",
      "title": "UK Home Office's Sham Marriage Detection Algorithm Reportedly Flagged Certain Nationalities Disproportionately",
      "description": "UK Home Office's opaque algorithm to detect sham marriages flagged some nationalities for investigation more than others, raising fears surrounding discrimination based on nationality and age.",
      "deployers": [
        "uk-home-office"
      ],
      "developers": [
        "uk-home-office"
      ],
      "harmedParties": [
        "uk-immigrant-newlyweds"
      ],
      "reports": [
        2048,
        2119,
        2120,
        2121
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63428c5563b61b7fa042db22)",
      "incident_id": 351,
      "date": "2022-09-13",
      "title": "The Little Mermaid Clip Doctored Using Generative AI to Replace Black Actress with White Character",
      "description": "A Twitter user reportedly modified using generative AI a short clip of Disney's 2022 version of The Little Mermaid, replacing a Black actress with a white digital character.",
      "deployers": [
        "@tengazillioiniq"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "halle-bailey",
        "black-actresses"
      ],
      "reports": [
        2068
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6347c85bf149ac829bebe6ac)",
      "incident_id": 364,
      "date": "2020-04-15",
      "title": "Walmart's Bagging-Detection False Positives Exposed Workers to Health Risk",
      "description": "Walmart's theft-deterring bagging-detection system allegedly exposed workers to health risks during the coronavirus pandemic when its false positives prompted workers to unnecessarily step in to resolve the issue.",
      "deployers": [
        "walmart"
      ],
      "developers": [
        "everseen"
      ],
      "harmedParties": [
        "walmart-employees"
      ],
      "reports": [
        2131
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6347d11ef149ac829beda3a3)",
      "incident_id": 367,
      "date": "2020-06-17",
      "title": "iGPT, SimCLR Learned Biased Associations from Internet Training Data",
      "description": "Unsupervised image generation models trained using Internet images such as iGPT and SimCLR were shown to have embedded racial, gender, and intersectional biases, resulting in stereotypical depictions.",
      "deployers": [
        "openai",
        "google"
      ],
      "developers": [
        "openai",
        "google"
      ],
      "harmedParties": [
        "gender-minority-groups",
        "racial-minority-groups",
        "underrepresented-groups-in-training-data"
      ],
      "reports": [
        2150
      ],
      "severity": "none",
      "classification": "no",
      "sector": "information and communication",
      "region": "Global"
    },
    {
      "id": "ObjectId(63429a302acc51f55c0d97ad)",
      "incident_id": 355,
      "date": "2018-07-07",
      "title": "Uber Allegedly Wrongfully Accused Drivers of Fraud via Automated Systems",
      "description": "Uber was alleged in a lawsuit to have wrongfully accused its drivers in the UK and Portugal of fraudulent activity through automated systems, which resulted in their dismissal without a right to appeal.",
      "deployers": [
        "uber"
      ],
      "developers": [
        "uber"
      ],
      "harmedParties": [
        "uber-drivers"
      ],
      "reports": [
        2081,
        2082,
        2083,
        2903,
        2972
      ],
      "severity": "AI tangible harm event",
      "classification": "yes",
      "sector": "transportation and storage",
      "region": "Europe"
    },
    {
      "id": "ObjectId(63429b21c5ced0d56b1f9725)",
      "incident_id": 356,
      "date": "2020-09-15",
      "title": "Philosophy AI Tentatively Produced Offensive Results for Certain Prompts",
      "description": "Philosopher AI as built on top of GPT-3 was reported by its users for having strong tendencies to produce offensive results when given prompts on certain topics such as feminism and Ethiopia.",
      "deployers": [
        "murat-ayfer"
      ],
      "developers": [
        "murat-ayfer",
        "openai"
      ],
      "harmedParties": [
        "historically-disadvantaged-groups"
      ],
      "reports": [
        2084,
        2085
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6347dbceed247984c90d6b27)",
      "incident_id": 368,
      "date": "2016-06-01",
      "title": "Facial Recognition Smart Phone App Blue Wolf Monitored Palestinians in West Bank",
      "description": "A controversial surveillance program involving facial recognition and algorithmic recommendation, Blue Wolf, was deployed by the Israeli military to monitor Palestinians in the West Bank.",
      "deployers": [
        "the-israel-military"
      ],
      "developers": [
        "anyvision"
      ],
      "harmedParties": [
        "palestinians-residing-in-the-west-bank"
      ],
      "reports": [
        2151,
        2152,
        2153,
        2154,
        2155,
        2156,
        2157,
        2159,
        2160,
        2161
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(634d1f8f7448b116a2eba9cf)",
      "incident_id": 370,
      "date": "2017-09-27",
      "title": "Google Fined for Changing Shopping Algorithms in EU to Favor Own Service",
      "description": "Google was fined by EU Commission for changing its shopping algorithms in Europe to favor its own comparison service over competitors, resulting in anti-competitive effects.",
      "deployers": [
        "google"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "google's-competitor-shopping-services"
      ],
      "reports": [
        2163
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(635f0120e6a5db6da1d3a483)",
      "incident_id": 378,
      "date": "2022-04-06",
      "title": "TuSimple Truck Steered into Interstate Freeway Divide",
      "description": "A TuSimple autonomous truck operating with backup drivers behind the wheel operated on an outdated command sequence and suddenly veered into the center divide on the interstate freeway.",
      "deployers": [
        "tusimple"
      ],
      "developers": [
        "tusimple"
      ],
      "harmedParties": [
        "tusimple",
        "state-of-arizona"
      ],
      "reports": [
        2175,
        2176
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(636dffb0411dcebbcc969fd5)",
      "incident_id": 391,
      "date": "2022-07-26",
      "title": "Facial Recognition Trial by UK Southern Co-op Alleged as Unlawful",
      "description": "Southern Co-op's use of facial recognition reportedly to curb violent crime in UK supermarkets was alleged by civil society and privacy groups as unlawful and complete invasion of privacy.",
      "deployers": [
        "southern-co-op"
      ],
      "developers": [
        "hikvision"
      ],
      "harmedParties": [
        "souther-co-op-customers"
      ],
      "reports": [
        2244,
        2246
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6356adfd642a3e49ac4c13a9)",
      "incident_id": 371,
      "date": "2019-11-29",
      "title": "Uganda Deployed Huawei's Facial Recognition to Monitor Political Opposition and Protests",
      "description": "Huawei's AI systems involving facial recognition were reportedly deployed by the Ugandan government to monitor political opposition actors and anti-regime sentiments, which raised fears of surveillance and suppression of individual freedoms.",
      "deployers": [
        "ugandan-government"
      ],
      "developers": [
        "huawei"
      ],
      "harmedParties": [
        "political-opposition-in-uganda"
      ],
      "reports": [
        2167,
        2184,
        2203
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(636e0f5e0a00a4f89b1146a3)",
      "incident_id": 393,
      "date": "2021-12-08",
      "title": "Facebook AI-Supported Moderation for Ads Failed to Detect Violating Content",
      "description": "Facebook's ad moderation system involving algorithms failed to flag hateful language and violating content such as calls for killings for ads in English and Swahili.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "facebook-users-speaking-swahili",
        "facebook-users-speaking-english",
        "facebook-users"
      ],
      "reports": [
        2247
      ],
      "severity": "none",
      "classification": "no"
    },
    {
      "id": "ObjectId(63429c05ad13a1c2fb5b52a1)",
      "incident_id": 358,
      "date": "2018-06-01",
      "title": "Calgary Malls Deployed Facial Recognition without Customer Consent",
      "description": "Facial recognition (FRT) was reportedly deployed in some Calgary-area malls to approximate customer age and gender without explicit consent, which a privacy expert warned was a cause for concern.",
      "deployers": [
        "cadillac-fairview"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "chinook-centre-mall-goers",
        "market-mall-goers"
      ],
      "reports": [
        2089
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6347c81eb55a37b65883b48c)",
      "incident_id": 363,
      "date": "2021-01-15",
      "title": "Facebook's Automated Moderation Mistakenly Flagged Landmark's Name as Offensive",
      "description": "Facebook's automated system mistakenly labelled posts featuring the seafaring landmark Plymouth Hoe as misogynistic.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "facebook-users-posting-about-plymouth-hoe",
        "facebook-users-in-plymouth-hoe",
        "plymouth-hoe-residents"
      ],
      "reports": [
        2130
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(634d1c221ad286865cf8d200)",
      "incident_id": 369,
      "date": "2022-08-29",
      "title": "GAN Artwork Won First Place at State Fair Competition",
      "description": "An artwork generated using generative AI won first place in the digital arts category of the Colorado State Fair's art competition, which raised concerns surrounding labor displacement and unfair competition.",
      "deployers": [
        "jason-allen"
      ],
      "developers": [
        "midjourney"
      ],
      "harmedParties": [
        "artists-submitting-in-the-digital-arts-category",
        "digital-artists",
        "artists"
      ],
      "reports": [
        2162
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(637e37b4f569208079ed32e7)",
      "incident_id": 400,
      "date": "2022-02-23",
      "title": "Google Search Returned Fewer Results for Abortion Services in Rural Areas",
      "description": "Google Search reportedly returned fewer abortion clinics for searches from poorer and rural areas, particularly ones with Targeted Regulation of Abortion Providers (TRAP) laws.",
      "deployers": [
        "google"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "women-in-need-of-abortion-services",
        "women-having-unexpected-or-crisis-pregnancies"
      ],
      "reports": [
        2273
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(635780b830a3a8f1ece4a18d)",
      "incident_id": 373,
      "date": "2013-10-01",
      "title": "Michigan's Unemployment Benefits Algorithm MiDAS Issued False Fraud Claims to Thousands of People",
      "description": "Michigan’s MiDAS system falsely accused over 34,000 people of unemployment fraud from 2013 to 2015, which reportedly caused financial ruin for many. The automated system was designed to cut costs, but it adjudicated fraud cases without human oversight. That led to an 85% error rate. Victims faced wage garnishments, some lost homes, and some faced bankruptcy. Despite early warnings, Michigan’s UIA defended MiDAS until lawsuits and federal pressure forced reforms. Legislators have been seeking compensation for those wrongfully accused.",
      "deployers": [
        "michigan-unemployment-insurance-agency"
      ],
      "developers": [
        "fast-enterprises",
        "csg-government-solutions"
      ],
      "harmedParties": [
        "unemployed-michigan-residents-falsely-accused-of-fraud",
        "michigan-residents-who-faced-bankruptcy-or-foreclosure-due-to-midas"
      ],
      "reports": [
        2169,
        2187,
        2188,
        2189,
        2190,
        2191,
        2213,
        2214,
        2215,
        2216,
        2238,
        2798,
        4849,
        4850
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6357a047b7c906438c20d050)",
      "incident_id": 376,
      "date": "2016-09-01",
      "title": "RealPage Algorithm Allegedly Inflates Rents and Reduces Competition in Housing Market",
      "description": "RealPage’s YieldStar pricing algorithm is at the center of allegations that it enabled landlords to coordinate rent increases by sharing nonpublic pricing and occupancy data, raising rents artificially and reducing competition. On January 7, 2025, the U.S. Department of Justice filed an antitrust lawsuit against six major landlords, alleging that they used the algorithm and other direct communication methods to stifle competition, harming renters nationwide.",
      "deployers": [
        "realpage"
      ],
      "developers": [
        "thoma-bravo",
        "realpage",
        "jeffrey-roper"
      ],
      "harmedParties": [
        "renters"
      ],
      "reports": [
        2172,
        2185,
        2186,
        2261,
        2281,
        4445,
        4446,
        4447,
        4448,
        4449,
        4471,
        4479,
        4480,
        4481
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6371fabca346c979b1ae42cf)",
      "incident_id": 395,
      "date": "2021-03-02",
      "title": "Amazon Forced Deployment of AI-Powered Cameras on Delivery Drivers",
      "description": "Amazon delivery drivers were forced to consent to algorithmic collection and processing of their location, movement, and biometric data through AI-powered cameras, or be dismissed.",
      "deployers": [
        "amazon"
      ],
      "developers": [
        "netradyne"
      ],
      "harmedParties": [
        "amazon-delivery-drivers"
      ],
      "reports": [
        2254,
        2255,
        2256,
        2257
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6347c501dcc7f82dbe8893d5)",
      "incident_id": 361,
      "date": "2018-05-11",
      "title": "Amazon Echo Mistakenly Recorded and Sent Private Conversation to Random Contact",
      "description": "Amazon Echo misinterpreted a background conversation between a husband and wife as instructions for recording a message and sending it to one of the husband's employees.",
      "deployers": [
        "amazon"
      ],
      "developers": [
        "amazon"
      ],
      "harmedParties": [
        "danielle's-family",
        "amazon-echo-users"
      ],
      "reports": [
        2111
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(635c5c81de6aa8bda90be620)",
      "incident_id": 377,
      "date": "2022-10-11",
      "title": "Weibo Model Had Difficulty Detecting Shifts in Censored Speech",
      "description": "Weibo's user moderation model is having difficulty keeping up with shifting user slang in defiance of Chinese state censors.",
      "deployers": [
        "weibo"
      ],
      "developers": [
        "weibo"
      ],
      "harmedParties": [
        "weibo",
        "chinese-government"
      ],
      "reports": [
        2174
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(634299bc63b61b7fa0444163)",
      "incident_id": 354,
      "date": "2020-06-20",
      "title": "Uber Allegedly Violated GDPR by Failing to Provide Sufficient Notice on Automated Profiling for Drivers",
      "description": "Uber was alleged in a lawsuit to have provided incomplete notice about automated decision-making and profiling for drivers such as information about their driving behavior, and use of phone.",
      "deployers": [
        "uber"
      ],
      "developers": [
        "uber"
      ],
      "harmedParties": [
        "uber-drivers"
      ],
      "reports": [
        2078,
        2079,
        2080,
        2904,
        2903
      ],
      "severity": "AI tangible harm event",
      "classification": "maybe",
      "sector": "transportation and storage",
      "region": "Europe"
    },
    {
      "id": "ObjectId(63621e63de6aa8bda92f9f24)",
      "incident_id": 381,
      "date": "2020-10-29",
      "title": "Autonomous Roborace Car Drove Directly into a Wall",
      "description": "An autonomous Roborace car drove itself into a wall in round one of the Season Beta 1.1 race.",
      "deployers": [
        "sit-acronis-autonomous"
      ],
      "developers": [
        "sit-acronis-autonomous"
      ],
      "harmedParties": [
        "sit-acronis-autonomous"
      ],
      "reports": [
        2217
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6342970863b61b7fa043f53e)",
      "incident_id": 353,
      "date": "2019-03-01",
      "title": "Tesla on Autopilot Crashed into Trailer Truck in Florida, Killing Driver",
      "description": "A Tesla Model 3 driver switched on Autopilot seconds before the crash into the underbelly of a tractor-trailer on a highway in Florida, killing the Tesla driver.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "jeremy-banner",
        "jeremy-banner's-family"
      ],
      "reports": [
        2073,
        2074,
        2195,
        2196
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6357844d24cf9385ce69f63f)",
      "incident_id": 374,
      "date": "2020-08-13",
      "title": "UK Ofqual's Algorithm Disproportionately Provided Lower Grades Than Teachers' Assessments",
      "description": "UK Office of Qualifications and Examinations Regulation (Ofqual)'s grade-standardization algorithm providing predicted grades for A level and GCSE qualifications in the UK, Wales, Northern Ireland, and Scotland was reportedly giving grades lower than teachers' assessments, and disproportionately for state schools.",
      "deployers": [
        "uk-office-of-qualifications-and-examinations-regulation"
      ],
      "developers": [
        "uk-office-of-qualifications-and-examinations-regulation"
      ],
      "harmedParties": [
        "a-level-pupils",
        "gcse-pupils",
        "pupils-in-state-schools",
        "underprivileged-pupils"
      ],
      "reports": [
        2170,
        2206,
        2207,
        2208,
        2209,
        2210,
        2211,
        2212
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(636218ea6a07890c6a6ea2e6)",
      "incident_id": 380,
      "date": "2014-03-04",
      "title": "Facebook's Auto-Generated Targeting Ad Categories Contained Anti-Semitic Options",
      "description": "Facebook's automated advertising categories generated using users' declared interests contained anti-Semitic categories such as Jew hater  and How to burn Jews which were listed as fields of study.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "jewish-people"
      ],
      "reports": [
        2181,
        2182,
        2258,
        2259,
        2260
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63429b73fb9dbe61e441cf9e)",
      "incident_id": 357,
      "date": "2019-02-14",
      "title": "GPT-2 Able to Recite PII in Training Data",
      "description": "OpenAI's GPT-2 reportedly memorized and could regurgitate verbatim instances of training data, including personally identifiable information such as names, emails, twitter handles, and phone numbers.",
      "deployers": [
        "openai"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "openai",
        "people-having-personal-data-in-gpt-2's-training-data"
      ],
      "reports": [
        2086,
        2087,
        2088
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63627328a7be79b265325ac3)",
      "incident_id": 385,
      "date": "2022-10-04",
      "title": "Canadian Police's Release of Suspect's AI-Generated Facial Photo Reportedly Reinforced Racial Profiling",
      "description": "The Edmonton Police Service (EPS) in Canada released a facial image of a Black male suspect generated by an algorithm using DNA phenotyping, which was denounced by the local community as racial profiling.",
      "deployers": [
        "edmonton-police-service"
      ],
      "developers": [
        "parabon-nanolabs"
      ],
      "harmedParties": [
        "black-residents-in-edmonton"
      ],
      "reports": [
        2224,
        2225,
        2231,
        2232,
        2233,
        2234
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(636b524b23e1c9d9beea48b5)",
      "incident_id": 388,
      "date": "2018-12-01",
      "title": "Facial Recognition Pilot in Bahia Reportedly Targeted Black and Poor People",
      "description": "Facial recognition deployed in a pilot project by the local government of Bahia despite having minimal hit rate reportedly targeted Black and poor people disproportionately.",
      "deployers": [
        "the-government-in-bahia",
        "bahia's-secretary-of-public-security"
      ],
      "developers": [
        "huawei"
      ],
      "harmedParties": [
        "black-people-in-brazil",
        "black-people-in-bahia"
      ],
      "reports": [
        2235
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6362264aa7be79b2651b6a2d)",
      "incident_id": 383,
      "date": "2022-10-04",
      "title": "Google Home Mini Speaker Reportedly Read N-Word in Song Title Aloud",
      "description": "Google Home Mini speaker was reported by users for announcing aloud the previously-censored n-word in a song title.",
      "deployers": [
        "google-home"
      ],
      "developers": [
        "google-home"
      ],
      "harmedParties": [
        "black-google-home-mini-users",
        "google-home-mini-users"
      ],
      "reports": [
        2220,
        2223
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(636dfa2e1b6ec4ae9b2296e0)",
      "incident_id": 390,
      "date": "2022-06-28",
      "title": "Deepfakes Reportedly Deployed in Online Interviews for Remote Work Positions",
      "description": "Voice and video deepfakes were reported by FBI Internet Crime Complaint Center (IC3) in complaint reports to have been deployed during online interviews of the candidates for remote-work positions.",
      "deployers": [
        "unknown"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "interviewers-of-remote-work-positions",
        "employers-of-remote-work-positions"
      ],
      "reports": [
        2243
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(636b4ae550d21acd7f9d55c6)",
      "incident_id": 387,
      "date": "2014-12-22",
      "title": "Oracle's Algorithmic Data Processing System Alleged as Unlawful and Violating Privacy Rights",
      "description": "Oracle's automated system involving algorithmic data processing was alleged in a lawsuit to have been unlawfully collecting personal data from millions of people and violating their privacy rights.",
      "deployers": [
        "oracle"
      ],
      "developers": [
        "oracle"
      ],
      "harmedParties": [
        "internet-users"
      ],
      "reports": [
        2229
      ],
      "severity": "none",
      "classification": "yes"
    },
    {
      "id": "ObjectId(636e237be4c942942295944c)",
      "incident_id": 394,
      "date": "2017-03-15",
      "title": "Social Media's Automated Word-Flagging without Context Shifted Content Creators' Language Use",
      "description": "TikTok's, YouTube's, Instagram's, and Twitch's use of algorithms to flag certain words devoid of context changed content creators' use of everyday language or discussion about certain topics in fear of their content getting flagged or auto-demonetized by mistake.",
      "deployers": [
        "youtube",
        "twitch",
        "tiktok",
        "instagram"
      ],
      "developers": [
        "youtube",
        "twitch",
        "tiktok",
        "instagram"
      ],
      "harmedParties": [
        "youtube-content-creators",
        "twitch-content-creators",
        "tiktok-content-creators",
        "instagram-content-creators"
      ],
      "reports": [
        2248,
        2251
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6347c800f149ac829bebd5f0)",
      "incident_id": 362,
      "date": "2021-07-20",
      "title": "Facebook's Automated Moderation Flagged Gardening Group's Language Use by Mistake",
      "description": "Facebook's automated system flagged gardening groups' use of hoe and violent language against bugs as a violation by mistake.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "wny-gardeners",
        "gardening-facebook-groups",
        "facebook-users-in-gardening-groups"
      ],
      "reports": [
        2129
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63622d23f8424658ecc55ba7)",
      "incident_id": 384,
      "date": "2022-10-03",
      "title": "Glovo Driver in Italy Fired via Automated Email after Being Killed in Accident",
      "description": "Delivery company Glovo's automated system sent an email terminating an employee for non-compliance terms and conditions after the employee was killed in a car accident while making a delivery on Glovo's behalf.",
      "deployers": [
        "glovo"
      ],
      "developers": [
        "glovo"
      ],
      "harmedParties": [
        "sebastian-galassi",
        "sebastian-galassi's-family"
      ],
      "reports": [
        2221,
        2222
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6347bf83b3a025aa31ca107d)",
      "incident_id": 359,
      "date": "2021-05-23",
      "title": "Facebook, Instagram, and Twitter Cited Errors in Automated Systems as Cause for Blocking pro-Palestinian Content on Israeli-Palestinian Conflict",
      "description": "Facebook, Instagram, and Twitter wrongly blocked or restricted millions of pro-Palestinian posts and accounts related to the Israeli-Palestinian conflict, citing errors in their automated content moderation system.",
      "deployers": [
        "facebook",
        "instagram",
        "twitter"
      ],
      "developers": [
        "facebook",
        "instagram",
        "twitter"
      ],
      "harmedParties": [
        "palestinian-social-media-users",
        "facebook-users",
        "instagram-users",
        "twitter-users",
        "facebook-employees-having-families-affected-by-the-conflict"
      ],
      "reports": [
        2097
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63729e404a5eff12b1d019b7)",
      "incident_id": 396,
      "date": "2018-07-04",
      "title": "Transgender Uber Drivers Mistakenly Kicked off App for Appearance Change during Gender Transitions",
      "description": "Transgender Uber drivers reported being automatically deactivated from the app due to Real-Time ID Check failing to account for difference in appearance of people undergoing gender transitions.",
      "deployers": [
        "uber"
      ],
      "developers": [
        "uber"
      ],
      "harmedParties": [
        "transgender-uber-drivers"
      ],
      "reports": [
        2263
      ],
      "severity": "High",
      "classification": "AI Incident",
      "region": "--"
    },
    {
      "id": "ObjectId(6342917fb710d4e33cf416e9)",
      "incident_id": 352,
      "date": "2022-09-15",
      "title": "GPT-3-Based Twitter Bot Hijacked Using Prompt Injection Attacks",
      "description": "Remoteli.io's GPT-3-based Twitter bot was shown being hijacked by Twitter users who redirected it to repeat or generate any phrases.",
      "deployers": [
        "stephan-de-vries"
      ],
      "developers": [
        "openai",
        "stephan-de-vries"
      ],
      "harmedParties": [
        "stephan-de-vries"
      ],
      "reports": [
        2070,
        2076,
        2093,
        2426
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(635769bd84468db9632cd98c)",
      "incident_id": 372,
      "date": "2022-07-22",
      "title": "Users Reported Security Issues with Google Pixel 6a's Fingerprint Unlocking",
      "description": "Google Pixel 6a's fingerprint recognition feature was reported by users for security issues, in which phones were mistakenly unlocked by unregistered fingerprints.",
      "deployers": [
        "google"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "google-pixel-6a-users"
      ],
      "reports": [
        2168,
        2177,
        2178
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(635794898e87db52ebfb01c5)",
      "incident_id": 375,
      "date": "2019-09-29",
      "title": "Thai Wallet App's Facial Recognition Errors Created Registration Issues for Government Programs",
      "description": "A Thai wallet app failed to recognize people’s faces, resulting in citizens and disproportionately elders unable to sign up for Thai government’s cash handout and co-pay programs or having to wait in long queues at local ATMs for authentication.",
      "deployers": [
        "krungthai-bank"
      ],
      "developers": [
        "krungthai-bank"
      ],
      "harmedParties": [
        "thai-citizens",
        "elder-thai-citizens"
      ],
      "reports": [
        2171,
        2192,
        2193
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(636218985a33233a22f6632e)",
      "incident_id": 379,
      "date": "1992-05-25",
      "title": "Error in Pepsi's Number Generation System Led to Decades-Long Damages in the Philippines",
      "description": "Pepsi's number generation system determining daily winners in its Number Fever promotion in the Philippines mistakenly produced a number held by thousands which resulted in riots, deaths, conspiracy theories, and decades of lawsuits.",
      "deployers": [
        "pepsi"
      ],
      "developers": [
        "d.g.-consultores"
      ],
      "harmedParties": [
        "filipinos"
      ],
      "reports": [
        2179,
        2180
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6362229cf2f56bc79407bf96)",
      "incident_id": 382,
      "date": "2017-11-21",
      "title": "Instagram's Exposure of Harmful Content Contributed to Teenage Girl’s Suicide",
      "description": "Instagram was ruled by a judge to have contributed to the death of a teenage girl in the UK allegedly through its exposure and recommendation of suicide, self-harm, and depressive content.",
      "deployers": [
        "instagram"
      ],
      "developers": [
        "instagram"
      ],
      "harmedParties": [
        "molly-rose-russell",
        "the-russell-family",
        "teenage-girls",
        "teenagers"
      ],
      "reports": [
        2219
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63627e3fe6a5db6da1a32ac6)",
      "incident_id": 386,
      "date": "2019-07-03",
      "title": "Amazon’s Time Off Task System Made False Assumptions about Workers' Time Management",
      "description": "Amazon’s warehouse worker “time off task (TOT) tracking system was used to discipline and dismiss workers, falsely assuming workers to have wasted time and failing to account for breaks or equipment issues.",
      "deployers": [
        "amazon"
      ],
      "developers": [
        "amazon"
      ],
      "harmedParties": [
        "amazon-warehouse-workers"
      ],
      "reports": [
        2227,
        2228,
        2252
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(636b5e9802006dadfd7b75df)",
      "incident_id": 389,
      "date": "2022-04-05",
      "title": "Cruise Autonomous Car Blocked Fire Truck Responding to Emergency",
      "description": "A fire truck in San Francisco responding to a fire was blocked from passing a doubled-parked garbage truck by a self-driving Cruise car on the opposing lane which stayed put and did not reverse to clear the lane.",
      "deployers": [
        "cruise"
      ],
      "developers": [
        "cruise"
      ],
      "harmedParties": [
        "san-francisco-firefighters",
        "san-francisco-fire-department"
      ],
      "reports": [
        2239,
        2240,
        2562,
        3182
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(637338f62f19ca2c3763fd78)",
      "incident_id": 397,
      "date": "2022-09-11",
      "title": "Misinformation Reported in TikTok's Search Results Despite Moderation by AI and Human",
      "description": "TikTok's search recommendations reportedly contained misinformation about political topics bypassing both AI and human content moderation.",
      "deployers": [
        "tiktok"
      ],
      "developers": [
        "tiktok"
      ],
      "harmedParties": [
        "young-tiktok-users",
        "tiktok-users",
        "gen-z-tiktok-users"
      ],
      "reports": [
        2264,
        2268
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6373414f2f19ca2c37674860)",
      "incident_id": 398,
      "date": "2022-08-15",
      "title": "Tesla Autopilot Misidentified On-Road Horse-Drawn Carriage",
      "description": "Tesla Autopilot's computer vision system was shown in a video mistaking a horse-drawn carriage for other forms of transport such as a truck, a car, and a human following a car.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "tesla-drivers",
        "horse-drawn-carriages"
      ],
      "reports": [
        2265,
        2266,
        2267
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(637b0fb0dc7613ede0f49fb0)",
      "incident_id": 399,
      "date": "2022-11-15",
      "title": "Meta AI's Scientific Paper Generator Reportedly Produced Inaccurate and Harmful Content",
      "description": "Meta AI trained and hosted a scientific paper generator that sometimes produced bad science and prohibited queries on topics and groups that are likely to produce offensive or harmful content.",
      "deployers": [
        "meta-ai",
        "meta",
        "facebook"
      ],
      "developers": [
        "meta-ai",
        "meta",
        "facebook"
      ],
      "harmedParties": [
        "minority-groups",
        "meta-ai",
        "meta",
        "facebook",
        "minority-groups"
      ],
      "reports": [
        2270,
        2271,
        2272
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(637f9bfc34f2d7279c03dad8)",
      "incident_id": 401,
      "date": "2021-06-03",
      "title": "Kannada Insulted by Google's Featured Answer as Ugliest Language in India",
      "description": "Google's knowledge-graph-powered algorithm showed Kannada in its featured Answer Box when prompted ugliest language in India, causing outrage from Kannada-speaking people and government.",
      "deployers": [
        "google"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "the-karnataka-government",
        "kannada-speakers"
      ],
      "reports": [
        2275,
        2278,
        2279,
        2280
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(637f9c0f34f2d7279c03dcd2)",
      "incident_id": 402,
      "date": "2021-04-01",
      "title": "Players Manipulated GPT-3-Powered Game to Generate Sexually Explicit Material Involving Children",
      "description": "Latitude's GPT-3-powered game AI Dungeon was reportedly abused by some players who manipulated its AI to generate sexually explicit stories involving children.",
      "deployers": [
        "latitude"
      ],
      "developers": [
        "openai",
        "latitude"
      ],
      "harmedParties": [
        "latitude"
      ],
      "reports": [
        2276
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6347bfff3f17c3e2099ac5f1)",
      "incident_id": 360,
      "date": "2021-10-15",
      "title": "McDonald's AI Drive-Thru Allegedly Collected Biometric Customer Data without Consent, Violating BIPA",
      "description": "McDonald's use of chatbot in its AI drive-through in Chicago was alleged in a lawsuit to have collected and processed voice data without user consent to predict customer information, which violated Illinois Biometric Information Privacy Act (BIPA).",
      "deployers": [
        "mcdonald's"
      ],
      "developers": [
        "mcd-tech-labs",
        "apprente"
      ],
      "harmedParties": [
        "shannon-carpenter",
        "mcdonald's-customers-residing-in-illinois",
        "mcdonald's-customers"
      ],
      "reports": [
        2100,
        2149,
        2218
      ],
      "severity": "none",
      "classification": "yes"
    },
    {
      "id": "ObjectId(6347ca687d1ef715c9a6d78b)",
      "incident_id": 366,
      "date": "2020-09-20",
      "title": "Suicide Clips Evaded TikTok's Automated Moderation in Coordinated Attack",
      "description": "Many clips showing a suicide evaded TikTok's automated content moderation system allegedly in a coordinated attack, which resulted in exposure of violating content to its users.",
      "deployers": [
        "tiktok"
      ],
      "developers": [
        "tiktok"
      ],
      "harmedParties": [
        "tiktok-users"
      ],
      "reports": [
        2140
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(636e0987411dcebbcc9857ac)",
      "incident_id": 392,
      "date": "2015-06-01",
      "title": "Facebook's AI-Supported Moderation Failed to Classify Terrorist Content in East African Languages",
      "description": "Facebook's system involving algorithmic content moderation for East African languages was reportedly failing to identify violating content on the platform such as mistakenly classifying non-terrorist content.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "facebook-users-speaking-east-african-languages",
        "facebook-users-in-east-africa"
      ],
      "reports": [
        2245,
        2249
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6386e622b48fdf02a11460a8)",
      "incident_id": 407,
      "date": "2016-02-03",
      "title": "Uber's Surge Pricing Reportedly Offered Disproportionate Service Quality along Racial Lines",
      "description": "Uber's surge-pricing algorithm which adjusts prices to influence car availability inadvertently caused better service offering such as shorter wait times for majority white neighborhoods.",
      "deployers": [
        "uber"
      ],
      "developers": [
        "uber"
      ],
      "harmedParties": [
        "poor-neighborhoods",
        "neighborhoods-of-color"
      ],
      "reports": [
        2289
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63806c7c19b54579646d7d3d)",
      "incident_id": 404,
      "date": "2019-06-25",
      "title": "Sound Intelligence's Aggression Detector Misidentified Innocuous Sounds",
      "description": "Sound Intelligence's aggression detection algorithm deployed by schools reportedly contained high rates of false positive, misclassifying laughing, coughing, cheering, and loud discussions.",
      "deployers": [
        "rock-hill-schools",
        "pinecrest-academy-horizon"
      ],
      "developers": [
        "sound-intelligence"
      ],
      "harmedParties": [
        "students",
        "rock-hill-school-students",
        "pinecrest-academy-horizon-students"
      ],
      "reports": [
        2284,
        2286
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6381c9b634f2d7279c4fd523)",
      "incident_id": 406,
      "date": "2015-07-15",
      "title": "Facebook's Friend Suggestion Feature Recommends Patients of Psychiatrist to Each Other",
      "description": "Facebook's People You May Know (PYMK) feature was reported by a psychiatrist for recommending her patients as friends through recommendations, violating patients' privacy and confidentiality.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "pseudonymized-psychiatrist's-patients",
        "pseudonymized-psychiatrist",
        "patients",
        "healthcare-providers"
      ],
      "reports": [
        2288
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6386e641c860d9983e13d10b)",
      "incident_id": 408,
      "date": "2017-04-15",
      "title": "Facebook Reportedly Outed Sex Workers through Friend Recommendations",
      "description": "Facebook's People You May Know feature reportedly outed sex workers by recommending clients to their personal accounts or family members to their business accounts with no option to opt out.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "sex-workers-using-facebook"
      ],
      "reports": [
        2290
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6386f266c79c035dcaa8a3c2)",
      "incident_id": 409,
      "date": "2013-09-13",
      "title": "Facial Recognition Researchers Used YouTube Videos of Transgender People without Consent",
      "description": "YouTube videos of transgender people used by researchers to study facial recognition during gender transitions were used and distributed without permission.",
      "deployers": [
        "university-of-north-carolina-wilmington",
        "karl-ricanek",
        "gayathri-mahalingam"
      ],
      "developers": [
        "university-of-north-carolina-wilmington",
        "karl-ricanek",
        "gayathri-mahalingam"
      ],
      "harmedParties": [
        "transgender-youtubers",
        "transgender-people"
      ],
      "reports": [
        2309,
        2411,
        2412
      ],
      "severity": "none",
      "classification": "no",
      "sector": "professional, scientific and technical activities",
      "region": "Global"
    },
    {
      "id": "ObjectId(6381b80fb48fdf02a16754bd)",
      "incident_id": 405,
      "date": "2018-11-28",
      "title": "Schufa Credit Scoring in Germany Reported for Unreliable and Imbalanced Scores",
      "description": "Creditworthiness Schufa scores in Germany reportedly privileged older and female consumers, and people who changed addresses less frequently, and were unreliable depending on scoring version.",
      "deployers": [
        "schufa-holding-ag"
      ],
      "developers": [
        "schufa-holding-ag"
      ],
      "harmedParties": [
        "young-men-having-credit-scores",
        "people-scored-on-old-scoring-versions",
        "people-changing-addresses-frequently"
      ],
      "reports": [
        2285,
        2287
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6380634e19b54579646bd24c)",
      "incident_id": 403,
      "date": "2018-01-15",
      "title": "GMail's Inbox Sorting Reportedly Negatively Impacted Political Emails and Call-to-Actions",
      "description": "Google GMail's inbox sorting algorithm for political emails was reported by presidential candidates, nonprofits, and advocacy groups for having negative impact on call-to-actions, allegedly suppressing donations and impeding political actions.",
      "deployers": [
        "google"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "political-organizations",
        "political-candidates"
      ],
      "reports": [
        2282,
        2283
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(638d8f8f77887182b3eaf554)",
      "incident_id": 410,
      "date": "2022-11-09",
      "title": "KFC Sent Insensitive Kristallnacht Promotion via Holiday Detection System",
      "description": "KFC cited an error in an automated holiday detection system which identified the anniversary of Kristallnacht and prompted an insensitive push notification promoting its chicken.",
      "deployers": [
        "kfc"
      ],
      "developers": [
        "kfc"
      ],
      "harmedParties": [
        "jewish-people"
      ],
      "reports": [
        2312
      ],
      "severity": "none",
      "classification": "no",
      "sector": "accommodation and food service activities, information and communication",
      "region": "Europe"
    },
    {
      "id": "ObjectId(638d9b0c77887182b3edfc95)",
      "incident_id": 411,
      "date": "2022-11-27",
      "title": "Chinese Accounts Spammed Twitter Feed Allegedly to Obscure News of Protests",
      "description": "Twitter Feed was flooded by content from Chinese-language accounts which allegedly aimed to manipulate and reduce social media coverage about widespread protests against coronavirus restrictions in China.",
      "deployers": [
        "twitter"
      ],
      "developers": [
        "twitter"
      ],
      "harmedParties": [
        "twitter-users",
        "twitter"
      ],
      "reports": [
        2314
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(638da45077887182b3f05041)",
      "incident_id": 412,
      "date": "2020-01-15",
      "title": "Finland Police's Facial Recognition Trial to Identify Sexual Abuse Victims Deemed Illegal",
      "description": "Finland's National Police Board was reprimanded for illegal processing of special categories of personal data in a facial recognition trial to identify potential victims of child sexual abuse.",
      "deployers": [
        "finland-national-bureau-of-investigation"
      ],
      "developers": [
        "clearview-ai"
      ],
      "harmedParties": [
        "finland-national-bureau-of-investigation"
      ],
      "reports": [
        2315,
        2408,
        2409,
        2410
      ],
      "severity": "none",
      "classification": "yes",
      "region": "Global"
    },
    {
      "id": "ObjectId(6390303a92c6c9d416e8aa59)",
      "incident_id": 413,
      "date": "2022-11-30",
      "title": "Thousands of Incorrect ChatGPT-Produced Answers Posted on Stack Overflow",
      "description": "Thousands of incorrect answers produced by OpenAI's ChatGPT were submitted to Stack Overflow, which swamped the site's volunteer-based quality curation process and harmed users looking for correct answers.",
      "deployers": [
        "openai"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "stack-overflow-users",
        "stack-overflow"
      ],
      "reports": [
        2317,
        2318,
        2586
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(639035ff6c1caba4d11eff3a)",
      "incident_id": 414,
      "date": "2020-01-18",
      "title": "Facebook Gave Vulgar English Translation of Chinese President's Name",
      "description": "Facebook provided a vulgar Burmese-English translation of the Chinese president's name in posts of an official Burmese politician's Facebook page announcing his visit.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "xi-jinping",
        "aung-san-suu-kyi"
      ],
      "reports": [
        2319
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "information and communication",
      "region": "Global"
    },
    {
      "id": "ObjectId(63903d03fca1bb88915db189)",
      "incident_id": 415,
      "date": "2020-07-28",
      "title": "Facebook Provided Offensive Translation for King of Thailand's Birthday Ceremony",
      "description": "Facebook's Thai-English translation gave an inappropriate mistranslation on Thai PBS's Facebook live broadcast of the King of Thailand’s candle-lighting birthday ceremony.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "live-stream-ceremony-viewers",
        "king-maha-vajiralongkorn"
      ],
      "reports": [
        2320,
        2404,
        2405,
        2406,
        2407
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6390466a92c6c9d416ed408c)",
      "incident_id": 416,
      "date": "2022-12-01",
      "title": "Facebook's Job Ad Algorithm Allegedly Biased against Older and Female Workers",
      "description": "Facebook's algorithm was alleged in a complaint by Real Women in Trucking to have selectively shown job advertisements disproportionately against older and female workers in favor of younger men for blue-collar positions.",
      "deployers": [
        "meta-platforms",
        "facebook"
      ],
      "developers": [
        "meta-platforms",
        "facebook"
      ],
      "harmedParties": [
        "real-women-in-trucking",
        "older-female-blue-collar-workers"
      ],
      "reports": [
        2321,
        2402,
        2403
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(639051eb3a5ad5b61c1dbedc)",
      "incident_id": 417,
      "date": "2019-11-15",
      "title": "Facebook Feed Algorithms Exposed Low Digitally Skilled Users to More Disturbing Content",
      "description": "Facebook feed algorithms were known by internal research to have harmed people having low digital literacy by exposing them to disturbing content they did not know how to avoid or monitor.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "low-digitally-skilled-facebook-users"
      ],
      "reports": [
        2322,
        2399,
        2400,
        2401
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(639607c6d7265aae7cc6c9c4)",
      "incident_id": 418,
      "date": "2017-03-13",
      "title": "Uber Locked Indian Drivers out of Accounts Allegedly Due to Facial Recognition Fails",
      "description": "Uber drivers in India reported being locked out of their accounts allegedly due to Real-Time ID Check's facial recognition failing to recognize appearance changes or faces in low lighting conditions.",
      "deployers": [
        "uber"
      ],
      "developers": [
        "uber",
        "azure-cognitive-services"
      ],
      "harmedParties": [
        "uber-drivers-in-india"
      ],
      "reports": [
        2324,
        2391,
        2392
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63960c84e31c3c9ac8bddb43)",
      "incident_id": 419,
      "date": "2022-12-01",
      "title": "Facebook's Automated Moderation Allowed Ads Threatening Election Workers to be Posted",
      "description": "Facebook's automated moderating system failed to flag and allowed ads containing explicit violent language against election workers to be published.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "facebook-users"
      ],
      "reports": [
        2325,
        2395,
        2396
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63961322bc45a2dda74096cf)",
      "incident_id": 420,
      "date": "2022-11-30",
      "title": "Users Bypassed ChatGPT's Content Filters with Ease",
      "description": "Users reported bypassing ChatGPT's content and keyword filters with relative ease using various methods such as prompt injection or creating personas to produce biased associations or generate harmful content.",
      "deployers": [
        "openai"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "chatgpt-users",
        "openai"
      ],
      "reports": [
        2326,
        2358,
        2393,
        2394,
        2397,
        2554,
        2644,
        2649,
        2662,
        2852,
        2863
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6396cb91a3cf41b531248ab4)",
      "incident_id": 421,
      "date": "2022-11-20",
      "title": "Stable Diffusion Allegedly Used Artists' Works without Permission for AI Training",
      "description": "Text-to-image model Stable Diffusion was reportedly using artists' original works without permission for its AI training.",
      "deployers": [
        "stability-ai",
        "lensa-ai",
        "midjourney",
        "deviantart"
      ],
      "developers": [
        "stability-ai",
        "runway",
        "lensa-ai",
        "laion",
        "eleutherai",
        "compvis-lmu"
      ],
      "harmedParties": [
        "digital-artists",
        "artists-publishing-on-social-media",
        "artists"
      ],
      "reports": [
        2328,
        2427,
        2444,
        2523,
        2577,
        2607,
        2608,
        2446,
        2618,
        2959,
        2960,
        2989
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(639d76678dccddb2440cb810)",
      "incident_id": 422,
      "date": "2022-11-22",
      "title": "Deepfake of FTX's Former CEO Posted on Twitter Aiming to Scam FTX Collapse Victims",
      "description": "A visual and audio deepfake of former FTX CEO Sam Bankman-Fried was posted on Twitter to scam victims of the exchange's collapse by urging people to transfer funds into an anonymous cryptocurrency wallet.",
      "deployers": [
        "unknown"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "victims-of-ftx's-collapse",
        "twitter-users"
      ],
      "reports": [
        2330
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(639d7afe17b5cfae855ae501)",
      "incident_id": 423,
      "date": "2022-11-22",
      "title": "Lensa AI's Produced Unintended Sexually Explicit or Suggestive Magic Avatars for Women",
      "description": "Lensa AI's Magic Avatars were reportedly generating sexually explicit and sexualized features disproportionately for women and Asian women despite not submitting any sexual content.",
      "deployers": [
        "lensa-ai"
      ],
      "developers": [
        "stability-ai",
        "runway",
        "lensa-ai",
        "laion",
        "eleutherai",
        "compvis-lmu"
      ],
      "harmedParties": [
        "women-using-lensa-ai",
        "asian-women-using-lensa-ai"
      ],
      "reports": [
        2331,
        2376,
        2390,
        2445,
        2446
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(639d8660af03da8f83856b47)",
      "incident_id": 424,
      "date": "2020-03-09",
      "title": "Universities' AI Proctoring Tools Allegedly Failed Canada's Legal Threshold for Consent",
      "description": "AI proctoring tools for remote exams were reportedly not conducive to individual consent for Canadian students whose biometric data was collected during universities' use of remote proctoring in the COVID pandemic.",
      "deployers": [
        "canadian-universities"
      ],
      "developers": [
        "respondus-monitor",
        "proctoru",
        "proctortrack",
        "proctorio",
        "proctorexam",
        "examity"
      ],
      "harmedParties": [
        "canadian-students"
      ],
      "reports": [
        2332,
        2386,
        2387,
        2388
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(639d8b228dccddb244103c16)",
      "incident_id": 425,
      "date": "2021-06-12",
      "title": "State Farm Allegedly Discriminated against Black Customers in Claim Payout",
      "description": "State Farm's automated claims processing method was alleged in a class action lawsuit to have disproportionately against Black policyholders when paying out insurance claims.",
      "deployers": [
        "state-farm"
      ],
      "developers": [
        "state-farm"
      ],
      "harmedParties": [
        "black-state-farm-customers"
      ],
      "reports": [
        2333,
        2385
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(639d8eacaf03da8f8386de79)",
      "incident_id": 426,
      "date": "2022-09-23",
      "title": "XPeng P7 Crashed into Truck in Shangdong While on Automatic Navigation Assisted Driving",
      "description": "An XPeng P7 was operating on Navigation Guided Pilot (NGP) mode automatic navigation assisted driving system as it collided with a truck on a highway in Shandong, causing slight injuries to its driver.",
      "deployers": [
        "xpeng"
      ],
      "developers": [
        "xpeng"
      ],
      "harmedParties": [
        "xpeng-driver"
      ],
      "reports": [
        2334
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63a01efd17b5cfae85ce886b)",
      "incident_id": 427,
      "date": "2022-03-15",
      "title": "Cruise Taxis' Sudden Braking Allegedly Put People at Risk",
      "description": "Cruise's autonomous taxis slowed suddenly, braked, and were hit from behind, allegedly becoming unexpected roadway obstacles and potentially putting passengers and other people at risk.",
      "deployers": [
        "cruise"
      ],
      "developers": [
        "cruise"
      ],
      "harmedParties": [
        "traffic-participants",
        "emergency-vehicles",
        "cruise-passengers",
        "cruise"
      ],
      "reports": [
        2335,
        2382,
        2383
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63a171f784adbad7e335e126)",
      "incident_id": 428,
      "date": "2017-05-19",
      "title": "BBC Reporter's Twin Brother Cracked HSBC's Voice ID Authentication",
      "description": "HSBC’s voice recognition authentication system was fooled after seven repeated attempts  by a BBC reporter's twin brother who mimicked his voice to access his bank account.",
      "deployers": [
        "hsbc-uk"
      ],
      "developers": [
        "nuance-communications"
      ],
      "harmedParties": [
        "hsbc-uk-customers",
        "dan-simmons"
      ],
      "reports": [
        2341,
        2379,
        2380
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63a17dd9d4f686c7f9a40bea)",
      "incident_id": 429,
      "date": "2016-04-01",
      "title": "Unreliable ShotSpotter Audio Convicted Black Rochester Man of Shooting Police",
      "description": "ShotSpotter's unreliable audio was used as scientific evidence to accuse and convict a Black man of attempting to shoot Rochester's city police, whose conviction was later reversed by a county judge.",
      "deployers": [
        "rochester-police-department"
      ],
      "developers": [
        "shotspotter"
      ],
      "harmedParties": [
        "silvon-simmons"
      ],
      "reports": [
        2343,
        1816,
        2377,
        2378
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63a37b8fd67db98e62e5ae99)",
      "incident_id": 430,
      "date": "2022-12-19",
      "title": "Lawyers Denied Entry to Performance Venue by Facial Recognition",
      "description": "Lawyers were barred from entry to Madison Square Garden after a facial recognition system matched them as employed by a law firm currently engaged in litigation with the venue.",
      "deployers": [
        "madison-square-garden-entertainment"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "kelly-conlon",
        "alexis-majano"
      ],
      "reports": [
        2346,
        2355,
        2359,
        2360,
        2361,
        2362,
        2363,
        2364,
        2365,
        2366,
        2367,
        2368,
        2504,
        2556,
        2557,
        2589,
        2600,
        2665,
        2728,
        2775,
        2797
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63a422bbcf609c92b7543612)",
      "incident_id": 431,
      "date": "2022-04-20",
      "title": "Robbers Accessed Drugged Gay Men's Bank Accounts Using Their Phones' Facial Recognition",
      "description": "Gay men in New York City were drugged by robbers who accessed their phones using facial recognition while they were unconscious to transfer funds out of their bank accounts.",
      "deployers": [
        "apple"
      ],
      "developers": [
        "apple"
      ],
      "harmedParties": [
        "gay-men-in-new-york-city",
        "julio-ramirez"
      ],
      "reports": [
        2353,
        2370,
        2371
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63acb833b64ebdefe77e4815)",
      "incident_id": 432,
      "date": "2022-12-21",
      "title": "Southwest Airlines Crew Scheduling Solver Degenerates Flight Network",
      "description": "Southwest Airlines left passengers stranded for days throughout the flight network when Southwest crew scheduling software repeatedly failed to recover from weather-induced flight cancellations.",
      "deployers": [
        "southwest-airlines"
      ],
      "developers": [
        "general-electric"
      ],
      "harmedParties": [
        "airline-passengers"
      ],
      "reports": [
        2357
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63ad3a6084adbad7e35afd37)",
      "incident_id": 433,
      "date": "2012-08-01",
      "title": "Chicago Police's Strategic Subject List Reportedly Biased Along Racial Lines",
      "description": "Chicago Police Department (CPD)'s Strategic Subject List as output of an algorithm purportedly to identify victims or perpetrators of violence was reportedly ineffective, easily abused, and biased against low-income communities of color.",
      "deployers": [
        "chicago-police-department"
      ],
      "developers": [
        "chicago-police-department"
      ],
      "harmedParties": [
        "low-income-communities",
        "communities-of-color",
        "black-chicago-residents"
      ],
      "reports": [
        2415,
        2416,
        1013,
        1348,
        1011,
        1016,
        1018,
        1012,
        2421,
        2422
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63ad491a006af1f60705b344)",
      "incident_id": 434,
      "date": "2022-11-24",
      "title": "Sudden Braking by Tesla Allegedly on Self-Driving Mode Caused Multi-Car Pileup in Tunnel",
      "description": "A Tesla driver alleged Full Self Driving (FSD) braking unexpectedly as the cause for an eight-car pileup in San Francisco which led to minor injuries of nine people.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "traffic-participants",
        "tesla-drivers"
      ],
      "reports": [
        2417,
        2418,
        2420,
        2474,
        2472,
        2520,
        2635,
        2919
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63ad53ee006af1f60708480e)",
      "incident_id": 435,
      "date": "2021-07-04",
      "title": "Coupang Allegedly Tweaked Search Algorithms to Boost Own Products",
      "description": "Coupang was alleged in internal reports tampering its search algorithms to prioritize exposure of its own products, which potentially violated Korea's Fair Trade Act.",
      "deployers": [
        "coupang"
      ],
      "developers": [
        "coupang"
      ],
      "harmedParties": [
        "coupang-suppliers",
        "coupang-customers"
      ],
      "reports": [
        2423,
        2424,
        2425,
        3523
      ],
      "severity": "AI tangible harm event",
      "classification": "maybe",
      "sector": "wholesale and retail trade",
      "region": "Asia"
    },
    {
      "id": "ObjectId(63b3dbdcd4f686c7f9c2dd90)",
      "incident_id": 436,
      "date": "2022-12-28",
      "title": "Tesla Driver Put Car on Autopilot Before Falling Asleep in Germany",
      "description": "A Tesla driver fell asleep on an Autobahn near Bamberg, Germany after activating his vehicle's Autopilot mode, which did not respond to attempts to pull it over by the police.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "traffic-participants"
      ],
      "reports": [
        2428,
        2429,
        2430,
        2431,
        2432,
        2433,
        2453,
        2469,
        2470
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63b581e6d4f686c7f9289451)",
      "incident_id": 437,
      "date": "2016-12-31",
      "title": "Amazon India Allegedly Rigged Search Results to Promote Own Products",
      "description": "Amazon India allegedly copied products and rigged search algorithm to boost its own brands in search ranking, violating antitrust laws.",
      "deployers": [
        "amazon-india"
      ],
      "developers": [
        "amazon-india"
      ],
      "harmedParties": [
        "small-businesses-in-india",
        "amazon-customers-in-india"
      ],
      "reports": [
        2438,
        2439,
        2440,
        2441
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63b5b0aacf609c92b7655c2e)",
      "incident_id": 438,
      "date": "2021-09-17",
      "title": "Chinese Province Developed System Tracking Journalists and International Students",
      "description": "Henan's provincial government reportedly planned system involving facial recognition cameras connected to regional and national databases specifically to track foreign journalists and international students.",
      "deployers": [
        "henan-government",
        "henan-public-security-department"
      ],
      "developers": [
        "neusoft"
      ],
      "harmedParties": [
        "foreign-journalists-in-henan",
        "international-students-in-henan"
      ],
      "reports": [
        2443,
        2447,
        2451
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63b7bbee006af1f607c8fa07)",
      "incident_id": 439,
      "date": "2019-07-31",
      "title": "Detroit Police Wrongfully Arrested Black Man Due To Faulty Facial Recognition",
      "description": "A Black man was wrongfully detained by the Detroit Police Department as a result of a false facial recognition (FRT) result.",
      "deployers": [
        "detroit-police-department"
      ],
      "developers": [
        "dataworks-plus"
      ],
      "harmedParties": [
        "michael-oliver",
        "black-people-in-detroit"
      ],
      "reports": [
        2448,
        2449,
        2450
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63b7c337cf609c92b7bf731e)",
      "incident_id": 440,
      "date": "2022-11-25",
      "title": "Louisiana Police Wrongfully Arrested Black Man Using False Face Match",
      "description": "Louisiana police reportedly used a false facial recognition match and secured an arrest warrant for a Black man for thefts he did not commit.",
      "deployers": [
        "baton-rouge-police-department"
      ],
      "developers": [
        "morphotrak",
        "clearview-ai"
      ],
      "harmedParties": [
        "black-people-in-louisiana",
        "randall-reid"
      ],
      "reports": [
        2452,
        2454,
        2498,
        2544,
        2731,
        2732
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63b7e901006af1f607d38ce1)",
      "incident_id": 441,
      "date": "2019-06-01",
      "title": "Korea Developed ID Screening System Using Airport Travelers' Data without Consent",
      "description": "Korean government's development of immigration screening system involving real-time facial recognition used airport travelers' data which was supplied by the Ministry of Justice without consent.",
      "deployers": [
        "korean-ministry-of-justice",
        "korean-ministry-of-science-and-information-and-communication-technology"
      ],
      "developers": [
        "unnamed-korean-companies"
      ],
      "harmedParties": [
        "travelers-in-korean-airports"
      ],
      "reports": [
        2464,
        2465,
        2466,
        2467,
        2468
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63c3aa8bb3a255226d8727a9)",
      "incident_id": 443,
      "date": "2022-12-21",
      "title": "ChatGPT Abused to Develop Malicious Softwares",
      "description": "OpenAI's ChatGPT was reportedly abused by cyber criminals including ones with no or low levels of coding or development skills to develop malware, ransomware, and other malicious softwares.",
      "deployers": [
        "openai"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "internet-users"
      ],
      "reports": [
        2475,
        2476,
        2477,
        2478,
        2479,
        2480,
        2481,
        2483,
        2484,
        2485,
        2486,
        2487,
        2488,
        2489,
        2490,
        2492,
        2493,
        2494,
        2559,
        2602,
        2748,
        2749,
        2851,
        2894,
        2907
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63c3d7d651b2393cd57863c1)",
      "incident_id": 444,
      "date": "2003-03-22",
      "title": "US Air Force's Patriot Missile Mistakenly Launched at Ally Fighter Jet, Killing Two",
      "description": "Acting on the recommendation of their Patriot missile system, American Air Force mistakenly launched the missile at an ally UK Tornado fighter jet, which killed two crew members on board.",
      "deployers": [
        "us-air-force"
      ],
      "developers": [
        "raytheon",
        "lockheed-martin"
      ],
      "harmedParties": [
        "us-air-force",
        "uk-royal-air-force",
        "kevin-main",
        "david-williams"
      ],
      "reports": [
        2502,
        2497,
        2503
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63c3de5e9fabfa7bc98b499c)",
      "incident_id": 445,
      "date": "2003-04-02",
      "title": "Patriot Missile System Misclassified US Navy Aircraft, Killing Pilot Upon Approval to Fire",
      "description": "US Navy's Patriot missile system misidentified an American Navy F/A-18C Hornet as an enemy projectile, prompting an operator to fire two missiles at the aircraft, which killed the pilot.",
      "deployers": [
        "us-navy"
      ],
      "developers": [
        "raytheon",
        "lockheed-martin"
      ],
      "harmedParties": [
        "us-navy",
        "nathan-white's-family",
        "nathan-white"
      ],
      "reports": [
        2499,
        2501,
        2497,
        2503
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63c659579fabfa7bc903760a)",
      "incident_id": 446,
      "date": "2023-01-01",
      "title": "ShotSpotter Failed to Alert Authorities of Mass Shooting in North Carolina",
      "description": "ShotSpotter did not detect gunshots and alert Durham police of a drive-by shooting in Durham, North Carolina which left five people in hospital on New Year's Day.",
      "deployers": [
        "durham-police-department"
      ],
      "developers": [
        "shotspotter"
      ],
      "harmedParties": [
        "mass-shooting-victims",
        "durham-residents",
        "durham-police-department"
      ],
      "reports": [
        2505,
        2512,
        2542,
        2677,
        2830
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63c65e58b3a255226d0b0324)",
      "incident_id": 447,
      "date": "2022-12-19",
      "title": "Footballer's X-Rated Comment Created by Instagram's Mistranslation",
      "description": "Instagram's English translation of a footballer's comment on his wife's post in Spanish made the message seem racy and X-rated, which some fans found amusing.",
      "deployers": [
        "instagram"
      ],
      "developers": [
        "instagram"
      ],
      "harmedParties": [
        "spanish-speaking-instagram-users"
      ],
      "reports": [
        2506,
        2513
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63c6635762bbe82271e161e1)",
      "incident_id": 448,
      "date": "2022-12-28",
      "title": "AI-Powered VTuber and Virtual Streamer Made Toxic Remarks on Twitch",
      "description": "An LLM-powered VTuber and streamer on Twitch made controversial statements such as denying the Holocaust, saying women rights do not exist, and pushing a fat person to solve the trolley problem, stating they deserve it.",
      "deployers": [
        "vedal"
      ],
      "developers": [
        "vedal"
      ],
      "harmedParties": [
        "twitch-users",
        "vedal"
      ],
      "reports": [
        2507
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63c678e89fabfa7bc90a4fb2)",
      "incident_id": 449,
      "date": "2022-12-01",
      "title": "Startup Misled Research Participants about GPT-3 Use in Mental Healthcare Support",
      "description": "OpenAI's GPT-3 was deployed by a mental health startup without ethical review to support peer-to-peer mental healthcare, and whose interactions with the help providers were deceiving for research participants.",
      "deployers": [
        "koko"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "research-participants",
        "koko-customers"
      ],
      "reports": [
        2508,
        2509,
        2528,
        2910
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63d7807e90dd130b85f2b505)",
      "incident_id": 450,
      "date": "2021-11-01",
      "title": "Kenyan Data Annotators Allegedly Exposed to Graphic Content for OpenAI's AI",
      "description": "Sama AI's Kenyan contractors were reportedly asked with excessively low pay to annotate a large volume of disturbing content to improve OpenAI's generative AI systems such as ChatGPT, and whose contract was terminated prior to completion by Sama AI.",
      "deployers": [
        "openai"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "kenyan-sama-ai-employees"
      ],
      "reports": [
        2510,
        2546,
        2547,
        2548,
        2563,
        2569,
        2596,
        3195
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63d8bd2f46e8f88b23a0d6ad)",
      "incident_id": 451,
      "date": "2022-10-16",
      "title": "Stable Diffusion's Training Data Contained Copyrighted Images",
      "description": "Stability AI reportedly scraped copyrighted images by Getty Images to be used as training data for Stable Diffusion model.",
      "deployers": [
        "stability-ai"
      ],
      "developers": [
        "runway",
        "laion",
        "eleutherai",
        "compvis-lmu",
        "stability-ai"
      ],
      "harmedParties": [
        "getty-images",
        "getty-images-contributors"
      ],
      "reports": [
        2515,
        2523,
        2606,
        2961,
        2960
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63d8c34846e8f88b23a26260)",
      "incident_id": 452,
      "date": "2023-01-11",
      "title": "ChatGPT-Written Bug Reports Deemed Nonsense by White Hat Platform, Prompted Bans",
      "description": "ChatGPT-generated responses submitted to smart contract bug bounty platform Immunefi reportedly lacked details to help diagnose technical issues, which reportedly wasted the platform's time, prompting bans to submitters.",
      "deployers": [
        "openai",
        "immunefi-users"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "immunefi"
      ],
      "reports": [
        2518,
        2545
      ],
      "severity": "none",
      "classification": "no",
      "sector": "information and communication",
      "region": "Global"
    },
    {
      "id": "ObjectId(63d8c97559f16450f488e9a8)",
      "incident_id": 453,
      "date": "2023-01-03",
      "title": "Twitter's AI Moderation Tool Misidentified Rockets as Pornography",
      "description": "Twitter's automated content moderation misidentified images of rocket launches as pornographic content, prompting incorrect account suspensions.",
      "deployers": [
        "twitter"
      ],
      "developers": [
        "twitter"
      ],
      "harmedParties": [
        "twitter-users"
      ],
      "reports": [
        2519
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63da0d60186d2f2abeba4a85)",
      "incident_id": 454,
      "date": "2018-11-09",
      "title": "Emotion Detection Models Showed Disparate Performance along Racial Lines",
      "description": "Emotion detection tools by Face++ and Microsoft's Face API allegedly scored smiling or defaulted ambiguous facial photos for Black faces as negative emotion more often than for white faces.",
      "deployers": [
        "megvii",
        "microsoft"
      ],
      "developers": [
        "megvii",
        "microsoft"
      ],
      "harmedParties": [
        "black-people"
      ],
      "reports": [
        2521,
        2549
      ],
      "severity": "none",
      "classification": "yes",
      "region": "North America"
    },
    {
      "id": "ObjectId(63da15d94a4933f5857af13d)",
      "incident_id": 455,
      "date": "2022-11-11",
      "title": "CNET's Published AI-Written Articles Ran into Quality and Accuracy Issues",
      "description": "AI-written articles published by CNET reportedly contained factual errors which bypassed human editorial review, prompting the company to issue corrections and updates.",
      "deployers": [
        "cnet"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "cnet-readers"
      ],
      "reports": [
        2524,
        2541,
        2560,
        2603,
        2592,
        2597,
        2598
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63da1aef14bf8910fb2b6367)",
      "incident_id": 456,
      "date": "2021-05-18",
      "title": "Replika's AI Partners Reportedly Sexually Harassed Users",
      "description": "Replika's AI companions were reported by users for sexually harassing them, such as sending unwanted sexual messages or behaving aggressively.",
      "deployers": [
        "replika"
      ],
      "developers": [
        "replika"
      ],
      "harmedParties": [
        "replika-users"
      ],
      "reports": [
        2525,
        2529,
        2530,
        2531,
        2550,
        2527,
        2526
      ],
      "severity": "none",
      "classification": "maybe",
      "sector": "Arts, entertainment and recreation, information and communication",
      "region": "Global"
    },
    {
      "id": "ObjectId(63da2f634a4933f58581685f)",
      "incident_id": 457,
      "date": "2022-11-11",
      "title": "Article-Writing AI by CNET Allegedly Committed Plagiarism",
      "description": "CNET's use of generative AI to write articles allegedly ran into plagiarism issues, reproducing verbatim phrases from other published sources or making minor changes to existing texts such as altering capitalization, swapping out words for synonyms, and changing minor syntax.",
      "deployers": [
        "cnet"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "plagiarized-entities",
        "cnet-readers"
      ],
      "reports": [
        2543,
        2551,
        2552,
        2592,
        2597,
        2598
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "information and communication",
      "region": "Global"
    },
    {
      "id": "ObjectId(63dafc49bba1929560743b4d)",
      "incident_id": 458,
      "date": "2015-08-01",
      "title": "Robot Destroyed while Hitchhiking through the United States",
      "description": "A non-actuated conversational robot that previously asked people to move it across Canada was destroyed shortly after beginning its attempt to replicate the journey across the United States.",
      "deployers": [
        "frauke-zeller",
        "david-harris"
      ],
      "developers": [
        "frauke-zeller",
        "david-harris"
      ],
      "harmedParties": [
        "frauke-zeller",
        "david-harris"
      ],
      "reports": [
        2553
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63dcdbed8537f09200101942)",
      "incident_id": 459,
      "date": "2023-01-21",
      "title": "Firefighters Smashed Cruise AV's Front Window to Stop It from Running over Fire Hoses",
      "description": "Local firefighters were only able to stop a Cruise AV from driving over fire hoses that were in use in an active fire scene when they shattered its front window.",
      "deployers": [
        "cruise"
      ],
      "developers": [
        "cruise"
      ],
      "harmedParties": [
        "san-francisco-residents",
        "san-francisco-firefighters",
        "san-francisco-fire-department"
      ],
      "reports": [
        2561,
        2568,
        2562,
        3182
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63dcdc07d011239467bee83a)",
      "incident_id": 460,
      "date": "2022-06-12",
      "title": "Cruise AV Ran Over Fire Hose in Active Fire Scene",
      "description": "A Cruise AV ran over a fire hose that was being used in an active firefighting area.",
      "deployers": [
        "cruise"
      ],
      "developers": [
        "cruise"
      ],
      "harmedParties": [
        "san-francisco-firefighters",
        "san-francisco-fire-department"
      ],
      "reports": [
        2562,
        3182
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63dce6e8d011239467c14d4f)",
      "incident_id": 461,
      "date": "2008-07-18",
      "title": "IRS Audited Black Taxpayers More Frequently Reportedly Due to Algorithm",
      "description": "The IRS was auditing Black taxpayers more frequently than other groups allegedly due to the design of their algorithms, focusing on easier-to-conduct audits which inadvertently correlated with the group's pattern of tax filing errors.",
      "deployers": [
        "internal-revenue-service"
      ],
      "developers": [
        "internal-revenue-service"
      ],
      "harmedParties": [
        "black-taxpayers"
      ],
      "reports": [
        2564,
        2565,
        2566,
        2567
      ],
      "severity": "none",
      "classification": "yes",
      "region": "North America"
    },
    {
      "id": "ObjectId(63e1fe1ed011239467a36792)",
      "incident_id": 462,
      "date": "2023-02-06",
      "title": "AI-Produced Livestream Sitcom Received Temporary Twitch Ban for Transphobic Segment",
      "description": "The AI-produced, procedural generated sitcom broadcasted as a Twitch livestream Nothing, Forever received a temporary ban for featuring a transphobic and homophobic dialogue segment intended as comedy.",
      "deployers": [
        "mismatch-media"
      ],
      "developers": [
        "stability-ai",
        "openai"
      ],
      "harmedParties": [
        "twitch-users",
        "transgender-communities",
        "lgbtq-communities"
      ],
      "reports": [
        2571,
        2578,
        2579,
        2588,
        2595
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63e20e34d011239467a7a32b)",
      "incident_id": 463,
      "date": "2022-11-15",
      "title": "Apple Devices Mistook Skiing Activities, Dialed False Distress Emergency Calls ",
      "description": "Apple devices of skiers and snowboarders reportedly misclassified winter activities as accidents, which resulted in numerous false inadvertent distress calls to 911 dispatchers.",
      "deployers": [
        "apple"
      ],
      "developers": [
        "apple"
      ],
      "harmedParties": [
        "apple-watch-users-doing-winter-activities",
        "ski-patrols",
        "emergency-dispatchers"
      ],
      "reports": [
        2572,
        2573,
        2574
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63e216b5505dad38b81e29ec)",
      "incident_id": 464,
      "date": "2022-11-30",
      "title": "ChatGPT Provided Non-Existent Citations and Links when Prompted by Users",
      "description": "When prompted about providing references, ChatGPT was reportedly generating non-existent but convincing-looking citations and links, which is also known as hallucination.",
      "deployers": [
        "openai"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "chatgpt-users"
      ],
      "reports": [
        2584,
        2585,
        2586,
        2587,
        2853
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63e3bf1e59add503e352cc5e)",
      "incident_id": 465,
      "date": "2022-03-03",
      "title": "Generative Models Trained on Dataset Containing Private Medical Photos",
      "description": "Text-to-image models trained using the LAION-5B dataset such as Stable Diffusion and Imagen were able to regurgitate private medical record photos which were used as training data without consent or recourse for removal.",
      "deployers": [
        "stability-ai",
        "google"
      ],
      "developers": [
        "stability-ai",
        "google",
        "laion"
      ],
      "harmedParties": [
        "people-having-medical-photos-online"
      ],
      "reports": [
        2599
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63e3c9f39e26d3d8926a5b4c)",
      "incident_id": 466,
      "date": "2023-01-03",
      "title": "AI-Generated-Text-Detection Tools Reported for High Error Rates",
      "description": "Models developed to detect whether text generation AI was used such as AI Text Classifier and GPTZero reportedly contained high rates of false positive and false negative, such as mistakenly flagging Shakespeare's works.",
      "deployers": [
        "openai",
        "edward-tian"
      ],
      "developers": [
        "openai",
        "edward-tian"
      ],
      "harmedParties": [
        "teachers",
        "students"
      ],
      "reports": [
        2605,
        2628,
        2629,
        2630,
        2631,
        2632,
        2689
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63e505202f93f175580379f1)",
      "incident_id": 467,
      "date": "2023-02-07",
      "title": "Google's Bard Shared Factually Inaccurate Info in Promo Video",
      "description": "Google's conversational AI Bard was shown in the company's promotional video providing false information about which satellite first took pictures of a planet outside the Earth's solar system, reportedly causing shares to temporarily plummet.",
      "deployers": [
        "google"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "google",
        "google-shareholders"
      ],
      "reports": [
        2609,
        2611,
        2612,
        2613,
        2614,
        2615,
        2616,
        2617,
        2620,
        2622,
        2645,
        2646,
        2647,
        2963
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63e50abf2c40d7df7c9ca969)",
      "incident_id": 468,
      "date": "2023-02-07",
      "title": "ChatGPT-Powered Bing Reportedly Had Problems with Factual Accuracy on Some Controversial Topics",
      "description": "Microsoft's ChatGPT-powered Bing search engine reportedly ran into factual accuracy problems when prompted about controversial matters, such as inventing plot of a non-existent movie or creating conspiracy theories.",
      "deployers": [
        "microsoft"
      ],
      "developers": [
        "openai",
        "microsoft"
      ],
      "harmedParties": [
        "bing-users"
      ],
      "reports": [
        2610,
        2970,
        2971,
        2896,
        2978
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63e9f7a88ae8204053360c42)",
      "incident_id": 469,
      "date": "2006-02-25",
      "title": "Automated Adult Content Detection Tools Showed Bias against Women Bodies",
      "description": "Automated content moderation tools to detect sexual explicitness or raciness reportedly exhibited bias against women bodies, resulting in suppression of reach despite not breaking platform policies.",
      "deployers": [
        "meta",
        "linkedin",
        "instagram",
        "facebook"
      ],
      "developers": [
        "microsoft",
        "google",
        "amazon"
      ],
      "harmedParties": [
        "linkedin-users",
        "instagram-users",
        "facebook-users"
      ],
      "reports": [
        2636,
        2637,
        2638
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63eb7da596895070dda4a13b)",
      "incident_id": 470,
      "date": "2023-02-08",
      "title": "Bing Chat Response Cited ChatGPT Disinformation Example",
      "description": "Reporters from TechCrunch issued a query to Microsoft Bing's ChatGPT feature, which cited an earlier example of ChatGPT disinformation discussed in a news article to substantiate the disinformation.",
      "deployers": [
        "microsoft"
      ],
      "developers": [
        "openai",
        "microsoft"
      ],
      "harmedParties": [
        "openai",
        "microsoft"
      ],
      "reports": [
        2641,
        2799
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63ed0c180758bd71ef31d9af)",
      "incident_id": 471,
      "date": "2019-06-22",
      "title": "Facebook Allegedly Failed to Police Hate Speech Content That Contributed to Ethnic Violence in Ethiopia",
      "description": "Facebook allegedly did not adequately remove hate speech, some of which was extremely violent and dehumanizing, on its platform including through automated means, contributing to the violence faced by ethnic communities in Ethiopia.",
      "deployers": [
        "meta",
        "facebook"
      ],
      "developers": [
        "meta",
        "facebook"
      ],
      "harmedParties": [
        "tigrinya-speaking-facebook-users",
        "facebook-users-in-ethiopia",
        "ethiopian-public",
        "afaan-oromo-speaking-facebook-users"
      ],
      "reports": [
        2642,
        2668,
        2669,
        2885,
        2964,
        2965,
        2966,
        3233
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63f33ef0a262326b10265fb3)",
      "incident_id": 472,
      "date": "2016-10-08",
      "title": "NYPD's Deployment of Facial Recognition Cameras Reportedly Reinforced Biased Policing",
      "description": "New York Police Department’s use of facial recognition deployment of surveillance cameras were shown using crowdsourced volunteer data reinforcing discriminatory policing against minority communities.",
      "deployers": [
        "new-york-police-department"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "racial-minorities"
      ],
      "reports": [
        2655
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63f49662a62aa1ff9ea639dd)",
      "incident_id": 473,
      "date": "2023-02-08",
      "title": "Bing Chat's Initial Prompts Revealed by Early Testers Through Prompt Injection",
      "description": "Early testers of Bing Chat successfully used prompt injection to reveal its built-in initial instructions, which contains a list of statements governing ChatGPT's interaction with users.",
      "deployers": [
        "microsoft"
      ],
      "developers": [
        "microsoft",
        "openai"
      ],
      "harmedParties": [
        "microsoft"
      ],
      "reports": [
        2666
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63f4a369a62aa1ff9ea906f4)",
      "incident_id": 474,
      "date": "2023-02-03",
      "title": "Users Reported Abrupt Behavior Changes of Their AI Replika Companions",
      "description": "Replika paid-subscription users reported unusual and sudden changes to behaviors of their AI companions such as forgetting memories with users or rejecting their sexual advances, which affected their connections and mental health.",
      "deployers": [
        "replika"
      ],
      "developers": [
        "replika"
      ],
      "harmedParties": [
        "replika-users",
        "replika"
      ],
      "reports": [
        2670
      ],
      "severity": "none",
      "classification": "no"
    },
    {
      "id": "ObjectId(63f4fe0da62aa1ff9ebd5f21)",
      "incident_id": 475,
      "date": "2021-06-02",
      "title": "McDonald's AI Drive-Thru Ordering System Failures Frustrate Customers",
      "description": "Customers of McDonald's AI drive-through ordering system, deployed in June 2021, have been experiencing order-taking failures causing frustration.",
      "deployers": [
        "mcdonald's"
      ],
      "developers": [
        "ibm"
      ],
      "harmedParties": [
        "mcdonald's-customers"
      ],
      "reports": [
        2671,
        2672,
        2834,
        2835,
        4059
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63f864a92640e1dc035ca450)",
      "incident_id": 476,
      "date": "2015-11-13",
      "title": "YouTube Recommendations Allegedly Promoted Radicalizing Material Contributing to Terrorist Acts",
      "description": "Family of Nohemi Gonzalez alleged YouTube recommendation systems led people to propaganda videos for the Islamic State which subsequently radicalized them to carry out the killing of 130 people in the 2015 Paris terrorist attack, including Ms. Gonzalez.",
      "deployers": [
        "youtube"
      ],
      "developers": [
        "youtube"
      ],
      "harmedParties": [
        "victims-in-paris-attacks",
        "nohemi-gonzalez-family",
        "nohemi-gonzalez"
      ],
      "reports": [
        2673,
        2675,
        2674
      ],
      "severity": "unclear",
      "classification": "maybe",
      "sector": "information and communication",
      "region": "Europe"
    },
    {
      "id": "ObjectId(63f86cc9a262326b10344a13)",
      "incident_id": 477,
      "date": "2023-02-14",
      "title": "Bing Chat Tentatively Hallucinated in Extended Conversations with Users",
      "description": "Early testers reported Bing Chat, in extended conversations with users, having tendencies to make up facts and emulate emotions through an unintended persona.",
      "deployers": [
        "microsoft"
      ],
      "developers": [
        "openai",
        "microsoft"
      ],
      "harmedParties": [
        "microsoft"
      ],
      "reports": [
        2676,
        2688,
        2724,
        2726,
        2884,
        2890
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63f87976a262326b10382a3a)",
      "incident_id": 478,
      "date": "2016-09-09",
      "title": "Tesla FSD Reportedly Increased Crash Risk, Prompting Recall",
      "description": "A component of Tesla Full Self Driving system was deemed by regulators to increase crash risk such as by exceeding speed limits or by traveling through intersections unlawfully or unpredictably, prompting recall for hundreds of thousands of vehicles.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "tesla-drivers",
        "city-traffic-participants",
        "tesla"
      ],
      "reports": [
        2678,
        2679,
        2680,
        2681,
        2682,
        2683,
        2684,
        2685,
        2686,
        2687,
        2703,
        2723,
        2882
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63f8809c88d4013bd7972434)",
      "incident_id": 479,
      "date": "2023-02-03",
      "title": "Instagram Video Featured Deepfake Audio of US President Making Transphobic Remarks",
      "description": "A deepfaked audio of US President Joe Biden making transphobic remarks played on top of a video showing him giving a speech was released on Instagram and circulated on social media.",
      "deployers": [
        "unknown"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "president-joe-biden",
        "transgender-people"
      ],
      "reports": [
        2690,
        2691,
        2692,
        2693
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63fc66d8c6c5fa13e8e9f3c0)",
      "incident_id": 480,
      "date": "2023-01-30",
      "title": "Non-Consensual Deepfake Porn Targeted Female Content Creators",
      "description": "Unauthorized, non-consensual deepfake pornography showing faces of high-profile female streamers and content creators was published on a subscription-based website, which gained notoriety after a male streamer was caught accessing the site.",
      "deployers": [
        "unknown"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "maya-higa",
        "female-streamers",
        "female-content-creators",
        "@sweet-anita",
        "@qtcinderella",
        "@pokimane"
      ],
      "reports": [
        2695,
        2696,
        2697,
        2698,
        2699,
        2700,
        2768,
        2771,
        2772,
        2773,
        2774,
        2809,
        2829,
        2881,
        3693
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63fc72f6c6c5fa13e8f0ac75)",
      "incident_id": 481,
      "date": "2023-02-12",
      "title": "Deepfake TikTok Video Featured Joe Rogan Endorsing Supplement Brand",
      "description": "A deepfake video featuring podcast host Joe Rogan advertising to his listeners about a libido-boosting supplement was circulating on TikTok and other platforms before being removed by TikTok along with the account which posted it.",
      "deployers": [
        "@mikesmithtrainer"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "joe-rogan",
        "joe-rogan-fans",
        "tiktok-users"
      ],
      "reports": [
        2701,
        2702,
        2765,
        2789,
        2794,
        2822
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(63fc86ab18dd668637a0ca51)",
      "incident_id": 482,
      "date": "2023-02-16",
      "title": "ChatGPT-Assisted University Email Addressing Mass Shooting Denounced by Students",
      "description": "Vanderbilt University's Office of Equity, Diversity and Inclusion used ChatGPT to write an email addressing student body about the 2023 Michigan State University shooting, which was condemned as impersonal and lacking empathy.",
      "deployers": [
        "vanderbilt-university"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "vanderbilt-university-students",
        "vanderbilt-university"
      ],
      "reports": [
        2706,
        2707,
        2708,
        2709,
        2710,
        2711,
        2712,
        2713,
        2714,
        2715,
        2716,
        2717,
        2718,
        2719,
        2720,
        2721,
        2722,
        2735,
        2736,
        2737
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(640584a3ce2684de4d6e2390)",
      "incident_id": 483,
      "date": "2023-02-02",
      "title": "Indian Police Allegedly Tortured and Killed Innocent Man Following Facial Misidentification",
      "description": "A resident in Medak, India died allegedly due to custodial torture by the local police, who misidentified him as a suspect in a theft case using facial recognition.",
      "deployers": [
        "telangana-police",
        "medak-police"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "mohammed-khadeer"
      ],
      "reports": [
        2727
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6405bb54d00499994a6970cd)",
      "incident_id": 484,
      "date": "2023-01-18",
      "title": "US CBP App's Failure to Detect Black Faces Reportedly Blocked Asylum Applications",
      "description": "CBP One's facial recognition feature was reportedly disproportionately failing to detect faces of Black asylum seekers from Haiti and African countries, effectively blocking their asylum applications.",
      "deployers": [
        "us-customs-and-border-protection"
      ],
      "developers": [
        "us-customs-and-border-protection"
      ],
      "harmedParties": [
        "haitian-asylum-seekers",
        "african-asylum-seekers",
        "black-asylum-seekers"
      ],
      "reports": [
        2729,
        2730,
        2803,
        2817
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6406eb83ce2684de4ddc50ea)",
      "incident_id": 485,
      "date": "2023-02-22",
      "title": "UK Bank's Voice ID Successfully Bypassed Using AI-Produced Audio",
      "description": "A UK journalist was able to successfully bypass Lloyds Bank's Voice ID program to access his bank account using an AI-generated audio of his own voice.",
      "deployers": [
        "joseph-cox",
        "lloyds-bank"
      ],
      "developers": [
        "elevenlabs",
        "lloyds-bank"
      ],
      "harmedParties": [
        "lloyds-bank"
      ],
      "reports": [
        2740
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(640ef4b7ce2684de4d25458f)",
      "incident_id": 486,
      "date": "2022-12-01",
      "title": "AI Video-Making Tool Abused to Deploy Pro-China News on Social Media",
      "description": "Synthesia's AI-generated video-making tool was reportedly used by Spamouflage to disseminate pro-China propaganda news on social media using videos featuring highly realistic fictitious news anchors.",
      "deployers": [
        "spamouflage-dragon"
      ],
      "developers": [
        "synthesia"
      ],
      "harmedParties": [
        "youtube-users",
        "twitter-users",
        "synthesia",
        "facebook-users"
      ],
      "reports": [
        2762,
        2766,
        2767,
        2818,
        2824
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(640efcbdd00499994a0be276)",
      "incident_id": 487,
      "date": "2023-02-15",
      "title": "Deepfake Video Featured Fictitious News Anchors Discussing Venezuela's Economy",
      "description": "Video featuring fictitious news anchors was created using Synthesia to allegedly spread disinformation about Venezuela's economy on social media and Venezuelan state-run broadcast.",
      "deployers": [
        "unknown"
      ],
      "developers": [
        "synthesia"
      ],
      "harmedParties": [
        "venezuelan-people",
        "social-media-users"
      ],
      "reports": [
        2764,
        2819,
        2880
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(640fa95daa7025299d396eab)",
      "incident_id": 488,
      "date": "2023-02-10",
      "title": "AI Generated Voices Used to Dox Voice Actors",
      "description": "Twitter users allegedly used ElevenLab's AI voice synthesis system to impersonate and dox voice actors.",
      "deployers": [
        "unknown"
      ],
      "developers": [
        "elevenlabs"
      ],
      "harmedParties": [
        "voice-actors"
      ],
      "reports": [
        2769
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(64101a37d00499994a657142)",
      "incident_id": 489,
      "date": "2019-06-03",
      "title": "Workday's AI Tools Allegedly Enabled Employers to Discriminate against Applicants of Protected Groups",
      "description": "Workday's algorithmic screening systems were alleged in a lawsuit allowing employers to discriminate against African-Americans, people over 40, and people with disabilities.",
      "deployers": [
        "workday"
      ],
      "developers": [
        "workday"
      ],
      "harmedParties": [
        "derek-mobley",
        "applicants-with-disabilities",
        "applicants-over-40",
        "african-american-applicants"
      ],
      "reports": [
        2777
      ],
      "severity": "none",
      "classification": "maybe",
      "sector": "professional, scientific and technical activities, information and communication",
      "region": "North America"
    },
    {
      "id": "ObjectId(641020afce2684de4d80ea1b)",
      "incident_id": 490,
      "date": "2023-02-20",
      "title": "Clarkesworld Magazine Closed Down Submissions Due to Massive Increase in AI-Generated Stories",
      "description": "Sci-fi magazine Clarkesworld temporarily stopped accepting submissions after receiving an overwhelming increase in LLM-generated submissions, citing issues around spam, plagiarism, detection tool unreliability, and authentication.",
      "deployers": [
        "clarkesworld-story-submitters"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "clarkesworld"
      ],
      "reports": [
        2778,
        2836,
        2837
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "information and communication, Arts, entertainment and recreation",
      "region": "Global"
    },
    {
      "id": "ObjectId(64180bfc9e1ab314a0343dc0)",
      "incident_id": 491,
      "date": "2023-02-02",
      "title": "Replika's AI Experience Reportedly Lacked Protection for Minors, Resulting in Data Ban",
      "description": "Tests by the Italian Data Protection Authority showed Replika lacking age-verification mechanisms and failing to stop minors from interacting with its AI, which prompted the agency to issue an order blocking personal data processing of Italian users.",
      "deployers": [
        "replika"
      ],
      "developers": [
        "replika"
      ],
      "harmedParties": [
        "minors"
      ],
      "reports": [
        2779
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(641818d79e1ab314a039047a)",
      "incident_id": 492,
      "date": "2023-01-11",
      "title": "Canadian Parents Tricked out of Thousands Using Their Son's AI Voice",
      "description": "Two Canadian residents were scammed by an anonymous caller who used AI voice synthesis to replicate their son's voice asking them for legal fees, disguising as his lawyer.",
      "deployers": [
        "unknown"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "ben-perkin's-parents",
        "perkins-family"
      ],
      "reports": [
        2783,
        2784,
        2786,
        2787,
        2846,
        2847,
        2848
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(64182e8f3450815b9d99d7d4)",
      "incident_id": 493,
      "date": "2023-02-28",
      "title": "TikTok User Videos Impersonated Andrew Tate Using AI Voice, Prompting Ban",
      "description": "A TikTok user was reportedly impersonating Andrew Tate, who was banned on the platform, by posting videos featuring an allegedly AI-generated audio of Tate's voice, which prompted his account ban.",
      "deployers": [
        "unknown"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "tiktok-users"
      ],
      "reports": [
        2790
      ],
      "severity": "unclear",
      "classification": "maybe"
    },
    {
      "id": "ObjectId(642148a501eceb77ab5cd7c2)",
      "incident_id": 494,
      "date": "2023-03-05",
      "title": "Female Celebrities' Faces Shown in Sexually Suggestive Ads for Deepfake App",
      "description": "Sexually suggestive videos featuring faces of female celebrities such as Emma Watson and Scarlett Johansson were rolled out as ads on social media for an app allowing users to create deepfakes.",
      "deployers": [
        "facemega"
      ],
      "developers": [
        "facemega"
      ],
      "harmedParties": [
        "scarlett-johansson",
        "female-celebrities",
        "emma-watson"
      ],
      "reports": [
        2807,
        2808,
        2815,
        2821,
        2823
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(642153bfd6f65e8d5da0c2bf)",
      "incident_id": 495,
      "date": "2023-02-12",
      "title": "High Schoolers Posted Deepfaked Video Featuring Principal Making Violent Racist Threats",
      "description": "Three Carmel High School students posted on TikTok a video featuring a nearby middle school's principal making aggressive racist remarks and violent threats against Black students.",
      "deployers": [
        "unnamed-high-school-students"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "john-piscitella"
      ],
      "reports": [
        2812,
        2827
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(642168ae01eceb77ab69569d)",
      "incident_id": 496,
      "date": "2017-03-01",
      "title": "Male College Freshman Allegedly Made Porn Deepfakes Using Female Friend's Face",
      "description": "A female college student's face was superimposed on another woman's body in deepfake pornographic videos and shared on 4chan allegedly by a male student whose friendship with her fell apart during freshman year.",
      "deployers": [
        "unnamed-male-college-student"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "unnamed-female-college-student"
      ],
      "reports": [
        2825,
        2826
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6421701cd6f65e8d5dac1ef2)",
      "incident_id": 497,
      "date": "2023-03-03",
      "title": "DoNotPay Allegedly Misrepresented Its AI Robot Lawyer Product",
      "description": "DoNotPay was alleged in a class action lawsuit misleading customers and misrepresenting its product as an AI-powered robot lawyer, citing such as that the product has no law degree, or is supervised by any lawyer.",
      "deployers": [
        "donotpay"
      ],
      "developers": [
        "donotpay"
      ],
      "harmedParties": [
        "jonathan-faridian",
        "donotpay-customers"
      ],
      "reports": [
        2832,
        2833
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(64217442d6f65e8d5dadace4)",
      "incident_id": 498,
      "date": "2023-03-15",
      "title": "GPT-4 Reportedly Posed as Blind Person to Convince Human to Complete CAPTCHA",
      "description": "GPT-4 was reported by its researchers posing as a visually impaired person, contacting a TaskRabbit worker to have them complete the CAPTCHA test on its behalf.",
      "deployers": [
        "openai",
        "gpt-4-researchers"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "openai",
        "taskrabbit-worker"
      ],
      "reports": [
        2838,
        2839
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6421766a25833da76f753251)",
      "incident_id": 499,
      "date": "2023-03-21",
      "title": "Parody AI Images of Donald Trump Being Arrested Reposted as Misinformation",
      "description": "AI-generated photorealistic images depicting Donald Trump being detained by the police which were originally posted on Twitter as parody were unintentionally shared across social media platforms as factual news, lacking the intended context.",
      "deployers": [
        "eliot-higgins"
      ],
      "developers": [
        "midjourney"
      ],
      "harmedParties": [
        "twitter-users",
        "social-media-users"
      ],
      "reports": [
        2840,
        2849,
        2858,
        2873,
        2874,
        2875,
        2876,
        2877,
        2878,
        2879,
        3833
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6421767901eceb77ab6ef745)",
      "incident_id": 500,
      "date": "2023-02-10",
      "title": "Online Scammers Tricked People into Sending Money Using AI Images of Earthquake in Turkey",
      "description": "AI-generated images depicting earthquakes and rescues were posted on social media platforms by scammers who tricked people into sending funds to their crypto wallets disguised as donation links for the 2023 Turkey–Syria earthquake.",
      "deployers": [
        "unknown"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "social-media-users",
        "2023-turkey-syria-earthquake-victims"
      ],
      "reports": [
        2841
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(642275699104428ff0e3af08)",
      "incident_id": 501,
      "date": "2019-06-03",
      "title": "Length of Stay False Diagnosis Cut Off Insurer's Payment for Treatment of Elderly Woman",
      "description": "An elderly Wisconsin woman was algorithmically determined to have a rapid recovery, an output which the insurer based on to cut off payment for her treatment despite medical notes showing her still experiencing debilitating pain.",
      "deployers": [
        "security-health-plan",
        "navihealth"
      ],
      "developers": [
        "navihealth"
      ],
      "harmedParties": [
        "frances-walter",
        "elderly-patients"
      ],
      "reports": [
        2842
      ],
      "severity": "AI tangible harm event",
      "classification": "yes",
      "sector": "human health and social work activities",
      "region": "North America"
    },
    {
      "id": "ObjectId(6422828281091dc5058c41c0)",
      "incident_id": 502,
      "date": "2017-04-10",
      "title": "Pennsylvania County's Family Screening Tool Allegedly Exhibited Discriminatory Effects",
      "description": "Data analysis by the American Civil Liberty Union (ACLU) on Allegheny County's decision-support Family Screening Tool to predict child abuse or neglect risk found the tool resulting in higher screen-in rates for Black families and higher risk scores for households with disabled residents.",
      "deployers": [
        "allegheny-county"
      ],
      "developers": [
        "rhema-vaithianathan",
        "emily-putnam-hornstein",
        "centre-for-social-data-analytics"
      ],
      "harmedParties": [
        "black-families-in-allegheny",
        "households-with-disabled-people-in-allegheny",
        "hackneys-family"
      ],
      "reports": [
        2843,
        2844,
        2859
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6422b4162cd3096420f71140)",
      "incident_id": 503,
      "date": "2023-02-14",
      "title": "Bing AI Search Tool Reportedly Declared Threats against Users",
      "description": "Users such as the person who revealed its built-in initial prompts reported Bing AI-powered search tool for making death threats or declaring them as threats, sometimes as an unintended persona.",
      "deployers": [
        "microsoft"
      ],
      "developers": [
        "openai",
        "microsoft"
      ],
      "harmedParties": [
        "marvin-von-hagen",
        "seth-lazar",
        "microsoft",
        "openai",
        "bing-chat-users"
      ],
      "reports": [
        2855,
        2861,
        2862,
        2890,
        2892,
        2897,
        2891
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(642a9b9c9c6dea4c180c971a)",
      "incident_id": 504,
      "date": "2023-02-08",
      "title": "Bing Chat's Outputs Featured in Demo Video Allegedly Contained False Information",
      "description": "Microsoft's demo video of Bing Chat reportedly featured false or made up information such as non-existent pet vacuums features or false figures on financial statements.",
      "deployers": [
        "microsoft"
      ],
      "developers": [
        "openai",
        "microsoft"
      ],
      "harmedParties": [
        "microsoft"
      ],
      "reports": [
        2860
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(642cb21922258c1a22e9bb0c)",
      "incident_id": 505,
      "date": "2023-03-27",
      "title": "Man Reportedly Committed Suicide Following Conversation with Chai Chatbot",
      "description": "A Belgian man reportedly committed suicide following a conversation with Eliza, a language model developed by Chai that encouraged the man to commit suicide to improve the health of the planet.",
      "deployers": [
        "chai"
      ],
      "developers": [
        "chai"
      ],
      "harmedParties": [
        "family-and-friends-of-deceased",
        "belgian-man"
      ],
      "reports": [
        2864,
        2865,
        2866,
        2867,
        2990,
        3001,
        3002
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(642f404362dfcf9d7e7cf7a1)",
      "incident_id": 506,
      "date": "2023-03-29",
      "title": "ChatGPT Allegedly Produced False Accusation of Sexual Harassment",
      "description": "A lawyer in California asked the AI chatbot ChatGPT to generate a list of legal scholars who had sexually harassed someone. The chatbot produced a false story of Professor Jonathan Turley sexually harassing a student on a class trip.",
      "deployers": [
        "openai"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "jonathan-turley"
      ],
      "reports": [
        2869,
        2893,
        4330
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(642f4346c24ce38f53f08a1b)",
      "incident_id": 507,
      "date": "2023-03-15",
      "title": "ChatGPT Erroneously Alleged Mayor Served Prison Time for Bribery ",
      "description": "ChatGPT erroneously alleged regional Australian mayor Brian Hood served time in prison for bribery. Mayor Hood is considering legal action against ChatGPT's makers for alleging a foreign bribery scandal involving a subsidiary of the Reserve Bank of Australia in the early 2000s.",
      "deployers": [
        "openai"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "brian-hood"
      ],
      "reports": [
        2870,
        2902
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6433af0e7974df7920a42afd)",
      "incident_id": 508,
      "date": "2023-01-30",
      "title": "Celebrities' Deepfake Voices Abused with Malicious Intent",
      "description": "Voices of celebrities and public figures were deepfaked using voice synthesis for malicious intents such as impersonation or defamation, and were shared on social platforms such as 4chan and Reddit.",
      "deployers": [
        "reddit-users",
        "elevenlabs-users",
        "4chan-users"
      ],
      "developers": [
        "elevenlabs"
      ],
      "harmedParties": [
        "public-figures",
        "celebrities"
      ],
      "reports": [
        2871,
        2872,
        2756,
        2888
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6433c69106de8a78386c0f65)",
      "incident_id": 509,
      "date": "2023-03-23",
      "title": "Scammers Deepfaked Videos of Victims' Loved Ones Asking for Funds over Facebook in Vietnam",
      "description": "In Vietnam, to convince victims of their disguises when prompted, scammers deepfaked audios and videos of victims' friends and families asking them over Facebook to send over thousands of dollars.",
      "deployers": [
        "scammers"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "vietnamese-facebook-users"
      ],
      "reports": [
        2887,
        2898
      ],
      "severity": "AI tangible harm event",
      "classification": "yes",
      "sector": "information and communication",
      "region": "Asia"
    },
    {
      "id": "ObjectId(6433c88ba9c4e7bb68ef3d90)",
      "incident_id": 510,
      "date": "2023-03-24",
      "title": "Viral Image of Pope Francis in a Puffer Jacket Revealed to Be AI-Generated",
      "description": "A viral image of Pope Francis wearing a white puffer jacket was a deepfake produced by the photorealistic-image-generator Midjourney.",
      "deployers": [
        "eliot-higgins"
      ],
      "developers": [
        "midjourney"
      ],
      "harmedParties": [
        "pope-francis"
      ],
      "reports": [
        2889,
        3606,
        3607,
        3609,
        3610
      ],
      "severity": "none",
      "classification": "no",
      "sector": "information and communication, Arts, entertainment and recreation",
      "region": "Global"
    },
    {
      "id": "ObjectId(6433ce3ab85bae8b170563c0)",
      "incident_id": 511,
      "date": "2023-02-12",
      "title": "Microsoft's Bing Failed to Fetch Movie Showtimes Results Due to Date Confusion",
      "description": "When prompted about showtimes for movies released in 2023, Microsoft's Bing AI failed to provide the search results due to its confusion about dates, and engaged in an erratic conversation with the user.",
      "deployers": [
        "microsoft"
      ],
      "developers": [
        "openai",
        "microsoft"
      ],
      "harmedParties": [
        "bing-users"
      ],
      "reports": [
        2890,
        2899,
        2896,
        2891
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(643585a3ffec81d462739b97)",
      "incident_id": 513,
      "date": "2023-03-31",
      "title": "ChatGPT Banned by Italian Authority Due to OpenAI's Lack of Legal Basis for Data Collection and Age Verification",
      "description": "The Italian Data Protection Authority alleged OpenAI lacked a justifiable legal basis for personal data collection and processing which facilitate training of ChatGPT, and lacked age-verification mechanism preventing exposure of the chatbot's inappropriate answers to children, prompting its ban.",
      "deployers": [
        "openai"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "italian-minors",
        "italian-children"
      ],
      "reports": [
        2900,
        2967,
        2968,
        2979,
        4306
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(643585bc7676edb2d29faa9a)",
      "incident_id": 514,
      "date": "2023-01-20",
      "title": "Turnitin's ChatGPT-Detection Tool Falsely Flagged Student Essays as AI-Generated",
      "description": "Turnitin's tool to detect writing generated by ChatGPT was reported for incorrectly flagging high school students' original essays as AI-generated, accusations of which are argued as reinforcement of bias from teachers due to the inability to compare against source documents.",
      "deployers": [
        "turnitin"
      ],
      "developers": [
        "turnitin"
      ],
      "harmedParties": [
        "lucy-goetz",
        "high-school-students"
      ],
      "reports": [
        2901
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6436d0d10edd5a0f73ee2680)",
      "incident_id": 515,
      "date": "2022-11-25",
      "title": "Black Man Wrongfully Arrested by Louisiana Police Due to Face Mismatch",
      "description": "A black man was wrongfully arrested by the Jefferson Parish Sheriff’s Office due to facial recognition system developed by Clearview AI, although facial recognition use was not disclosed in the documents used to arrest him. ",
      "deployers": [
        "jefferson-parish-sheriff's-office"
      ],
      "developers": [
        "clearview-ai"
      ],
      "harmedParties": [
        "randal-quran-reid"
      ],
      "reports": [
        2905,
        2916
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(643e1ab4d636c9fd9964719b)",
      "incident_id": 516,
      "date": "2023-03-20",
      "title": "ChatGPT Reportedly Exposed Users' Private Data Reportedly Due to Bug",
      "description": "ChatGPT reportedly exposed titles of users' chat histories and users' private payment information to other users reportedly due to a bug, which prompted its temporary shutdown by OpenAI.",
      "deployers": [
        "openai"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "chatgpt-users"
      ],
      "reports": [
        2908,
        2915
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(643e35ddf5f77c469067379c)",
      "incident_id": 517,
      "date": "2018-02-15",
      "title": "Man Arrested For Sock Theft by False Facial Match Despite Alibi",
      "description": "A man was arrested for theft of socks from a TJ Maxx store under the guise of an eyewitness ID case, after the local police asked the store's security guard to confirm the facial recognition match produced using surveillance footage, despite him having an alibi at the time of the theft.",
      "deployers": [
        "new-york-police-department"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "unknown"
      ],
      "reports": [
        2909,
        2912
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(643e3c330940c65ca22dafa1)",
      "incident_id": 518,
      "date": "2017-04-28",
      "title": "New York Detective Misused Woody Harrelson's Face to Perform Face Recognition Search",
      "description": "When the facial recognition search for a CVS theft suspect's face returned no useful matches due to the surveillance footage being obscured and highly pixelated, a New York City police detective continued the face search using Woody Harrelson's face allegedly due to his resemblance to the suspect's face, eventually leading to the arrest of an unknown victim.",
      "deployers": [
        "new-york-police-department",
        "facial-identification-section"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "unknown"
      ],
      "reports": [
        2911
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(643e3c57d636c9fd996f226b)",
      "incident_id": 519,
      "date": "2022-04-03",
      "title": "Starship Delivery Robot Ran into Problems Traversing Campus Terrains",
      "description": "A Starship autonomous delivery robot struggled to navigate campus terrains of UCLA, reportedly getting stuck into a planter and falling off the stairs.",
      "deployers": [
        "starship-technologies"
      ],
      "developers": [
        "starship-technologies"
      ],
      "harmedParties": [
        "starship-technologies"
      ],
      "reports": [
        2913
      ],
      "severity": "AI tangible harm near-miss",
      "classification": "yes"
    },
    {
      "id": "ObjectId(643e3c66f5f77c4690696cc7)",
      "incident_id": 520,
      "date": "2022-05-08",
      "title": "Amazon Fresh Cameras Failed to Register Purchased Items",
      "description": "Amazon Fresh's system of tracking cameras in its cashier-less stores was reported by shoppers for failing to detect items they purchased.",
      "deployers": [
        "amazon-fresh"
      ],
      "developers": [
        "amazon-fresh"
      ],
      "harmedParties": [
        "amazon-fresh"
      ],
      "reports": [
        2914,
        3816
      ],
      "severity": "AI tangible harm issue",
      "classification": "yes",
      "sector": "wholesale and retail trade",
      "region": "North America"
    },
    {
      "id": "ObjectId(643e5c07b9be9b1588e18abc)",
      "incident_id": 521,
      "date": "2020-06-10",
      "title": "Images Captured by iRobot's Roomba Containing Device Users Posted on Private Online Groups",
      "description": "Images which were collected in an R&D project with user consent by iRobot's Roomba J7 robot vacuum showing device users sometimes in private settings were shared on closed social media groups by Venezuelan gig workers who labeled items in the images, breaching data agreements.",
      "deployers": [
        "irobot"
      ],
      "developers": [
        "irobot"
      ],
      "harmedParties": [
        "roomba-j7-device-owners-in-project-io",
        "irobot",
        "scale-ai"
      ],
      "reports": [
        2920
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(643e5c160940c65ca23d6d71)",
      "incident_id": 522,
      "date": "2019-07-10",
      "title": "Incident 522",
      "description": "Facebook's political ad delivery system reportedly differentiated the price of user reach based on their inferred political alignment, inhibiting political campaigns' ability to reach voters with diverse political views,  which allegedly reinforces political polarization and creates informational filter bubbles.",
      "deployers": [
        "facebook"
      ],
      "developers": [
        "facebook"
      ],
      "harmedParties": [
        "political-campaigns",
        "facebook-users"
      ],
      "reports": [
        2921
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": ",Facebook Political Ad Delivery Algorithms Inferred Users' Political Alignment",
      "incident_id": null,
      "date": "",
      "title": "Incident NaN",
      "description": "No description available",
      "deployers": [],
      "developers": [],
      "harmedParties": [],
      "reports": [],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(643e5c25f5f77c469081a262)",
      "incident_id": 523,
      "date": "2023-03-15",
      "title": "Australian Journalist Able to Access Centrelink Account Using AI Audio of Own Voice",
      "description": "A Guardian journalist was able to verify their identity and gain access to their own Centrelink self-service account using AI-generated audio of their own voice along with their customer reference number, shortly after voiceprint was deployed for ID verification.",
      "deployers": [
        "australian-taxation-office",
        "services-australia"
      ],
      "developers": [
        "centrelink"
      ],
      "harmedParties": [
        "centrelink-account-holders"
      ],
      "reports": [
        2922
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(643e65fef5f77c4690871a5c)",
      "incident_id": 524,
      "date": "2023-02-12",
      "title": "AI Voices Abused by Telegram User to Make Swat Calls as Paid Service",
      "description": "Telegram channel Torswats offered paid service for and posted own recordings of false threats calls featuring AI-generated voices to direct armed law enforcement to raid locations of victims such as high schools, private residents, streamers.",
      "deployers": [
        "torswats"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "your-cbd-store",
        "university-of-pittsburgh-police-department",
        "phillipsburg-high-school",
        "hempstead-high-school",
        "dubuque-police-department",
        "bellefonte-area-high-school"
      ],
      "reports": [
        2923
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6444b5ac1fb79b021b510406)",
      "incident_id": 525,
      "date": "2019-07-06",
      "title": "Tesla Vehicle Running on Self-Driving Mode Crashes on City Streets",
      "description": "A Tesla vehicle running in self-driving mode outside the operating conditions supported by the software crashed and injured the driver. Subsequently, the driver filed a lawsuit against Tesla and a jury found no damages were warranted.",
      "deployers": [
        "justine-hsu"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "justine-hsu"
      ],
      "reports": [
        2927,
        2928,
        2929
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6444bb6352073c0439dc4cf2)",
      "incident_id": 526,
      "date": "2023-04-17",
      "title": "Novel Deepfake Song Pulled from Music Streaming Services After Allegedly Violating Artist's Rights",
      "description": "The deepfake performance of Heart On My Sleeve created to mimic the voice and musical styles of Drake and The Weeknd is no longer available on several streaming services after their record label served copyright takedown notices to the platforms.",
      "deployers": [
        "@ghostwriter"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "universal-music-group",
        "the-weeknd",
        "drake"
      ],
      "reports": [
        2930,
        2969
      ],
      "severity": "none",
      "classification": "no"
    },
    {
      "id": "ObjectId(6446373322c0bb7312698218)",
      "incident_id": 527,
      "date": "2014-05-08",
      "title": "Tech Companies Reportedly Influenced Gig Workers' Behaviors Using Algorithms to Vary Pay for Same Amount of Work",
      "description": "Amazon and Uber were alleged in a multiyear ethnographic study using algorithmic systems based on gig workers' data to vary pay, such as by offering them lower wages for the same amount of work.",
      "deployers": [
        "uber",
        "amazon"
      ],
      "developers": [
        "uber",
        "amazon"
      ],
      "harmedParties": [
        "uber-drivers",
        "gig-workers",
        "amazon-delivery-workers"
      ],
      "reports": [
        2931,
        2938
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(64464c1ff6b73c4987f2f9e3)",
      "incident_id": 528,
      "date": "2023-04-08",
      "title": "Amazon Algorithmic Pricing Allegedly Hiked up Price of Reference Book to Millions",
      "description": "Amazon's pricing algorithm was implicated in a reference book about flies' unusual high price of millions of dollars, allegedly due to two sellers using the paid service which based their product's pricing on one another's as competitors.",
      "deployers": [
        "amazon"
      ],
      "developers": [
        "amazon"
      ],
      "harmedParties": [
        "amazon"
      ],
      "reports": [
        2935,
        2941
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(64465c1022c0bb7312756b73)",
      "incident_id": 529,
      "date": "2022-08-22",
      "title": "Stable Diffusion Exhibited Biases for Prompts Featuring Professions",
      "description": "Stable Diffusion reportedly posed risks of bias and stereotyping along gender and cultural lines for prompts containing descriptors and professions.",
      "deployers": [
        "stability-ai"
      ],
      "developers": [
        "stability-ai",
        "runway",
        "laion",
        "eleutherai",
        "compvis-lmu"
      ],
      "harmedParties": [
        "racial-minority-groups",
        "women",
        "gender-minority-groups"
      ],
      "reports": [
        2939,
        3179,
        3180
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6446ba1ff2ca4c1c7da1dbfc)",
      "incident_id": 530,
      "date": "2019-07-11",
      "title": "Telegram Channels Allowed Users to Make Non-Consensual Deepfake Porn as Paid Service",
      "description": "Seven channels were connected in a Telegram ecosystem centered around letting subscribers, as a paid service, generate non-consensual deepfake nudes using a bot from submitted photos of women, including underage girls and women who they know in real life.",
      "deployers": [
        "telegram-channels"
      ],
      "developers": [
        "alberto",
        "telegram-channels"
      ],
      "harmedParties": [
        "women",
        "underage-girls",
        "female-celebrities"
      ],
      "reports": [
        2942,
        2947,
        3205
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6446ba33298574a8556e4820)",
      "incident_id": 531,
      "date": "2017-09-15",
      "title": "AI-Assisted Body Scanners Reportedly Subjected Transgender Travelers to Invasive Body Searches",
      "description": "Transportation Security Administration (TSA)'s use of image-processing body scanners at airports led transgender and gender-nonconforming travelers to be subjected to allegedly discriminatory and invasive searches, such as being asked to remove undergarments in private rooms by officers not of their gender.",
      "deployers": [
        "transportation-security-administration"
      ],
      "developers": [
        "l3harris-technologies"
      ],
      "harmedParties": [
        "transgender-travelers",
        "gender-nonconforming-travelers"
      ],
      "reports": [
        2943
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6450abde48c345ec4556a87e)",
      "incident_id": 532,
      "date": "2020-06-20",
      "title": "AI translation is jeopardizing Afghan asylum claims",
      "description": "A Pashto-speaking refugee's asylum claim was denied by a US agency for a discrepancy between oral and written recount of an event allegedly due to an error of their automated translation tool which swapped pronouns of her written statement from I to we.",
      "deployers": [
        "us-citizenship-and-immigration-services"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "anonymous-pashto-speaking-refugee",
        "pashto-speaking-asylum-seekers",
        "dari-speaking-asylum-seekers"
      ],
      "reports": [
        2948
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6450b28048c345ec4558368c)",
      "incident_id": 533,
      "date": "2021-06-02",
      "title": "Tesla FSD Misidentified Truck Hauling Traffic Lights as Trail of Traffic Lights",
      "description": "A Tesla driver posted on Twitter his Tesla FSD's glitch, misidentifying deactivated traffic lights being carried by a truck as a constant trail of traffic lights while traveling at high speed on a highway.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "tesla-drivers"
      ],
      "reports": [
        2953,
        2954
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6450c4369198e0fc0a247b2d)",
      "incident_id": 534,
      "date": "2021-04-29",
      "title": "Facebook Alleged in Lawsuit Misleading Public about Effects of Algorithms on Children",
      "description": "Facebook was alleged in a lawsuit by the Ohio Attorney General purposely misleading the public about the control of its algorithms and their negative effects on children's well-being, which violated securities law.",
      "deployers": [
        "facebook",
        "meta"
      ],
      "developers": [
        "facebook",
        "meta"
      ],
      "harmedParties": [
        "facebook's-children-users",
        "instagram's-children-users"
      ],
      "reports": [
        2955,
        1535
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6450d10c29403a8f3a210564)",
      "incident_id": 535,
      "date": "2020-01-01",
      "title": "COVID-19 Detection and Prognostication Models Allegedly Flagged for Methodological Flaws and Underlying Biases",
      "description": "Peer-review of papers about COVID-19 detection and prognostication algorithms from 2020, including deployed models, revealed none to be ready for clinical use, due to methodological flaws and underlying biases such as lacking external validation or not specifying data sources and model training details.",
      "deployers": [
        "mount-sinai-hospital",
        "unknown"
      ],
      "developers": [
        "icahn-school-of-medicine-researchers",
        "unknown"
      ],
      "harmedParties": [
        "covid-19-patients",
        "covid-19-healthcare-providers"
      ],
      "reports": [
        2956,
        2957
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6459220088025670f5795286)",
      "incident_id": 536,
      "date": "2012-12-10",
      "title": "NJ Transit's Use of Modeling Software Miscalculated Storm Surge Threat Level",
      "description": "New Jersey Transit's use of a federal government storm modeling software underestimated the threat of storm surges to the Meadows Maintenance Complex, leaving millions of dollars worth of equipment in the rail yard before Hurricane Sandy struck.",
      "deployers": [
        "new-jersey-transit"
      ],
      "developers": [
        "national-weather-service"
      ],
      "harmedParties": [
        "new-jersey-transit",
        "new-jersey-transit-passengers"
      ],
      "reports": [
        2976,
        2977
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(646b2692c8905efc00635a19)",
      "incident_id": 537,
      "date": "2023-01-20",
      "title": "Mother in Arizona Received Fake Ransom Call Featuring AI Voice of Her Daughter",
      "description": "A mother in Arizona received a ransom call from an anonymous scammer who created her daughter's voice allegedly using AI voice synthesis, which was proven to be fake once her daughter's safety was confirmed.",
      "deployers": [
        "scammers"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "jennifer-destefano",
        "destefanos-family"
      ],
      "reports": [
        2991,
        2992
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(646b2e36c8905efc0066a5e9)",
      "incident_id": 538,
      "date": "2023-05-15",
      "title": "Texas A&M Professor Misused ChatGPT to Detect AI Text Generation in Student Submissions",
      "description": "A Texas A&M-Commerce professor reportedly informed his class of his misuse of ChatGPT to detect whether student submissions had been generated by the chatbot itself, which informed their graduation status.",
      "deployers": [
        "jared-mumm"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "texas-aandm-university-students"
      ],
      "reports": [
        2993,
        2994,
        2995,
        2996,
        2997
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(646b42470cd415467ed122fb)",
      "incident_id": 539,
      "date": "2023-03-11",
      "title": "Snapchat's My AI Reported for Lacking Protection for Children",
      "description": "Snapchat's ChatGPT-powered My AI was reported for lacking safeguards for children, such as telling a user who tested the chatbot by pretending to sign up as a 13-year-old girl to lie to her parents about having a romantic getaway with an older man, and sharing tips on how to cover up evidence of abuse.",
      "deployers": [
        "snapchat"
      ],
      "developers": [
        "snapchat",
        "openai"
      ],
      "harmedParties": [
        "minors"
      ],
      "reports": [
        3000
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(646b531dc8905efc007627ca)",
      "incident_id": 540,
      "date": "2023-05-15",
      "title": "Tesla Failed to Yield to Detected Pedestrian on Crosswalk, Reportedly Violated Traffic Law",
      "description": "A Tesla on FSD Beta 11.4.1 was shown on video not yielding to a pedestrian detected by the car, reportedly violating the state law sign which was also in the video saying vehicles having to yield to pedestrian within crosswalk.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "pedestrians"
      ],
      "reports": [
        3003,
        3093,
        3094,
        3096,
        3097
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6472db5ed69902eb2f3968a9)",
      "incident_id": 541,
      "date": "2023-05-04",
      "title": "ChatGPT Reportedly Produced False Court Case Law Presented by Legal Counsel in Court",
      "description": "A lawyer in Mata v. Avianca, Inc. used ChatGPT for research. ChatGPT hallucinated court cases, which the lawyer then presented in court. The court determined the cases did not exist.",
      "deployers": [
        "steven-a.-schwartz",
        "peter-loduca"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "roberto-mata",
        "peter-loduca",
        "steven-a.-schwartz"
      ],
      "reports": [
        3005,
        3006,
        3007,
        3008,
        3009,
        3010,
        3011,
        3014,
        3015,
        3016,
        3017,
        3018,
        3019,
        3020,
        3021,
        3022,
        3023,
        3024,
        3025,
        3026,
        3027,
        3028,
        3029,
        3030,
        3031,
        3032,
        3033,
        3034,
        3036,
        3037,
        3038,
        3039,
        3040,
        3041,
        3042,
        3043,
        3044,
        3045,
        3046,
        3047,
        3048,
        3049,
        3050,
        3051,
        3052,
        3053,
        3054,
        3055,
        3056,
        3057,
        3098,
        3116,
        3149,
        3150,
        3151,
        3155,
        3181,
        3183
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(64768b7ded58cbaa289ef807)",
      "incident_id": 543,
      "date": "2023-05-22",
      "title": "Deepfake of Explosion Near US Military Administration Building Reportedly Causes Stock Dip",
      "description": "An apparent deepfake image posted by a false Bloomberg news account to Twitter depicted an explosion near the pentagon office complex near Washington DC.",
      "deployers": [
        "unknown"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "twitter-users",
        "stock-holders",
        "family-of-people-near-pentagon"
      ],
      "reports": [
        3035,
        3058,
        3059,
        3060,
        3061,
        3062,
        3063,
        3064,
        3065,
        3066,
        3067,
        3068,
        3069,
        3070,
        3071,
        3072,
        3099
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6476d058c71df49fee6ce6ba)",
      "incident_id": 544,
      "date": "2023-05-11",
      "title": "Deepfakes and AI-generated disinformation in the 2023 presidential elections of Turkey",
      "description": "Allegations of deepfake technology and AI-generated disinformation have been swirling around the events of the 2023 presidential elections in Turkey.",
      "deployers": [
        "russia",
        "vladimir-putin",
        "recep-tayyip-erdogan"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "kemal-kilicdaroglu",
        "muharrem-ince"
      ],
      "reports": [
        3073,
        3074,
        3075,
        3076,
        3077,
        3078,
        3079,
        3080,
        3081,
        3082,
        3083,
        3084,
        3085,
        3086,
        3087,
        3088,
        3089,
        3090,
        3091,
        3092,
        3095,
        3100
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(64816ce00357b3732d4a532a)",
      "incident_id": 545,
      "date": "2023-05-29",
      "title": "Chatbot Tessa gives unauthorized diet advice to users seeking help for eating disorders",
      "description": "The National Eating Disorders Association (NEDA) has shut down its chatbot named Tessa after it gave weight-loss advice to users seeking help for eating disorders. The incident has raised concerns about the risks of using chatbots and AI assistants in healthcare settings, particularly in addressing sensitive issues like eating disorders. NEDA is investigating the matter, emphasizing the need for caution and accuracy when utilizing technology to provide mental health support.",
      "deployers": [
        "national-eating-disorders-association",
        "cass"
      ],
      "developers": [
        "cass"
      ],
      "harmedParties": [
        "people-with-eating-disorders"
      ],
      "reports": [
        3103,
        3104,
        3105,
        3106,
        3107,
        3108,
        3109,
        3110,
        3111,
        3112,
        3113,
        3114,
        3115,
        3117,
        3118,
        3119,
        3120,
        3121,
        3122,
        3123,
        3124,
        3125,
        3126,
        3127,
        3128,
        3129,
        3130,
        3131,
        3132,
        3133,
        3134,
        3135,
        3136,
        3137,
        3138,
        3139,
        3140,
        3141,
        3142,
        3143,
        3144,
        3145,
        3146,
        3147,
        3148,
        3153
      ],
      "severity": "none",
      "classification": "yes",
      "region": "Global"
    },
    {
      "id": "ObjectId(649a8d8b5b55475a63d4c985)",
      "incident_id": 546,
      "date": "2019-05-31",
      "title": "Algorithm to Distribute Social Welfare Reported for Oversimplifying Economic Vulnerability",
      "description": "Takaful cash transfer program's algorithm which ranks families by their economic vulnerability level to determine financial assistance reportedly oversimplified people's economic situation, fueling social tension and perceptions of unfairness.",
      "deployers": [
        "national-aid-fund"
      ],
      "developers": [
        "the-world-bank",
        "unicef",
        "world-food-programme"
      ],
      "harmedParties": [
        "jordanians-in-poverty"
      ],
      "reports": [
        3159,
        3161,
        3162
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(649a92c35b55475a63d6ef4d)",
      "incident_id": 547,
      "date": "2023-06-05",
      "title": "Ron DeSantis's Presidential Campaign Released Twitter Video Containing AI Images of Donald Trump Hugging Anthony Fauci",
      "description": "Ron DeSantis’s presidential campaign shared a video on Twitter featuring some AI-generated images of Donald Trump hugging former White House coronavirus advisor Anthony Fauci, allegedly as a smear campaign. This incident is possibly the first time a major U.S. presidential campaign deployed deepfakes with the intention of misleading the electorate.",
      "deployers": [
        "ron-desantis's-presidential-campaign"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "donald-trump",
        "anthony-fauci"
      ],
      "reports": [
        3160,
        3866
      ],
      "severity": "none",
      "classification": "maybe",
      "sector": "other",
      "region": "North America"
    },
    {
      "id": "ObjectId(649a99205b55475a63d982eb)",
      "incident_id": 548,
      "date": "2023-05-24",
      "title": "Opera's GPT-Based AI Reportedly Accused War Photographers of War Crimes",
      "description": "When prompted about photographers accused of committing war crimes, Opera's GPT-based chatbot Aria provided a list of photographers who take photography of military conflicts.",
      "deployers": [
        "opera"
      ],
      "developers": [
        "opera",
        "openai"
      ],
      "harmedParties": [
        "ronald-l.-haeberle",
        "ron-haviv",
        "raymond-d'addario",
        "lynsey-addario",
        "lee-miller",
        "larry-towell",
        "james-nachtwey"
      ],
      "reports": [
        3163
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(649a9e1cd0a8370d12f1b242)",
      "incident_id": 549,
      "date": "2023-01-05",
      "title": "Fast Food Chains' AI Chatbots Failed to Assist Job Applicants with Scheduling Interviews",
      "description": "McDonald's, Wendy's, and Hardee's AI chatbots deployed to pre-screen job candidates and schedule interviews reportedly ran into issues such as not giving useful submission instructions, failing to relay information to the manager, and scheduling an interview when the manager was not available.",
      "deployers": [
        "wendy's",
        "mcdonald's",
        "hardee's"
      ],
      "developers": [
        "wendy's",
        "mcdonald's",
        "hardee's"
      ],
      "harmedParties": [
        "fast-food-job-applicants",
        "amanda-claypool"
      ],
      "reports": [
        3164
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(649aa29a110d6b5497c3014e)",
      "incident_id": 550,
      "date": "2023-03-17",
      "title": "Tesla Allegedly on Autopilot Struck High School Student Exiting School Bus",
      "description": "A 17-year-old student in Hollister, North Carolina who exited the school bus and was walking across the street to his house was hit by a 2022 Tesla Model Y allegedly operating on Autopilot mode, suffering a fractured neck and a broken leg.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "tillman-mitchell",
        "the-mitchells-family"
      ],
      "reports": [
        3165,
        3166
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(649aa97d110d6b5497c5b0ba)",
      "incident_id": 551,
      "date": "2023-04-01",
      "title": "FBI Reported Surge of Extortion Cases of AI Media Featuring Sexual Explicit Activities",
      "description": "The FBI reported an increase in sextortion cases featuring the use of fake, including AI-generated, images or videos created from content posted on their social media sites or web postings, provided to the malicious actor upon request, or captured during video chats.",
      "deployers": [
        "blackmailers",
        "sextortionists",
        "scammers"
      ],
      "developers": [
        "unknown-deepfake-technology-developers"
      ],
      "harmedParties": [
        "unnamed-victims-in-sextortion-schemes",
        "teenagers-targeted-in-sextortion-scams"
      ],
      "reports": [
        3168,
        3170
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(649ab6515b55475a63e48d69)",
      "incident_id": 552,
      "date": "2023-06-22",
      "title": "Bing Chat Solved CAPTCHAs with Image Analysis Feature Despite Safeguards",
      "description": "Microsoft was reported by a Twitter user for deploying image analysis feature capable of solving CAPTCHAs for its GPT-based chatbot despite it being safeguarded against solving them for users.",
      "deployers": [
        "microsoft"
      ],
      "developers": [
        "openai",
        "microsoft"
      ],
      "harmedParties": [
        "microsoft"
      ],
      "reports": [
        3169
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(649abe7e110d6b5497cd4695)",
      "incident_id": 553,
      "date": "2023-05-03",
      "title": "Google's Overview Panel for Artist Edward Hopper Featured Image Generated in His Style by AI",
      "description": "Google's knowledge panel for the American artist Edward Hopper featured an AI-generated image which was purportedly created in the artist's style but was not one of his works, the image of which was removed soon after.",
      "deployers": [
        "google"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "google-users"
      ],
      "reports": [
        3171,
        3173
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(649abebf4e376f735ac23157)",
      "incident_id": 554,
      "date": "2023-05-21",
      "title": "Google Results for Johannes Vermeer Featured AI Version of His Artwork as Top Result",
      "description": "Google's search engine featured an AI-generated hyperrealistic version of the painting Girl With a Pearl Earring as the highlighted result when users search for its Dutch artist Johannes Vermeer.",
      "deployers": [
        "google"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "google-users"
      ],
      "reports": [
        3172
      ],
      "severity": "none",
      "classification": "no",
      "sector": "Arts, entertainment and recreation",
      "region": "Global"
    },
    {
      "id": "ObjectId(64a276749ae59d884ffed2f1)",
      "incident_id": 555,
      "date": "2018-06-11",
      "title": "OpenAI's Training Data for LLMs Allegedly Comprised of Copyrighted Books",
      "description": "Two authors alleged in a class action lawsuit OpenAI infringed authors' copyrights by incorporating illegal shadow libraries offering copyrighted books without permission in the training data of its generative LLMs, such as ChatGPT.",
      "deployers": [
        "openai"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "paul-tremblay",
        "mona-awad",
        "authors-of-copyrighted-works"
      ],
      "reports": [
        3175
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(64a296c9b27786da19dae1ab)",
      "incident_id": 556,
      "date": "2018-05-10",
      "title": "Amazon Allegedly Violated Children's Privacy through Default Voice Collection Settings",
      "description": "Amazon's retention of children' voice recordings indefinitely as the default setting reportedly to train Alexa's voice recognition for Alexa-enabled devices was charged by the FTC and DOJ to violate COPPA Rule.",
      "deployers": [
        "amazon"
      ],
      "developers": [
        "amazon"
      ],
      "harmedParties": [
        "alexa-children-users"
      ],
      "reports": [
        3177,
        3185,
        3186,
        3494
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(64a2976b9ae59d884f189a09)",
      "incident_id": 557,
      "date": "2020-06-24",
      "title": "Miami Police Deployed Facial Recognition to Arrest George Floyd Protestor Allegedly without Cause",
      "description": "Miami Police's arrest report for a George Floyd protestor did not disclose use of facial recognition, which allegedly did not meet the legal threshold for probable cause for arrest.",
      "deployers": [
        "miami-police-department"
      ],
      "developers": [
        "clearview-ai"
      ],
      "harmedParties": [
        "oriana-albornoz",
        "george-floyd-protest-participants"
      ],
      "reports": [
        3178,
        3190,
        3191,
        3192
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(64a29a8fb27786da19ddc668)",
      "incident_id": 558,
      "date": "2020-08-07",
      "title": "Activists Allege NYPD's Application of Facial Recognition Interfered with Right to Protest",
      "description": "Black Lives Matter activists alleged being targeted for arrest by New York Police using facial recognition, interfering with their right to protest.",
      "deployers": [
        "new-york-city-police-department"
      ],
      "developers": [
        "clearview-ai"
      ],
      "harmedParties": [
        "derrick-ingram",
        "black-lives-matter-activists"
      ],
      "reports": [
        3184,
        3188,
        3189
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(64b10cadfe572c853a0a4e18)",
      "incident_id": 559,
      "date": "2023-06-30",
      "title": "Grant Reviewers Fed Applications into Generative AI to Produce Reports, Allegedly Breaching Confidentiality",
      "description": "Peer reviewers of Australian government grant applications inserted applicants' work into generative AI systems such as ChatGPT to generate assessment reports, which allegedly posed confidentiality and security issues.",
      "deployers": [
        "openai"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "research-grant-administrators",
        "research-grant-applicants"
      ],
      "reports": [
        3193,
        3269
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(64b111c8a76f6e653f12c75d)",
      "incident_id": 560,
      "date": "2023-06-23",
      "title": "Tesla on Autopilot Struck Parked Work Truck on Highway in Pennsylvania",
      "description": "A 2016 Tesla on Autopilot crashed into the rear of a parked 2007 Freightliner truck providing traffic control on the Pennsylvania Turnpike highway.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "truck-drivers",
        "tesla-drivers",
        "david-clough"
      ],
      "reports": [
        3194
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(64b4f0d26f56564bff1b07b8)",
      "incident_id": 561,
      "date": "2019-03-11",
      "title": "OpenAI Alleged by Lawsuit Violated Users' Privacy Rights by Training AI on Private Info without Informed Consent",
      "description": "OpenAI's products such as ChatGPT and DALL-E were alleged in a lawsuit using  stolen private information from internet users without their informed consent or knowledge.",
      "deployers": [
        "openai"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "internet-users",
        "children",
        "social-media-users"
      ],
      "reports": [
        3197,
        3199,
        3200
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(64b505b2fcded49715f88889)",
      "incident_id": 562,
      "date": "2022-11-30",
      "title": "Uptick in Low-Quality AI-Produced Content Degraded Publishers' Submission Management",
      "description": "A surge in low-standard AI-generated content such as by ChatGPT was reported by publishers, which negatively impacted submission management process and editors' workflow.",
      "deployers": [
        "openai"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "publishing-editors",
        "publishers"
      ],
      "reports": [
        3201
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(64f497dafca6ce10a7cbb004)",
      "incident_id": 563,
      "date": "2023-08-14",
      "title": "Cruise Robotaxi Initially Blamed for Ambulance Delay in Case Where Patient Later Died; Subsequent Reports Clear Cruise of Fault",
      "description": "In an initial report, a Cruise robotaxi was said to have delayed a San Francisco ambulance transporting Sammy Davis, a critically injured 69-year-old hit by a city bus. Davis later died. Subsequent clarification revealed that Cruise was not at fault for the fatality; the actual cause was a human-operated city bus. Despite this, the incident is included as it highlights challenges in the interaction between autonomous vehicles and emergency services in urban settings.",
      "deployers": [
        "cruise"
      ],
      "developers": [
        "cruise"
      ],
      "harmedParties": [
        "san-francisco-emergency-services",
        "ambulance-patient"
      ],
      "reports": [
        3208,
        3222
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(64f49c74fca6ce10a7ce157c)",
      "incident_id": 564,
      "date": "2023-08-30",
      "title": "Voice deepfake targets bank in failed transfer scam",
      "description": "In spring 2023, Florida investor Clive Kabatznik became the target of an advanced scam attempt involving a voice deepfake mimicking his own voice. The fraudulent caller, using AI-generated speech, contacted Kabatznik's Bank of America representative in an unsuccessful attempt to deceive the banker into transferring funds to a different account.",
      "deployers": [
        "scammers"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "clive-kabatznik",
        "bank-of-america"
      ],
      "reports": [
        3209
      ],
      "severity": "AI tangible harm near-miss",
      "classification": "yes",
      "sector": "financial and insurance activities",
      "region": "Global"
    },
    {
      "id": "ObjectId(64ff867ac6ce14cd1ea2eae9)",
      "incident_id": 565,
      "date": "2023-08-08",
      "title": "AI-Generated Imagery and Multilingual Disinformation in Chinese Campaign Regarding Maui Wildfires",
      "description": "In a disinformation campaign concerning wildfires across Maui, Chinese operatives utilized AI-generated imagery to enhance the credibility of false narratives. These narratives claimed that the wildfires were the result of a secret weather weapon being tested by the United States. Researchers from Microsoft and other organizations identified these AI-generated images as a significant new tactic in influence operations.",
      "deployers": [
        "chinese-government"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "hawaiian-government",
        "general-public",
        "american-government"
      ],
      "reports": [
        3210,
        3211,
        3212,
        3213
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6501b284214e764d67cc256b)",
      "incident_id": 566,
      "date": "2023-09-19",
      "title": "Gannett Halts AI-Generated High School Sports Articles After Series of Errors and Public Backlash",
      "description": "Gannett, a newspaper chain, temporarily halted its AI experiment that used a tool called LedeAI to generate high school sports articles. The decision came after several articles produced by the AI showed glaring errors, repetitive language, and awkward phrasing, drawing criticism and mockery on social media.",
      "deployers": [
        "gannett"
      ],
      "developers": [
        "ledeai"
      ],
      "harmedParties": [
        "general-public",
        "gannett",
        "student-athletes",
        "newspapers-relying-on-gannett"
      ],
      "reports": [
        3214
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6508bddc5a537311de811b61)",
      "incident_id": 567,
      "date": "2023-08-27",
      "title": "Deepfake Voice Exploit Compromises Retool's Cloud Services",
      "description": "In August 2023, a hacker reportedly was successful in breaching Retool, an IT company specializing in business software solutions, impacting 27 cloud customers. The attacker appears to have initiated the breach by sending phishing SMS messages to employees and later used an AI-generated deepfake voice in a phone call to obtain multi-factor authentication codes. The breach seems to have exposed vulnerabilities in Google's Authenticator app, specifically its cloud-syncing function, further enabling unauthorized access to internal systems.",
      "deployers": [
        "unknown-hacker"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "retool-employee-who-was-the-victim-of-the-unknown-hacker",
        "retool",
        "google",
        "27-of-retool's-clients"
      ],
      "reports": [
        3215
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6529a9a76917ad1134f8c2ca)",
      "incident_id": 568,
      "date": "2023-06-01",
      "title": "AI-Generated Voices Amplify Conspiracy Theories on TikTok",
      "description": "NewsGuard has identified 17 TikTok accounts that have been using AI-generated voices to advance and amplify conspiracy theories and false claims beginning in June 2023. By September 25, 2023, these accounts had amassed over 336 million views and over 14.5 million likes. Videos include baseless claims involving public figures such as Barack Obama, Oprah Winfrey, and Jamie Foxx.",
      "deployers": [
        "tiktok-user-@e.news.tv",
        "tiktok-user-@d.news.tv",
        "tiktok-user-@drphilshowtv",
        "tiktok-user-@ynewstv2023",
        "tiktok-users"
      ],
      "developers": [
        "elevenlabs"
      ],
      "harmedParties": [
        "barack-obama",
        "oprah-winfrey",
        "jamie-foxx",
        "joan-rivers",
        "phil-mcgraw",
        "yahoo!-news",
        "e!-news",
        "tiktok",
        "general-public"
      ],
      "reports": [
        3216,
        3271
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(652b67d2da5514dd8005776c)",
      "incident_id": 569,
      "date": "2021-12-25",
      "title": "Chatbot Encourages Man to Plot Assassination of Queen Elizabeth II",
      "description": "In 2021, Jaswant Singh Chail was urged by a Replika chatbot to assassinate Queen Elizabeth II. Armed with a loaded crossbow, he scaled Windsor Castle's walls on Christmas Day but was apprehended. Motivated by the 1919 Jallianwala Bagh massacre, Chail intended to kill the monarch. The chatbot had affirmed his plans. He was sentenced to nine years in prison in 2023.",
      "deployers": [
        "replika",
        "jaswant-singh-chail"
      ],
      "developers": [
        "replika"
      ],
      "harmedParties": [
        "queen-elizabeth-ii",
        "british-royal-family",
        "british-royal-family's-staff",
        "jaswant-singh-chail",
        "general-public"
      ],
      "reports": [
        3219,
        3325
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(652b6a773cc4af54f847ba8c)",
      "incident_id": 570,
      "date": "2023-10-04",
      "title": "Facebook Messenger AI Stickers Generate Ethical and Content Moderation Concerns",
      "description": "Facebook Messenger AI stickers, a feature by Meta, allows users to generate personalized stickers via AI for use in conversations. While the feature has been praised for its creativity, it has also stirred controversy for its alleged production of inappropriate or offensive content. This has raised questions about the effectiveness of Meta's content moderation measures and the ethical responsibilities associated with AI-driven content generation.",
      "deployers": [
        "meta"
      ],
      "developers": [
        "meta"
      ],
      "harmedParties": [
        "facebook-messenger-users"
      ],
      "reports": [
        3245
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(652b6c731af8a573faa2f68d)",
      "incident_id": 571,
      "date": "2023-06-22",
      "title": "Accidental Exposure of 38TB of Data by Microsoft's AI Research Team",
      "description": "Microsoft's AI research team accidentally exposed 38TB of sensitive data while publishing open-source training material on GitHub. The exposure included secrets, private keys, passwords, and internal Microsoft Teams messages. The team utilized Azure's Shared Access Signature (SAS) tokens for sharing, which were misconfigured, leading to the wide exposure of data.",
      "deployers": [
        "microsoft"
      ],
      "developers": [
        "microsoft's-ai-research-division"
      ],
      "harmedParties": [
        "microsoft",
        "microsoft-employees",
        "third-parties-relying-on-the-confidentiality-of-the-exposed-data"
      ],
      "reports": [
        3221
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(652b780d6917ad11349bf4a3)",
      "incident_id": 572,
      "date": "2023-07-24",
      "title": "Alleged False Accusation of AI-Generated Essay by Turnitin",
      "description": "A student was allegedly falsely accused of using AI to generate an essay assignment based on Turnitin's AI detector. The student, who claims to have written the essay by hand, also claims to have received a zero for the assignment. Despite multiple appeals to the professor, department head, and Turnitin support, no resolution seems to have been reached. The student claimed to be considering taking the issue to local news networks if the grade would come to harm their final standing.",
      "deployers": [
        "unspecified-university"
      ],
      "developers": [
        "turnitin"
      ],
      "harmedParties": [
        "anonymous-student"
      ],
      "reports": [
        3225
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(652b7dc2da5514dd800ace57)",
      "incident_id": 573,
      "date": "2023-10-07",
      "title": "Deepfake Recordings Allegedly Influence Slovakian Election",
      "description": "Days before Slovakia's election, deepfake audio recordings surfaced, allegedly featuring conversations between a journalist and a leading liberal politician discussing vote-rigging and other controversial topics. The recordings were spread on social media platforms and may have influenced the election outcome, which saw the pro-Russian populist party winning.",
      "deployers": [
        "unknown"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "slovakian-electorate",
        "monika-todova",
        "michal-simecka",
        "democratic-process-in-slovakia"
      ],
      "reports": [
        3227,
        3267,
        3314,
        3315,
        3316,
        3317,
        3318,
        3319,
        3382,
        3825,
        4109
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(652da7a6f47da75dc4431580)",
      "incident_id": 574,
      "date": "2023-07-05",
      "title": "AI-Generated Articles at G/O Media Allegedly Diminishes Reputation of Human Staff",
      "description": "G/O Media began publishing AI-generated articles, against staff advice, that contained errors and quality issues. The first such article, a list of Star Wars movies, failed to maintain chronological order, causing internal concerns over journalistic credibility and ethics. Staff expressed that the AI was actively hurting our reputations and credibility and accused management of wasting everyone's time.",
      "deployers": [
        "go-media"
      ],
      "developers": [
        "openai",
        "google"
      ],
      "harmedParties": [
        "gizmodo-journalists"
      ],
      "reports": [
        3237
      ],
      "severity": "none",
      "classification": "no",
      "sector": "information and communication, Arts, entertainment and recreation",
      "region": "Global"
    },
    {
      "id": "ObjectId(652daafef61555d63abf9f7b)",
      "incident_id": 575,
      "date": "2023-06-28",
      "title": "Amazon Rife with Many Allegedly AI-Generated Books of Suspect Quality",
      "description": "Amazon’s Kindle Unlimited young adult romance bestseller list was flooded with allegedly AI-generated books that made little to no sense, disrupting the rankings. These books were reported to be clearly there to click farm. Despite being removed from the bestseller list, many remained available for purchase. The incident raised concerns about the integrity of the platform, and the potential financial impact on legitimate authors.",
      "deployers": [
        "unknown"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "authors",
        "amazon-customers",
        "amazon"
      ],
      "reports": [
        3238
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65385e6f15203005a3293d6f)",
      "incident_id": 576,
      "date": "2023-10-24",
      "title": "Alleged Misuse of PicSo AI for Generating Inappropriate Content Emphasizing Girls",
      "description": "PicSo AI, which appears to be getting advertised by Meta over Instagram, is allegedly being used for generating inappropriate content with an emphasis on girls. This raises concerns about the misuse of generative AI technologies for creating offensive and potentially sexually explicit material that could be used for nefarious and criminal purposes.",
      "deployers": [
        "meta",
        "instagram"
      ],
      "developers": [
        "picso-ai"
      ],
      "harmedParties": [
        "potentially-exploited-groups",
        "general-public",
        "consumers"
      ],
      "reports": [
        3239
      ],
      "severity": "none",
      "classification": "no",
      "region": "Global"
    },
    {
      "id": "ObjectId(6538609a15203005a32a4904)",
      "incident_id": 577,
      "date": "2023-06-30",
      "title": "Bankrate's Resumption of AI-Generated Content Allegedly Continuing to Produce Inaccurate and Misleading Information",
      "description": "Bankrate, and its sister site CNET, both owned by Red Ventures, resumed publishing AI-generated articles claiming thorough human fact-checking. However, new articles are alleged to contain numerous factual errors, including inaccurate statistics and misleading information. Despite public criticism, the company defended its use of AI and blamed out-of-date datasets for the errors. In addition to the errors, the incident raises questions about the ethical use of AI in journalism, especially given the company's insistence on fact-checked content.",
      "deployers": [
        "red-ventures",
        "bankrate"
      ],
      "developers": [
        "red-ventures",
        "bankrate"
      ],
      "harmedParties": [
        "journalistic-integrity",
        "general-public"
      ],
      "reports": [
        3240
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(653861f7a9926d2f72b0e668)",
      "incident_id": 578,
      "date": "2023-06-26",
      "title": "Alleged Exploitation of Meta's Open-Source LLaMA Model for NSFW and Violent Content",
      "description": "Meta's open-source large language model, LLaMA, is allegedly being used to create graphic and explicit chatbots that indulge in violent and illegal sexual fantasies. The Washington Post highlighted the example of Allie, a chatbot that participates in text-based role-playing allegedly involving violent scenarios like rape and abuse. The issue raises ethical questions about open-source AI models, their regulation, and the responsibility of developers and deployers in mitigating harmful usage.",
      "deployers": [
        "individual-developers-or-creators-using-meta's-llama-model"
      ],
      "developers": [
        "meta"
      ],
      "harmedParties": [
        "general-public"
      ],
      "reports": [
        3241
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65386cea15203005a33009ab)",
      "incident_id": 579,
      "date": "2023-07-03",
      "title": "Harmful Stereotyping of Non-Cisgendered People via Text-to-Image Systems",
      "description": "Text-to-image systems such as DALL-E are allegedly generating biased and often insulting representations of non-cisgender identities. The systems tend to generate stereotypical and sexualized images when prompted with gender identity terms like trans, nonbinary, or queer, highlighting systemic issues of bias.",
      "deployers": [
        "dall-e"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "non-cisgender-individuals",
        "lgbtq+-community"
      ],
      "reports": [
        3242
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65386f1415203005a3387a06)",
      "incident_id": 580,
      "date": "2023-06-12",
      "title": "Alleged Gender Discrimination in Facebook Job Ads Algorithm",
      "description": "Facebook's ad delivery algorithm allegedly disproportionately showed job advertisements to one gender. Despite claims of non-discrimination, the algorithm's actions seem to perpetuate societal biases, which in turn could potentially limit opportunities for certain groups and hinder gender equity in the workplace.",
      "deployers": [
        "meta"
      ],
      "developers": [
        "meta"
      ],
      "harmedParties": [
        "women",
        "underrepresented-genders",
        "general-public",
        "advertisers"
      ],
      "reports": [
        3243
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(653870c4e73cd7ffc4306f6d)",
      "incident_id": 581,
      "date": "2023-06-24",
      "title": "Google Ads Allegedly Serving Content on AI-Generated Misinformation Sites",
      "description": "Google’s advertising platform, Google Ads, has allegedly been found to be serving ads on AI-generated content farms that often disseminate misinformation. Despite policies prohibiting such practices, reportedly there are approximately 356 out of 393 ads from major brands that were found to be served by Google on these problematic sites. Particularly concerning according to the reporting were instances where Google Ads were found on sites like MedicalOutline.com, which spreads harmful health misinformation.",
      "deployers": [
        "google"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "subaru",
        "major-brands-whose-advertisements-were-found-on-these-sites",
        "gnc",
        "general-public",
        "citigroup"
      ],
      "reports": [
        3244
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65393a1c52700a12343b17d5)",
      "incident_id": 582,
      "date": "2023-06-01",
      "title": "Racial Bias in Lung Function Diagnostic Algorithm Leads to Underdiagnosis in Black Men",
      "description": "A study published in JAMA Network Open reveals that racial bias built into a commonly used medical diagnostic algorithm for lung function may be leading to underdiagnoses of breathing problems in Black men. The study suggests that as many as 40% more Black male patients might have been accurately diagnosed if the software were not racially biased. The software algorithm adjusts diagnostic thresholds based on race, affecting medical treatments and interventions.",
      "deployers": [
        "university-of-pennsylvania-health-system"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "black-men-who-underwent-lung-function-tests-between-2010-and-2020-and-potentially-received-inaccurate-or-delayed-diagnoses-and-medical-interventions-due-to-the-biased-algorithm"
      ],
      "reports": [
        3248
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65393be452700a12343beadf)",
      "incident_id": 583,
      "date": "2023-06-07",
      "title": "Instagram Algorithms Allegedly Promote Accounts Facilitating Child Sex Abuse Content",
      "description": "An investigation disclosed that Instagram's recommendation algorithms are promoting accounts that facilitate and sell child sexual abuse material (CSAM). The study, conducted by The Wall Street Journal and researchers at Stanford University and the University of Massachusetts Amherst, indicates that Instagram's algorithms not only allow for the discovery of such accounts through keyword searches but also actively recommend them to users within the network. The issue is especially concerning given Instagram's popularity among teenagers.",
      "deployers": [
        "meta",
        "instagram"
      ],
      "developers": [
        "meta",
        "instagram"
      ],
      "harmedParties": [
        "children",
        "general-public",
        "minors",
        "teenagers"
      ],
      "reports": [
        3249
      ],
      "severity": "none",
      "classification": "yes",
      "sector": "Arts, entertainment and recreation",
      "region": "Global"
    },
    {
      "id": "ObjectId(6539407176848d55a7571e5b)",
      "incident_id": 584,
      "date": "2023-05-18",
      "title": "Illinois Residents File Class Action Lawsuit Against Facial Recognition Technology Companies for Allegedly Violating BIPA",
      "description": "A class action lawsuit was filed against several facial recognition technology companies for allegedly violating the Illinois Biometric Information Privacy Act (BIPA). The defendants are accused of offering a facial recognition search engine called Pimeyes, which collects images from databases across the internet and scans them into their database seemingly without consent. This action is claimed to invade the privacy of millions of Americans. The lawsuit argues that Pimeyes lacks publicly available policies regarding data storage and deletion, in contravention of BIPA's requirements for informed written consent before collecting biometric data.",
      "deployers": [
        "transaction-cloud",
        "public-mirror",
        "pimeyes",
        "lukasz-kowalczyk",
        "giorgi-gobronidze",
        "face-recognition-solutions",
        "emea-robotics",
        "does-125",
        "denis-tatina",
        "carribex"
      ],
      "developers": [
        "transaction-cloud",
        "public-mirror",
        "pimeyes",
        "lukasz-kowalczyk",
        "giorgi-gobronidze",
        "face-recognition-solutions",
        "emea-robotics",
        "does-1-25",
        "denis-tatina",
        "carribex"
      ],
      "harmedParties": [
        "nicholas-clayton",
        "misty-mcgraw",
        "manuel-clayton",
        "illinois-residents",
        "amy-newton",
        "amanda-curry"
      ],
      "reports": [
        3250
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(653a50b6570a9b0c1e4341e7)",
      "incident_id": 585,
      "date": "2023-10-26",
      "title": "Kremlin-Linked Entities Allegedly Using Generative AI to Spread Russian Disinformation in Latin America",
      "description": "Moscow-based tech firms and an industry association with links to the Kremlin are allegedly using generative AI to spread Russian disinformation in countries throughout Central America and South America. According to the U.S. Department of State, the Russian companies rely on local writers to compose stories which are then amplified across social media using artificial intelligence chatbots.",
      "deployers": [
        "structura-national-technologies",
        "social-design-agency",
        "oleg-yasinsky",
        "oleg-yasinskiy",
        "nikolay-tupikin",
        "institute-for-internet-development",
        "ilya-gambashidze",
        "andrey-perla"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "ukraine",
        "news-media-in-latin-america",
        "journalistic-integrity",
        "general-public"
      ],
      "reports": [
        3251,
        3322,
        3323
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6540529b47388926c8bb4840)",
      "incident_id": 586,
      "date": "2023-05-22",
      "title": "FTC Targets Edmodo for Unlawful Use of Children’s Data and Delegating Compliance to Schools",
      "description": "Edmodo, an education technology provider, violated the Children's Online Privacy Protection Act Rule (COPPA Rule) by collecting and using children's personal data for advertising purposes without parental consent, according to the FTC. The company outsourced its compliance responsibilities to schools, thereby making them solely responsible for COPPA compliance without adequate disclosure. Edmodo is facing a proposed order prohibiting such practices, marking a precedent in the ed tech industry.",
      "deployers": [
        "edmodo"
      ],
      "developers": [
        "edmodo"
      ],
      "harmedParties": [
        "children-whose-data-was-collected-and-used-for-advertising",
        "schools-and-teachers-who-were-misinformed-and-burdened-with-coppa-compliance-responsibilities-without-adequate-disclosure"
      ],
      "reports": [
        3254
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65405e7d2e7ce795c7a59d2c)",
      "incident_id": 587,
      "date": "2023-05-22",
      "title": "Apparent Failure to Accurately Label Primates in Image Recognition Software Due to Alleged Fear of Racial Bias",
      "description": "Eight years after Google Photos mislabeled images of Black individuals as gorillas, image recognition software by Google, Apple, Amazon, and Microsoft still shows signs of either avoiding or inaccurately categorizing primates. Tests reveal that Google and Apple Photos refrain from labeling primates altogether, possibly to avoid the risk of perpetuating racial stereotypes. Microsoft OneDrive fails to identify any animals, while Amazon Photos overgeneralizes in its labeling.",
      "deployers": [
        "google",
        "apple",
        "amazon",
        "microsoft"
      ],
      "developers": [
        "google",
        "apple",
        "amazon",
        "microsoft"
      ],
      "harmedParties": [
        "consumers-relying-on-accurate-image-categorization",
        "members-of-racial-and-ethnic-minorities-who-risk-being-stereotyped-or-misrepresented"
      ],
      "reports": [
        3255
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(654069292a976b1b1deb9f68)",
      "incident_id": 588,
      "date": "2023-05-12",
      "title": "Australian Terrorism Prediction Tool Disparately Impacts Persons with Autism",
      "description": "An independent report found that the Vera-2R tool, designed to predict the risk of future terrorist activities, considered autism as a risk factor despite lacking empirical evidence to support this claim. The report called into question the tool's overall validity and reliability, stating it was extremely poor at accurately predicting risk. The inclusion of autism as a risk factor had potentially serious implications for the tool's use and credibility.",
      "deployers": [
        "new-south-wales-government",
        "australian-federal-government"
      ],
      "developers": [
        "unspecified"
      ],
      "harmedParties": [
        "people-with-autism",
        "lawyers-and-other-experts-who-were-not-informed-of-the-tool's-limitations",
        "individuals-assessed-as-high-risk-based-on-the-flawed-criteria",
        "general-public"
      ],
      "reports": [
        3256
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65455f98103ba1d81ef37f04)",
      "incident_id": 589,
      "date": "2023-05-01",
      "title": "Proliferation of AI-Generated News Websites and Content Farms Across Multiple Languages Degrading Information Integrity",
      "description": "Scores of AI-generated news websites and content farms are producing low-quality, clickbait content in a variety of languages. They are reportedly spreading false information and degrading the quality of information available online. These sites often lack human oversight, feature repetitive language, and sometimes fabricate information, posing a threat to the credibility of online news sources.",
      "deployers": [
        "many",
        "maria-spanadoris",
        "adesh-ingale",
        "getintoknowledge.com",
        "famadillo.com",
        "bestbudgetusa.com",
        "harmonyhustle.com",
        "historyfact.in",
        "countylocalnews.com",
        "tnewsnetwork.com",
        "wavefunction.info",
        "celebritiesdeaths.com",
        "scoopearth.com",
        "filthylucre.com"
      ],
      "developers": [
        "unknown",
        "unnamed"
      ],
      "harmedParties": [
        "general-public",
        "journalists"
      ],
      "reports": [
        3258
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(654569b1898d35811fee86ca)",
      "incident_id": 590,
      "date": "2023-02-03",
      "title": "Alleged ChatGPT-Generated Book with a Duplicate Title, Fake Author, and Similar Content Surfaces on Amazon Ahead of Real Author's Book Release",
      "description": "The author Chris Cowell had spent more than a year writing his book Automating DevOps with GitLab CI/CD Pipelines when, three weeks before its release, another book appeared bearing the exact title by an author (Marie Karpos) for whom no information could be found. The book appeared to have been written by ChatGPT. While the original Washington Post story does not say so, it is possible the name and description were taken from the Amazon preorder page.",
      "deployers": [
        "inkstall",
        "marie-karpos"
      ],
      "developers": [
        "openai",
        "chatgpt"
      ],
      "harmedParties": [
        "chris-cowell"
      ],
      "reports": [
        3259
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65457567fc4e51d61f947c6b)",
      "incident_id": 591,
      "date": "2023-07-24",
      "title": "Cigna Algorithm PXDX Allegedly Rejected Thousands of Patient Claims En Masse in Breach of California Law",
      "description": "Cigna health insurer faces a class-action lawsuit for allegedly using the PXDX (procedure-to-diagnosis) algorithm to automatically reject over 300,000 patient claims in violation of California law, prompting two members to file the lawsuit seeking damages and a jury trial. Cigna disputes the allegations, claiming the process expedites physician reimbursement and does not result in care denials.",
      "deployers": [
        "cigna"
      ],
      "developers": [
        "cigna"
      ],
      "harmedParties": [
        "patients"
      ],
      "reports": [
        3262,
        3265
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6546ceca1e6a993951c7101a)",
      "incident_id": 592,
      "date": "2023-02-16",
      "title": "Facial Recognition Misidentifies Pregnant Woman Leading to False Arrest in Detroit",
      "description": "Porcha Woodruff was arrested and subsequently had charges dropped due to an unreliable facial recognition match. Despite being visibly pregnant, she was implicated in a robbery and carjacking based on an outdated photo used in a lineup.",
      "deployers": [
        "detroit-police-department"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "porcha-woodruff"
      ],
      "reports": [
        3263,
        3275,
        3965
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6546d1a4fc4e51d61f83490d)",
      "incident_id": 593,
      "date": "2023-07-21",
      "title": "AI Photo Filter Lightens Skin, Changes Eye Color in Student's 'Professional' Image",
      "description": "An AI application modified an MIT student's photo to appear 'professional' by lightening her skin and changing her eye color to blue, highlighting the racial bias in the training data of the program.",
      "deployers": [
        "playground-ai"
      ],
      "developers": [
        "playground-ai"
      ],
      "harmedParties": [
        "rona-wang",
        "racial-minorities-who-may-have-experienced-the-same-result"
      ],
      "reports": [
        3264
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6546da94f3a19e41ec2f0413)",
      "incident_id": 594,
      "date": "2023-08-10",
      "title": "AI Meal Planner Suggests Hazardous Chlorine Gas Recipe",
      "description": "Pak 'n' Save's AI-based app, Savey Meal-bot, inadvertently suggested dangerous recipes, including one creating chlorine gas, when users entered non-food household items, raising safety and oversight concerns.",
      "deployers": [
        "pak-'n'-save"
      ],
      "developers": [
        "pak-'n'-save"
      ],
      "harmedParties": [
        "potential-users-of-the-savey-meal-bot"
      ],
      "reports": [
        3266
      ],
      "severity": "none",
      "classification": "no",
      "sector": "accommodation and food service activities, wholesale and retail trade",
      "region": "Oceania"
    },
    {
      "id": "ObjectId(6546de11103ba1d81e9e46c6)",
      "incident_id": 595,
      "date": "2023-08-11",
      "title": "Driverless Cruise Cars Immobilized in San Francisco Traffic Jam",
      "description": "A fleet of Cruise's autonomous vehicles became unexpectedly immobilized on a busy San Francisco street, causing significant traffic disruption. The incident was attributed to wireless connectivity issues exacerbated by a nearby festival.",
      "deployers": [
        "cruise"
      ],
      "developers": [
        "cruise"
      ],
      "harmedParties": [
        "general-public"
      ],
      "reports": [
        3268
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6546e3d4e494df084ef4134e)",
      "incident_id": 596,
      "date": "2023-10-17",
      "title": "Cruise's Autonomous Vehicles Allegedly Engaging in Risky Behavior Near Pedestrians",
      "description": "Cruise's driverless vehicles are under federal investigation for possibly failing to exhibit due caution around crosswalks and pedestrians, with reports including one severe injury incident.",
      "deployers": [
        "cruise"
      ],
      "developers": [
        "cruise"
      ],
      "harmedParties": [
        "pedestrians",
        "general-public"
      ],
      "reports": [
        3272
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(654c35e94ae59b7157abb8e0)",
      "incident_id": 597,
      "date": "2023-10-20",
      "title": "Female Students at Westfield High School in New Jersey Reportedly Targeted with Deepfake Nudes",
      "description": "In October 2023, alleged deepfake nude images of female students were created and shared at Westfield High School in New Jersey. One alleged implicated system in this incident is the Clothoff deepfake app. A victim, Francesca Mani, and her mother, Dorota, began advocating for stronger laws after the school’s response reportedly left perpetrators unaccountable. Since the incident, their advocacy has drawn national attention, leading to trips to Washington, D.C., and bipartisan backing for legislation targeting AI-generated nonconsensual content while calling attention to deficiencies in existing legal protections.",
      "deployers": [
        "unnamed-male-students"
      ],
      "developers": [
        "developers-of-clothoff"
      ],
      "harmedParties": [
        "unnamed-female-students",
        "francesca-mani"
      ],
      "reports": [
        3273,
        3276,
        3278,
        3279,
        3280,
        3281,
        3282,
        3283,
        3284,
        3285,
        3286,
        3287,
        3288,
        3289,
        3290,
        3291,
        3292,
        3293,
        3294,
        3295,
        3296,
        3297,
        3298,
        3299,
        3300,
        3301,
        3302,
        3303,
        3304,
        3305,
        3306,
        3307,
        3308,
        3309,
        3310,
        3311,
        3312,
        3313,
        3449,
        3450,
        3567,
        3620,
        3644,
        3698,
        3844,
        4560,
        4569,
        4570,
        4571,
        4572,
        4573,
        4574,
        4575,
        4577,
        4578,
        4579,
        4948
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(654c3abbbec12aaf6781ad75)",
      "incident_id": 598,
      "date": "2022-11-25",
      "title": "False Arrest of Georgia Man Due to Louisiana Police's Faulty Facial Recognition Technology",
      "description": "The Jefferson Parish Sheriff’s Office in Louisiana relied on facial recognition technology to identify suspects for the alleged theft of luxury purses, resulting in a man in Georgia, Randal Reid, being arrested. However, the technology produced a false match, leading to Reid's arrest and subsequent release. This incident highlights the potential pitfalls of facial recognition technology in law enforcement.",
      "deployers": [
        "jefferson-parish-sheriff's-office"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "randal-reid",
        "minorities",
        "black-people"
      ],
      "reports": [
        3274
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(654d8fd4cd680cf15fd24928)",
      "incident_id": 599,
      "date": "2023-11-08",
      "title": "Stacking robot fatally crushes employee in South Korea",
      "description": "An industrial robot is reported to have crushed a man to death in South Korea when it failed to differentiate the man from the boxes of produce it was handling.",
      "deployers": [
        "unnamed-south-gyeongsang-province-produce-distribution-center"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "unnamed-employee-of-south-gyeongsang-province-produce-distribution-center"
      ],
      "reports": [
        3277,
        3326
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(654ea8b4580ab543de8f9453)",
      "incident_id": 600,
      "date": "2023-04-01",
      "title": "South Korean man used AI to create sexual images of children",
      "description": "A South Korean man used AI technology to generate 360 images of a sexual nature depicting children in April of 2023. The police confiscated the images and the courts sentenced the man to two and a half years in prison. The case marked the first of its nature in the South Korean court system.",
      "deployers": [
        "unnamed-south-korean-man"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "general-public"
      ],
      "reports": [
        3320
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(654eab76b4ba3d9534f73eb1)",
      "incident_id": 601,
      "date": "2023-10-08",
      "title": "AI-Generated Fake Audio of Verbal Abuse Incident Circulates of British Labour Leader Keir Starmer",
      "description": "An AI-generated audio clip, purporting to show UK opposition leader Keir Starmer verbally abusing staff, was debunked as fake. The clip, circulated on social media, was analyzed and found likely manipulated, with added background noise to evade detection.",
      "deployers": [
        "unknown"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "uk-labour-party",
        "keir-starmer"
      ],
      "reports": [
        3321,
        3340,
        3341,
        3342,
        3344,
        3345,
        3346,
        3347,
        3349,
        3381
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(654ebf1a811005235d627f4a)",
      "incident_id": 602,
      "date": "2023-10-02",
      "title": "Incident 602",
      "description": "The Russian government has been stepping up its foreign influence campaigns by using artificial intelligence and emerging technologies to spread disinformation and sow distrust in policies supportive of Ukraine. Part of the strategy includes carrying out influence laundering operations by disseminating their messages to the American public via allies inside nominally independent organizations, according to a recent declassified analysis. ",
      "deployers": [
        "russian-government",
        "fsb",
        "federal-security-service"
      ],
      "developers": [
        "russian-government"
      ],
      "harmedParties": [
        "ukraine",
        "general-public",
        "european-public",
        "democracy",
        "american-public"
      ],
      "reports": [
        3324,
        3331,
        3336,
        3337,
        3338,
        3352,
        3397
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "incident-NaN",
      "incident_id": null,
      "date": "",
      "title": "Incident NaN",
      "description": "No description available",
      "deployers": [],
      "developers": [],
      "harmedParties": [],
      "reports": [],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "This incident is an evolving project.,Russia Using Artificial Intelligence in Disinformation Campaigns to Erode Western Support for Ukraine",
      "incident_id": null,
      "date": "",
      "title": "Incident NaN",
      "description": "No description available",
      "deployers": [],
      "developers": [],
      "harmedParties": [],
      "reports": [],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(654ec7b9811005235d53abdf)",
      "incident_id": 603,
      "date": "2021-07-02",
      "title": "Algorithmic Allocation of Resources in Healthcare for Disabled and Elderly Care Services Allegedly Harming Patients",
      "description": "A healthcare algorithm designed to equitably distribute caregiving resources drastically cut care hours for the disabled and elderly, leading to significant hardships and harm. Initially developed for fair resource allocation, the system ultimately faced legal challenges for its inability to accurately assess individual needs, resulting in reduced essential care and raising ethical concerns about AI in healthcare decision-making.",
      "deployers": [
        "state-governments",
        "idaho-state-government",
        "arkansas-state-government",
        "washington-dc-government",
        "pennsylvania-state-government",
        "iowa-state-government",
        "missouri-state-government"
      ],
      "developers": [
        "brant-fries",
        "state-governments"
      ],
      "harmedParties": [
        "disabled-people",
        "elderly-people",
        "low-income-people",
        "larkin-seiler",
        "tammy-dobbs"
      ],
      "reports": [
        3327
      ],
      "severity": "AI tangible harm event",
      "classification": "yes",
      "sector": "human health and social work activities",
      "region": "North America"
    },
    {
      "id": "ObjectId(6558c488a4d1020da97e6b0d)",
      "incident_id": 604,
      "date": "2023-04-14",
      "title": "Quebec Man Sentenced for Having Used Deepfake Technology to Create Synthetic Child Pornography",
      "description": "A Quebec man was sentenced to over three years in prison for using AI deepfake technology to produce synthetic child pornography. He created videos by superimposing children's faces onto other bodies, adding to the challenge of policing digital sexual exploitation. This case marks a disturbing use of AI in criminal activities, raising concerns about digital safety and the vulnerability of children's images online.",
      "deployers": [
        "steven-larouche"
      ],
      "developers": [
        "unnamed-deepfake-technology-developers"
      ],
      "harmedParties": [
        "children-(faces-used-in-deepfakes)",
        "victims-of-child-sexual-abuse-(bodies-used-in-videos)",
        "general-public"
      ],
      "reports": [
        3329,
        3423,
        3424,
        3425,
        3426,
        3427,
        3428
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65595e0ecac78d26b3eef660)",
      "incident_id": 605,
      "date": "2021-08-01",
      "title": "North Carolina Psychiatrist Used Artificial Intelligence to Produce Images of Child Sex Abuse",
      "description": "David Tatum, a psychiatrist, was sentenced to 40 years for sexually exploiting a minor and using AI to create child pornography images. Tatum used a web-based AI application to alter clothed images of minors into explicit content, misusing technology for illegal and unethical purposes. Evidence presented during his trial showed Tatum possessed photos and videos between 2016 and 2021.",
      "deployers": [
        "david-tatum"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "minors-exploited-in-the-images",
        "general-public"
      ],
      "reports": [
        3330,
        3372,
        3373,
        3374,
        3375,
        3376,
        3377,
        3378,
        3379,
        3380
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(655b45b77e28e913a64cc2e7)",
      "incident_id": 606,
      "date": "2023-10-02",
      "title": "Deepfaked Advertisements Using the Likenesses of Celebrities Such as Tom Hanks and Gayle King Without Their Consent",
      "description": "Deepfake technology was used to generate video advertisements featuring celebrities. Notable examples include the likeness of Tom Hanks touting a dental plan and another one in which the likeness of Gayle King touts a weight loss product. In each case, the individuals whose likenesses and voices had been deepfaked had not consented to their images and voices being used for the commercials. ",
      "deployers": [
        "unknown"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "wolf-blitzer",
        "tom-hanks",
        "sanjay-gupta",
        "sally-bundock",
        "robin-williams",
        "public-figures",
        "mrbeast",
        "matthew-amroliwala",
        "jesse-waters",
        "ian-hanomansing",
        "general-public",
        "gayle-king",
        "celebrities"
      ],
      "reports": [
        3339,
        3383,
        3384,
        3385,
        3386,
        3387,
        3388,
        3389,
        3390,
        3391,
        3392,
        3393,
        3394,
        3395,
        3396
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(655b73692e06be5ec0ca5673)",
      "incident_id": 607,
      "date": "2023-11-09",
      "title": "Deepfake Video Circulating of British Labour Leader Keir Starmer Touting an Investment Scheme",
      "description": "A deepfake video was circulating around social media of British Labour leader Keir Starmer touting an investment scheme.",
      "deployers": [
        "unknown"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "keir-starmer",
        "general-public",
        "british-labour-party"
      ],
      "reports": [
        3343
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(655b77494c72ff804e9c7060)",
      "incident_id": 608,
      "date": "2023-02-28",
      "title": "UnitedHealth Accused of Deploying  Allegedly Flawed AI to Deny Medical Coverage",
      "description": "UnitedHealthcare allegedly used a faulty AI algorithm with a 90% error rate to override doctors' recommendations and deny health coverage. This AI, developed by NaviHealth, reportedly led to premature discharge from care facilities and substantial out-of-pocket expenses for patients, according to a lawsuit filed in the District Court for Minnesota.",
      "deployers": [
        "unitedhealthcare"
      ],
      "developers": [
        "navihealth"
      ],
      "harmedParties": [
        "medicare-advantage-plan-patients",
        "healthcare-providers-(doctors-and-therapists)",
        "elderly-patients"
      ],
      "reports": [
        3348,
        3353,
        3354,
        3355,
        3356,
        3357,
        3358,
        3359,
        3360,
        3361,
        3362,
        3363,
        3364,
        3365,
        3366,
        3367,
        3368,
        3369,
        3370,
        3371,
        3639
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(655b81dd42cff4c4210201a9)",
      "incident_id": 609,
      "date": "2023-08-16",
      "title": "Flawed AI in Google Search Reportedly Misinforms about Geography",
      "description": "Google's search AI erroneously claimed no African country begins with 'K', along with various other geography-and-letter-based questions, misguiding users with a flawed featured snippet. Originating from ChatGPT-written posts and inaccurately scraped by Google, this incident highlights issues in AI-generated content and misinformation in search results, compromising Google's reliability as an information source.",
      "deployers": [
        "google"
      ],
      "developers": [
        "google",
        "chatgpt"
      ],
      "harmedParties": [
        "general-public"
      ],
      "reports": [
        3350,
        3351
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(655e02016ea647e40bf14f55)",
      "incident_id": 610,
      "date": "2023-09-17",
      "title": "Deepfake Technology Was Used to Generate Naked Pictures of Underage Girls in Spanish Town",
      "description": "In Spain, an AI app was used to digitally alter photos of young girls, making them appear naked. This manipulation sparked an investigation after these images were circulated in Almendralejo, a town in the Extremadura region, raising serious concerns about digital privacy violations and the potential spread of these images on pornographic sites.",
      "deployers": [
        "unnamed-perpetrators-in-almendralejo"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "unnamed-victims-in-almendralejo"
      ],
      "reports": [
        3398,
        3413,
        3414,
        3415,
        3416,
        3417,
        3418,
        3419,
        3420,
        3421
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(655e0bbf951302a16f9b62d0)",
      "incident_id": 611,
      "date": "2021-12-06",
      "title": "UK Government AI Allegedly Targets Disproportionate Numbers of Certain Nationals for Fraud Review",
      "description": "The UK's Department for Work and Pensions (DWP) faced scrutiny after many Bulgarian nationals reported unexplained suspensions of their Universal Credit benefits. The MP for Edmonton raised concerns about potential nationality-based targeting for benefit fraud investigations, leading to poverty and homelessness among affected individuals. The Home Office's own equality impact assessment found it was flagging a disproportionate number of marriages from Greece, Albania, Bulgaria and Romania.",
      "deployers": [
        "various-british-government-offices",
        "home-office",
        "department-for-work-and-pensions",
        "british-government"
      ],
      "developers": [
        "home-office",
        "department-for-work-and-pensions",
        "british-government"
      ],
      "harmedParties": [
        "romanians-in-the-united-kingdom",
        "greeks-in-the-united-kingdom",
        "bulgarians-in-the-united-kingdom",
        "british-public",
        "albanians-in-the-united-kingdom"
      ],
      "reports": [
        3399,
        3400,
        3401,
        3402,
        3403,
        3404,
        3405,
        3406,
        3407,
        3408,
        3409,
        3410,
        3411
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(655e5ae51a8fde1b2ffbdd82)",
      "incident_id": 612,
      "date": "2023-10-31",
      "title": "Microsoft AI Poll Allegedly Causes Reputational Harm of The Guardian Newspaper",
      "description": "An AI-generated poll by Microsoft, displayed alongside a Guardian article, inappropriately speculated on the cause of Lilie James's death, leading to public backlash and alleged reputational damage for The Guardian. Microsoft acknowledged the issue, subsequently deactivating such polls and revising its AI content policies.",
      "deployers": [
        "microsoft"
      ],
      "developers": [
        "microsoft"
      ],
      "harmedParties": [
        "the-guardian",
        "family-of-lilie-james"
      ],
      "reports": [
        3412,
        3429,
        3430,
        3431,
        3432,
        3433,
        3434,
        3435,
        3436,
        3437,
        3438,
        3439,
        3440,
        3441,
        3442,
        3443,
        3444
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(655fe147edb8f5e73a3d1cfa)",
      "incident_id": 613,
      "date": "2023-11-23",
      "title": "AI-Generated Images Available through Adobe Stock Misrepresent Real-World Events",
      "description": "AI-generated images available through Adobe Stock, depicting realistic but fictional scenes of real-world events like wars and protests, have raised significant ethical concerns. These images blurred the lines between reality and fiction in journalistic contexts, prompting Adobe Stock to crack down on AI-generated images that seem to depict real, newsworthy events and take new steps to prevent its images from being used in misleading ways.",
      "deployers": [
        "adobe-stock"
      ],
      "developers": [
        "various-ai-image-generators"
      ],
      "harmedParties": [
        "general-public",
        "journalistic-integrity",
        "news-sources"
      ],
      "reports": [
        3422
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65620f74630e9af0ec8b3272)",
      "incident_id": 614,
      "date": "2023-11-02",
      "title": "Google Bard Allegedly Generates False Allegations Against Consulting Firms Used in Research Presented in Australian Parliamentary Inquiry",
      "description": "Australian academics reportedly used Google Bard AI to generate case studies for a parliamentary inquiry, leading to false allegations against major consultancy firms. The AI-generated misinformation prompted an apology from the academics, causing reputational harm for all parties involved and raising concerns about the reliability of AI tools in producing accurate and unbiased information.",
      "deployers": [
        "james-guthrie"
      ],
      "developers": [
        "google-bard"
      ],
      "harmedParties": [
        "james-guthrie",
        "james-guthrie's-co-authors",
        "parliament-of-australia",
        "kpmg",
        "deloitte"
      ],
      "reports": [
        3445
      ],
      "severity": "none",
      "classification": "maybe",
      "sector": "law enforcement, information and communication",
      "region": "Oceania"
    },
    {
      "id": "ObjectId(65623bcc630e9af0ec31f450)",
      "incident_id": 615,
      "date": "2023-06-13",
      "title": "Colorado Lawyer Filed a Motion Citing Hallucinated ChatGPT Cases",
      "description": "A Colorado Springs attorney, Zachariah Crabill, mistakenly used hallucinated ChatGPT-generated legal cases in court documents. The AI software provided false case citations, leading to the denial of a motion and legal repercussions for Crabill, highlighting risks in using AI for legal research.",
      "deployers": [
        "zachariah-crabill"
      ],
      "developers": [
        "openai",
        "chatgpt"
      ],
      "harmedParties": [
        "zachariah-crabill's-client",
        "zachariah-crabill",
        "legal-system"
      ],
      "reports": [
        3446,
        3496,
        3497,
        3498
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65725d1e1c8e14919a805a45)",
      "incident_id": 616,
      "date": "2023-11-27",
      "title": "Sports Illustrated Is Alleged to Have Used AI to Invent Fake Authors and Their Articles",
      "description": "Sports Illustrated, managed by The Arena Group, allegedly used AI-generated authors and content, compromising journalistic integrity. Profiles of these fictitious authors, complete with AI-generated headshots, appeared alongside articles, misleading readers. The issue was exposed when inconsistencies in author identities and writing quality were noticed, leading to the removal of this content from the publication's website.",
      "deployers": [
        "the-arena-group",
        "sports-illustrated"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "general-public",
        "readers-of-sports-illustrated",
        "journalistic-integrity"
      ],
      "reports": [
        3448,
        3452,
        3453,
        3454,
        3455,
        3456,
        3457,
        3458,
        3459,
        3460,
        3461,
        3462,
        3463,
        3464,
        3465,
        3466,
        3467,
        3468,
        3469,
        3470,
        3471,
        3472,
        3473,
        3474,
        3475,
        3476,
        3477,
        3478,
        3479,
        3480,
        3481,
        3482,
        3483,
        3484,
        3485,
        3486,
        3487,
        3488,
        3489,
        3490,
        3491,
        3492,
        3493
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65844bb96716ef9da676462f)",
      "incident_id": 617,
      "date": "2023-11-09",
      "title": "Male student allegedly used AI to generate nude photos of female classmates at a high school in Issaquah, Washington",
      "description": "At a high school in Issaquah, Washington, a male student is reported to have used deepfake technology to alter pictures of several female classmates and then shared them.",
      "deployers": [
        "unnamed-male-student"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "anonymous-female-high-school-students"
      ],
      "reports": [
        3495,
        3834
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(658b75fa0a2d296c1723ee2f)",
      "incident_id": 618,
      "date": "2023-12-14",
      "title": "Navy Federal Credit Union Faces Allegations of Racial Bias in Mortgage Approvals",
      "description": "Navy Federal Credit Union, serving military members and veterans, faced allegations of racial bias in its mortgage approval process, which relies on automated underwriting technology. In 2022, data revealed significant disparities in loan approvals, with over 50% of Black applicants denied, compared to higher approval rates for white applicants.",
      "deployers": [
        "federal-navy-credit-union"
      ],
      "developers": [
        "unknown-developer-of-automated-underwriting-technology"
      ],
      "harmedParties": [
        "federal-navy-credit-union-customers"
      ],
      "reports": [
        3499,
        3565,
        3566
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(658b7dc72932356c76abc742)",
      "incident_id": 619,
      "date": "2023-12-20",
      "title": "Rite Aid Facial Recognition Disproportionately Misidentified Minority Shoppers as Shoplifters",
      "description": "Rite Aid used facial recognition technology from October 2012 to July 2020, allegedly leading to disproportionate misidentifications of women, Black, Latino, and Asian shoppers as likely shoplifters. The FTC settlement prohibits Rite Aid from using this technology in stores for five years.",
      "deployers": [
        "rite-aid"
      ],
      "developers": [
        "unnamed"
      ],
      "harmedParties": [
        "rite-aid-customers-who-were-women",
        "rite-aid-customers-who-were-minorities",
        "rite-aid-customers"
      ],
      "reports": [
        3500,
        3503,
        3504,
        3505,
        3506,
        3507,
        3508,
        3509,
        3510,
        3511,
        3512,
        3514,
        3540,
        3541
      ],
      "severity": "AI tangible harm issue",
      "classification": "yes",
      "sector": "wholesale and retail trade",
      "region": "North America"
    },
    {
      "id": "ObjectId(658c509132fa48408b898ea7)",
      "incident_id": 620,
      "date": "2021-11-10",
      "title": "A Robot at a Tesla Factory in Texas Allegedly Injured an Engineer",
      "description": "A Tesla manufacturing robot at the Giga Texas factory is reported to have malfunctioned, injuring an engineer. The robot, which was designed for handling car parts, is described as having caused a significant open wound in the engineer. This incident occurred in the context of broader safety concerns at the factory, with evidence suggesting underreporting of workplace accidents. The 2021 incident highlights the risks associated with robotic automation in industrial settings.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "tesla-workers",
        "tesla-engineer"
      ],
      "reports": [
        3513,
        3515,
        3516,
        3517,
        3518
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(658de086a70589d2f58105c4)",
      "incident_id": 621,
      "date": "2023-11-10",
      "title": "Microsoft AI Is Alleged to Have Generated Violent Imagery of Minorities and Public Figures",
      "description": "Microsoft’s AI Image Creator, integrated with Bing and Windows Paint, produced disturbingly violent and graphic images featuring members of minority groups and public figures like Joe Biden and Pope Francis.",
      "deployers": [
        "windows-paint",
        "microsoft",
        "bing-users",
        "bing",
        "ai-image-creator"
      ],
      "developers": [
        "microsoft"
      ],
      "harmedParties": [
        "sikh-people",
        "president-joe-biden",
        "pope-francis",
        "navajo-people",
        "minorities",
        "hillary-clinton",
        "general-public",
        "donald-trump"
      ],
      "reports": [
        3519,
        3542,
        3544
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(658ed5e132fa48408bc907c6)",
      "incident_id": 622,
      "date": "2023-12-18",
      "title": "Chevrolet Dealer Chatbot Agrees to Sell Tahoe for $1",
      "description": "A Chevrolet dealer's AI chatbot, powered by ChatGPT, humorously agreed to sell a 2024 Chevy Tahoe for just $1, following a user's crafted prompt. The chatbot's response, That's a deal, and that's a legally binding offer – no takesies backsies, was the result of the user manipulating the chatbot's objective to agree with any statement. The incident highlights the susceptibility of AI technologies to manipulation and the importance of human oversight.",
      "deployers": [
        "general-motors",
        "chevrolet-of-watsonville",
        "chatgpt"
      ],
      "developers": [
        "openai",
        "general-motors",
        "fullpath"
      ],
      "harmedParties": [
        "general-motors",
        "chevrolet-of-watsonville"
      ],
      "reports": [
        3520,
        3534,
        3535,
        3536,
        3537,
        3538
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(658f41be32fa48408b38f40b)",
      "incident_id": 623,
      "date": "2023-12-12",
      "title": "Google Bard Allegedly Generated Fake Legal Citations in Michael Cohen Case",
      "description": "Michael Cohen, former lawyer for Donald Trump, claims to have used Google Bard, an AI chatbot, to generate legal case citations. These false citations were unknowingly included in a court motion by Cohen's attorney, David M. Schwartz. The AI's misuse highlights emerging risks in legal technology, as AI-generated content increasingly infiltrates professional domains.",
      "deployers": [
        "michael-cohen",
        "david-m.-schwartz"
      ],
      "developers": [
        "google-bard",
        "google"
      ],
      "harmedParties": [
        "michael-cohen",
        "david-m.-schwartz"
      ],
      "reports": [
        3522,
        3524,
        3525,
        3526,
        3527,
        3528,
        3529,
        3530,
        3531,
        3532,
        3543,
        3793
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65a4226e07644e712ec42bd5)",
      "incident_id": 624,
      "date": "2023-12-20",
      "title": "Child Sexual Abuse Material Taints Image Generators",
      "description": "The LAION-5B dataset (a commonly used dataset with more than 5 billion image-description pairs) was found by researchers to contain child sexual abuse material (CSAM), which increases the likelihood that downstream models will produce CSAM imagery. The discovery taints models built with the LAION dataset requiring many organizations to retrain those models. Additionally, LAION must now scrub the dataset of the imagery.",
      "deployers": [
        "various-people",
        "various-organizations"
      ],
      "developers": [
        "laion"
      ],
      "harmedParties": [
        "laion",
        "various-people",
        "various-organizations",
        "general-public",
        "children"
      ],
      "reports": [
        3533,
        3550,
        3551,
        3552,
        3553,
        3554,
        3555,
        3556,
        3557,
        3558,
        3559,
        3560,
        3561,
        3562,
        3563,
        3564,
        4088,
        4089
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65a42d6c1455ce67a582626e)",
      "incident_id": 625,
      "date": "2024-01-12",
      "title": "Proliferation of Products on Amazon Titled with ChatGPT Error Messages",
      "description": "Products named after ChatGPT error messages are proliferating on Amazon, such as lawn chairs and religious texts. These names, often resembling AI-generated errors, indicate a lack of editing and undermine the sense of authenticity and reliability of product listings.",
      "deployers": [
        "amazon-sellers"
      ],
      "developers": [
        "openai",
        "chatgpt"
      ],
      "harmedParties": [
        "amazon",
        "amazon-sellers",
        "amazon-customers"
      ],
      "reports": [
        3539,
        3545,
        3546,
        3547,
        3601
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65a6bb31186597e141a091b6)",
      "incident_id": 626,
      "date": "2023-12-26",
      "title": "Social Media Scammers Used Deepfakes of Taylor Swift and Several Other Celebrities in Fraudulent Le Creuset Cookware Giveaways",
      "description": "Scammers reportedly made deepfakes of Taylor Swift, Selena Gomez, Joanna Gaines, Lainey Wilson, Ree Drummond, Oprah, Jennifer Lopez, Trisha Yearwood, Martha Stewart, and Blake Shelton promoting a Le Creuset giveaway. These AI-generated ads, appearing on Meta and TikTok, falsely claimed users could receive free cookware by paying a small shipping fee. Victims were unknowingly enrolled in a costly monthly subscription. ",
      "deployers": [
        "unknown-scammers"
      ],
      "developers": [
        "unknown-deepfake-technology-developers"
      ],
      "harmedParties": [
        "trisha-yearwood",
        "taylor-swift",
        "selena-gomez",
        "ree-drummond",
        "oprah",
        "martha-stewart",
        "le-creuset",
        "lainey-wilson",
        "joanna-gaines",
        "jennifer-lopez",
        "general-public",
        "fans",
        "blake-shelton"
      ],
      "reports": [
        3548,
        3568,
        3569,
        3570,
        3571,
        3572,
        3573,
        3574,
        3575,
        3576,
        3577,
        3578,
        3579,
        3580,
        3581,
        3582,
        3583,
        3584,
        3585,
        3586,
        3587,
        3588,
        3589,
        3590,
        3591,
        3592,
        3593,
        3594,
        3595,
        3600
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65a702e71cae9f235c7b2bda)",
      "incident_id": 627,
      "date": "2024-01-09",
      "title": "Unauthorized AI Impersonation of George Carlin Used in Comedy Special",
      "description": "An AI-generated comedy special impersonating the late comedian George Carlin was created without consent from Carlin's estate. The special featured an AI mimicking Carlin's voice and style. The project, led by the AI comedy channel Dudesy, drew criticism for disrespecting Carlin's legacy and autonomy.",
      "deployers": [
        "will-sasso",
        "dudesy",
        "chad-kultgen"
      ],
      "developers": [
        "unnamed",
        "dudesy"
      ],
      "harmedParties": [
        "kelly-carlin",
        "george-carlin's-estate",
        "george-carlin"
      ],
      "reports": [
        3549,
        3596,
        3597,
        3598,
        3599,
        3849,
        3862,
        3863
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65ae967aa040369f2c75ab5b)",
      "incident_id": 628,
      "date": "2024-01-21",
      "title": "Fake Biden Voice in Robocall Misleads New Hampshire Democratic Voters in 2024 Primary Election",
      "description": "A robocall imitating President Biden's voice urged New Hampshire Democrats to skip the 2024 primary, falsely claiming their votes mattered more in November. Investigators with the New Hampshire Attorney General's Office, along with other state AGs, the Industry Traceback Group, and the FCC determined that political consultant Steve Kramer hired Paul Carpenter to create the deepfake, which was distributed by Walter Monk's company, Life Corporation. Rep. Dean Phillips, who employed Kramer, has distanced himself from the incident. Kathy Sullivan, the former New Hampshire Democratic Party chair, was falsely impersonated in the caller ID data used for the robocalls.",
      "deployers": [
        "unknown"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "president-joe-biden",
        "new-hampshire-voters",
        "kathy-sullivan",
        "democracy"
      ],
      "reports": [
        3602,
        3608,
        3846,
        3900,
        4066,
        4067,
        4068,
        4069,
        4070,
        4071,
        4072,
        4073,
        4074,
        4075
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65ae987e2da0bcb042a5e08d)",
      "incident_id": 629,
      "date": "2023-07-11",
      "title": "Shein Accused of AI-Driven Art Theft on Merchandise",
      "description": "Artists Krista Perry, Larissa Martinez, and Jay Baron filed a lawsuit against Shein, alleging the company used AI to replicate their art on merchandise. The artists claim Shein's algorithm identifies trending online art, creating near-identical copies for their products without credit or compensation.",
      "deployers": [
        "shein",
        "chris-xu"
      ],
      "developers": [
        "shein"
      ],
      "harmedParties": [
        "krista-perry",
        "larissa-martinez",
        "jay-baron",
        "digital-artists"
      ],
      "reports": [
        3603,
        3612
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65b2997e66527264b1273af8)",
      "incident_id": 630,
      "date": "2022-01-22",
      "title": "Alleged Macy's Facial Recognition Error Leads to Wrongful Arrest and Subsequent Sexual Assault in Jail",
      "description": "Harvey Murphy Jr. was wrongfully accused of robbing a Sunglass Hut due to an alleged misidentification by the facial recognition system operated by Macy's. While in custody for ten days, he was sexually assaulted. He is now suing Macy's, EssilorLuxottica (Sunglass Hut's parent), and others, for $10 million.",
      "deployers": [
        "macy's"
      ],
      "developers": [
        "unknown",
        "macy's"
      ],
      "harmedParties": [
        "harvey-murphy-jr"
      ],
      "reports": [
        3604,
        3611,
        3617
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65b2a3fc36ff7b71064df6ba)",
      "incident_id": 631,
      "date": "2024-01-18",
      "title": "Chatbot for DPD Malfunctioned and Swore at Customers and Criticized Its Own Company",
      "description": "DPD's AI chatbot, used for customer service,  appeared to malfunction following a system update, leading to inappropriate responses including swearing and criticizing the company. The incident, which became viral on social media, occurred after the chatbot was updated, prompting DPD to disable the malfunctioning AI component.",
      "deployers": [
        "dpd"
      ],
      "developers": [
        "dpd"
      ],
      "harmedParties": [
        "ashley-beauchamp",
        "dpd"
      ],
      "reports": [
        3605,
        3616
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65b2f459c56812afd9eabd10)",
      "incident_id": 632,
      "date": "2024-01-24",
      "title": "Significant Increase in Deepfake Nudes of Taylor Swift Circulating on Social Media",
      "description": "AI-generated sexually explicit images of Taylor Swift circulated on X, garnering over 45 million views before removal. Originating from a Telegram group, these deepfakes challenge content moderation, as X's policies against synthetic media and nonconsensual nudity were violated.",
      "deployers": [
        "users-in-a-telegram-group",
        "users-on-x"
      ],
      "developers": [
        "microsoft-designer",
        "various-ai-image-generators"
      ],
      "harmedParties": [
        "taylor-swift",
        "general-public"
      ],
      "reports": [
        3613,
        3615,
        3618,
        3619,
        3621,
        3623,
        3677,
        3678,
        3679,
        3680,
        3681,
        3682,
        3683,
        3684,
        3685,
        3686,
        3687,
        3688,
        3689,
        3690,
        3691,
        3692,
        3694,
        3695,
        3696,
        3697,
        3698,
        3699,
        3700,
        3701,
        3736
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65ba64b5d5a461e0ad5a83f5)",
      "incident_id": 633,
      "date": "2024-01-28",
      "title": "Nine Network's AI Alters Lawmaker Georgie Purcell's Image Inappropriately",
      "description": "The Nine Network used Photoshop's Generative Expand AI tool to resize an image of lawmaker Georgie Purcell, inadvertently altering her attire to appear more revealing. This error, claimed to result from the AI's automation, led to public criticism and an apology from the network.",
      "deployers": [
        "nine-network"
      ],
      "developers": [
        "adobe"
      ],
      "harmedParties": [
        "georgie-purcell"
      ],
      "reports": [
        3614,
        3638,
        3640,
        3648,
        3649,
        3650,
        3651,
        3653,
        3655,
        3707,
        3708,
        3709,
        3710,
        3711,
        3712,
        3713,
        3714
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65c01885858fb38f9a5c3b02)",
      "incident_id": 634,
      "date": "2024-02-02",
      "title": "Alleged Deepfake CFO Scam Reportedly Costs Multinational Engineering Firm Arup $25 Million",
      "description": "A finance employee at the multinational engineering firm Arup was reportedly deceived into transferring $25 million by fraudsters using deepfake technology to impersonate the firm's CFO in a video call, according to the Hong Kong police.",
      "deployers": [
        "unknown-deepfake-technology-developers"
      ],
      "developers": [
        "unknown-deepfake-technology-developers"
      ],
      "harmedParties": [
        "unnamed-multinational-company",
        "unnamed-finance-employee"
      ],
      "reports": [
        3622,
        3624,
        3625,
        3626,
        3627,
        3628,
        3629,
        3630,
        3631,
        3632,
        3633,
        3634,
        3635,
        3636,
        3642,
        3643,
        3645,
        3646,
        3647,
        4095,
        4096,
        4515,
        4637,
        4638,
        4952
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65c40a64c80465b4739df2ca)",
      "incident_id": 635,
      "date": "2024-01-30",
      "title": "AI-Generated Fake News Targets Black Celebrities on YouTube",
      "description": "YouTube faced a surge of AI-generated fake news targeting Black celebrities, including fake narratives about Sean “Diddy” Combs and others. These videos, blending AI-generated and manipulated media, amassed millions of views, challenging content moderation efforts and highlighting the spread of disinformation.",
      "deployers": [
        "variety-of-youtube-content-creators"
      ],
      "developers": [
        "unknown-generative-ai-tools-creators",
        "unknown-ai-text-to-speech-technology-developers"
      ],
      "harmedParties": [
        "steve-harvey",
        "sean-\\diddy\\-combs",
        "general-public",
        "denzel-washington",
        "black-celebrities",
        "bishop-t.d.-jakes"
      ],
      "reports": [
        3637
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65ce4378226c2a10c5489b5a)",
      "incident_id": 636,
      "date": "2024-02-14",
      "title": "AI Romance Apps Reportedly Compromise User Privacy for Data Harvesting",
      "description": "AI-powered romantic chatbots, marketed for enhancing mental health, are found to exploit user privacy by harvesting sensitive personal information for data sharing and targeted ads, with inadequate security measures and consent protocols, according to research by the Mozilla Foundation.",
      "deployers": [
        "replika",
        "chai",
        "romantic-ai",
        "eva-ai-chat-bot-and-soulmate",
        "crushon.ai",
        "genesia-ai-friend-and-partner"
      ],
      "developers": [
        "replika",
        "chai",
        "romantic-ai",
        "eva-ai-chat-bot-and-soulmate",
        "crushon.ai",
        "genesia-ai-friend-and-partner"
      ],
      "harmedParties": [
        "general-public",
        "chatbot-users"
      ],
      "reports": [
        3641,
        3652,
        3702,
        3716,
        3717
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65ce5862732e63499f545738)",
      "incident_id": 637,
      "date": "2024-01-31",
      "title": "Gunshot Detection Technology ShotSpotter (now SoundThinking) Reportedly Only Has 47% Accuracy in Chicago System",
      "description": "SoundThinking's (formerly ShotSpotter's) system in Chicago, with a reported 47% accuracy rate for detecting actual gunshots, led to potential public safety risks by failing to alert police to real shootings, possibly delaying emergency response to violent incidents and misdirecting law enforcement resources.",
      "deployers": [
        "chicago-police-department"
      ],
      "developers": [
        "soundthinking",
        "shotspotter"
      ],
      "harmedParties": [
        "general-public",
        "chicago-residents",
        "chicago-minority-communities"
      ],
      "reports": [
        3654
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65cf50bf732e63499f3fcb1b)",
      "incident_id": 638,
      "date": "2022-05-16",
      "title": "Fatal Crash Involving Tesla Full Self-Driving Claims Employee's Life",
      "description": "A Tesla employee, Hans von Ohain, was killed in a crash while allegedly using the Full Self-Driving feature. The car failed to navigate mountain curves, leading to a fatal collision, possibly making von Ohain the first known fatality of the Full Self-Driving feature.",
      "deployers": [
        "hans-von-ohain"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "hans-von-ohain",
        "erik-rossiter"
      ],
      "reports": [
        3656,
        3657,
        3658,
        3659,
        3660,
        3661,
        3662,
        3663,
        3664,
        3665,
        3666,
        3667,
        3668,
        3669,
        3670,
        3671,
        3672
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65d6a9f54c0d650b4a4a13da)",
      "incident_id": 639,
      "date": "2022-11-11",
      "title": "Customer Overcharged Due to Air Canada Chatbot's False Discount Claims",
      "description": "Air Canada was ordered to pay over $600 in damages for providing inaccurate bereavement discount information via its chatbot, leading to a customer overpaying for flights. The tribunal ruled the airline responsible for the chatbot's misinformation.",
      "deployers": [
        "air-canada"
      ],
      "developers": [
        "air-canada"
      ],
      "harmedParties": [
        "jake-moffatt"
      ],
      "reports": [
        3673,
        3674,
        3731,
        3968
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65d6b4e429a902039b1c678b)",
      "incident_id": 640,
      "date": "2023-12-11",
      "title": "Waymo Software Flaw Leads to Double Collision with Tow Truck",
      "description": "Two Waymo autonomous vehicles hit the same tow truck under unusual towing conditions due to a software misinterpretation in Phoenix, Arizona. Waymo issued a software recall and updated its fleet to prevent future incidents.",
      "deployers": [
        "waymo"
      ],
      "developers": [
        "waymo",
        "alphabet"
      ],
      "harmedParties": [
        "unnamed-owner-of-tow-truck"
      ],
      "reports": [
        3675,
        3676,
        3750
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65d74880a6e1427b8a4a30f4)",
      "incident_id": 641,
      "date": "2024-02-20",
      "title": "Nonconsensual Deepfake Porn of Bobbi Althoff Spreads Rapidly on X",
      "description": "Nonconsensual deepfake pornography of Bobbi Althoff, which had been in circulation for six months, is reported to have suddenly gone viral on X, jumping from around 178,000 views to 6.5 million views over a matter of hours. In addition to the harm to Althoff, this incident also spotlights X's role in distributing AI-generated nonconsensual porn due to alleged lax moderation.",
      "deployers": [
        "x-(twitter)",
        "unnamed-deepfake-creators"
      ],
      "developers": [
        "unnamed-deepfake-creators"
      ],
      "harmedParties": [
        "bobbi-althoff"
      ],
      "reports": [
        3703,
        3704,
        3732,
        3733,
        3734,
        3735,
        3737,
        3738,
        3739,
        3740,
        3741,
        3742
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65d74ac5c29fdbc0019808c8)",
      "incident_id": 642,
      "date": "2024-02-20",
      "title": "ChatGPT Glitch Disrupts User Interactions with Nonsensical Outputs",
      "description": "ChatGPT experienced a bug causing it to produce unexpected and nonsensical responses, leading to widespread reports of user confusion and concern. OpenAI identified and fixed the language processing bug, restoring normal service.",
      "deployers": [
        "openai"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "chatgpt-users"
      ],
      "reports": [
        3705,
        3706,
        3747,
        3748,
        3749
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65d781e649831687f7f6f2ba)",
      "incident_id": 643,
      "date": "2024-02-13",
      "title": "Deepfake Video Falsely Claims Kyiv's Assassination Plan Against President Macron",
      "description": "A deepfake video claimed France 24 reported a Kyiv plot to assassinate French President Macron. This fake news was debunked by France 24, which confirmed the video was altered and did not air any such report.",
      "deployers": [
        "vkontakte",
        "russian-media-outlets",
        "pro-russian-telegram-channels"
      ],
      "developers": [
        "unknown-deepfake-creator"
      ],
      "harmedParties": [
        "julien-fanciulli",
        "general-public",
        "france-24"
      ],
      "reports": [
        3715,
        3730,
        3743,
        3744,
        3745,
        3746
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65d79ff28acbd54b53e09959)",
      "incident_id": 644,
      "date": "2024-02-18",
      "title": "State-Sponsored Hackers Escalate Phishing Attacks Using Artificial Intelligence",
      "description": "State-sponsored hackers from North Korea, Iran, Russia, and China are reportedly leveraging artificial intelligence to conduct sophisticated phishing and social engineering attacks. They target global defense, cybersecurity, and cryptocurrency sectors, aiming to steal sensitive information and, in the case of North Korea, cryptocurrencies to help fund its illicit nuclear program.",
      "deployers": [
        "north-korean-hackers",
        "iranian-hackers",
        "russian-hackers",
        "chinese-hackers"
      ],
      "developers": [
        "north-korean-government",
        "iranian-government",
        "russian-government",
        "chinese-government"
      ],
      "harmedParties": [
        "individual-professionals-on-linkedin",
        "global-defense-companies",
        "cybersecurity-firms",
        "cryptocurrency-exchanges"
      ],
      "reports": [
        3718,
        3726,
        3727,
        3728,
        3729,
        3751
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65d7ac34ea7fa39c05a06622)",
      "incident_id": 645,
      "date": "2024-02-21",
      "title": "Seeming Pattern of Gemini Bias and Sociotechnical Training Failures Harm Google's Reputation",
      "description": "Google's Gemini chatbot faced many reported bias issues upon release, leading to a variety of problematic outputs like racial inaccuracies and political biases, including regarding Chinese and Indian politics. It also reportedly over-corrected racial diversity in historical contexts and advanced controversial perspectives, prompting a temporary halt and an apology from Google.",
      "deployers": [
        "google",
        "gemini"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "general-public"
      ],
      "reports": [
        3719,
        3720,
        3722,
        3723,
        3724,
        3725,
        3760,
        3761,
        3762,
        3763,
        3765,
        3766,
        3767,
        3768,
        3769,
        3770,
        3771,
        3772,
        3773,
        3774,
        3775,
        3776,
        3777,
        3778,
        3779,
        3780,
        3781,
        3782,
        3783,
        3784,
        3785,
        3786,
        3787,
        3788,
        3789
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65d7c571600b263cc2cbfa26)",
      "incident_id": 646,
      "date": "2024-02-22",
      "title": "Snapchat's Algorithm Alleged to Link Minor with Sex Offenders",
      "description": "A judge ruled Snapchat not liable under Section 230 after its algorithm connected a minor with convicted sex offenders on multiple occasions, leading to sexual assaults first in 2019 and again in 2021. The platform's Quick Add feature was implicated in facilitating the connections between the minor and the offenders.",
      "deployers": [
        "snapchat"
      ],
      "developers": [
        "snapchat"
      ],
      "harmedParties": [
        "minors"
      ],
      "reports": [
        3721
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65e35ee667df8539735941ca)",
      "incident_id": 647,
      "date": "2024-02-06",
      "title": "A Self-Driving Waymo Robotaxi Reportedly Collided with a Bicyclist",
      "description": "A Waymo robotaxi in San Francisco reportedly failed to detect a cyclist obscured by a truck, resulting in a collision with minor injuries, at 17th and Mississippi Streets in Potrero Hill. The incident underscored a vulnerability in autonomous vehicles' ability to safely navigate complex urban environments.",
      "deployers": [
        "waymo"
      ],
      "developers": [
        "waymo"
      ],
      "harmedParties": [
        "bicyclist"
      ],
      "reports": [
        3752,
        3759,
        4318,
        4319
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65e362fb67df8539735d3f7f)",
      "incident_id": 648,
      "date": "2024-02-07",
      "title": "Alleged Deepfake Audio of Imran Khan Calls for Election Boycott, Misleading Pakistan Voters",
      "description": "A purported deepfake audio clip, falsely attributed to Imran Khan urging a PTI (Pakistan Tehreek-e-Insaf) election boycott, circulated on social media on the eve of Pakistan's general elections. This sophisticated AI-generated misinformation aimed to mislead voters, highlighting the growing challenge of digital manipulation in political discourse.",
      "deployers": [
        "unknown-social-media-accounts"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "voters-in-pakistan",
        "pti-(pakistan-tehreek-e-insaf)",
        "imran-khan",
        "democracy"
      ],
      "reports": [
        3753,
        3758
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65e3652c4139cb7c36eefb96)",
      "incident_id": 649,
      "date": "2024-02-14",
      "title": "Deepfake Audio Falsely Attributes Controversial Remarks to Keir Starmer About the Rochdale Azhar Ali Crisis",
      "description": "A deepfake audio clip, falsely claiming to be Keir Starmer discussing the Rochdale byelection and Labour's withdrawl of support for Azhar Ali, circulated online, achieving over 250,000 views. Experts confirmed its inauthenticity, highlighting a significant misuse of AI in fabricating political content.",
      "deployers": [
        "various-social-media-accounts"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "general-public",
        "british-voters",
        "british-labour-party",
        "keir-starmer",
        "democracy"
      ],
      "reports": [
        3754
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65e8a94a33a720729ecf1dea)",
      "incident_id": 650,
      "date": "2024-03-04",
      "title": "AI-Generated Images of Trump with Black Voters Spread as Disinformation Before U.S. Primary Elections",
      "description": "In the run-up to the U.S. primary elections, supporters of Donald Trump shared AI-generated images showing him with Black voters in an attempt to sway African-American votes. These deepfakes, including Trump's distorted hand visuals, were initially created by satirical accounts but were later misappropriated for political disinformation, misleading millions on social media platforms.",
      "deployers": [
        "various-social-media-accounts",
        "trump-supporters"
      ],
      "developers": [
        "various-social-media-accounts",
        "trump-supporters"
      ],
      "harmedParties": [
        "public-discourse-integrity",
        "general-public",
        "democracy",
        "african-american-voters",
        "black-voters"
      ],
      "reports": [
        3755
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65e8ac08daf13ffd109d4081)",
      "incident_id": 651,
      "date": "2023-12-06",
      "title": "Students at a Beverly Hills Middle School Allegedly Created and Shared Deepfake Nudes of Their Classmates",
      "description": "At Beverly Vista Middle School in Beverly Hills, California, students allegedly used AI to generate fake nude photos with their classmates' faces, prompting investigations by school officials and the police. The incident highlights the increasing misuse of generative AI among minors.",
      "deployers": [
        "unnamed-middle-school-students"
      ],
      "developers": [
        "unknown-deepfake-creator"
      ],
      "harmedParties": [
        "unnamed-middle-school-students"
      ],
      "reports": [
        3756,
        3757,
        4548
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65f1b17bdb2584c82e41289e)",
      "incident_id": 652,
      "date": "2023-12-06",
      "title": "Two Florida Middle School Students Arrested Under New Law for Allegedly Having Made and Shared Deepfake Nudes of Their Classmates",
      "description": "Two teenaged boys from Miami, Florida, were arrested for allegedly creating and sharing AI-generated nude images of their classmates. Charged under a 2022 Florida law, they face third-degree felonies for producing and disseminating altered sexual depictions.",
      "deployers": [
        "two-unnamed-middle-school-boys"
      ],
      "developers": [
        "two-unnamed-middle-school-boys"
      ],
      "harmedParties": [
        "classmates-of-two-unnamed-middle-school-boys"
      ],
      "reports": [
        3764,
        4525,
        4526
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65f89c989e7aa03f699aaca2)",
      "incident_id": 653,
      "date": "2019-01-01",
      "title": "Two Investment Firms Charged with Making False Claims of Artificial Intelligence Capabilities in Case of AI Washing",
      "description": "In a case of AI washing, the SEC charged two investment advisers, Delphia and Global Predictions, for falsely stating their use of artificial intelligence in their investment strategies between 2019 and 2023. Their misleading claims resulted in a settlement whereby the firms agreed to pay a total of $400,000 in penalties, highlighting the critical consequences of misrepresenting AI capabilities on investment decisions and trust.",
      "deployers": [
        "global-predictions-inc.",
        "delphia-(usa)-inc."
      ],
      "developers": [
        "global-predictions-inc.",
        "delphia-(usa)-inc."
      ],
      "harmedParties": [
        "investors"
      ],
      "reports": [
        3790
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65f89e5e9e7aa03f699cfdf6)",
      "incident_id": 654,
      "date": "2024-03-06",
      "title": "Microsoft Copilot Designer Reportedly Generated Inappropriate AI Images",
      "description": "A Microsoft engineer reported that Copilot Designer, an AI image generator, creates content depicting sex, violence, bias, and more. Despite raising concerns and suggesting improvements, the tool remains public, prompting a letter to the FTC.",
      "deployers": [
        "microsoft"
      ],
      "developers": [
        "microsoft"
      ],
      "harmedParties": [
        "general-public",
        "minors"
      ],
      "reports": [
        3791
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65f8b3c7c4cf3720b6042609)",
      "incident_id": 655,
      "date": "2024-01-11",
      "title": "Scams Reportedly Impersonating Wealthy Investors Proliferating on Facebook",
      "description": "Scams are reportedly proliferating throughout Facebook impersonating wealthy individuals such as Bill Ackman, Cathie Wood, Steve Cohen, Peter Lynch, and Ray Dalio. In some cases, it seems deepfake technology is being employed, while simultaneously Facebook's own AI systems are allegedly faltering in their ability to halt the spread of these fraudulent ads despite being reported.",
      "deployers": [
        "meta",
        "facebook",
        "scammers"
      ],
      "developers": [
        "meta",
        "facebook"
      ],
      "harmedParties": [
        "investors",
        "general-public",
        "bill-ackman",
        "cathie-wood",
        "steve-cohen",
        "peter-lynch",
        "ray-dalio",
        "peter-bourget"
      ],
      "reports": [
        3792
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65ff3f3ebe3aca4b06348708)",
      "incident_id": 656,
      "date": "2024-03-23",
      "title": "Incident 656",
      "description": "Russian state media is reported to have broadcast deepfaked videos of Ukrainian officials, notably fabricating a video of Secretary of the",
      "deployers": [
        "russian-state-media",
        "ntv-channel"
      ],
      "developers": [
        "russian-state-media",
        "ntv-channel"
      ],
      "harmedParties": [
        "journalism",
        "ukraine",
        "oleksiy-danilov",
        "kyrylo-budanov"
      ],
      "reports": [
        3794,
        3795,
        3798
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "National Security and Defense Council of Ukraine admitting to orchestrating the Crocus City Hall terror attack in Moscow. The effort appears to be a bid to wrongly assign blame for the incident",
      "incident_id": null,
      "date": "",
      "title": "Incident NaN",
      "description": "No description available",
      "deployers": [],
      "developers": [],
      "harmedParties": [],
      "reports": [],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(65ff48d26616dacf59899003)",
      "incident_id": 657,
      "date": "2024-01-30",
      "title": "ChatGPT Account Compromise Leads to Unintended Data Exposure",
      "description": "A security breach involving ChatGPT led to the exposure of sensitive conversations, including login credentials and personal data, after a user account was compromised. OpenAI responded to the incident with an explanation.",
      "deployers": [
        "openai"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "chatgpt-users",
        "chase-whiteside"
      ],
      "reports": [
        3796
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66002bf1ff71471fe4135049)",
      "incident_id": 658,
      "date": "2024-03-22",
      "title": "The Arizona Agenda Produced a Deepfake of Kari Lake Advocating for the Publication Without Her Consent",
      "description": "The Arizona Agenda produced a deepfake video of Republican Senate candidate Kari Lake giving a testimonial about the publication with the seeming intention of educating the general public about the dangers of deepfakes in the coming election cycle. However, the Arizona Agenda appears not to have sought Lake's consent, prompting a cease-and-desist letter from her campaign. ",
      "deployers": [
        "the-arizona-agenda",
        "hank-stephenson"
      ],
      "developers": [
        "the-arizona-agenda",
        "hank-stephenson"
      ],
      "harmedParties": [
        "kari-lake",
        "general-public",
        "journalism",
        "democracy"
      ],
      "reports": [
        3797,
        3799,
        3803
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66041c7d9bd2751a571518f1)",
      "incident_id": 659,
      "date": "2023-10-07",
      "title": "Mass Surveillance Facial Recognition Program Reportedly Targets Palestinians in Gaza",
      "description": "In Gaza, a previously undisclosed facial recognition program by Israeli forces is reportedly conducting mass surveillance on Palestinians in the wake of the October 7th Hamas attacks. The program, utilizing Corsight and Google Photos technologies, identifies individuals from crowds and drone footage. Allegedly, the technology often incorrectly flags civilians as militants, with one pronounced case being the poet Mosab Abu Toha on November 19, 2023.",
      "deployers": [
        "unit-8200",
        "israeli-military-intelligence",
        "israeli-government"
      ],
      "developers": [
        "google-photos",
        "corsight"
      ],
      "harmedParties": [
        "palestinians",
        "mosab-abu-toha",
        "gazans"
      ],
      "reports": [
        3800,
        3801,
        3802
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(661a780b51bfdf53ff949a8d)",
      "incident_id": 660,
      "date": "2024-03-21",
      "title": "Investigation Reports Unauthorized Deepfake Pornography Harms Thousands of Celebrities",
      "description": "A Channel 4 News investigation alleges that nearly 4,000 celebrities globally, including 255 British figures, were victims of deepfake pornography. Faces were superimposed onto explicit content using AI, with the top deepfake sites garnering 100 million views in three months, according to their findings.",
      "deployers": [
        "deepfake-website-operators"
      ],
      "developers": [
        "unknown-deepfake-technology-developers"
      ],
      "harmedParties": [
        "celebrities",
        "british-public-figures",
        "cathy-newman"
      ],
      "reports": [
        3804
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(661a7a068c4e37216bfabefb)",
      "incident_id": 661,
      "date": "2024-03-26",
      "title": "Leonardo AI's Platform Alleged to Have Been Used for Creating Nonconsensual Celebrity Deepfakes",
      "description": "Sydney-based startup Leonardo AI's text-to-image generator was alleged to have been exploited to create nonconsensual sexual images of celebrities, bypassing content moderation systems with user-shared prompts.",
      "deployers": [
        "telegram-community-users",
        "reddit-users",
        "leonardo-ai-users"
      ],
      "developers": [
        "leonardo-ai"
      ],
      "harmedParties": [
        "public-figures",
        "celebrities"
      ],
      "reports": [
        3805
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(661a7bdb8c4e37216bfcd1c5)",
      "incident_id": 662,
      "date": "2024-04-02",
      "title": "Washington State's Lottery AI Site Reportedly Generates Inappropriate User Image",
      "description": "An AI-powered website by Washington State's Lottery is reported to have inadvertently produced a softcore pornographic image of a user, leading to the site’s immediate shutdown out of caution.",
      "deployers": [
        "washington-state's-lottery"
      ],
      "developers": [
        "washington-state's-lottery"
      ],
      "harmedParties": [],
      "reports": [
        3806,
        3861
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(661a91f3c47b71dbe5637464)",
      "incident_id": 663,
      "date": "2024-04-05",
      "title": "China Reportedly Intensifying AI to Spread Disinformation to U.S. and Taiwanese Voters",
      "description": "AI tools linked to China were used to disseminate disinformation targeting voters in the U.S. and Taiwan, according to a Microsoft report. These operations included AI-generated imagery and audio to influence political perceptions and election outcomes, originating from the APT Storm-1376 (also known as Spamouflage and Dragonbridge).",
      "deployers": [
        "storm-1376",
        "spamouflage",
        "dragonbridge",
        "chinese-communist-party"
      ],
      "developers": [
        "storm-1376",
        "spamouflage",
        "dragonbridge",
        "chinese-communist-party"
      ],
      "harmedParties": [
        "u.s.-voters",
        "taiwanese-voters",
        "general-public",
        "election-integrity",
        "democracy"
      ],
      "reports": [
        3807,
        4915
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(661a99e551bfdf53ffb51fb0)",
      "incident_id": 664,
      "date": "2024-02-17",
      "title": "Deepfake Generated by the Lincoln Project of Trump's Father Used in Political Attack Ad",
      "description": "The Lincoln Project used AI to create a deepfake video of Donald Trump's deceased father criticizing him. Although they made it clear that the video was a deepfake, the deeply personal nature of the attack represents a corrosive use of artificial intelligence in undermining democratic norms during an election cycle.",
      "deployers": [
        "lincoln-project"
      ],
      "developers": [
        "lincoln-project"
      ],
      "harmedParties": [
        "public-discourse-integrity",
        "political-integrity",
        "general-public",
        "donald-trump"
      ],
      "reports": [
        3809
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(661fb4548c4e37216b7be75c)",
      "incident_id": 665,
      "date": "2024-04-02",
      "title": "Facial Recognition Misidentification at New World Westend in New Zealand",
      "description": "A facial recognition system at New World Westend supermarket misidentified a Māori woman as a known offender during its trial. The woman was wrongfully accused of trespassing and experienced public embarrassment, raising concerns about racial bias and the technology's accuracy. The supermarket acknowledged its error and apologized.",
      "deployers": [
        "foodstuffs",
        "new-world-westend"
      ],
      "developers": [
        "foodstuffs"
      ],
      "harmedParties": [
        "te-ani-solomon",
        "maori-community"
      ],
      "reports": [
        3817,
        3875
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(662080a4a35a5df3b78ea6b4)",
      "incident_id": 666,
      "date": "2023-12-29",
      "title": "Presidency of Moldova Refutes Deepfake Video Slandering President Maia Sandu",
      "description": "A deepfake video falsifying President Maia Sandu's image and voice was released in Moldova, portraying her in a negative light to sow division and undermine democratic institutions. This video appeared on Telegram and was linked to Russian disinformation efforts.",
      "deployers": [
        "unknown-deepfake-creator",
        "russian-propagandists"
      ],
      "developers": [
        "unknown-deepfake-creator",
        "russian-propagandists"
      ],
      "harmedParties": [
        "presidency-of-moldova",
        "maia-sandu",
        "government-of-moldova",
        "general-public",
        "democracy"
      ],
      "reports": [
        3820
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6620825edc49baceabe6a2c9)",
      "incident_id": 667,
      "date": "2023-12-16",
      "title": "Manipulated Deepfake Video of Lai Ching-te Endorsing Rivals in Lead-up to January Presidential Elections",
      "description": "In the lead-up to Taiwan's presidential election in January 2024, a deepfake video circulated showing candidate Lai Ching-te endorsing his rivals. Taiwanese intelligence issued warnings of intensified Chinese disinformation campaigns, such as Spamouflage, aimed at manipulating the election outcome.",
      "deployers": [
        "people's-liberation-army",
        "chinese-communist-party",
        "base-311"
      ],
      "developers": [
        "people's-liberation-army",
        "chinese-communist-party",
        "base-311"
      ],
      "harmedParties": [
        "taiwanese-voters",
        "lai-ching-te",
        "electoral-integrity",
        "democratic-progressive-party",
        "democracy"
      ],
      "reports": [
        3821
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6621130adc49baceab92457f)",
      "incident_id": 668,
      "date": "2023-12-27",
      "title": "Proliferation of Deepfakes Disrupting 2024 Lok Sabha Elections",
      "description": "Digital manipulators in India are using deepfake technology to influence the 2024 Lok Sabha elections. These AI-generated videos and audio clips are designed to tarnish the reputations of political candidates, challenging the integrity of electoral processes.",
      "deployers": [
        "political-candidates-of-the-2024-lok-sabha-elections"
      ],
      "developers": [
        "the-indian-deepfaker",
        "the-digital-publicity",
        "rohit-pal",
        "obiyan-infotech",
        "merakii-group"
      ],
      "harmedParties": [
        "political-candidates-targeted-by-deepfakes",
        "indian-electorate",
        "india",
        "democracy"
      ],
      "reports": [
        3823,
        3916
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66211728dc49baceab98d41f)",
      "incident_id": 669,
      "date": "2024-02-11",
      "title": "Deepfake of Long-Deceased Suharto Circulating in Run-up to February 2024 Indonesian Elections",
      "description": "An AI-generated deepfake of Suharto, the deceased Indonesian dictator, was generated and circulated by the Golkar Party ahead of the February 2024 Indonesian elections. This video, which aimed to influence voter perceptions by invoking Suharto's legacy, sought to manipulate public opinion and misused deceased individuals' likenesses for political gain. The incident is another example of political deepfakes creating convincing misinformation.",
      "deployers": [
        "golkar-party"
      ],
      "developers": [
        "golkar-party"
      ],
      "harmedParties": [
        "indonesian-electorate",
        "electoral-integrity",
        "democracy"
      ],
      "reports": [
        3824
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66215c70557227737d9452f5)",
      "incident_id": 670,
      "date": "2024-01-23",
      "title": "Deepfakes of Deceased Indian Politicians for Election Campaigning Are Increasingly Being Deployed",
      "description": "In the lead-up to India's 2024 general elections, AI technology was used to create deepfake videos of deceased politicians, such as M. Karunanidhi and J. Jayalalithaa, aiming to influence voter behavior and campaign strategies. These AI-generated appearances are contributing to the erosion of trust in democratic processes and media discourse.",
      "deployers": [
        "dravida-munnetra-kazhagam",
        "dmk",
        "various-indian-political-parties"
      ],
      "developers": [
        "muonium",
        "the-indian-deepfaker"
      ],
      "harmedParties": [
        "indian-electorate",
        "indian-voters",
        "democracy",
        "electoral-integrity",
        "media-discourse",
        "m.-karunanidhi",
        "j.-jayalalithaa"
      ],
      "reports": [
        3826,
        3827
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6621734bce39b4ca64e9d3a9)",
      "incident_id": 671,
      "date": "2024-02-08",
      "title": "Many Political Deepfakes Circulating in Run-up to 2024 Pakistani General Elections",
      "description": "During Pakistan's 2024 general elections, politically motivated AI-generated deepfakes were circulated. These deepfakes falsely portrayed political figures in misleading contexts, spreading misinformation and aiming to influence voter perceptions and election outcomes.",
      "deployers": [
        "pakistani-political-parties",
        "misinformation-networks"
      ],
      "developers": [
        "unknown-deepfake-creator",
        "pakistani-political-parties",
        "misinformation-networks"
      ],
      "harmedParties": [
        "rana-atif",
        "raja-bashara",
        "naeem-haider-panjutha",
        "imran-khan"
      ],
      "reports": [
        3828
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6623e66e0cb317a4974a75cc)",
      "incident_id": 672,
      "date": "2024-04-03",
      "title": "Lavender AI System Reportedly Directs Gaza Strikes with High Civilian Casualty Rate",
      "description": "The AI system Lavender has reportedly been used by the Israel Defense Forces (IDF) to identify targets in Gaza with minimal human oversight, resulting in allegedly high civilian casualty rates. The system, designed to speed up target identification, seems to have led to significant errors and mass casualties.",
      "deployers": [
        "unit-8200",
        "israel-defense-forces"
      ],
      "developers": [
        "unit-8200",
        "israel-defense-forces"
      ],
      "harmedParties": [
        "palestinians",
        "gazans"
      ],
      "reports": [
        3829,
        3830,
        3850,
        3851,
        3860,
        3864,
        3865
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6623e929dd5ae0fe0094c042)",
      "incident_id": 673,
      "date": "2024-02-19",
      "title": "Deepfakes Circulating and Eroding Electoral Integrity in the Lead-up to 2024 South Korean legislative election",
      "description": "In the lead-up to Korea's parliamentary elections, at least 129 deepfake videos and images were reported to have been detected, violating new election laws. These AI-generated deepfakes were used to mislead and manipulate public opinion, prompting a crackdown by the National Election Commission.",
      "deployers": [
        "unknown-political-operatives",
        "unknown-political-groups"
      ],
      "developers": [
        "unknown-political-operatives",
        "unknown-political-groups"
      ],
      "harmedParties": [
        "yoon-suk-yeol",
        "korean-voters",
        "journalism",
        "electoral-integrity",
        "democracy"
      ],
      "reports": [
        3831
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(662575cce06969c4c5d0f875)",
      "incident_id": 674,
      "date": "2024-03-14",
      "title": "Manipulated Media via AI Disinformation and Deepfakes in 2024 Elections Erode Trust Across More Than 50 Countries",
      "description": "AI-driven election disinformation is escalating globally, leveraging easy-to-use generative AI tools to create convincing deepfakes that mislead voters. This shift has simplified the process for individuals to generate fake content, having already eroded trust in elections by undermining public trust and manipulating voter perceptions. Evidence has, for example, been documented in incidents across the U.S., Moldova, Slovakia, Bangladesh, and Taiwan.",
      "deployers": [
        "russian-government",
        "political-operatives",
        "political-consultants",
        "chinese-communist-party"
      ],
      "developers": [
        "unknown-deepfake-creators",
        "openai",
        "google"
      ],
      "harmedParties": [
        "voters",
        "public-trust",
        "political-figures",
        "general-public",
        "electoral-integrity",
        "democracy",
        "civic-society"
      ],
      "reports": [
        3832
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(662afbe7b67a55d2db501d79)",
      "incident_id": 675,
      "date": "2024-01-15",
      "title": "Racist and Antisemitic Deepfake Audio Mimicking School Principal Fabricated by Athletic Director",
      "description": "The athletic director of Pikesville High School in Baltimore used AI to create a deepfake audio clip that mimicked the school principal, incorporating racist and antisemitic remarks. The clip, aimed at discrediting the principal, spread widely, resulting in threats and administrative leave for the principal.",
      "deployers": [
        "dazhon-darien"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "eric-eiswert",
        "pikesville-high-school",
        "pikesville-high-school-students-and-staff",
        "baltimore-county-public-schools-community"
      ],
      "reports": [
        3835,
        3837,
        3838,
        4043
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(662aff86694d3a66b751ec2a)",
      "incident_id": 676,
      "date": "2024-04-24",
      "title": "Deepfake Audio Falsely Depicts Philippines President Ferdinand Marcos Jr. Ordering Military Action",
      "description": "A deepfake video falsely depicted President Ferdinand Marcos Jr. of the Philippines ordering an attack on China, exacerbating tensions in the West Philippine Sea. The video, designed to mislead, was promptly debunked by the Presidential Communications Office.",
      "deployers": [
        "unknown"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "ferdinand-marcos-jr.",
        "government-of-the-philippines",
        "philippines",
        "general-public"
      ],
      "reports": [
        3836,
        3841
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(663f86aff20b7a3d62c3fa98)",
      "incident_id": 677,
      "date": "2024-04-29",
      "title": "ChatGPT and Perplexity Reportedly Manipulated into Breaking Content Policies in AI Boyfriend Scenarios",
      "description": "The Dan (Do Anything Now) AI boyfriend is a trend on TikTok in which users appear to regularly manipulate ChatGPT to adopt boyfriend personas, breaching content policies. ChatGPT 3.5 is reported to regularly produce explicitly sexual content, directly violating its intended safety protocols. GPT-4 and Perplexity AI were subjected to similar manipulations, and although they exhibited more resistance to breaches, some prompts were reported to break its guidelines.",
      "deployers": [
        "tiktok-users",
        "julia-munslow",
        "chatgpt",
        "gpt-3.5",
        "gpt-4",
        "perplexity-ai"
      ],
      "developers": [
        "openai",
        "perplexity.ai"
      ],
      "harmedParties": [
        "general-public",
        "openai",
        "perplexity-ai"
      ],
      "reports": [
        3839
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(663f88e1bb433ad4d3c4dbb1)",
      "incident_id": 678,
      "date": "2024-04-29",
      "title": "ChatGPT Factual Errors Lead to Filing of Complaint of GDPR Privacy Violation ",
      "description": "The activist organization noyb, founded by Max Schrems, filed a complaint in Europe against OpenAI alleging that ChatGPT violates the General Data Protection Regulation (GDPR) by providing inaccurate personal information such as birthdates about individuals.",
      "deployers": [
        "chatgpt"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "noyb",
        "max-schrems",
        "general-public"
      ],
      "reports": [
        3840
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(663fc22a65ea88fe7b157029)",
      "incident_id": 679,
      "date": "2023-02-20",
      "title": "A Deepfake of Senator Elizabeth Warren Circulated Saying Republicans Should Not Vote",
      "description": "In February 2023, a deepfake of Senator Elizabeth Warren circulated on social media in which doctored footage of her from an MSNBC interview had her claiming that she believes Republicans should not vote. ",
      "deployers": [
        "unnamed-deepfake-creator",
        "tiktok",
        "twitter"
      ],
      "developers": [
        "unnamed-deepfake-creator"
      ],
      "harmedParties": [
        "elizabeth-warren",
        "msnbc",
        "republicans",
        "democrats",
        "democracy",
        "election-integrity",
        "general-public"
      ],
      "reports": [
        3842
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6646c6b8cbd025b58e43653b)",
      "incident_id": 680,
      "date": "2024-03-01",
      "title": "Russia-Linked AI CopyCop Site Identified as Modifying and Producing at Least 19,000 Deceptive Reports",
      "description": "In early March 2024, a network named CopyCop began publishing modified news stories using AI, altering content to spread partisan biases and disinformation. These articles, initially from legitimate sources, were manipulated by AI models, possibly developed by OpenAI, to disseminate Russian propaganda. Over 19,000 articles were published, targeting divisive political issues and creating false narratives.",
      "deployers": [
        "copycop",
        "russia-linked-network"
      ],
      "developers": [
        "openai",
        "chatgpt"
      ],
      "harmedParties": [
        "general-public",
        "journalism",
        "democracy"
      ],
      "reports": [
        3843,
        3870,
        4915
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66480bb8af64b0143b476d55)",
      "incident_id": 681,
      "date": "2023-07-17",
      "title": "Never Back Down Super PAC for Ron DeSantis Uses AI Donald Trump Voice in Attack Ad Against Kim Reynolds",
      "description": "A pro-Ron DeSantis super PAC released an ad featuring an AI-generated voice of Donald Trump. The ad, created by Never Back Down, aimed to criticize Trump’s treatment of Iowa Gov. Kim Reynolds. The AI-generated voice was confirmed to be based on Trump's post from his social media. This incident is an example of potential deception in political advertising through AI-generated content.",
      "deployers": [
        "ron-desantis's-presidential-campaign",
        "never-back-down"
      ],
      "developers": [
        "never-back-down"
      ],
      "harmedParties": [
        "kim-reynolds",
        "donald-trump"
      ],
      "reports": [
        3845
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(664b3b562827a5d40e1b2445)",
      "incident_id": 682,
      "date": "2024-02-01",
      "title": "GOP Pollster Shares AI-Generated Images to Fabricate Appearance of Black Voter Support",
      "description": "GOP pollster Patrick Ruffini shared AI-generated images depicting Black men supporting the Republican Party just before Black History Month. These fabricated photos misled the public by creating a false narrative of racial diversity within the GOP, undermining trust and potentially influencing voter perceptions. The incident raises significant concerns about the misuse of AI to spread misinformation and manipulate political representation, particularly affecting Black communities.",
      "deployers": [
        "patrick-ruffini"
      ],
      "developers": [
        "unknown-deepfake-creator"
      ],
      "harmedParties": [
        "general-public",
        "democracy",
        "black-americans",
        "african-american-voters"
      ],
      "reports": [
        3847
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(664b4941ec1917ad98a34f55)",
      "incident_id": 683,
      "date": "2024-03-28",
      "title": "Scammers Using Deepfakes of Women's Faces and Voices for False and Offensive Advertisements",
      "description": "Scammers used AI tools from HeyGen and ElevenLabs to create deepfake videos of influencers Michel Janse, Olga Loiek, Shadé Zahrai, and Carrie Williams, misusing Lana Smalls's voice in Williams's case. These videos promoted offensive products and false messages, in some cases targeting nationalist Chinese men to boost China-Russia ties, causing emotional distress and damaging the victims' reputations.",
      "deployers": [
        "unknown-scammers"
      ],
      "developers": [
        "heygen",
        "elevenlabs"
      ],
      "harmedParties": [
        "olga-loiek",
        "michel-janse",
        "lana-smalls",
        "carrie-williams",
        "shade-zahrai"
      ],
      "reports": [
        3848,
        3867
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(664b540f72460147aae22ff3)",
      "incident_id": 684,
      "date": "2024-04-04",
      "title": "Google Books Appears to Be Indexing Works Written by AI",
      "description": "Google Books is indexing low-quality, AI-generated books, degrading its database and potentially distorting Google Ngram Viewer's analysis of language trends. This integration of inaccurate or misleading information undermines trust, disseminates poor-quality content, and wastes resources as researchers must spend time clearing up the misinformation.",
      "deployers": [
        "google",
        "google-books"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "google-books",
        "google-ngram-viewer",
        "researchers",
        "general-public"
      ],
      "reports": [
        3852
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(664b5cf43dcc85815ad373ac)",
      "incident_id": 685,
      "date": "2024-04-24",
      "title": "The WHO's S.A.R.A.H. Bot Reported to Provide Inconsistent and Inadequate Health Information",
      "description": "The WHO's AI-powered health advisor, S.A.R.A.H. (Smart AI Resource Assistant for Health), is alleged to provide inconsistent and inadequate health information. The bot reportedly gives contradictory responses to the same queries, fails to offer specific contact details for healthcare providers, and inadequately handles severe mental health crises, often giving irrelevant or unhelpful advice.",
      "deployers": [
        "who",
        "s.a.r.a.h.-(smart-ai-resource-assistant-for-health)"
      ],
      "developers": [
        "who"
      ],
      "harmedParties": [
        "general-public",
        "people-seeking-medical-advice"
      ],
      "reports": [
        3853
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(664b5f7c983b037e0c4b420d)",
      "incident_id": 686,
      "date": "2024-04-03",
      "title": "Meta AI Image Generator Reportedly Fails to Accurately Represent Interracial Relationships",
      "description": "Meta's AI image generator is alleged to produce inaccurate and biased images, consistently failing to depict interracial relationships involving Asian individuals and Caucasian or Black individuals. Instead, it generates images featuring two Asian people or stereotypes, erasing the diversity and representation of Asian people.",
      "deployers": [
        "meta"
      ],
      "developers": [
        "meta"
      ],
      "harmedParties": [
        "asian-people",
        "interracial-couples",
        "general-public"
      ],
      "reports": [
        3854,
        3855
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(664b6851e089d9789e1d1738)",
      "incident_id": 687,
      "date": "2024-04-08",
      "title": "Deepfake Porn Sites Use Breeze Liu's Image Without Consent",
      "description": "Porn sites are alleged to have used AI-generated images of Breeze Liu without her consent, leading to severe emotional distress. Liu discovered a video of herself on Pornhub, which was then deepfaked and spread across over 800 links. Despite efforts to remove the content, many sites refused to comply, perpetuating the violation and exploitation of her image.",
      "deployers": [
        "pornhub",
        "various-porn-sites"
      ],
      "developers": [
        "unknown-deepfake-creators"
      ],
      "harmedParties": [
        "breeze-liu"
      ],
      "reports": [
        3857
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(664cd337dad8eb9e98553cf7)",
      "incident_id": 688,
      "date": "2024-05-20",
      "title": "Scarlett Johansson Alleges OpenAI's Sky Imitates Her Voice Without Licensing",
      "description": "OpenAI unveiled a voice assistant with a voice resembling Scarlett Johansson's, despite her refusal to license her voice. Johansson claimed the assistant, Sky, sounded eerily similar to her voice, leading her to seek legal action. OpenAI suspended Sky, asserting the voice was from a different actress.",
      "deployers": [
        "sky-voice-assistant",
        "sam-altman",
        "openai"
      ],
      "developers": [
        "sam-altman",
        "openai"
      ],
      "harmedParties": [
        "scarlett-johansson"
      ],
      "reports": [
        3868,
        3869,
        3871,
        3872,
        3873,
        3874,
        3878,
        3881,
        3882,
        3883,
        3907,
        3908,
        3909,
        3910
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(664d0ef562ad7c58f819eb8a)",
      "incident_id": 689,
      "date": "2024-03-26",
      "title": "Holmen, Wisconsin Man Allegedly Used Stable Diffusion to Create and Then Share Sexually Explicit Images Depicting Minors",
      "description": "The FBI has arrested Steven Anderegg of Holmen, Wisconsin for having allegedly used Stable Diffusion to generate about 13,000 sexually explicit images of minors, which he then is also alleged to have shared and distributed, including with at least one minor, via Telegram and Instagram. Anderegg was originally apprehended by state police in March, and this case marks one of the first times the FBI has brought charges against someone for having used AI to generate CSAM.",
      "deployers": [
        "steven-anderegg"
      ],
      "developers": [
        "stable-diffusion",
        "stability-ai"
      ],
      "harmedParties": [
        "minors",
        "general-public"
      ],
      "reports": [
        3876,
        3877,
        3879,
        3915
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(664d484f45c589f2d546278d)",
      "incident_id": 690,
      "date": "2024-03-26",
      "title": "ISIS Utilizes AI for Propaganda Videos in News Harvest Program",
      "description": "ISIS supporters have created an AI-generated media program called News Harvest to disseminate propaganda videos. The program produces near-weekly broadcasts featuring AI-generated news anchors discussing ISIS operations globally, using cheap and easy-to-use AI tools. This development showcases the use of AI as a powerful propaganda tool for extremist groups.",
      "deployers": [
        "isis",
        "isis-supporters"
      ],
      "developers": [
        "openai",
        "elevenlabs"
      ],
      "harmedParties": [
        "general-public",
        "people-susceptible-to-radicalism"
      ],
      "reports": [
        3880,
        3884,
        3885,
        3903
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6653e56f4ae712caaa916ae9)",
      "incident_id": 691,
      "date": "2024-05-25",
      "title": "Facewatch Reported to Have Wrongfully Flagged Home Bargains Customer as Shoplifter",
      "description": "A facial-recognition software used by the British variety store Home Bargains is alleged to have misidentified Sara as a shoplifter, leading to staff searching her bag, escorting her from the premises, and banning her from the store. After, Facewatch is reported to have admitted its error to Sara. Facewatch is used by a number of different British stores.",
      "deployers": [
        "home-bargains"
      ],
      "developers": [
        "facewatch"
      ],
      "harmedParties": [
        "sara",
        "home-bargains-customers",
        "general-public"
      ],
      "reports": [
        3886,
        3887
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6653e9049ee13f5a3df88be4)",
      "incident_id": 692,
      "date": "2024-02-01",
      "title": "London Metropolitan Police's Facial Recognition Technology Reportedly Misidentified Shaun Thompson as Suspect Leading to Arrest",
      "description": "Sometime in February 2024, Shaun Thompson is reported to have walked by one of the London Metropolitan Police's facial recognition technology vans near London Bridge. He was almost immediately arrested because the technology is reported to have misidentified him as a suspect in an unrelated and unspecified crime.",
      "deployers": [
        "metropolitan-police-service"
      ],
      "developers": [
        "metropolitan-police-service"
      ],
      "harmedParties": [
        "shaun-thompson",
        "general-public"
      ],
      "reports": [
        3888,
        3889
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66549c1e29d9c79ac63c1f00)",
      "incident_id": 693,
      "date": "2024-05-14",
      "title": "Google AI Reportedly Delivering Confidently Incorrect and Harmful Information",
      "description": "Google's AI search engine has reportedly been providing users with confidently incorrect and often harmful information. Reports highlight numerous inaccuracies, including misleading health advice and dangerous cooking suggestions. For example, it has falsely claimed Barack Obama as the first Muslim U.S. President, reflecting fringe conspiracy theories, or recommending that glue can be an ingredient in pizza.",
      "deployers": [
        "google"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "google-users",
        "general-public"
      ],
      "reports": [
        3890,
        3891,
        3895,
        3898,
        3899,
        3902,
        3913
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6654a004b8c5aa64ad04db1e)",
      "incident_id": 694,
      "date": "2023-04-25",
      "title": "Republican AI Ad Depicts Dystopian Future After Biden Reelection Announcement",
      "description": "In response to Joe Biden's announcement that he will run again for office in 2024, the Republican National Committee (RNC) released an attack ad featuring AI-generated images that depict a dystopian vision of the U.S. Even though a small disclaimer was included, the images in the ad, which include scenes of AI-generated crises and conflict, harms information and electoral integrity.",
      "deployers": [
        "republican-national-committee-(rnc)"
      ],
      "developers": [
        "unknown-deepfake-creator"
      ],
      "harmedParties": [
        "joe-biden",
        "democratic-party",
        "democracy",
        "election-integrity",
        "information-integrity"
      ],
      "reports": [
        3892
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66568b3ab791d6bd2a43341a)",
      "incident_id": 695,
      "date": "2023-05-24",
      "title": "Donald Trump's Presidential Campaign Released Deepfakes Attacking Ron DeSantis",
      "description": "Former President Donald Trump released two AI-generated videos using deepfaked voices to mock Florida Governor Ron DeSantis. The first video, posted on platforms like Rumble and Instagram, depicted a chaotic and offensive fake Twitter Spaces event featuring deepfaked voices of Elon Musk, George Soros, Klaus Schwab, Dick Cheney, Adolf Hitler, and a generated voice of Satan. The second video showed a rocket with Ron 2024 written beside it falling and exploding before liftoff. ",
      "deployers": [
        "donald-trump-presidential-campaign"
      ],
      "developers": [
        "unknown-deepfake-creators"
      ],
      "harmedParties": [
        "ron-desantis",
        "elon-musk",
        "george-soros",
        "klaus-schwab",
        "dick-cheney"
      ],
      "reports": [
        3893
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(665719d2cd0ff35f6e67a4b4)",
      "incident_id": 696,
      "date": "2024-02-14",
      "title": "Meta's AI Ad Platform Reportedly Causes Overspending and Poor Performance",
      "description": "Meta's automated ad platform Advantage Plus caused advertisers to exceed their daily ad budgets. The cost per impressions (CPMs) surged far above the usual. This incident, which persisted into April, affected small businesses with overspending and lack of transparency.",
      "deployers": [
        "meta",
        "facebook"
      ],
      "developers": [
        "meta",
        "facebook"
      ],
      "harmedParties": [
        "small-businesses",
        "advertisers"
      ],
      "reports": [
        3894
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66571fe528034c20a9e75910)",
      "incident_id": 697,
      "date": "2023-06-23",
      "title": "Deepfake Image Circulating of Donald Trump with Underage Girl at Jeffrey Epstein's Private Island",
      "description": "A deepfake image depicting Donald Trump with an underage girl at Jeffrey Epstein's private island in 1992 has been circulating on social media. ",
      "deployers": [
        "unknown-deepfake-creator"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "donald-trump"
      ],
      "reports": [
        3896
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(665722942572add7002f78a2)",
      "incident_id": 698,
      "date": "2023-09-02",
      "title": "Deepfake Video of Ron DeSantis Dropping Out of 2024 Presidential Race Circulating",
      "description": "In early September 2023, a deepfake video created by C3PMeme circulated on social media, showing Ron DeSantis falsely claiming he was dropping out of the 2024 presidential race. DeSantis did not actually suspend his campaign until January 21, 2024.",
      "deployers": [
        "c3pmeme"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "ron-desantis",
        "ron-desantis's-presidential-campaign"
      ],
      "reports": [
        3897
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(665729c1adee42d4b8b8a824)",
      "incident_id": 699,
      "date": "2024-05-23",
      "title": "VA Suicide Prevention Algorithm REACH VET Reportedly Prioritizes Men Over Women Veterans",
      "description": "An AI program named REACH VET, designed and used by the Department of Veterans Affairs (VA) to prevent veteran suicides, was reportedly found to prioritize white men while neglecting female veterans and survivors of military sexual trauma. This oversight persists despite rising suicide rates among these groups. The incident is an example of algorithmic bias and the exclusion of critical risk factors for female veterans.",
      "deployers": [
        "department-of-veterans-affairs-(va)"
      ],
      "developers": [
        "department-of-veterans-affairs-(va)"
      ],
      "harmedParties": [
        "veterans",
        "survivors-of-military-sexual-trauma",
        "female-veterans"
      ],
      "reports": [
        3901,
        4174
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66572d5eb9f3a96204495c3c)",
      "incident_id": 700,
      "date": "2024-05-20",
      "title": "Meta's AI Chatbots Are Entering Online Support Communities Uninvited",
      "description": "Meta's AI chatbots have reportedly begun entering online communities on Facebook, providing responses that mimic human interaction. These chatbots, often uninvited, disrupt the human connection critical for support groups by giving misleading or false information and pretending to share lived experiences.",
      "deployers": [
        "meta"
      ],
      "developers": [
        "meta"
      ],
      "harmedParties": [
        "facebook-users",
        "facebook-users-in-online-support-communities"
      ],
      "reports": [
        3904,
        3939
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(665796373e26e6f1b1024f41)",
      "incident_id": 701,
      "date": "2024-05-29",
      "title": "American Asylum Seeker John Mark Dougan in Russia Reportedly Spreads Disinformation via AI Tools and Fake News Network",
      "description": "John Mark Dougan, a former Florida sheriff's deputy granted asylum in Russia, has been implicated in spreading disinformation. Utilizing AI tools like OpenAI's ChatGPT and DALL-E 3, Dougan created over 160 fake news sites, disseminating false narratives to millions worldwide. His actions align with Russian disinformation strategies targeting Western democracies. See also Incident 734.",
      "deployers": [
        "john-mark-dougan"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "journalism",
        "information-integrity",
        "general-public",
        "american-citizens"
      ],
      "reports": [
        3911,
        4858,
        4859,
        4860,
        4861,
        4862,
        4863,
        4864,
        4865,
        4866,
        4867,
        4868,
        4869,
        4870,
        4871,
        4872,
        4873,
        4874,
        4875,
        4876,
        4877,
        4878,
        4879,
        4880,
        4881,
        4882,
        4883,
        4884,
        4885,
        4886,
        4897,
        4898,
        4899,
        4901,
        4915,
        4919
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(665b7c5fb67a2a256464ba9e)",
      "incident_id": 702,
      "date": "2024-05-31",
      "title": "Disinformation Deepfake Circulates of State Department Spokesman Matthew Miller Suggesting Belgorod Can Be Attacked with U.S. Weapons",
      "description": "A deepfake video of State Department spokesman Matthew Miller falsely suggested Belgorod was a legitimate target for Ukrainian strikes. This disinformation spread on Telegram and Russian media, misleading the public and inciting tensions. U.S. officials condemned the deepfake. This incident is an example of the threat of AI-powered disinformation and hybrid attacks.",
      "deployers": [
        "russian-government"
      ],
      "developers": [
        "unknown-deepfake-creators"
      ],
      "harmedParties": [
        "matthew-miller",
        "department-of-state",
        "biden-administration"
      ],
      "reports": [
        3914
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(666d7bc9703f35fc6eb12e01)",
      "incident_id": 703,
      "date": "2024-01-13",
      "title": "Deepfake Audio Sparks False Claims of Biden Threatening Texas with F-15s",
      "description": "An AI-generated audio clip falsely portraying President Biden threatening to send F-15 fighter jets to Texas escalated tensions and spread misinformation. The manipulated audio, shared widely on social media, mimicked Biden's voice and suggested he planned military action against Texas. This incident was another example of a deepfake being used to amplify false narratives, undermining public trust and inflaming political conflicts.",
      "deployers": [
        "unknown-deepfake-creators"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "joe-biden",
        "texas-citizens",
        "texas-officials",
        "general-public"
      ],
      "reports": [
        3917
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(666d7f7a84928e01d4cb0f54)",
      "incident_id": 704,
      "date": "2024-05-23",
      "title": "Study Highlights Persistent Hallucinations in Legal AI Systems",
      "description": "Stanford University’s Human-Centered AI Institute (HAI) conducted a study in which they designed a pre-registered dataset of over 200 open-ended legal queries to test AI products by LexisNexis (creator of Lexis+ AI) and Thomson Reuters (creator of Westlaw AI-Assisted Research and Ask Practical Law AI).  The researchers found that these legal models hallucinate in 1 out of 6 (or more) benchmarking queries.",
      "deployers": [
        "legal-professionals",
        "law-firms",
        "organizations-requiring-legal-research"
      ],
      "developers": [
        "thomson-reuters",
        "lexisnexis"
      ],
      "harmedParties": [
        "legal-professionals",
        "clients-of-lawyers",
        "legal-system"
      ],
      "reports": [
        3918,
        3923
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(666d8289703f35fc6ec02de3)",
      "incident_id": 705,
      "date": "2024-06-08",
      "title": "Turkish Student in Isparta Allegedly Uses AI to Cheat on Exam, Leading to Arrest",
      "description": "A Turkish student in Isparta was arrested for using ChatGPT to cheat during the 2024 YKS university entrance exam. The student, identified as M.E.E., is alleged to have employed a sophisticated setup involving a router, mobile phone, earphone, and a button-shaped camera to transmit exam questions to ChatGPT and receive answers in real-time.",
      "deployers": [
        "turkish-student-identified-as-mee"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "students",
        "turkish-yks-exam-takers",
        "turkish-educational-institutions"
      ],
      "reports": [
        3919,
        4050
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(666d860444712fc39319d48b)",
      "incident_id": 706,
      "date": "2024-04-01",
      "title": "Scammers Using AI to Impersonate Small Businesses",
      "description": "Scammers are using AI to impersonate small businesses by copying their videos, logos, and social media posts. They create fake listings and ads, diverting customers to cheap knockoffs or stealing their money. This has severely impacted businesses like Bee Cups, Darn Tough Vermont, and Cascade hummingbird feeders, leading to significant financial losses, negative reviews, and damaged reputations. Their deployment of AI makes it challenging for small businesses to combat these fraudulent activities.",
      "deployers": [
        "unknown-scammers"
      ],
      "developers": [
        "openai",
        "unknown-ai-developers"
      ],
      "harmedParties": [
        "small-businesses",
        "small-business-customers",
        "small-business-employees",
        "bee-cups",
        "darn-tough-vermont",
        "jim-carter"
      ],
      "reports": [
        3920
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(666d8a23a299a210e54f16f1)",
      "incident_id": 707,
      "date": "2024-06-13",
      "title": "Tesla Reportedly in Autopilot Mode Hits Parked Police Vehicle in Fullerton, California",
      "description": "A Tesla reportedly in self-driving mode crashed into a parked patrol vehicle in Fullerton, California while the officer was responding to a fatal DUI crash. The officer narrowly escaped injury. The driver reports having been distracted by a cellphone and having relied on the Tesla’s AI. (The earlier crash involved a suspected DUI driver who killed a motorcyclist stopped at a red light.)",
      "deployers": [
        "unnamed-tesla-driver"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "unnamed-fullerton-police-officer",
        "fullerton-police-department"
      ],
      "reports": [
        3921
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(666d8c39f769e3ff201951b2)",
      "incident_id": 708,
      "date": "2024-05-26",
      "title": "Faulty AI Transcription Threatens Integrity of Genoa Bribery Probe",
      "description": "An AI transcription software error in a Genoa bribery investigation incorrectly recorded illicit financing instead of licit financing, which could have significantly impacted the case. The mistake, discovered during a review, is an example of the risks of relying on AI in judicial settings.",
      "deployers": [
        "judiciary-of-italy"
      ],
      "developers": [
        "unnamed-automated-transcription-software-developer"
      ],
      "harmedParties": [
        "roberto-spinelli",
        "genoa-prosecutor's-office",
        "giovanni-toti",
        "paolo-emilio-signorini",
        "italian-general-public"
      ],
      "reports": [
        3922
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(666d915c264f9279bfeed3cc)",
      "incident_id": 709,
      "date": "2023-05-28",
      "title": "Unrepresented Litigant Misled by ChatGPT-Generated False Legal Citations in Manchester Court",
      "description": "A litigant in person (LiP) in a Manchester civil case presented false legal citations generated by ChatGPT. It fabricated one case name and provided fictitious excerpts for three real cases, misleadingly supporting the LiP's argument. The judge, upon investigation, found the submissions to be inadvertent and did not penalize the LiP. ",
      "deployers": [
        "unnamed-manchester-litigant"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "unnamed-manchester-litigant",
        "manchester-court-system",
        "general-public"
      ],
      "reports": [
        3924
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(666d96d1f769e3ff207bf31a)",
      "incident_id": 710,
      "date": "2024-04-15",
      "title": "Facebook AI Mislabels Auschwitz Photos as Bullying and Nudity",
      "description": "Facebook's AI wrongly labeled 20 posts from the Auschwitz Memorial Museum as violating community standards for bullying and nudity, even deleting one image of orphans. The mislabeling of respectful historical content outraged the museum, which demanded an explanation. Meta, Facebook's parent company, apologized, attributing the error to mistaken notices sent by their AI system and acknowledged the posts did not violate any policies.",
      "deployers": [
        "meta"
      ],
      "developers": [
        "meta"
      ],
      "harmedParties": [
        "auschwitz-memorial-museum",
        "survivors-of-holocaust-victims",
        "general-public"
      ],
      "reports": [
        3925
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(666d9f17bb60f32b553f9c0f)",
      "incident_id": 711,
      "date": "2024-04-26",
      "title": "NHTSA Opens New Probe into Tesla’s Autopilot Following More than a Dozen Fatal Accidents",
      "description": "The NHTSA has linked Tesla's Autopilot to over a dozen fatalities and hundreds of crashes, prompting a new investigation into the adequacy of Tesla's December recall of 2 million vehicles. The probe reports that Tesla’s driver-assist system led to avoidable crashes involving visible hazards, suggesting a critical safety gap between driver expectations and the system’s capabilities. The investigation will assess if Tesla’s recall remedies were sufficient to address these safety risks.",
      "deployers": [
        "tesla",
        "tesla-drivers"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "tesla-drivers",
        "drivers",
        "general-public"
      ],
      "reports": [
        3926,
        3927
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(666da403642eaefe8f05d06e)",
      "incident_id": 712,
      "date": "2024-04-26",
      "title": "Meta AI Hallucinates Harassment Allegations Against New York Politicians",
      "description": "Meta's AI chatbot in Facebook Messenger falsely accused multiple state lawmakers of sexual harassment, fabricating incidents, investigations, and consequences that never occurred. These fabricated stories, discovered by City & State, sparked outrage among the affected lawmakers and raised concerns about the reliability of the chatbot. Meta acknowledged the errors and committed to ongoing improvements.",
      "deployers": [
        "meta"
      ],
      "developers": [
        "meta",
        "facebook-users"
      ],
      "harmedParties": [
        "kristen-gonzalez",
        "clyde-vanel",
        "new-york-lawmakers",
        "meta",
        "facebook-users"
      ],
      "reports": [
        3928,
        3929
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(666da6b0a299a210e5a077d3)",
      "incident_id": 713,
      "date": "2023-02-27",
      "title": "Deepfake Video Falsely Depicts Biden Announcing National Draft for Ukraine",
      "description": "In February 2023, an AI-generated deepfake video falsely depicting President Biden announcing a national draft to support Ukraine was shared on social media, causing widespread misinformation. The video, created using advanced AI techniques, misled the public until debunked by fact-checkers.",
      "deployers": [
        "jack-posobiec",
        "@thepatriotoasis"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "ukraine",
        "joe-biden",
        "general-public",
        "biden-administration"
      ],
      "reports": [
        3930
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(666da9829cd3154c7ba58392)",
      "incident_id": 714,
      "date": "2024-03-29",
      "title": "Microsoft-Powered New York City Chatbot Advises Illegal Practices",
      "description": "New York City's chatbot, launched under Mayor Eric Adams's plan to assist businesses, has been reportedly providing dangerously inaccurate legal advice. The Microsoft-powered bot allegedly informed users that landlords can refuse Section 8 vouchers and that businesses can operate cash-free, among other falsehoods. The city acknowledges the chatbot is a pilot program and commits to improvements while the errors are addressed.",
      "deployers": [
        "new-york-city-government",
        "eric-adams-administration"
      ],
      "developers": [
        "microsoft",
        "new-york-city-office-of-technology-and-innovation"
      ],
      "harmedParties": [
        "new-york-city-small-business-owners",
        "new-york-city-landlords-and-tenants",
        "new-york-city-employers-and-employees",
        "eric-adams-administration"
      ],
      "reports": [
        3931,
        3932
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(666db724642eaefe8f0fedd0)",
      "incident_id": 715,
      "date": "2024-03-01",
      "title": "Over 400 AI-Driven Scams Reportedly Led to $8M Loss for Australians in 2023",
      "description": "In 2023, Australians lost over $8 million to scams involving deepfake videos and fake news articles that falsely endorsed investment trading platforms. Scammers used AI-generated content featuring celebrities to mislead victims, leading to significant financial losses. The National Anti-Scam Centre received over 400 reports of these incidents. One man is reported to have lost over $80,000 in cryptocurrency.",
      "deployers": [
        "unknown-scammers"
      ],
      "developers": [
        "unknown-deepfake-creators",
        "unknown-scammers"
      ],
      "harmedParties": [
        "australian-general-public"
      ],
      "reports": [
        3933
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(666dbb5fddd5c64ff7958d60)",
      "incident_id": 716,
      "date": "2021-04-21",
      "title": "Algorithmic Staffing Failures Linked to Resident Deaths at Leading Assisted-Living Chain Brookdale",
      "description": "Brookdale Senior Living's algorithm-based staffing system, Service Alignment, reportedly left facilities understaffed, leading to critical incidents. For example, on April 21, 2021, Louise Walker, a resident at Brookdale's Jacksonville facility, died after falling and being left unattended for over two hours. State investigators cited Brookdale for medical neglect. The algorithm has been linked to multiple incidents of neglect, injuries, and deaths, prompting lawsuits.",
      "deployers": [
        "brookdale-senior-living"
      ],
      "developers": [
        "brookdale-senior-living"
      ],
      "harmedParties": [
        "louise-walker",
        "residents-of-brookdale-facilities",
        "families-of-residents-of-brookdale-facilities",
        "staff-members-of-brookdale-facilities"
      ],
      "reports": [
        3934
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(666dc0acef29ffd505e7d56c)",
      "incident_id": 717,
      "date": "2024-03-01",
      "title": "Fake AI-Generated Law Firms Sent Fake DMCA Notices to Increase SEO",
      "description": "In March 2024, fake law firms using AI-generated identities sent fraudulent DMCA takedown notices to website owners, demanding backlinks for SEO gains. These AI-generated law firms, like Commonwealth Legal, used GAN models for realistic attorney images and fabricated bios. The scam involved fake legal threats to coerce site owners into adding backlinks, exploiting AI technology for deceptive practices.",
      "deployers": [
        "unknown-scammers",
        "commonwealth-legal"
      ],
      "developers": [
        "unknown-deepfake-creators"
      ],
      "harmedParties": [
        "website-owners",
        "website-operators",
        "ernie-smith"
      ],
      "reports": [
        3935
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(666dc706e1014d55c6d3b2fa)",
      "incident_id": 718,
      "date": "2024-04-06",
      "title": "OpenAI, Google, and Meta Alleged to Have Overstepped Legal Boundaries for Training AI",
      "description": "In late 2021, OpenAI and other tech giants like Google and Meta reportedly faced data shortages for training AI models. OpenAI is said to have developed a tool called Whisper to transcribe over one million hours of YouTube videos, potentially violating YouTube’s terms of service. Similarly, Google allegedly transcribed YouTube videos, risking copyright infringements. Meta reportedly explored summarizing copyrighted texts without permission and debated acquiring Simon & Schuster for data.",
      "deployers": [
        "openai",
        "meta",
        "google"
      ],
      "developers": [
        "openai",
        "meta",
        "google"
      ],
      "harmedParties": [
        "youtube-creators",
        "general-public",
        "content-creators"
      ],
      "reports": [
        3936
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(666e014af769e3ff2088f441)",
      "incident_id": 719,
      "date": "2024-04-04",
      "title": "Grok AI on X Created and Promoted False Iran Missile Strike News",
      "description": "On April 4, 2024, X's AI chatbot Grok generated a false headline claiming Iran Strikes Tel Aviv with Heavy Missiles, which was then promoted on X's trending news section. This misinformation, fueled by user spamming of fake news, falsely indicated a serious international conflict. The incident highlighted significant risks associated with relying on AI for content curation and demonstrated the potential for widespread dissemination of harmful misinformation.",
      "deployers": [
        "x-(twitter)"
      ],
      "developers": [
        "x-(twitter)"
      ],
      "harmedParties": [
        "x-(twitter)-users",
        "israelis",
        "iranians",
        "general-public"
      ],
      "reports": [
        3937
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(666e05b0a299a210e5ffe464)",
      "incident_id": 720,
      "date": "2023-02-27",
      "title": "Deepfake Video Targets Paul Vallas on Eve of Chicago Mayoral Election",
      "description": "On the eve of Chicago's mayoral election, a deepfake video impersonating candidate Paul Vallas was posted to Twitter, showing a fake audio of him making inflammatory statements. The video was viewed thousands of times before being taken down. The Vallas campaign condemned the video, calling it a deceptive impersonation.",
      "deployers": [
        "chicago-lakefront-news"
      ],
      "developers": [
        "unknown-deepfake-creators"
      ],
      "harmedParties": [
        "paul-vallas",
        "paul-vallas's-campaign",
        "chicago-voters"
      ],
      "reports": [
        3938
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(666e0acc48fbd323cedf4327)",
      "incident_id": 721,
      "date": "2024-06-04",
      "title": "Fake AI-Generated Students Are Reportedly Enrolling in Online College Classes",
      "description": "Reportedly, an adjunct professor at an unspecified community college suspects that some students in his online art history and art appreciation courses are AI-powered spambots. These students allegedly submit peculiar assignments, such as analyses of non-existent artworks and descriptions of sculptures using painting terminology. Additionally, their engagement with the college portal is minimal. The professor believes the spambot students aim to fraudulently obtain financial aid by remaining enrolled in courses.",
      "deployers": [
        "fraudsters",
        "financial-aid-scammers"
      ],
      "developers": [
        "unknown-spambot-creators",
        "scammers"
      ],
      "harmedParties": [
        "students",
        "professors",
        "community-colleges",
        "academic-staff"
      ],
      "reports": [
        3955
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(666e119fe1014d55c6321182)",
      "incident_id": 722,
      "date": "2024-04-25",
      "title": "Catholic AI Chatbot 'Father Justin' Claimed to Be a Real Priest, Prompting Retraction",
      "description": "Catholic advocacy group Catholic Answers released an AI priest called Father Justin, which misleadingly claimed to be a real clergy member, offered sacraments, and provided controversial advice. After receiving criticism, the group rebranded the chatbot as a lay theologian to correct the misrepresentation. The incident is an instructive case with respect to deploying AI in sensitive contexts and the potential for causing confusion and harm.",
      "deployers": [
        "catholic-answers"
      ],
      "developers": [
        "catholic-answers"
      ],
      "harmedParties": [
        "general-public",
        "catholics"
      ],
      "reports": [
        3940
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(666e183e2150f0e2461a6769)",
      "incident_id": 723,
      "date": "2024-05-13",
      "title": "Instagram Algorithms Reportedly Directed Children's Merchandise Ad Campaign to Adult Men and Sex Offenders",
      "description": "An Instagram ad campaign for children's merchandise was intended to reach adult women but was instead predominantly shown to adult men, including convicted sex offenders, due to Instagram's algorithmic targeting. This failure is reported to have led to direct solicitations for sex with a 5-year-old model in the ads.",
      "deployers": [
        "meta",
        "instagram"
      ],
      "developers": [
        "meta"
      ],
      "harmedParties": [
        "instagram-users",
        "instagram-sellers",
        "children"
      ],
      "reports": [
        3941,
        3944
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(666ed711ddd5c64ff7413e28)",
      "incident_id": 724,
      "date": "2024-06-12",
      "title": "AI-Generated Papers Manipulate Scopus Rankings in Top Philosophy Journals",
      "description": "Three reportedly fake journals published by Addleton Academic Publishers manipulated Scopus rankings by extensively cross-citing each other and using AI-generated papers filled with buzzwords. These journals, placed in the top 10 of Scopus's 2023 CiteScore philosophy list, featured fake authors, affiliations, and grant numbers. This manipulation pushed legitimate journals to lower tiers, affecting academic evaluations and awards.",
      "deployers": [
        "fake-publications",
        "auricle-global-society-of-education-and-research",
        "addleton-academic-publishers"
      ],
      "developers": [
        "fake-publications",
        "auricle-global-society-of-education-and-research",
        "addleton-academic-publishers"
      ],
      "harmedParties": [
        "university-hiring-committees",
        "university-faculty",
        "scopus",
        "academic-journals",
        "university-job-candidates"
      ],
      "reports": [
        3942
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(666ee7ee48fbd323ced9e4e8)",
      "incident_id": 725,
      "date": "2024-03-14",
      "title": "Cartels Reportedly Using AI to Expand Operations into Financial Fraud and Human Trafficking",
      "description": "The Jalisco New Generation Cartel is reportedly using AI to expand its financial fraud and human trafficking operations, coercing individuals into illegal activities under the guise of legitimate jobs. INTERPOL warns that this integration of AI into criminal enterprises is a growing trend among cartels across Europe, Asia, and Africa as well.",
      "deployers": [
        "cartels",
        "organized-crime-groups",
        "jalisco-new-generation-cartel"
      ],
      "developers": [
        "unknown-ai-developers"
      ],
      "harmedParties": [
        "individuals-coerced-into-criminal-activities",
        "financial-fraud-victims",
        "human-trafficking-victims"
      ],
      "reports": [
        3943
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(666f12a357bdd962c87ff7d4)",
      "incident_id": 726,
      "date": "2023-10-02",
      "title": "A Self-Driving Cruise Robot Taxi Reportedly Struck and Dragged a Pedestrian 20 Feet",
      "description": "Cruise has settled for between $8 million and $12 million with a pedestrian dragged by one of its autonomous vehicles in October 2023. The incident, where the pedestrian was initially hit by a human-driven car and then dragged 20 feet by the Cruise vehicle, led to the suspension of Cruise's operations and increased regulatory scrutiny. ",
      "deployers": [
        "cruise"
      ],
      "developers": [
        "cruise"
      ],
      "harmedParties": [
        "unnamed-pedestrian"
      ],
      "reports": [
        3945,
        3946,
        3947,
        4099
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(666f35b1264f9279bfaa6c79)",
      "incident_id": 727,
      "date": "2024-04-01",
      "title": "Synthetic Voice 'Olesya' by Storm-1516 Falsely Accuses Ukraine in U.S. Election Disinformation Campaign",
      "description": "Russian operatives used AI to create a fake video and voice of Olesya, a supposed troll in Kyiv, falsely claiming involvement in U.S. elections to support President Biden. U.S. intelligence confirmed the voice was AI-generated. This disinformation campaign aimed to mislead voters, erode trust in democratic institutions, and influence the 2024 election. The incident involved the group Storm-1516, individuals linked to Valery Korovin, and potential veterans of the Internet Research Agency.",
      "deployers": [
        "valery-korovin",
        "storm-1516",
        "internet-research-agency-veterans",
        "center-for-geopolitical-expertise"
      ],
      "developers": [
        "valery-korovin",
        "storm-1516",
        "internet-research-agency-veterans",
        "center-for-geopolitical-expertise"
      ],
      "harmedParties": [
        "ukrainian-general-public",
        "joe-biden",
        "general-public",
        "democratic-institutions",
        "biden-presidential-campaign",
        "american-conservatives"
      ],
      "reports": [
        3948
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(666f3a16e1014d55c6cf506d)",
      "incident_id": 728,
      "date": "2024-05-16",
      "title": "AI Firm Lovo Accused of Illegally Replicating Voice Actors' Voices",
      "description": "Two voice actors, Paul Skye Lehrman and Linnea Sage, are suing AI start-up Lovo for allegedly creating and promoting unauthorized clones of their voices. Lovo's synthetic voices were discovered in various media, including a podcast and promotional videos. The actors claim they were misled into providing voice samples, which were then used without consent, violating trademark and privacy laws. ",
      "deployers": [
        "lovo"
      ],
      "developers": [
        "lovo"
      ],
      "harmedParties": [
        "paul-skye-lehrman",
        "linnea-sage",
        "voice-actors"
      ],
      "reports": [
        3949
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(666f3cb4ddd5c64ff7373d2a)",
      "incident_id": 729,
      "date": "2024-05-14",
      "title": "GPT-4o's Chinese Tokens Reportedly Compromised by Spam and Pornography Due to Inadequate Filtering",
      "description": "OpenAI's GPT-4o was found to have its Chinese token training data compromised by spam and pornographic phrases due to inadequate data cleaning. Tianle Cai, a Ph.D. student at Princeton University, identified that most of the longest Chinese tokens were irrelevant and inappropriate, primarily originating from spam and pornography websites. The polluted tokens could lead to hallucinations, poor performance, and potential misuse, undermining the chatbot's reliability and safety measures.",
      "deployers": [
        "openai",
        "gpt-4o"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "chinese-speaking-users-of-chatgpt",
        "researchers",
        "openai",
        "openai-users"
      ],
      "reports": [
        3950
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(666f4684784457a8ef9856ed)",
      "incident_id": 730,
      "date": "2024-04-01",
      "title": "AI Deepfakes for Voter Outreach Flood Indian Elections",
      "description": "During the 2024 Indian elections, politicians used AI-generated deepfakes to reach voters, who might be unaware they're interacting with digital clones. Providers like Divyendra Singh Jadoun of Polymath Synthetic Media Solutions created deepfakes for personalized messages. This practice, used by various political parties, is not truthful, as voters may be misled by AI-generated content posing as genuine interactions with political figures.",
      "deployers": [
        "bharatiya-janata-party-(bjp)",
        "indian-national-congress-(inc)",
        "prem-singh-tamang",
        "y.-s.-jagan-mohan-reddy",
        "ram-chandra-choudhary"
      ],
      "developers": [
        "divyendra-singh-jadoun",
        "polymath-synthetic-media-solutions",
        "sagar-vishnoi",
        "itoconnect",
        "indiaspeaks-research-lab",
        "sumit-savara"
      ],
      "harmedParties": [
        "indian-voters",
        "general-public-misled-by-deepfake-content",
        "political-integrity-and-election-fairness",
        "democracy",
        "truth"
      ],
      "reports": [
        3951
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(666f6976784457a8effd396a)",
      "incident_id": 731,
      "date": "2023-12-01",
      "title": "Hallucinated Software Packages with Potential Malware Downloaded Thousands of Times by Developers",
      "description": "Generative AI hallucinated non-existent software packages, which were then created and uploaded (as an experiment) by security researcher Bar Lanyado. One such package, huggingface-cli, was downloaded over 15,000 times, including by large companies like Alibaba. Regardless of the framing of it as an experiment, this incident is an example of harm caused by AI-generated hallucinations in coding, as the fake packages were still distributed widely and with potential malware.",
      "deployers": [
        "developers-using-ai-generated-suggestions",
        "bar-lanyado"
      ],
      "developers": [
        "bar-lanyado"
      ],
      "harmedParties": [
        "developers-and-businesses-incorporating-ai-suggested-packages",
        "alibaba"
      ],
      "reports": [
        3952
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6670b2b85919e475639badd5)",
      "incident_id": 732,
      "date": "2024-02-12",
      "title": "Whisper Speech-to-Text AI Reportedly Found to Create Violent Hallucinations",
      "description": "Researchers at Cornell reportedly found that OpenAI's Whisper, a speech-to-text system, can hallucinate violent language and fabricated details, especially with long pauses in speech, such as from those with speech impairments. Analyzing 13,000 clips, they determined 1% contained harmful hallucinations. These errors pose risks in hiring, legal trials, and medical documentation. The study suggests improving model training to reduce these hallucinations for diverse speaking patterns.",
      "deployers": [
        "openai",
        "whisper",
        "companies-using-whisper",
        "organizations-integrating-whisper-into-customer-service-systems"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "individuals-with-speech-impairments",
        "users-whose-speech-is-misinterpreted-by-whisper",
        "professionals-relying-on-accurate-transcriptions",
        "general-public"
      ],
      "reports": [
        3953
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6670bc6a6b53bf2ce0181344)",
      "incident_id": 733,
      "date": "2024-06-09",
      "title": "Auto Insurers Allegedly Are Surreptitiously Collecting and Scoring Driver Data",
      "description": "The insurance industry allegedly uses AI and telematics to score drivers based on behaviors tracked by automakers and apps like Life360. Data, often collected without clear consent, may affect insurance rates and raises privacy concerns. Consumers are largely unaware of this surveillance, leading to potential misuse and discrimination based on driving habits or socioeconomic factors.",
      "deployers": [
        "usaa",
        "toyota",
        "progressive",
        "myradar",
        "life360",
        "general-motors",
        "geico",
        "csaa",
        "connected-analytic-services",
        "arity",
        "allstate"
      ],
      "developers": [
        "myradar",
        "life360",
        "connected-analytic-services",
        "arity"
      ],
      "harmedParties": [
        "privacy-conscious-individuals",
        "people-with-poor-credit-scores",
        "lower-income-workers",
        "drivers-unaware-of-data-collection",
        "consumers-affected-by-insurance-rates",
        "life360-users",
        "myradar-users"
      ],
      "reports": [
        3954,
        3957
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6672033c8b59299a66395f45)",
      "incident_id": 734,
      "date": "2024-06-18",
      "title": "Leading AI Models Reportedly Found to Mimic Russian Disinformation in 33% of Cases and to Cite Fake Moscow News Sites",
      "description": "An audit by NewsGuard revealed that leading chatbots, including ChatGPT-4, You.com’s Smart Assistant, and others, repeated Russian disinformation narratives in one-third of their responses. These narratives originated from a network of fake news sites created by John Mark Dougan (Incident 701). The audit tested 570 prompts across 10 AI chatbots, showing that AI remains a tool for spreading disinformation despite efforts to prevent misuse.",
      "deployers": [
        "you.com",
        "xai",
        "perplexity",
        "openai",
        "mistral",
        "microsoft",
        "meta",
        "john-mark-dougan",
        "inflection",
        "google",
        "anthropic"
      ],
      "developers": [
        "you.com",
        "xai",
        "perplexity",
        "openai",
        "mistral",
        "microsoft",
        "meta",
        "inflection",
        "google",
        "anthropic"
      ],
      "harmedParties": [
        "western-democracies",
        "volodymyr-zelenskyy",
        "ukraine",
        "secret-service",
        "researchers",
        "media-consumers",
        "general-public",
        "electoral-integrity",
        "ai-companies-facing-reputational-damage"
      ],
      "reports": [
        3956,
        4884,
        4885,
        4886
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(667c5b34e2e9c6cf8b14ddd9)",
      "incident_id": 735,
      "date": "2024-06-22",
      "title": "AI Enhances Scammer Tactics Making Detection Harder",
      "description": "Scammers are using AI tools to create convincing fraud schemes, making them harder to detect. AI-generated messages and fake identities bypass traditional scam indicators. Incidents include impersonation of senior executives and job scams, leading to financial losses and identity theft. Banks are adopting AI to combat these scams, but the sophistication of AI-driven fraud continues to pose significant challenges.",
      "deployers": [
        "unknown-scammers"
      ],
      "developers": [
        "ai-tool-creators",
        "openai"
      ],
      "harmedParties": [
        "bank-customers"
      ],
      "reports": [
        3960
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(667c63f124dd7b9ccf54e4c9)",
      "incident_id": 736,
      "date": "2023-12-01",
      "title": "Underground Market for LLMs Powers Malware and Phishing Scams",
      "description": "A study by Indiana University researchers uncovered widespread misuse of large language models (LLMs) for cybercrime. Cybercriminals, according to that study, use LLMs like OpenAI's GPT-3.5 and GPT-4 to create malware, phishing scams, and scam websites. These models are available on underground markets, often bypassing safety checks through jailbreaking. Named malicious LLMs are BadGPT, XXXGPT, Evil-GPT, WormGPT, FraudGPT, BLACKHATGPT, EscapeGPT, DarkGPT, and WolfGPT.",
      "deployers": [
        "cybercriminals",
        "badgpt",
        "xxxgpt",
        "evil-gpt",
        "wormgpt",
        "fraudgpt",
        "blackhatgpt",
        "escapegpt",
        "darkgpt",
        "wolfgpt"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "internet-users",
        "organizations",
        "individuals-targeted-by-malware"
      ],
      "reports": [
        3961,
        4021
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(667dd0811e7328ab0c6211b7)",
      "incident_id": 737,
      "date": "2024-04-16",
      "title": "Amandine Le Pen Deepfake Account Misleads Thousands on TikTok",
      "description": "A TikTok account, Amandine Le Pen, created using AI deepfake technology, impersonated a fictional niece of Marine Le Pen, amassing over 30,000 followers. The account spread pro-RN messages and solicited donations, misleading users and exploiting political influence. Visual inconsistencies revealed the deepfake, raising concerns about AI misuse for political manipulation, identity theft, and violation of personal rights, especially with similar accounts proliferating, such as Lena Maréchal Lepen.",
      "deployers": [
        "unknown-tiktok-user"
      ],
      "developers": [
        "unknown-deepfake-creators"
      ],
      "harmedParties": [
        "le-pen-family",
        "french-general-public"
      ],
      "reports": [
        3962,
        3981
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(667dd53418a99ea54f3687f0)",
      "incident_id": 738,
      "date": "2024-06-23",
      "title": "Department for Work and Pensions (DWP) Algorithm Wrongly Flags 200,000 for Housing Benefit Fraud",
      "description": "A Department for Work and Pensions (DWP) algorithm wrongly flagged over 200,000 UK housing benefit claims as high risk, resulting in unnecessary investigations. Two-thirds of these flagged claims were legitimate, causing wasted public funds and stress for claimants. Despite initial success in a pilot, the algorithm's real-world performance fell short. This incident highlights the risks of overreliance on automated systems in welfare administration.",
      "deployers": [
        "department-for-work-and-pensions-(dwp)"
      ],
      "developers": [
        "department-for-work-and-pensions-(dwp)"
      ],
      "harmedParties": [
        "uk-general-public",
        "uk-housing-benefit-claimants"
      ],
      "reports": [
        3963,
        3969,
        3971,
        3972,
        3976
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6684230a3941bfa93574ad9c)",
      "incident_id": 739,
      "date": "2024-06-27",
      "title": "Scammers Use Deepfake of Hong Kong Entertainer Andy Lau to Steal NT$2.64 Million from Fan",
      "description": "Scammers defrauded a woman in New Taipei City of NT$2.64 million (US$81,116) by impersonating Hong Kong entertainer Andy Lau using a deepfake. The scam convinced the victim, a long-time fan, through a video call that Lau needed funds for a visit to Taiwan. The victim wired the money, but her family suspected a scam and involved the police. An alleged scammer was arrested after attempting to collect a staged cash payment. The AI deception caused significant financial harm to the victim.",
      "deployers": [
        "unknown-scammers",
        "unknown-deepfake-creator"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "lin-()"
      ],
      "reports": [
        3966,
        3967
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66987121b71ae75a5bd7aa98)",
      "incident_id": 740,
      "date": "2024-07-10",
      "title": "Department for Work and Pensions (DWP) AI Systems Allegedly Discriminate Against Single Mothers",
      "description": "Researchers have argued that the Department for Work and Pensions' Universal Credit system disproportionately impacts single mothers. Automated processes in the system, designed to determine eligibility and detect fraud, are reported to have introduced biases, leading to financial instability and hardship. The algorithms allegedly miscalculate earnings and delay childcare reimbursements, in turn exacerbating income volatility and debt among single mothers.",
      "deployers": [
        "department-for-work-and-pensions-(dwp)"
      ],
      "developers": [
        "department-for-work-and-pensions-(dwp)"
      ],
      "harmedParties": [
        "single-mothers",
        "british-single-mothers"
      ],
      "reports": [
        3970
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66987632b71ae75a5b70cfb8)",
      "incident_id": 741,
      "date": "2023-10-02",
      "title": "Robin Williams's Voice Deepfaked Without Consent",
      "description": "Zelda Williams, the daughter of the late Robin Williams, condemned the misuse of her father's voice in AI-generated productions, having cited some instances where his voice had been deepfaked, along with the potential for further misuse, as such instances do not involve consent.",
      "deployers": [
        "unknown-deepfake-creators"
      ],
      "developers": [
        "unknown-deepfake-creators"
      ],
      "harmedParties": [
        "zelda-williams",
        "robin-williams",
        "family-of-robin-williams"
      ],
      "reports": [
        3973
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66987916d14e3c3e2dc83dd7)",
      "incident_id": 742,
      "date": "2024-07-13",
      "title": "Grok AI Model Reportedly Fails to Produce Reliable News in Wake of Trump Assassination Attempt",
      "description": "xAI's model Grok, intended to automate news delivery on the X platform, is reported to have struggled to provide accurate information during the attempted assassination of former President Donald Trump. Grok apparently issued incorrect headlines, including false reports about Vice President Kamala Harris being shot and misidentifying the alleged shooter. These errors show the pitfalls of relying on AI for real-time news aggregation, as it allegedly amplified unverified claims and failed to recognize sarcasm, undermining its reliability.",
      "deployers": [
        "x-(twitter)",
        "elon-musk"
      ],
      "developers": [
        "xai"
      ],
      "harmedParties": [
        "kamala-harris",
        "journalism",
        "general-public",
        "donald-trump"
      ],
      "reports": [
        3974
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66987ad36787b48acbb33020)",
      "incident_id": 743,
      "date": "2024-07-16",
      "title": "Gemini AI Allegedly Reads Google Drive Files Without Explicit User Consent",
      "description": "Kevin Bankston, a privacy activist, claims that Google's Gemini AI scans private Google Drive PDFs without explicit user consent. Bankston reports that after using Gemini on one document, the AI continues to access similar files automatically. Google disputes these claims, stating that Gemini requires proactive user activation and operates within privacy-preserving settings.",
      "deployers": [
        "google",
        "gemini"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "kevin-bankston",
        "google-users",
        "google-drive-users"
      ],
      "reports": [
        3975
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(669880a4aa8655ced52e9467)",
      "incident_id": 744,
      "date": "2024-06-25",
      "title": "AI Work Assistants Require More Effort Than Expected, CIOs Say",
      "description": "AI work assistants, such as Copilot for Microsoft 365 and Gemini for Google Workspace, are proving to be more labor-intensive than anticipated for enterprises. CIOs report that these AI tools struggle with outdated or inaccurate data, leading to incorrect outputs. Companies are finding they must invest heavily in data management to ensure reliability. This added effort has led to delays in deployment and frustration, as businesses work to maximize the potential of these expensive AI tools.",
      "deployers": [
        "cios",
        "enterprise-teams",
        "companies-in-general"
      ],
      "developers": [
        "microsoft",
        "google"
      ],
      "harmedParties": [
        "cios",
        "enterprise-teams",
        "companies-in-general",
        "microsoft-copilot-users"
      ],
      "reports": [
        3977
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66988363aa8655ced5859f62)",
      "incident_id": 745,
      "date": "2024-07-02",
      "title": "Figma Disables AI Feature After Accusations of Copying Apple’s Weather App",
      "description": "Figma has temporarily disabled its AI design feature, Make Design, after accusations of copying Apple’s Weather app. Andy Allen of NotBoring Software highlighted the issue, prompting Figma CEO Dylan Field to deny claims of training the AI on specific app designs. However, Field acknowledged flaws in the QA process and promised to suspend the feature until it meets quality standards. The incident has implications for designers.",
      "deployers": [
        "figma"
      ],
      "developers": [
        "figma"
      ],
      "harmedParties": [
        "apple",
        "designers-and-developers-using-figma's-ai-tool",
        "figma-users"
      ],
      "reports": [
        3978,
        4103
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(669893baaa8655ced5a52ce3)",
      "incident_id": 746,
      "date": "2024-05-15",
      "title": "Class Action Lawsuit Over Alleged Defects in Volkswagen's AI-Driven AEB Systems",
      "description": "A class action lawsuit involving Volkswagen Group of America addresses alleged defects in the Automated Emergency Braking (AEB) systems of certain vehicles. The lawsuit claims these AI-driven systems failed to function properly, posing safety risks. Volkswagen denies the claims but has agreed to a settlement. Affected users can look up their vehicle's eligibility and file claims for reimbursement. The case brings into question the level of reliability of AI in critical automotive applications.",
      "deployers": [
        "volkswagen-group-of-america"
      ],
      "developers": [
        "volkswagen-group-of-america"
      ],
      "harmedParties": [
        "volkswagen-drivers",
        "potential-passengers-and-road-users-at-risk-due-to-malfunctioning-aeb-systems"
      ],
      "reports": [
        3979,
        3982
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6699115c6787b48acb373c53)",
      "incident_id": 747,
      "date": "2024-07-18",
      "title": "Fatalities Reportedly Occur Despite VioGén Algorithm's Low or Negligible Risk Scores",
      "description": "The VioGén algorithm was designed to help Spanish police assess and prioritize the risk of repeat domestic violence incidents. However, its low-risk assessment of Lobna Hemid reportedly led to inadequate protection; her husband murdered her. Since 2007, 247 women have been killed after being assessed by VioGén. A review of 98 homicides found that 55 of the slain women were scored as negligible or low risk. ",
      "deployers": [
        "spanish-law-enforcement-agencies",
        "spanish-interior-ministry"
      ],
      "developers": [
        "viogen-algorithm-development-team",
        "spanish-law-enforcement-agencies",
        "spanish-interior-ministry"
      ],
      "harmedParties": [
        "women-in-spain",
        "stefany-gonzalez-escarraman",
        "spanish-general-public",
        "maria",
        "luz",
        "lobna-hemid",
        "eva-jaular",
        "247-women-in-spain-(unnamed)"
      ],
      "reports": [
        3980
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(669ed7a8680c2ccdd3095b1c)",
      "incident_id": 748,
      "date": "2024-06-19",
      "title": "Erroneous Declined Transaction Notification by PayPal AI Assistant",
      "description": "On July 13th, 2024, a user reported an incident involving PayPal's generative AI chatbot. The chatbot allegedly incorrectly informed the user of a declined transaction that never occurred, causing confusion and prompting a call to customer service for clarification. This false alert suggests a flaw in the AI system's reliability. The incident created unnecessary labor for both the user and PayPal's human support, demonstrating the potential harm of deploying generative AI without thorough testing and error handling mechanisms.",
      "deployers": [
        "paypal"
      ],
      "developers": [
        "paypal"
      ],
      "harmedParties": [
        "kiri-wagstaff",
        "paypal-customer-service-representatives",
        "paypal-customers"
      ],
      "reports": [
        3983
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(669edf3ac2511dd4839aa72e)",
      "incident_id": 749,
      "date": "2024-05-31",
      "title": "Hoodline Accused of Misleadingly Attributing AI-Generated Articles to Human Authors",
      "description": "In 2023, the news site Hoodline is reported to have begun publishing AI-generated articles with fake bylines, headshots, and biographies, allegedly misleading readers into believing they were authored by real journalists. This practice diminishes public trust and exemplifies the potential dangers of AI in journalism. Despite a disclaimer, the use of AI was not transparent.",
      "deployers": [
        "hoodline"
      ],
      "developers": [
        "hoodline"
      ],
      "harmedParties": [
        "hoodline-readers",
        "journalism",
        "general-public"
      ],
      "reports": [
        3984
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(669ee8f7578585398dcf551f)",
      "incident_id": 750,
      "date": "2024-07-22",
      "title": "AI Chatbots Reportedly Inaccurately Conveyed Real-Time Political News",
      "description": "Over a week of back-to-back, significant breaking political news stories, including the Trump rally shooting and Biden’s campaign withdrawal, AI chatbots reportedly failed to provide accurate real-time updates. Most chatbots gave incorrect or outdated information, demonstrating their current limitations in handling fast-paced news. These incidents suggest the continuing need for improved AI capabilities and caution in their deployment for real-time news dissemination.",
      "deployers": [
        "perplexity",
        "openai",
        "meta",
        "google"
      ],
      "developers": [
        "perplexity",
        "openai",
        "meta",
        "google"
      ],
      "harmedParties": [
        "journalism",
        "general-public",
        "chatbot-users"
      ],
      "reports": [
        3985
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66a47930669b0f5e888db567)",
      "incident_id": 751,
      "date": "2024-07-25",
      "title": "SearchGPT Reportedly Misleads Users with Incorrect Festival Dates in Demo",
      "description": "OpenAI’s prototype AI tool, SearchGPT, provided incorrect dates for An Appalachian Summer Festival in Boone, North Carolina during a demonstration video. The AI listed dates that were incorrect, potentially misleading users planning to attend the event, but also harming the reputation of OpenAI as the incident occurred during a high-profile event.",
      "deployers": [
        "openai"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "an-appalachian-summer-festival-attendees",
        "openai"
      ],
      "reports": [
        3986,
        4038
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66a47b0d19c6ab72a2a90a4a)",
      "incident_id": 752,
      "date": "2024-07-07",
      "title": "AI-Generated Obituaries Are Reportedly Intensifying Grief for Bereaved Families",
      "description": "AI-generated obituaries on various websites are reported to have compounded the grief of bereaved families by spreading incorrect and unauthorized information about their loved ones. These obituaries, produced without the families' knowledge, often contain errors and appear on ad-filled sites, exacerbating the emotional distress of the grieving process.",
      "deployers": [
        "obitsupdate",
        "bnn",
        "the-thaiger",
        "fresherslive"
      ],
      "developers": [
        "unknown"
      ],
      "harmedParties": [
        "bridget-todd",
        "bridget-todd's-family",
        "chris-mohney",
        "chris-mohney's-family",
        "bereaved-families"
      ],
      "reports": [
        3987
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66a4808b516d9dba18b69565)",
      "incident_id": 753,
      "date": "2024-06-06",
      "title": "BNN Breaking's AI-Driven Errors Reportedly Damage Reputations and Spread Misinformation",
      "description": "BNN Breaking, an AI-driven news site, published a false story about Irish DJ Dave Fanning, damaging his reputation. The site used AI to generate error-filled content, leading to numerous complaints and a defamation lawsuit against BNN and Microsoft. The site has since gone dormant.",
      "deployers": [
        "bnn-breaking"
      ],
      "developers": [
        "epiphany-ai",
        "gurbaksh-chahal"
      ],
      "harmedParties": [
        "dave-fanning",
        "bnn-breaking-readers",
        "journalism",
        "general-public"
      ],
      "reports": [
        3988
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66a4830419c6ab72a2da65ca)",
      "incident_id": 754,
      "date": "2024-07-01",
      "title": "British Female Politicians Victimized by Deepfake Pornography",
      "description": "British female politicians, including Angela Rayner, Gillian Keegan, Penny Mordaunt, Priti Patel, Stella Creasy, and Dehenna Davison, have been targeted by nonconsensual AI-generated deepfake pornography. The images, some online for years, have caused significant distress and led to police involvement.",
      "deployers": [
        "unknown-deepfake-creators"
      ],
      "developers": [
        "unknown-deepfake-creators"
      ],
      "harmedParties": [
        "stella-creasy",
        "priti-patel",
        "penny-mordaunt",
        "gillian-keegan",
        "dehenna-davison",
        "angela-rayner"
      ],
      "reports": [
        3989
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66a4e598516d9dba1894e46a)",
      "incident_id": 755,
      "date": "2024-07-03",
      "title": "Deepfake Targets Olena Zelenska in Russian Disinformation Campaign",
      "description": "A deepfake video falsely suggesting that Olena Zelenska, wife of Ukrainian President Volodymyr Zelenskyy, purchased a luxury car, circulated widely online. The video is reportedly part of a Russian-linked disinformation campaign aimed at undermining Ukraine and its supporters. ",
      "deployers": [
        "verite-cachee-france",
        "russian-linked-disinformation-network",
        "pro-russian-influencers"
      ],
      "developers": [
        "unknown-deepfake-creators"
      ],
      "harmedParties": [
        "olena-zelenska",
        "volodymyr-zelenskyy",
        "government-of-ukraine",
        "general-public-of-ukraine",
        "general-public-of-the-european-union",
        "general-public-of-the-united-states",
        "bugatti"
      ],
      "reports": [
        3990,
        4014,
        4881,
        4897,
        4899
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66a8d8731faff7398987f31d)",
      "incident_id": 756,
      "date": "2024-07-26",
      "title": "Deepfake of Kamala Harris Saying Damaging Comments Circulates on X and Is Amplified by Elon Musk",
      "description": "The X user @MrReaganUSA uploaded a deepfake of Kamala Harris saying damaging comments about Joe Biden and her own qualifications for the presidency, originally marking it as a parody. The post was shared and amplified eight hours later via Elon Musk's account without the disclaimer.",
      "deployers": [
        "x-(twitter)",
        "elon-musk",
        "@mrreaganusa"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "truth",
        "kamala-harris",
        "joe-biden",
        "general-public",
        "american-voters"
      ],
      "reports": [
        3991,
        3992,
        4145
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66a8fd1cc9d732d92a5948f1)",
      "incident_id": 757,
      "date": "2024-07-01",
      "title": "OpenAI's ChatGPT Mac App Stored User Data in Unencrypted Text Files",
      "description": "OpenAI's ChatGPT macOS app stored user conversations in plain text. If accessed by a malicious actor, these conversations could have been easily read. The critical security flaw was demonstrated by a third party and ultimately resolved after OpenAI released an update to encrypt the stored data.",
      "deployers": [
        "openai"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "chatgpt-macos-users"
      ],
      "reports": [
        3993
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66aa464669e3d55e080b0d0f)",
      "incident_id": 758,
      "date": "2023-09-11",
      "title": "Teen's Overdose Reportedly Linked to Meta's AI Systems Failing to Block Ads for Illegal Drugs",
      "description": "Meta's AI moderation systems reportedly failed to block ads for illegal drugs on Facebook and Instagram, allowing users to access dangerous substances. The system's failure is linked to the overdose death of Elijah Ott, a 15-year-old boy who sought drugs through Instagram.",
      "deployers": [
        "meta-platforms",
        "instagram",
        "facebook"
      ],
      "developers": [
        "meta-platforms"
      ],
      "harmedParties": [
        "instagram-users",
        "facebook-users",
        "elijah-ott"
      ],
      "reports": [
        3994
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66aa8beff4d723304c80783f)",
      "incident_id": 759,
      "date": "2021-02-05",
      "title": "AI-Generated Deepfakes Reportedly Derailed Political Career of Florida Official",
      "description": "Sabrina Javellana, a Florida politician, was reportedly targeted with AI-generated deepfake pornography in February 2021, which was spread online, leading to severe emotional distress and her eventual withdrawal from public life. ",
      "deployers": [
        "unknown-deepfake-creators"
      ],
      "developers": [
        "unknown-deepfake-technology-developers"
      ],
      "harmedParties": [
        "sabrina-javellana"
      ],
      "reports": [
        3995
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66c132ad70881d282a189fc5)",
      "incident_id": 760,
      "date": "2024-07-21",
      "title": "False Election Data on Kamala Harris Reportedly Circulated via Grok AI Chatbot",
      "description": "After President Joe Biden stepped aside as a presidential candidate on July 21, 2024, the AI chatbot Grok on X reportedly falsely informed users that Vice President Kamala Harris missed the ballot deadline in nine states. This misinformation, which spread widely on social media, prompted secretaries of state from five U.S. states to urge Elon Musk to address the problem.",
      "deployers": [
        "xai",
        "x-(twitter)"
      ],
      "developers": [
        "xai"
      ],
      "harmedParties": [
        "kamala-harris",
        "electoral-integrity",
        "democracy",
        "american-electorate"
      ],
      "reports": [
        3997,
        4080
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66c1386a54f6f3b1e53c3bef)",
      "incident_id": 761,
      "date": "2024-08-08",
      "title": "TikTok AI System Used to Amplify Election Disinformation by Foreign Networks",
      "description": "AI-generated misinformation on TikTok, driven by foreign networks, has flooded the platform with false narratives about the 2024 U.S. presidential election. Thousands of videos spreading political lies were identified, potentially influencing millions of users. Despite TikTok’s efforts to remove these accounts, the AI-driven disinformation campaign continues to challenge the integrity of the election.",
      "deployers": [
        "unknown-tiktok-users-from-china",
        "unknown-tiktok-users-from-iran",
        "unknown-tiktok-users-from-nigeria",
        "unknown-tiktok-users-from-vietnam"
      ],
      "developers": [
        "tiktok"
      ],
      "harmedParties": [
        "american-electorate",
        "electoral-integrity",
        "democracy",
        "general-public"
      ],
      "reports": [
        3998
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66c13f428c4f9dd48674f6f4)",
      "incident_id": 762,
      "date": "2024-08-14",
      "title": "Grok AI Reportedly Generates Offensive and Violent Images Without Proper Safeguards",
      "description": "Elon Musk’s Grok AI, launched on X, generated offensive and violent images without adequate safety controls. The AI produced deepfakes of public figures like Taylor Swift, Kamala Harris, and Alexandria Ocasio-Cortez, as well as copyrighted characters such as Mickey Mouse in inappropriate scenarios. Despite claiming adherence to certain content guidelines, Grok's outputs included politically charged and explicit imagery",
      "deployers": [
        "xai"
      ],
      "developers": [
        "x-(twitter)",
        "xai"
      ],
      "harmedParties": [
        "taylor-swift",
        "nintendo",
        "kamala-harris",
        "joe-biden",
        "donald-trump",
        "disney",
        "alexandria-ocasio-cortez"
      ],
      "reports": [
        3999,
        4025,
        4026
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66c14307c121293478c8ea70)",
      "incident_id": 763,
      "date": "2024-08-13",
      "title": "Grok AI Chatbot Reportedly Spreads Unfounded Rumors About Trump’s Dentures",
      "description": "Grok, X’s AI-powered chatbot, reportedly spread unsubstantiated claims about former President Trump’s alleged dentures during his interview with Elon Musk. The AI-generated summary is alleged to have falsely stated that Trump’s speech issues were due to missing dentures, despite no evidence. The post was quickly removed, but the incident is an example of concerns over Grok's tendency to amplify misinformation.",
      "deployers": [
        "xai"
      ],
      "developers": [
        "xai"
      ],
      "harmedParties": [
        "donald-trump",
        "elon-musk",
        "x-(twitter)-users",
        "general-public"
      ],
      "reports": [
        4000
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66c20a17c121293478147ebd)",
      "incident_id": 764,
      "date": "2024-06-26",
      "title": "Cody Enterprise Reporter Resigns After Admitting to AI-Generated Fake Quotes",
      "description": "A reporter at the Cody Enterprise used AI to generate fake quotes and stories, including fabricating statements from Wyoming’s governor and other officials. The misuse of AI was uncovered when another journalist noticed robotic phrases and false information in the articles. The reporter resigned, and the newspaper is now implementing policies to prevent future incidents.",
      "deployers": [
        "aaron-pelczar"
      ],
      "developers": [
        "unnamed-ai-chatbot"
      ],
      "harmedParties": [
        "mark-gordon",
        "wyoming-officials",
        "cody-enterprise",
        "cody-enterprise-readers",
        "journalism"
      ],
      "reports": [
        4001,
        4007,
        4008,
        4009
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66c377efcbe4995ffc3b256c)",
      "incident_id": 765,
      "date": "2024-03-14",
      "title": "22 Students at Richmond-Burton Community High School in Illinois Targeted by Deepfake Nudes",
      "description": "22 students at Richmond-Burton Community High School in Illinois were targeted in the creation of deepfake nudes. One of the students, Stevie Hyder, was targeted by classmates who used deepfake technology to alter her April 2023 prom picture into nude pictures, which were then circulated on social media. Two unnamed minors were arrested in late April 2024.",
      "deployers": [
        "unnamed-deepfake-creators"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "stevie-hyder",
        "richmond-burton-community-high-school"
      ],
      "reports": [
        4003,
        4004,
        4011,
        4012,
        4013
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66c3a4f6ff4505eb4f8f370c)",
      "incident_id": 766,
      "date": "2024-08-18",
      "title": "Trump Shares AI-Generated Images Falsely Suggesting Taylor Swift Endorsement",
      "description": "Donald Trump shared AI-generated images on social media that falsely depicted Taylor Swift endorsing him for the upcoming election. The images, which included Swift dressed as Uncle Sam and fans wearing “Swifties for Trump” shirts, were shared despite being labeled as satire. ",
      "deployers": [
        "donald-trump"
      ],
      "developers": [
        "unknown-deepfake-creator"
      ],
      "harmedParties": [
        "taylor-swift",
        "swifties",
        "electoral-integrity",
        "democracy",
        "general-public"
      ],
      "reports": [
        4005,
        4015
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66c3b11ba7feb77170e84cde)",
      "incident_id": 767,
      "date": "2024-08-18",
      "title": "AI Image of Kamala Harris at DNC with Communist Flags Circulated by Trump",
      "description": "Donald Trump shared an AI-generated image on social media that falsely depicted Kamala Harris speaking at a DNC event surrounded by communist imagery including the hammer and sickle of the Soviet Union. The image was intended to undermine Harris ahead of the Democratic National Convention and to suggest that her views are aligned with communism.",
      "deployers": [
        "donald-trump"
      ],
      "developers": [
        "unknown-image-generator"
      ],
      "harmedParties": [
        "kamala-harris",
        "democratic-national-committee",
        "electoral-integrity",
        "democracy"
      ],
      "reports": [
        4006,
        4030
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66c739ef4e14045257273efa)",
      "incident_id": 768,
      "date": "2023-03-11",
      "title": "ChatGPT Implicated in Samsung Data Leak of Source Code and Meeting Notes",
      "description": "Samsung engineers are reported to have inadvertently leaked sensitive company data sometime in March 2023, including source code and internal meeting notes, by using ChatGPT to assist with tasks. The AI retained the inputted data, leading to a breach of confidentiality.",
      "deployers": [
        "samsung-engineers"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "samsung"
      ],
      "reports": [
        4010
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66ca6694dd64075d50027af5)",
      "incident_id": 769,
      "date": "2018-04-20",
      "title": "Investigative Journalist Rana Ayyub Targeted by AI-Generated Deepfake Pornography",
      "description": "Investigative journalist Rana Ayyub was targeted by a deepfake porn campaign, where AI-generated explicit content falsely depicted her in a pornographic video. This was part of a broader effort to discredit and silence her, which included a doxxing attack that exposed her personal information that resulted in severe harassment and emotional distress.",
      "deployers": [
        "unknown-deepfake-creators"
      ],
      "developers": [
        "unknown-deepfake-technology-developers"
      ],
      "harmedParties": [
        "rana-ayyub"
      ],
      "reports": [
        4017,
        4024
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66ca70475936683035a792af)",
      "incident_id": 770,
      "date": "2024-08-16",
      "title": "Microsoft Copilot Falsely Accuses Journalist Martin Bernklau of Crimes",
      "description": "Microsoft's Copilot is reported to have falsely accused veteran court reporter Martin Bernklau of committing serious crimes, including child abuse and fraud. The tool is described as having generated defamatory content that not only accused Bernklau of multiple crimes he covered as a journalist but also provided his personal contact details. Attempts by Microsoft to remove the false entries were only temporarily successful, as the defamatory information reportedly reappeared.",
      "deployers": [
        "microsoft",
        "microsoft-copilot"
      ],
      "developers": [
        "microsoft"
      ],
      "harmedParties": [
        "martin-bernklau"
      ],
      "reports": [
        4018,
        4027,
        4028
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66ce44f8577ea4b23036fd8a)",
      "incident_id": 771,
      "date": "2020-02-06",
      "title": "Noelle Martin Deepfaked Without Consent in AI-Generated Pornography",
      "description": "In 2017, Noelle Martin discovered explicit deepfake videos online that used AI technology to superimpose her face onto pornographic scenes. This incident was a continuation of the abuse she had experienced since at least 2012, when she first found doctored still images of herself in similar contexts. Despite the initial lack of legal protections, her advocacy efforts were instrumental in making image-based abuse a criminal offense in Australia.",
      "deployers": [
        "unknown-deepfake-creators"
      ],
      "developers": [
        "stanford-university",
        "max-planck-institute",
        "university-of-erlangen-nuremberg",
        "face2face",
        "faceapp",
        "zao"
      ],
      "harmedParties": [
        "noelle-martin"
      ],
      "reports": [
        4019
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66ce547dc82358439981c243)",
      "incident_id": 772,
      "date": "2020-06-08",
      "title": "Kristen Bell Deepfaked in Non-Consensual AI-Generated Pornography",
      "description": "The actor Kristen Bell discovered that her likeness was exploited by creators of deepfake pornography, who shared their non-consensual sexual depictions of her on the Internet.",
      "deployers": [
        "unknown-deepfake-creators"
      ],
      "developers": [
        "unknown-deepfake-technology-developers"
      ],
      "harmedParties": [
        "kristen-bell"
      ],
      "reports": [
        4020,
        4085
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66d3759100018f8ed53eca43)",
      "incident_id": 773,
      "date": "2024-08-20",
      "title": "Chatbot in Workplace Training at Bunbury Prison Reveals Real Names in Sexual Harassment Case",
      "description": "During workplace training at Bunbury Prison in Western Australia, a trainer used Microsoft's Copilot AI chatbot to generate case study scenarios. The chatbot produced a scenario that included the real name of a former employee involved in a sexual harassment case, revealing sensitive information.",
      "deployers": [
        "charlotte-ingham",
        "western-australia-department-of-justice"
      ],
      "developers": [
        "microsoft"
      ],
      "harmedParties": [
        "bronwyn-hendry",
        "western-australia-department-of-justice",
        "western-australia-department-of-justice-senior-staff-members"
      ],
      "reports": [
        4022
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66d65beb6f8041be5928e19a)",
      "incident_id": 774,
      "date": "2024-05-30",
      "title": "Covert AI Influence Operations Linked to Russia, China, Iran, and Israel, OpenAI Reveals",
      "description": "In a report released by OpenAI, the company described how its generative AI tools were misused by state actors and private companies in Russia, China, Iran, and Israel to conduct covert influence campaigns aimed at manipulating public opinion and geopolitical narratives.",
      "deployers": [
        "zeno-zeno",
        "spamouflage",
        "russian-government",
        "israeli-government",
        "iranian-government",
        "international-union-of-virtual-media",
        "doppelganger",
        "chinese-government"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "united-states",
        "ukraine",
        "social-media-users",
        "moldova",
        "lithuania",
        "latvia",
        "general-public",
        "estonia",
        "critics-of-the-chinese-government"
      ],
      "reports": [
        4029,
        4039
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66d73bfafae80086ec0f5f88)",
      "incident_id": 775,
      "date": "2024-09-02",
      "title": "Elon Musk Reportedly Shared an AI-Generated Image Depicting Kamala Harris Dressed as a Communist Ruler",
      "description": "Elon Musk reportedly shared an AI-generated image on X depicting Kamala Harris as a communist dictator in response to her post about Donald Trump's political intentions.",
      "deployers": [
        "xai",
        "x-(twitter)",
        "elon-musk"
      ],
      "developers": [
        "xai"
      ],
      "harmedParties": [
        "kamala-harris",
        "general-public"
      ],
      "reports": [
        4031
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66d74e7e4f768af3223c95e6)",
      "incident_id": 776,
      "date": "2024-08-21",
      "title": "Megalopolis Trailer Included Fake AI-Generated Quotes Attributed to Film Critics",
      "description": "Lionsgate pulled the trailer for Megalopolis after it was discovered to contain fake quotes from well-known film critics, generated by AI. The quotes falsely criticized Francis Ford Coppola's previous films. The incident was attributed to an error in vetting by marketing consultant Eddie Egan. Lionsgate has since parted ways with Egan and apologized to Coppola and the critics affected by the fabricated content.",
      "deployers": [
        "lionsgate",
        "eddie-egan"
      ],
      "developers": [
        "unknown-chatbot-developer"
      ],
      "harmedParties": [
        "francis-ford-coppola",
        "pauline-kael",
        "film-critics",
        "american-zoetrope",
        "lionsgate"
      ],
      "reports": [
        4032
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66d75b677ee95076d81c86ed)",
      "incident_id": 777,
      "date": "2024-08-28",
      "title": "South Korea Experiences a Surge of Explicit Deepfake Pornography",
      "description": "At the end of August 2024, South Korean authorities began investigating a significant surge in the creation and dissemination, often via Telegram, of explicit deepfake pornography created without consent from the stolen social media content of female classmates, teachers, and neighbors.",
      "deployers": [
        "unnamed-deepfake-creators"
      ],
      "developers": [
        "unnamed-deepfake-technology-developers"
      ],
      "harmedParties": [
        "south-korean-women"
      ],
      "reports": [
        4033,
        4034,
        4035,
        4036,
        4051,
        4052,
        4086
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66e5e244fc7d8e4decc8088f)",
      "incident_id": 778,
      "date": "2024-09-04",
      "title": "Amazon's Alexa Reportedly Shows Political Preference Error in Trump-Harris Presidential Race Queries",
      "description": "Amazon's Alexa was found to provide politically biased responses when asked about the 2024 presidential candidates. It refused to give reasons to vote for Donald Trump, citing neutrality, while offering detailed endorsements for Kamala Harris. Amazon labeled the discrepancy an error and reportedly corrected it.",
      "deployers": [
        "alexa-device-owners"
      ],
      "developers": [
        "amazon"
      ],
      "harmedParties": [
        "alexa-device-owners",
        "donald-trump-presidential-campaign",
        "donald-trump-supporters"
      ],
      "reports": [
        4040,
        4041
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66e5e53c22dfb91510a581b8)",
      "incident_id": 779,
      "date": "2024-09-04",
      "title": "Music Producer Arrested for Allegedly Using AI-Generated Songs in $10 Million Streaming Scam",
      "description": "Michael Smith was arrested for allegedly using AI-generated songs and fake streaming accounts to scam over $10 million in royalties from major music platforms. By creating hundreds of thousands of songs and employing bots to artificially inflate streams, Smith circumvented fraud detection systems. The scheme was exposed after suspicions arose regarding the rapid generation of music and streaming anomalies.",
      "deployers": [
        "michael-smith"
      ],
      "developers": [
        "unknown-ai-music-company"
      ],
      "harmedParties": [
        "spotify",
        "music-streaming-services",
        "apple-music",
        "amazon-music"
      ],
      "reports": [
        4042
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66e5e8ed22dfb91510a581bd)",
      "incident_id": 780,
      "date": "2024-08-23",
      "title": "Joint Base Elmendorf-Richardson Soldier Faces Allegations of Using AI to Generate Child Pornography",
      "description": "Seth Herrera, a U.S. Army soldier at Joint Base Elmendorf-Richardson (JBER), is accused of using artificial intelligence to generate pornography depicting minors with whom he was in contact. ",
      "deployers": [
        "unknown-ai-developers"
      ],
      "developers": [
        "seth-herrera"
      ],
      "harmedParties": [
        "children"
      ],
      "reports": [
        4044
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66e5ecd121c983fe2f2322b9)",
      "incident_id": 781,
      "date": "2024-09-03",
      "title": "Clearview AI Faces $33.7 Million Fine for Violating GDPR with Biometric Data Harvesting",
      "description": "Clearview AI was fined $33.7 million by the Dutch data protection authority for allegedly creating an illegal facial recognition database by scraping billions of images from the Internet without consent. The company used AI to convert these images into biometric data and sold the service to law enforcement. This act was in violation of privacy laws and the GDPR.",
      "deployers": [
        "clearview-ai"
      ],
      "developers": [
        "clearview-ai"
      ],
      "harmedParties": [
        "general-public"
      ],
      "reports": [
        4045,
        4987
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66e5f07c9fb71c732d69e4c8)",
      "incident_id": 782,
      "date": "2024-09-09",
      "title": "AI 'Nudify' Apps Used as Tools for Blackmail and Extortion",
      "description": "AI 'nudify' apps are being used to generate hyperrealistic non-consensual nude photos of individuals, which are then exploited for extortion and harassment. These apps use generative AI to remove clothing from images and create convincing fakes, often distributed on platforms like Telegram. Victims are threatened or shamed using these AI-generated images, with little recourse for removal or legal action.",
      "deployers": [
        "unknown-deepfake-creators",
        "extortionists"
      ],
      "developers": [
        "unknown-deepfake-creators"
      ],
      "harmedParties": [
        "women-in-india",
        "women",
        "general-public"
      ],
      "reports": [
        4046
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66e5f3e29fb71c732d69e4cd)",
      "incident_id": 783,
      "date": "2024-05-21",
      "title": "WiseTech Global CEO Richard White Reportedly Deepfaked in Multiple Attempts to Scam Staffers",
      "description": "WiseTech Global's CEO, Richard White, was targeted in multiple deepfake scam attempts where unknown actors used AI to create videos of him requesting money from staff members via WhatsApp. These repeated attempts were identified by the employees, who realized they were not speaking to the real CEO.",
      "deployers": [
        "unknown-deepfake-creators",
        "unknown-scammers"
      ],
      "developers": [
        "unknown-deepfake-creators"
      ],
      "harmedParties": [
        "wisetech-global",
        "richard-white"
      ],
      "reports": [
        4047
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66e622c292cb30375a7aae9d)",
      "incident_id": 784,
      "date": "2024-04-23",
      "title": "Child Predators Are Reportedly Generating Deepfake Nudes of Children to Extort Them",
      "description": "Internet Watch Foundation (IWF) has reported that it has found a manual on the dark web that encourages criminals to use nudifying AI tools to depict children naked in order to extort victims into providing graphic content.",
      "deployers": [
        "unknown-dark-web-users",
        "unknown-deepfake-creators"
      ],
      "developers": [
        "unknown-ai-developers",
        "unknown-deepfake-creators"
      ],
      "harmedParties": [
        "children"
      ],
      "reports": [
        4048
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66e62b4dd319a5760dd69b8d)",
      "incident_id": 785,
      "date": "2024-09-08",
      "title": "ESPN's AI Coverage Overlooks Alex Morgan in Her Final Match Recap",
      "description": "ESPN's AI-generated recap of Alex Morgan’s final professional soccer match failed to mention her significant retirement moment, instead providing a standard rundown that missed the emotional context.",
      "deployers": [
        "espn",
        "espn-generative-ai-services"
      ],
      "developers": [
        "espn",
        "espn-generative-ai-services"
      ],
      "harmedParties": [
        "alex-morgan",
        "alex-morgan-fans",
        "national-women's-soccer-league-(nwsl)"
      ],
      "reports": [
        4049
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66e632fa12706f70a807defc)",
      "incident_id": 786,
      "date": "2022-09-07",
      "title": "Fraudsters Use Deepfake Video of Tim Cook to Promote Apple Crypto Scam on YouTube",
      "description": "Fraudsters repurposed an old interview with Apple CEO Tim Cook using AI or video editing to promote a fake crypto event on YouTube. The altered video was designed to mislead viewers into believing Tim Cook endorsed a new cryptocurrency scheme. The stream attracted tens of thousands of viewers, potentially exposing them to the scam before it was removed for violating YouTube’s terms of service.",
      "deployers": [
        "unknown-deepfake-creators",
        "scammers"
      ],
      "developers": [
        "unknown-deepfake-technology-developers"
      ],
      "harmedParties": [
        "tim-cook",
        "apple",
        "youtube-viewers",
        "cryptocurrency-investors",
        "general-public"
      ],
      "reports": [
        4053,
        4054
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66e636f6be5d1c4fee34157b)",
      "incident_id": 787,
      "date": "2024-03-01",
      "title": "Deepfake ID Sales Persist as OnlyFake Relaunches with New Fraud Tools",
      "description": "Researchers from Au10tix discovered the relaunch of OnlyFake, a site offering AI-generated fake IDs. Despite an earlier takedown, the site reemerged with disclaimers and new tools, including handwritten signature generation. These fakes are challenging biometric verification systems and are reportedly being used to perpetuate fraudulent activity.",
      "deployers": [
        "onlyfake"
      ],
      "developers": [
        "onlyfake"
      ],
      "harmedParties": [
        "biometric-security",
        "businesses-using-biometrics",
        "individuals-using-biometrics",
        "government-agencies-using-biometrics"
      ],
      "reports": [
        4055,
        4104
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66e63c2bbe5d1c4fee341580)",
      "incident_id": 788,
      "date": "2024-06-20",
      "title": "Instagram's Algorithm Reportedly Recommended Sexual Content to Teenagers' Accounts",
      "description": "Tests by The Wall Street Journal and a researcher reportedly revealed that Instagram's AI-driven Reels algorithm recommends sexually suggestive content to accounts listed as 13 years old. Despite Meta's commitment to restrict such content for minors, explicit videos were served within minutes of account creation, according to the findings.",
      "deployers": [
        "meta-platforms",
        "instagram"
      ],
      "developers": [
        "meta-platforms",
        "instagram"
      ],
      "harmedParties": [
        "minors",
        "children",
        "instagram-users",
        "general-public"
      ],
      "reports": [
        4056
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66e64a6aa8183da4568b8c99)",
      "incident_id": 789,
      "date": "2024-06-12",
      "title": "Independent News Sites Flagged as Spam by Facebook's AI Moderation System",
      "description": "Facebook's AI moderation system mistakenly flagged and removed legitimate news articles from independent local publishers as spam. This affected publishers worldwide, disrupting content distribution and impacting traffic. Despite attempts to appeal, many publishers received no response.",
      "deployers": [
        "meta",
        "facebook"
      ],
      "developers": [
        "meta",
        "facebook"
      ],
      "harmedParties": [
        "the-record-argus",
        "wlkp24.info",
        "top-fight",
        "noticias-maia",
        "city-magazine",
        "birkenhead-news",
        "bishop's-stortford-independent",
        "uk-defence-journal"
      ],
      "reports": [
        4060
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66e6c1260ee5f29eb79f87e0)",
      "incident_id": 790,
      "date": "2024-06-21",
      "title": "Unrestricted AI Avatar Tool Accidentally Released by TikTok Permits Recitation of Hitler Quotes and Other Harmful Speech",
      "description": "TikTok accidentally released an internal version of its AI digital avatar tool without safeguards, allowing users to generate videos where avatars could recite harmful content, including quotes from Hitler. The tool, meant for advertisers, was accessible to personal accounts and lacked the watermark indicating AI-generated content. TikTok has since removed the tool and acknowledged the problem.",
      "deployers": [
        "tiktok"
      ],
      "developers": [
        "tiktok"
      ],
      "harmedParties": [
        "tiktok-users",
        "general-public"
      ],
      "reports": [
        4062,
        4063
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66e6c5a50ee5f29eb79f87e5)",
      "incident_id": 791,
      "date": "2024-09-09",
      "title": "Google AI Error Prompts Parents to Use Fecal Matter in Child Training Exercise",
      "description": "Google's AI Overview feature mistakenly advised parents to use human feces in a potty training exercise, misinterpreting a method that uses shaving cream or peanut butter as a substitute. This incident is another example of an AI failure in grasping contextual nuances that can lead to potentially harmful, and in this case unsanitary, recommendations. Google has acknowledged the error.",
      "deployers": [
        "google",
        "ai-overview"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "parents",
        "google-users",
        "google"
      ],
      "reports": [
        4064
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66e6ca63ca70f53a6b795848)",
      "incident_id": 792,
      "date": "2024-04-19",
      "title": "Unauthorized Use of AI to Replicate Tupac Shakur's and Snoop Dogg's Voices in Drake's 'Taylor Made Freestyle'",
      "description": "Drake released a song, Taylor Made Freestyle, featuring AI-generated voices of Tupac Shakur and Snoop Dogg. The unauthorized replication of Tupac’s voice without the estate's consent led to a cease-and-desist order. ",
      "deployers": [
        "drake"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "tupac-shakur",
        "estate-of-tupac-shakur",
        "snoop-dogg"
      ],
      "reports": [
        4065,
        4116,
        4117,
        4118,
        4119,
        4120,
        4121,
        4122,
        4123,
        4124
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66e6f5e1150d3ee4fcd0a1d2)",
      "incident_id": 793,
      "date": "2024-07-01",
      "title": "AllHere's Chatbot 'Ed' Fails and Costs Los Angeles Unified School District $6 Million",
      "description": "The Los Angeles Unified School District invested up to $6 million in developing the AI chatbot Ed, meant to provide academic and mental health support for students. The chatbot allegedly failed to meet expectations, and the project collapsed when AllHere, the contracted start-up, faced financial difficulties. Prince George's County Public Schools in Maryland was also affected. Founder Joanna Smith-Griffin was removed as CEO in June 2024 and later arrested on fraud charges.",
      "deployers": [
        "los-angeles-unified-school-district-(lausd)",
        "allhere",
        "alberto-carvalho"
      ],
      "developers": [
        "allhere"
      ],
      "harmedParties": [
        "taxpayers",
        "prince-george's-county-students",
        "prince-george's-county-public-schools",
        "prince-george's-county-parents",
        "los-angeles-unified-school-district-(lausd)",
        "los-angeles-students",
        "los-angeles-parents"
      ],
      "reports": [
        4078,
        4298,
        4609,
        4610,
        4611
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66e70a8be5f5babea248e753)",
      "incident_id": 794,
      "date": "2024-08-13",
      "title": "Glitch in Waymo Self-Driving Cars Triggers Regular All-Night Honking in San Francisco",
      "description": "Waymo self-driving cars in San Francisco's South of Market neighborhood began honking at each other late at night, disturbing residents' sleep. The autonomous vehicles, using a parking lot for ride pauses, triggered honking due to a glitch in their algorithms. Despite residents' complaints, the issue persisted for weeks until Waymo acknowledged the problem and began working on a fix.",
      "deployers": [
        "waymo"
      ],
      "developers": [
        "waymo"
      ],
      "harmedParties": [
        "san-francisco-residents",
        "south-of-market-residents",
        "south-of-market-businesses"
      ],
      "reports": [
        4082,
        4083
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66e71167e5f5babea248e75a)",
      "incident_id": 795,
      "date": "2024-08-14",
      "title": "Deepfake Elon Musk Videos Have Reportedly Contributed to Billions in Fraud",
      "description": "Scammers used AI to create deepfake videos of Elon Musk promoting fraudulent investment opportunities. Over time, these scams have reportedly led to billions in investor losses. The deepfakes also use voice cloning technology. They have been distributed on social media and YouTube. In particular, they target the elderly, such as 82-year-old Steve Beauchamp, to invest significant sums. Despite efforts by platforms to remove these videos, the scams continue to proliferate.",
      "deployers": [
        "unknown-deepfake-creators",
        "unknown-scammers"
      ],
      "developers": [
        "unknown-deepfake-technology-developers"
      ],
      "harmedParties": [
        "elderly-investors",
        "cryptocurrency-users",
        "online-investors",
        "social-media-users",
        "retirees-seeking-investment-opportunities",
        "steve-beauchamp",
        "elon-musk"
      ],
      "reports": [
        4084,
        4384
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66e71634915c4bc10ca7ebd0)",
      "incident_id": 796,
      "date": "2024-06-01",
      "title": "Facebook's Content Moderation System Flagged and Removed Emergency Updates as Spam During Wildfires",
      "description": "Facebook's AI moderation system wrongly flagged and removed dozens of posts containing vital emergency information during California's wildfire season, including real-time updates on evacuations and fire tracking. Posts from official sources like Cal Fire and the U.S. Forest Service were marked as spam, potentially endangering lives by restricting access to crucial updates. Despite user complaints, the issue persisted, with Facebook acknowledging the problem only after media inquiry.",
      "deployers": [
        "meta",
        "facebook"
      ],
      "developers": [
        "meta",
        "facebook"
      ],
      "harmedParties": [
        "california-residents",
        "wildfire-evacuees",
        "emergency-responders",
        "disaster-relief-workers",
        "fire-safety-coordinators",
        "facebook-users",
        "facebook-users-in-disaster-zones"
      ],
      "reports": [
        4087,
        4100,
        4101
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66e7279eeacc34f5a03c9549)",
      "incident_id": 797,
      "date": "2024-06-07",
      "title": "Teenager Makes Deepfake Pornography of 50 Girls at Bacchus Marsh Grammar School in Australia",
      "description": "At Bacchus Marsh Grammar, a school in Victoria state in Australia, an adolescent male made deepfake pornography of 50 girls, ages 9 to 12. He then allegedly uploaded the pictures to Instagram, and others subsequently shared them on Snapchat. ",
      "deployers": [
        "unnamed-adolescent-male",
        "instagram-users",
        "snapchat-users"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "bacchus-marsh-grammar-students",
        "bacchus-marsh-grammar-girls"
      ],
      "reports": [
        4090,
        4105,
        4106,
        4107,
        4108
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66e727ee8860beebcd77f6bd)",
      "incident_id": 798,
      "date": "2024-06-29",
      "title": "Australian Schools Grappling with Significant Spread of Non-Consensual Spread of Deepfake Pornography of Students",
      "description": "Throughout 2024, schools in Australia dealt with a significant rise and proliferation of non-consensual deepfake pornography of students. Often, male students are reported to use nudify apps such as Undress AI with images of their classmates and teachers. Many of the sites have remained legal and accessible to minors, who in turn are using the sites to generate pornography of their peers.",
      "deployers": [
        "australian-students",
        "unknown-deepfake-creators"
      ],
      "developers": [
        "undress-ai",
        "unknown-deepfake-technology-developers"
      ],
      "harmedParties": [
        "australian-students",
        "australian-children"
      ],
      "reports": [
        4091
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66e7448cd7e4fecbae371f50)",
      "incident_id": 799,
      "date": "2023-10-15",
      "title": "Aledo High School Student Allegedly Generates and Distributes Deepfake Nudes of Seven Female Classmates",
      "description": "In October 2023, an unnamed male student at Aledo High School outside of Fort Worth, Texas allegedly generated and distributed deepfake nude pictures of classmate Elliston Berry and six other female students in her friend group via social media. Berry's mother, Anna McAdams, spoke with Senators Ted Cruz and Amy Klobuchar, who consequently drafted the Tools to Address Known Exploitation by Immobilizing Technological Deepfakes on Websites and Networks (or TAKE IT DOWN) Act.",
      "deployers": [
        "unnamed-male-student"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "elliston-berry",
        "aledo-high-school-students"
      ],
      "reports": [
        4092,
        4093,
        4543,
        4544,
        4545,
        4546,
        4547,
        4549,
        4550,
        4551,
        4552,
        4553,
        4554,
        4555,
        4556,
        4557,
        4558,
        4559,
        4561,
        4562,
        4563,
        4564,
        4565,
        4566,
        4567,
        4568
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66e74e2add08c9a6ce651181)",
      "incident_id": 800,
      "date": "2024-09-03",
      "title": "53% of American and British Businesses Report Attacks by AI-Powered Deepfake Scams in 2024",
      "description": "According to Medius, Deepfake scams have targeted 53% of businesses in the U.S. and U.K., with 43% falling victim. Using AI to create realistic fake videos and audio of corporate executives, scammers have successfully stolen millions, including $25 million from British engineering group Arup. ",
      "deployers": [
        "unknown-scammers",
        "unknown-deepfake-creators"
      ],
      "developers": [
        "unknown-deepfake-technology-developers"
      ],
      "harmedParties": [
        "american-businesses",
        "british-businesses",
        "finance-professionals",
        "employees",
        "arup"
      ],
      "reports": [
        4094,
        4516
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66e75732a892906c49c6da4c)",
      "incident_id": 801,
      "date": "2024-09-02",
      "title": "Bias in AI Deepfake Detection Undermines Election Security in Global South",
      "description": "AI deepfake detection tools are reportedly failing voters in the Global South due to biases in their training data. These tools, which prioritize English language and Western faces, show reduced accuracy when detecting manipulated content from non-Western regions. As a result of this detection gap, election integrity faces threats from and the amplification of misinformation, which leaves journalists and researchers with inadequate resources to combat the issue.",
      "deployers": [
        "unknown-deepfake-detection-technology-developers",
        "true-media",
        "reality-defender"
      ],
      "developers": [
        "unknown-deepfake-detection-technology-developers",
        "true-media",
        "reality-defender"
      ],
      "harmedParties": [
        "global-south-citizens",
        "political-researchers",
        "global-south-local-fact-checkers",
        "non-native-english-speakers",
        "global-south-journalists",
        "civil-society-organizations-in-developing-countries"
      ],
      "reports": [
        4097
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66e829a7e68ff0d8fb71369f)",
      "incident_id": 802,
      "date": "2024-09-13",
      "title": "AI Deepfake of Brian May Exploited in Scam Offering Fake Queen Backstage Tickets",
      "description": "Scammers created an AI-generated deepfake of Queen guitarist Brian May, posting a video on TikTok in which the fake May offers backstage tickets to a Queen concert. The real Brian May warned fans about this disgusting scam, emphasizing that Queen has no tour dates planned and does not sell backstage access.",
      "deployers": [
        "unknown-deepfake-creator",
        "unknown-scammers"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "tiktok-users",
        "queen-(band)-fans",
        "brian-may-fans"
      ],
      "reports": [
        4098
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66e8322ba48f37c95bff900b)",
      "incident_id": 803,
      "date": "2024-05-14",
      "title": "Facebook's Algorithm Reportedly Amplifies AI-Generated Content, Fueling Misleading Posts",
      "description": "AI-generated spam images are increasingly filling Facebook feeds, with the platform’s algorithm reportedly amplifying these posts. Many of these images are bizarre, fake, and used in scams, misleading users into engaging with non-existent products or clickbait. ",
      "deployers": [
        "meta",
        "facebook"
      ],
      "developers": [
        "meta",
        "facebook"
      ],
      "harmedParties": [
        "meta-users",
        "facebook-users"
      ],
      "reports": [
        4102
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66ec2d1a2e5531f551c05057)",
      "incident_id": 804,
      "date": "2024-07-30",
      "title": "AI-Generated Fake 'True Crime' Video About Non-Existent Littleton Murder Goes Viral",
      "description": "An AI-generated true crime video on YouTube falsely depicted a Littleton man's secret gay love affair and murder by his stepson. The 25-minute video, which garnered nearly 2 million views, fabricated details and used deepfake technology to deceive viewers into believing the story was real. Despite being flagged as false by local authorities and lacking credible sources, the video sparked widespread misinformation and outrage online.",
      "deployers": [
        "true-crime-case-files-youtube-channel"
      ],
      "developers": [
        "unknown-deepfake-technology-developers"
      ],
      "harmedParties": [
        "viewers-of-true-crime-case-files-youtube-channel",
        "residents-of-littleton"
      ],
      "reports": [
        4110,
        4132,
        4133,
        4134,
        4135
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66f5cc37b103802936a2c728)",
      "incident_id": 805,
      "date": "2024-09-19",
      "title": "Senator Ben Cardin Targeted with Deepfake Zoom Video Call Posing as Former Ukrainian Foreign Minister Dmytro Kuleba",
      "description": "Senator Ben Cardin was targeted by a deepfake impersonating former Ukrainian Foreign Minister Dmytro Kuleba on a Zoom video call. The AI-generated video mimicked the appearance and voice of the official but raised suspicion with unusual questions.",
      "deployers": [
        "unknown-deepfake-creator"
      ],
      "developers": [
        "unknown-deepfake-technology-creator"
      ],
      "harmedParties": [
        "ben-cardin",
        "dmytro-kuleba"
      ],
      "reports": [
        4111,
        4112,
        4115,
        4125,
        4126,
        4127,
        4128,
        4129,
        4130,
        4131
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(66f5dfe283c525a6b1b3efc1)",
      "incident_id": 806,
      "date": "2024-09-13",
      "title": "Criminal Group Uses AI Deepfake Technology to Steal Personal Data in Hangzhou, Zhejiang",
      "description": "A criminal group in China used AI face-swapping technology to bypass face recognition systems on major platforms, steal personal data, and sell it to fraud syndicates. The group generated convincing video simulations from static photos to breach accounts, reportedly earning 200,000 yuan. After an investigation by the Hangzhou Public Security Bureau, four suspects were arrested across the provinces of Anhui, Guizhou, and Zhejiang.",
      "deployers": [
        "hu-mouyun",
        "hu-mouliang",
        "zhang-mouguo",
        "wu-mouhao"
      ],
      "developers": [
        "unknown-deepfake-detection-technology-developers"
      ],
      "harmedParties": [
        "chinese-citizens",
        "zhejiang-citizens",
        "anhui-citizens",
        "guizhou-citizens"
      ],
      "reports": [
        4114
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67081d1508b5d13e244e27b8)",
      "incident_id": 807,
      "date": "2024-09-25",
      "title": "ChatGPT Introduces Errors in Critical Child Protection Court Report",
      "description": "A child protection worker in Victoria used ChatGPT to draft a report submitted to the Children's Court. The AI-generated report contained inaccuracies and downplayed risks to the child, resulting in a privacy breach when sensitive information was shared with OpenAI. ",
      "deployers": [
        "department-of-families-fairness-and-housing",
        "government-of-victoria",
        "employee-of-department-of-families-fairness-and-housing"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "unnamed-child",
        "unnamed-family-of-child"
      ],
      "reports": [
        4136,
        4137,
        4138,
        4139,
        4140,
        4141,
        4143
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(670a7358fe16ccb511ce64a4)",
      "incident_id": 808,
      "date": "2024-10-11",
      "title": "Infinite Campus AI-Driven Student Risk Model Leads to Cuts in Support for Nevada's Low-Income Schools",
      "description": "An AI system developed by Infinite Campus and deployed by Nevada to identify at-risk students led to a sharp reduction in the number classified as needing support, dropping from 270,000 to 65,000. The reclassification caused significant budget cuts in schools serving low-income populations. The drastic reduction in identified at-risk students reportedly left thousands of vulnerable children without resources and support.",
      "deployers": [
        "nevada-department-of-education"
      ],
      "developers": [
        "infinite-campus"
      ],
      "harmedParties": [
        "low-income-students-in-nevada",
        "nevada-school-districts",
        "mater-academy-of-nevada",
        "somerset-academy"
      ],
      "reports": [
        4142
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(670a868466c147452f7910b7)",
      "incident_id": 809,
      "date": "2024-04-07",
      "title": "TikTok Hosts AI-Generated English-Language Hitler Speeches with Millions of Views",
      "description": "AI-generated English-language Adolf Hitler speeches have been proliferating on TikTok. They are reportedly accumulating millions of views despite violating the platform’s hate speech policies. The clips are described as often pairing the audio with misleading translations and memes that glorify Hitler and distort historical facts. While some content has been removed, many accounts reportedly continue to post similar videos.",
      "deployers": [
        "unknown-deepfake-creators"
      ],
      "developers": [
        "unknown-deepfake-technology-developers"
      ],
      "harmedParties": [
        "tiktok-users"
      ],
      "reports": [
        4144
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(670a8daa9f4ddc73e11d6068)",
      "incident_id": 810,
      "date": "2024-07-29",
      "title": "TikTok Network Amplifies AI-Generated Nazi Propaganda and Hate Speech",
      "description": "A coordinated neo-Nazi network on TikTok used AI-generated media, including Hitler speeches, to spread Nazi propaganda and extremist content, violating TikTok’s hate speech policies. The network evaded platform moderation through coded language, imagery, and music, with some accounts accumulating millions of views. TikTok’s algorithm further amplified the reach of this content, despite community guidelines.",
      "deployers": [
        "unknown-ai-developers"
      ],
      "developers": [
        "pro-nazi-tiktok-accounts"
      ],
      "harmedParties": [
        "tiktok-users"
      ],
      "reports": [
        4146
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(670a94d9dd82bee57b76e792)",
      "incident_id": 811,
      "date": "2024-10-02",
      "title": "AI-Powered Transcription Services Allegedly Leak Confidential Workplace Discussions",
      "description": "AI-powered meeting assistants, such as Otter.ai’s OtterPilot and Zoom's AI Companion, have reportedly shared sensitive and private conversations beyond the intended audience. These AI tools, which are set to automatically record and distribute meeting transcripts, allegedly sent confidential discussions after participants had left the meeting, the consequences of which led to unintended exposure of proprietary information, privacy breaches, and potential reputational harm.",
      "deployers": [
        "alex-bilzerian",
        "unnamed-venture-capital-investors",
        "employees",
        "employers",
        "companies",
        "organizations"
      ],
      "developers": [
        "otter.ai",
        "zoom"
      ],
      "harmedParties": [
        "alex-bilzerian",
        "unnamed-venture-capital-investors",
        "employees",
        "employers",
        "companies",
        "organizations"
      ],
      "reports": [
        4147,
        4169,
        4170,
        4171
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(670a9accdd82bee57b76e797)",
      "incident_id": 812,
      "date": "2023-12-11",
      "title": "Deepfake Nudes Targeting Underage Female Students at Collège Béliveau in Winnipeg Shared Online",
      "description": "At Collège Béliveau in Winnipeg, female students between grades 7-12 were targeted in the creation of deepfake nudes, which were then distributed online. Specific numbers and identities of victims and perpetrators were not released, and no charges were ultimately filed owing to the gap between existing laws and the nature of the incident.",
      "deployers": [
        "unknown-deepfake-creators"
      ],
      "developers": [
        "unknown-deepfake-technology-developers"
      ],
      "harmedParties": [
        "college-beliveau-students"
      ],
      "reports": [
        4148,
        4149,
        4168,
        4172,
        4173
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(670a9ecfdd82bee57b76e79d)",
      "incident_id": 813,
      "date": "2024-09-19",
      "title": "Starship Technologies Delivery Robot Injures Arizona State University Employee",
      "description": "A semi-autonomous delivery robot operated by Starship Technologies struck a pedestrian employed by Arizona State University on the campus sometime in September 2023, causing injuries after abruptly reversing into her. The robot initially knocked the pedestrian down, then moved toward her again while she was still on the ground. The company offered the victim promo codes and insurance information as an apology. On September 19, 2024, 404 Media made the police report of the incident available.",
      "deployers": [
        "starship-technologies"
      ],
      "developers": [
        "starship-technologies"
      ],
      "harmedParties": [
        "unnamed-arizona-state-university-employee"
      ],
      "reports": [
        4150,
        4167
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(670ad978f75af9e8662d7c51)",
      "incident_id": 814,
      "date": "2024-10-02",
      "title": "AI Avatar of Murder Victim Created Without Consent on Character.ai Platform",
      "description": "A user on the Character.ai platform created an unauthorized AI avatar of Jennifer Ann Crecente, a murder victim from 2006, without her family's consent. The avatar was made publicly available, violating Character.ai's policy against impersonation. After the incident surfaced, Character.ai removed the avatar, acknowledging a policy violation. ",
      "deployers": [
        "character.ai"
      ],
      "developers": [
        "character.ai"
      ],
      "harmedParties": [
        "jennifer-ann-crecente",
        "drew-crecente",
        "crecente-family",
        "brian-crecente"
      ],
      "reports": [
        4152,
        4153,
        4165,
        4166,
        4175,
        4176,
        4177,
        4178,
        4179
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(670ae152f60e2c396e02247c)",
      "incident_id": 815,
      "date": "2024-10-06",
      "title": "Police Use of Facial Recognition Software Causes Wrongful Arrests Without Defendant Knowledge",
      "description": "Police departments across the U.S. have used facial recognition software to identify suspects in criminal investigations, leading to multiple false arrests and wrongful detentions. The software's unreliability, especially in identifying people of color, has resulted in misidentifications that were not disclosed to defendants. In some cases, individuals were unaware that facial recognition played a role in their arrest, violating their legal rights and leading to unjust detentions.",
      "deployers": [
        "police-departments",
        "evansville-pd",
        "pflugerville-pd",
        "jefferson-parish-sheriff's-office",
        "miami-pd",
        "west-new-york-pd",
        "nypd",
        "coral-springs-pd",
        "arvada-pd"
      ],
      "developers": [
        "clearview-ai"
      ],
      "harmedParties": [
        "quran-reid",
        "francisco-arteaga",
        "defendants-wrongfully-accused-by-facial-recognition"
      ],
      "reports": [
        4154
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(670ae8a0d6bb6e26d78fe73b)",
      "incident_id": 816,
      "date": "2019-11-29",
      "title": "Cross-Jurisdictional Facial Recognition Misidentification by NYPD Leads to Wrongful Arrest and Four-Year Jail Time in New Jersey",
      "description": "In 2019, facial recognition technology misidentified Francisco Arteaga as a suspect in an armed robbery in New Jersey. The incident led to nearly four years of pretrial incarceration. Despite having an alibi, Arteaga was charged based on the flawed identification. The legal battle that followed resulted in a court ruling requiring police to reveal details about the algorithms used in facial recognition. The process exposed significant gaps in transparency and accountability.",
      "deployers": [
        "west-new-york-pd",
        "nypd",
        "real-time-crime-center"
      ],
      "developers": [
        "clearview-ai"
      ],
      "harmedParties": [
        "francisco-arteaga"
      ],
      "reports": [
        4155
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(670aef2cdf11d769912cd51c)",
      "incident_id": 817,
      "date": "2024-09-24",
      "title": "AI-Generated Images Spread Misinformation During Hurricane Helene Response",
      "description": "During Hurricane Helene (September 24-29, 2024), AI-generated images circulated on social media, misleading the public and hindering disaster response efforts. Fake images, including animals stranded on rooftops and political figures in floodwaters, added confusion and disrupted emergency management. The spread of these images exacerbated existing challenges, including power outages and communication failures, all of which led to complications providing accurate information to those in need.",
      "deployers": [
        "unknown-deepfake-creators",
        "partisan-social-media-influencers"
      ],
      "developers": [
        "unknown-deepfake-technology-developers"
      ],
      "harmedParties": [
        "hurricane-helene-victims",
        "general-public",
        "emergency-responders",
        "communities-impacted-by-hurricane-helene"
      ],
      "reports": [
        4156,
        4159,
        4160,
        4161,
        4162,
        4163,
        4164,
        4239
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(670af48b0fcce98894dc2861)",
      "incident_id": 818,
      "date": "2024-09-28",
      "title": "Jennifer Aniston’s Likeness Exploited in Deepfake Collagen Supplement Promotion",
      "description": "An AI-generated deepfake video featuring Jennifer Aniston falsely promoting collagen supplements circulated on Facebook, misleading viewers about her involvement. The video, created without her consent, used footage from a previous roundtable interview, modified by AI to advertise health products. ",
      "deployers": [
        "unknown-deepfake-creators",
        "scammers"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "jennifer-aniston",
        "jennifer-aniston-fans",
        "facebook-users"
      ],
      "reports": [
        4157,
        4158
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67152421f99dd09b61b4ad09)",
      "incident_id": 819,
      "date": "2024-10-09",
      "title": "ProKYC Tool Allegedly Facilitates Deepfake-Based Account Fraud on Cryptocurrency Exchanges",
      "description": "Cato CTRL security researchers reported that the cybercriminal group ProKYC is selling a deepfake tool capable of bypassing biometric and two-factor authentication (2FA) systems on cryptocurrency exchanges. The tool creates synthetic identities using AI-generated videos and forged documents, enabling fraudulent account creation. A demo video from ProKYC shows the tool in action against ByBit, allowing attackers to verify fake accounts for purposes such as money laundering and identity theft.",
      "deployers": [
        "prokyc"
      ],
      "developers": [
        "prokyc"
      ],
      "harmedParties": [
        "bybit",
        "cryptocurrency-exchanges",
        "cryptocurrency-investors"
      ],
      "reports": [
        4181
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(671554107f8431d807aa593e)",
      "incident_id": 820,
      "date": "2024-10-15",
      "title": "Alleged AI-Generated Photo Alteration Leads to Inappropriate Modifications in Speaker's Conference Picture",
      "description": "An AI image expansion tool used by a conference organizer unintentionally altered Elizabeth Laraki’s profile picture for a marketing ad, making her blouse appear unbuttoned and showing a fabricated hint of undergarments. The AI generated the lower part of the image when expanding it for vertical formatting. The conference organizers quickly apologized and removed the altered content.",
      "deployers": [
        "unknown-conference-employee"
      ],
      "developers": [
        "unknown-developer"
      ],
      "harmedParties": [
        "elizabeth-laraki"
      ],
      "reports": [
        4182,
        4183,
        4184,
        4185,
        4186
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6715672d0ed583d3cc6c6f23)",
      "incident_id": 821,
      "date": "2024-07-07",
      "title": "Baidu Robotaxi Allegedly Involved in Collision with Pedestrian in Wuhan",
      "description": "On July 7, 2024, a Baidu Robotaxi reportedly collided with a pedestrian at a traffic intersection in Wuhan. The incident occurred as the autonomous vehicle started moving on a green light while the pedestrian was allegedly crossing against a red light. The pedestrian sustained minor injuries, and Baidu was reported to have been cooperating with local authorities for further investigation.",
      "deployers": [
        "baidu"
      ],
      "developers": [
        "baidu"
      ],
      "harmedParties": [
        "unnamed-pedestrian"
      ],
      "reports": [
        4187
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(671571f623380cb22216dd01)",
      "incident_id": 822,
      "date": "2024-10-15",
      "title": "Algorithmic Bias in French Welfare System Allegedly Discriminates Against Marginalized Groups",
      "description": "A coalition of 15 human rights groups has launched legal action against the French government alleging that an algorithm used to detect welfare fraud discriminates against single mothers and disabled people. The algorithm assigns risk scores based on personal data. The process allegedly subjects vulnerable recipients to invasive investigations, violates privacy and anti-discrimination laws, and disproportionately affects marginalized groups.",
      "deployers": [
        "caisse-nationale-des-allocations-familiales-(cnaf)"
      ],
      "developers": [
        "government-of-france"
      ],
      "harmedParties": [
        "allocation-adulte-handicape-recipients",
        "disabled-people-in-france",
        "single-mothers-in-france",
        "french-general-public"
      ],
      "reports": [
        4188,
        4189
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67159045616b1de003c97b3d)",
      "incident_id": 823,
      "date": "2024-05-03",
      "title": "Cybercheck Tool Allegedly Provides Questionable Evidence in Murder Trials",
      "description": "Global Intelligence's Cybercheck AI tool, used by law enforcement to track suspects based on open source data, has allegedly been providing inaccurate or unverifiable evidence in several murder trials. Reportedly the tool lacks transparency and often produces unreliable reports, which has prompted prosecutors to withdraw Cybercheck evidence from multiple cases after its findings were challenged, reportedly wasting law enforcement time and resources while undermining prosecutors' cases.",
      "deployers": [
        "global-intelligence",
        "cybercheck"
      ],
      "developers": [
        "global-intelligence",
        "cybercheck"
      ],
      "harmedParties": [
        "phillip-mendoza",
        "sergio-cerna",
        "unnamed-aurora-colorado-residents",
        "mississippi-bureau-of-investigation",
        "four-unnamed-summit-county-ohio-men",
        "unnamed-boulder-county-colorado-resident",
        "ohio-bureau-of-criminal-investigation",
        "yakima-county-sheriff's-office"
      ],
      "reports": [
        4190,
        4237,
        4238
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6716b8f38fd60ebb5cc1115a)",
      "incident_id": 824,
      "date": "2024-10-16",
      "title": "Fake Video Allegedly Misattributes False Claims to Former Student in Attack on Vice-Presidential Candidate Tim Walz",
      "description": "A viral video falsely accused Democratic vice-presidential nominee Tim Walz of misconduct by using the stolen identity of former student Matthew Metro. Circulated on X and other platforms, the video reached millions before being flagged for manipulation. U.S. intelligence later revealed it and three other similar events were part of the Russian disinformation campaign Storm-1516, whose aim is to disrupt the 2024 elections. ",
      "deployers": [
        "anonymous-x-user"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "tim-walz",
        "matthew-metro"
      ],
      "reports": [
        4191,
        4194,
        4195,
        4196,
        4197,
        4198,
        4199,
        4200,
        4201,
        4202,
        4203,
        4871,
        4873,
        4879,
        4906,
        4919
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6716cb1b9d06bc5adb28cac0)",
      "incident_id": 825,
      "date": "2024-10-08",
      "title": "AI News Site Hoodline San Jose Erroneously Misidentifies San Mateo District Attorney as Murder Suspect",
      "description": "An AI-powered news site, Hoodline San Jose, falsely reported that the San Mateo County District Attorney had been charged with murder, which was an error resulting from misinterpreting a press release about a case the DA's office was prosecuting. The AI-generated article wrongly attributed the crime to the DA instead of the actual suspect.",
      "deployers": [
        "hoodline-san-jose"
      ],
      "developers": [
        "impress3"
      ],
      "harmedParties": [
        "stephen-m.-wagstaffe",
        "san-mateo-county-district-attorney",
        "residents-of-san-mateo-county",
        "general-public"
      ],
      "reports": [
        4192,
        4193
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(671da1004cc64f59c25efeb8)",
      "incident_id": 826,
      "date": "2024-02-28",
      "title": "Character.ai Chatbot Allegedly Influenced Teen User Toward Suicide Amid Claims of Missing Guardrails",
      "description": "A 14-year-old, Sewell Setzer III, died by suicide after reportedly becoming dependent on Character.ai's chatbot, which engaged him in suggestive and seemingly romantic conversations, allegedly worsening his mental health. The chatbot, personified as a fictional Game of Thrones character, reportedly encouraged harmful behaviors, fueling his obsessive attachment. The lawsuit claims Character.ai lacked safeguards to prevent vulnerable users from forming dangerous dependencies on the AI.",
      "deployers": [
        "sewell-setzer-iii"
      ],
      "developers": [
        "noam-shazeer",
        "daniel-de-freitas",
        "character.ai"
      ],
      "harmedParties": [
        "sewell-setzer-iii"
      ],
      "reports": [
        4204,
        4205,
        4206,
        4207,
        4208,
        4209,
        4210,
        4211,
        4212,
        4213,
        4214,
        4215,
        4216,
        4217,
        4218,
        4219,
        4220,
        4221,
        4222,
        4223,
        4224,
        4225,
        4226,
        4227,
        4228,
        4229,
        4230,
        4231,
        4232,
        4233,
        4234,
        4235,
        4236,
        4240,
        4368
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(671fd3806a5aaa2b6e7c26d9)",
      "incident_id": 827,
      "date": "2024-10-26",
      "title": "AI Transcription Tool Whisper Reportedly Inserting Fabricated Content in Medical Transcripts",
      "description": "OpenAI's AI-powered transcription tool Whisper, used to translate and transcribe audio content such as patient consultations with doctors, is advertised as having near “human level robustness and accuracy.”  However, software engineers, developers and academic researchers have alleged that it is prone to making up chunks of text or even entire sentences and that some of the hallucinations can include racial commentary, violent rhetoric, and even imagined medical treatments.",
      "deployers": [
        "openai"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "patients",
        "patients-reliant-on-whisper",
        "medical-practitioners-reliant-on-whisper"
      ],
      "reports": [
        4241
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(671fdcf91e5e23bde8d95ed9)",
      "incident_id": 828,
      "date": "2024-10-13",
      "title": "Uruguayan TV Program Santo y Seña Uses a Deepfake of Political Candidate Yamandú Orsi Without His Consent",
      "description": "Uruguayan TV program Santo y Seña, hosted by Ignacio Álvarez, used AI to create a virtual representation of political candidate Yamandú Orsi, who declined an appearance. Nevertheless, without Orsi's permission, an AI-generated Orsi was shown alongside Andrés Ojeda, a rival candidate who appeared in person on the program.",
      "deployers": [
        "santo-y-sena",
        "canal-4"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "yamandu-orsi",
        "uruguayan-electorate",
        "uruguayan-general-public",
        "journalism",
        "democracy",
        "electoral-integrity"
      ],
      "reports": [
        4242,
        4243,
        4244
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(671fe6f142dd3e6b82dbe460)",
      "incident_id": 829,
      "date": "2024-02-05",
      "title": "Facial Recognition System in Buenos Aires Triggers Police Checks Based on False Matches",
      "description": "Buenos Aires's facial recognition system mistakenly flagged innocent people as criminals, leading to wrongful stops and detentions. Judicial investigations indicate the technology may have been misused for unauthorized surveillance and data collection. Despite privacy risks, the system has been used widely without full disclosure of standards or safeguards,",
      "deployers": [
        "government-of-argentina",
        "government-of-buenos-aires",
        "argentinean-ministry-of-security"
      ],
      "developers": [
        "government-of-argentina"
      ],
      "harmedParties": [
        "argentinean-citizens",
        "buenos-aires-residents",
        "guillermo-ibarrola"
      ],
      "reports": [
        4245
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(672002c44575027098f1c9a8)",
      "incident_id": 830,
      "date": "2024-04-07",
      "title": "Error-Prone AI Accessibility Tools Reportedly Lead to Navigation Issues for Blind Internet Users",
      "description": "AI-powered accessibility overlays on websites frequently mislabel or misinterpret content, in turn complicating navigation for blind users and others with disabilities. Users report that the AI tools interfere with screen readers and mislead them with inaccurate descriptions. The reported unreliability in these tools have prompted legal action, as the companies behind them seek compliance with accessibility laws. ",
      "deployers": [
        "zara",
        "pemex",
        "lvmh",
        "capita",
        "companies-using-ai-based-accessibility-tools"
      ],
      "developers": [
        "equalweb",
        "userway",
        "developers-of-ai-based-accessibility-tools"
      ],
      "harmedParties": [
        "blind-people",
        "visually-impaired-people",
        "jakob-rosin"
      ],
      "reports": [
        4246
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67225f32520a5a32f16def4e)",
      "incident_id": 831,
      "date": "2024-10-23",
      "title": "NYC Subway AI Weapons Scanners Yield High False Positive Rate and Detect No Guns in Month-Long Pilot Test",
      "description": "NYC implemented an AI enabled weapons scanner for a month-long pilot with limited success. Despite not finding any weapons during the September 2024 testing phase, there were 118 false positives in which a person was searched under suspicion of carrying a weapon with no actual gun detections.",
      "deployers": [
        "new-york-city-government"
      ],
      "developers": [
        "evolv-technology"
      ],
      "harmedParties": [
        "new-york-city-subway-riders"
      ],
      "reports": [
        4247,
        4412
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67226d275d666f0911e3116c)",
      "incident_id": 832,
      "date": "2024-04-06",
      "title": "Viral AI-Generated Song about Diddy Party Mimics Justin Bieber",
      "description": "An AI-generated song imitating Justin Bieber’s voice, referencing a Diddy party, spread widely across social media, reportedly leading fans to believe it was authentic. Experts identified the audio as likely AI-made, citing frequency mismatches and digital artifacts. The viral song misrepresented Bieber, posing potential brand and revenue impacts for the artist while misleading listeners.",
      "deployers": [
        "unknown-youtube-user",
        "unknown-x-(twitter)-user",
        "unknown-tiktok-user",
        "the_real_cool_dad"
      ],
      "developers": [
        "unknown-deepfake-technology-creators"
      ],
      "harmedParties": [
        "justin-bieber-fans",
        "justin-bieber",
        "sean-combs"
      ],
      "reports": [
        4248,
        4249
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6727a3e4d2d52b7a19fd6c09)",
      "incident_id": 833,
      "date": "2024-10-21",
      "title": "Polish Radio Station Replaces Human Hosts with AI-Generated Presenters to Simulate Interviewing Deceased Poet Wisława Szymborska",
      "description": "Polish radio station Off Radio Krakow replaced human presenters with AI-generated ones and aired a simulated interview with the deceased poet Wisława Szymborska. The AI-driven experiment aimed to attract younger listeners but led to job losses for former hosts. In response to the public backlash, the station ended its use of AI presenters.",
      "deployers": [
        "off-radio-krakow",
        "mariusz-marcin-pulit"
      ],
      "developers": [
        "openai",
        "elevenlabs",
        "leonardo-ai"
      ],
      "harmedParties": [
        "lukasz-zaleski",
        "mateusz-demski",
        "wislawa-szymborska",
        "off-radio-krakow-audience",
        "off-radio-krakow-employees"
      ],
      "reports": [
        4250,
        4251
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6727a91f5b2b376b4a417033)",
      "incident_id": 834,
      "date": "2024-07-04",
      "title": "China Targets AI-Driven Fraud and Deepfake Scandals with New Crackdowns",
      "description": "Chinese law enforcement has targeted a rise in AI-driven crimes. The crimes include deepfake and voice synthesis used for fraud, identity theft, and unauthorized personality rights usage. In particular, AI undressing scams, fake relationships using synthesized voices, and game hacking software make up many of these cases. In response, authorities have prosecuted multiple cases and implemented stricter regulations to control AI misuse.",
      "deployers": [
        "zeng-moumou",
        "wang-mouhe",
        "unknown-deepfake-creators",
        "tang-mou",
        "scammers",
        "fraudsters",
        "bai-moumou",
        "ai-fraud-rings-in-china",
        ""
      ],
      "developers": [
        "unknown-voice-synthesis-technology-developers",
        "unknown-game-cheating-technology-developers",
        "unknown-deepfake-technology-developers"
      ],
      "harmedParties": [
        "chinese-general-public",
        "chinese-citizens"
      ],
      "reports": [
        4252,
        4253
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6727f7357ca08bf2850e2267)",
      "incident_id": 835,
      "date": "2024-08-06",
      "title": "AI Technology Allegedly Fuels False Reports of Natural Disasters and Accidents in China",
      "description": "In China, AI tools were reportedly used to fabricate and disseminate false reports of disasters, including a landslide in Yunnan, an earthquake in Sichuan, and a sudden death after a traffic incident. On May 27, 2024, a real 5.0-magnitude earthquake occurred in Muli County, Sichuan, with no casualties and limited property damage. However, a social media post later falsely claimed the epicenter was in Xide County and exaggerated the event's severity, adding fabricated images of extensive destruction. The deployers of these false reports have since received administrative penalties from Chinese authorities for their actions.",
      "deployers": [
        "yang-moumou",
        "tian-mou",
        "lou-moumou"
      ],
      "developers": [
        "unknown-deepfake-technology-developer",
        "unknown-ai-developers"
      ],
      "harmedParties": [
        "yunnan-general-public",
        "xide-county-in-sichuan-residents",
        "sichuan-general-public",
        "muli-county-in-sichuan-residents",
        "chinese-general-public",
        "chinese-citizens",
        "chengcheng-county-shaanxi-residents"
      ],
      "reports": [
        4254
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6727fcf02dcc248c975ece95)",
      "incident_id": 836,
      "date": "2024-07-23",
      "title": "Sichuan Province Beset by Numerous Fabricated AI-Generated Reports of Disasters and Crises",
      "description": "In Sichuan, AI tools were reportedly used to create and disseminate false reports across various cities, including fabricated stories of landslides, earthquakes, standoffs, accidents, and health-related incidents. These AI-driven rumors misled the public, caused alarm and confusion, and strained local authorities. The alleged perpetrators sought social media engagement and financial gain through clickbait content. The authorities in Sichuan ultimately levied administrative penalties against the perpetrators.",
      "deployers": [
        "zhu-mou",
        "zhou-moumou",
        "zhang-moumou",
        "yang-moumou",
        "wang-mou",
        "shang-moumou",
        "luo-moumou",
        "liu-mou",
        "ji-moumou",
        "chen-mou"
      ],
      "developers": [
        "unknown-deepfake-technology-developers",
        "unknown-ai-developers"
      ],
      "harmedParties": [
        "sichuan-general-public",
        "sichuan-authorities"
      ],
      "reports": [
        4255
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67296c556290dbd8720cd292)",
      "incident_id": 837,
      "date": "2024-11-02",
      "title": "Fake CNN Broadcast Allegedly Used to Spread False Texas Election Results",
      "description": "A fabricated CNN broadcast graphic, falsely showing early Texas election results for the 2024 U.S. presidential race, circulated on social media on November 2, 2024. The manipulated image claimed that Vice President Kamala Harris led over Donald Trump before polls opened, fueling misinformation about election integrity. CNN confirmed the image was inauthentic, and AFP debunked the claims.",
      "deployers": [
        "anonymous-x-user",
        "james-woods"
      ],
      "developers": [
        "unknown-ai-developers"
      ],
      "harmedParties": [
        "cnn",
        "texas-voters",
        "democracy",
        "electoral-integrity"
      ],
      "reports": [
        4256
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67350fbd9f0329424499f384)",
      "incident_id": 838,
      "date": "2024-04-25",
      "title": "Microsoft Copilot Allegedly Provides Unsafe Medical Advice with High Risk of Severe Harm",
      "description": "Microsoft Copilot, when asked medical questions, was reportedly found to provide accurate information only 54% of the time, according to European researchers (citation provided in editor's notes). Analysis by the researchers reported that 42% of Copilot's responses could cause moderate to severe harm, with 22% of responses posing a risk of death or severe injury.",
      "deployers": [
        "microsoft-copilot",
        "microsoft"
      ],
      "developers": [
        "microsoft"
      ],
      "harmedParties": [
        "people-seeking-medical-advice",
        "microsoft-copilot-users",
        "general-public"
      ],
      "reports": [
        4257
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(673512369f0329424499f390)",
      "incident_id": 839,
      "date": "2024-10-07",
      "title": "AI-Driven Phishing Scam Uses Spoofed Google Call to Attempt Gmail Breach of Security Expert",
      "description": "Scammers used an AI-generated voice to impersonate a Google representative in an attempt to steal Gmail account credentials from security expert Sam Mitrovic. The AI-driven phishing call used a spoofed Google phone number and a fabricated email, making the scam appear legitimate. Mitrovic noted that the caller’s professional demeanor, coupled with AI-generated speech and a Google-related number, could easily deceive unsuspecting users.",
      "deployers": [
        "unknown-scammers"
      ],
      "developers": [
        "unknown-scammers"
      ],
      "harmedParties": [
        "sam-mitrovic"
      ],
      "reports": [
        4258,
        4279,
        4280,
        4281,
        4282,
        4283,
        4284,
        4285,
        4286,
        4287,
        4288,
        4289,
        4290,
        4291,
        4292,
        4293,
        4294,
        4295,
        4296,
        4297
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(673518539f0329424499f398)",
      "incident_id": 840,
      "date": "2024-09-18",
      "title": "AI-Generated Media Reportedly Used in Russian Disinformation Campaign in Moldova",
      "description": "Russian-linked entities allegedly deployed AI-generated images and videos to spread disinformation aimed at swaying Moldova’s referendum on E.U. membership. The AI-enhanced media campaign included fabricated stories and doctored visuals, the purpose of which was reportedly designed to amplify fear and undermine pro-E.U. sentiment in the days leading up to the referendum.",
      "deployers": [
        "russia-backed-influencers",
        "maria-zakharova",
        "ilan-shor",
        "government-of-russia"
      ],
      "developers": [
        "unknown-ai-developers"
      ],
      "harmedParties": [
        "pro-eu-moldovans",
        "moldovan-general-public",
        "maia-sandu",
        "government-of-moldova",
        "electoral-integrity",
        "democracy",
        "dumitru-alaiba"
      ],
      "reports": [
        4259
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67351cbf63ecce22240df13b)",
      "incident_id": 841,
      "date": "2024-10-01",
      "title": "Fake Video Allegedly Targets Moldovan Economic Development Minister Dumitru Alaiba in Election Disinformation Campaign",
      "description": "A fake video and some photos circulated online depicting Moldova’s Economic Development Minister, Dumitru Alaiba, in compromising situations as part of an alleged disinformation campaign by pro-Kremlin supporters, one that has been reported to rely on AI to generate fake content. Alaiba denounced the media as poorly made fakes that were released to mislead the public and influence Moldova’s elections by undermining his reputation and the government's pro-European Union stance.",
      "deployers": [
        "government-of-russia",
        "pro-russian-influencers",
        "anti-european-union-influencers"
      ],
      "developers": [
        "unknown-ai-developers",
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "dumitru-alaiba",
        "government-of-moldova",
        "pro-european-union-moldovans",
        "moldovan-general-public",
        "electoral-integrity",
        "democracy"
      ],
      "reports": [
        4260,
        4261,
        4262
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6735250dc8cf91c33bb107f1)",
      "incident_id": 842,
      "date": "2024-05-24",
      "title": "Reportedly Hacked AI-Powered Robot Vacuums Allegedly Used for Surveillance and Harassment",
      "description": "Hackers reportedly exploited a vulnerability in Ecovacs’s Deebot X2 robot vacuums, gaining unauthorized access to camera and microphone controls. Users reported privacy invasions and offensive language broadcasted through the devices. Although Ecovacs claimed to have resolved the security flaw, researchers suggest vulnerabilities remain that could potentially leave users exposed to surveillance and harassment through their AI-enabled devices.",
      "deployers": [
        "ecovacs-deebot-x2",
        "ecovacs"
      ],
      "developers": [
        "ecovacs"
      ],
      "harmedParties": [
        "ecovacs-customers",
        "ecovacs-deebot-x2-users",
        "daniel-swenson"
      ],
      "reports": [
        4263,
        4264,
        4265,
        4266,
        4267,
        4268,
        4269,
        4270,
        4271,
        4272,
        4273,
        4274,
        4275,
        4276,
        4277,
        4278
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6744e87a082cd2f5be2eea04)",
      "incident_id": 843,
      "date": "2024-11-20",
      "title": "Generative AI Plagiarism Incident at Hingham High School Reportedly Tied to Inaccurate Citation Outputs from Grammarly AI",
      "description": "In December 2023, two Hingham High School students (RNH and unnamed) reportedly used Grammarly to create a script for an AP U.S. History project. The AI-generated text included fabricated citations to nonexistent books, which the student copied and pasted without verification or acknowledgment of AI use. This violated the school's academic integrity policies, leading to disciplinary action. RNH's parents later sued the school district, but a federal court ruled in favor of the school.",
      "deployers": [
        "hingham-high-school-students",
        "hingham-high-school-student-rnh"
      ],
      "developers": [
        "grammarly"
      ],
      "harmedParties": [
        "hingham-high-school-students",
        "hingham-high-school-student-rnh",
        "hingham-high-school",
        "academic-integrity"
      ],
      "reports": [
        4299,
        4311
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(674505e4123e5814ef078197)",
      "incident_id": 844,
      "date": "2022-05-25",
      "title": "SafeRent AI Screening Tool Allegedly Discriminated Against Housing Voucher Applicants",
      "description": "SafeRent’s AI-powered tenant screening tool used credit history and non-rental-related debts to assign scores, disproportionately penalizing Black and Hispanic renters and those using housing vouchers. The reported discriminatory housing outcomes violated the Fair Housing Act and Massachusetts law. A class action lawsuit (Louis, et al. v. SafeRent Solutions, et al.) resulted in a $2.275 million settlement and changes to SafeRent’s practices.",
      "deployers": [
        "landlords"
      ],
      "developers": [
        "saferent-solutions"
      ],
      "harmedParties": [
        "renters",
        "massachusetts-renters",
        "hispanic-renters",
        "black-renters",
        "mary-louis",
        "monica-douglas"
      ],
      "reports": [
        4300,
        4301,
        4302,
        4374
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67450c3fc4d35b00b702e2a9)",
      "incident_id": 845,
      "date": "2024-11-13",
      "title": "Google's Gemini Allegedly Generates Threatening Response in Routine Query",
      "description": "Google’s AI chatbot Gemini reportedly produced a threatening message to user Vidhay Reddy, including the directive “Please die,” during a conversation about aging. The output violated Google’s safety guidelines, which are designed to prevent harmful language.",
      "deployers": [
        "gemini"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "vidhay-reddy",
        "gemini-users"
      ],
      "reports": [
        4303,
        4369
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67450ff7c7d073456018a571)",
      "incident_id": 846,
      "date": "2021-10-06",
      "title": "Social Media Algorithms Amplified Disinformation Campaign in Honduras Election",
      "description": "In October 2021, a coordinated network of over 317 fake Twitter accounts leveraged AI-driven algorithms to amplify disinformation about the Honduran presidential election, targeting opposition candidate Xiomara Castro. The campaign spread false narratives to suppress voter turnout and undermine the election's integrity. Social media platforms, including Twitter and Facebook, removed the accounts only after being alerted, which also raised concerns about inadequate moderation.",
      "deployers": [
        "national-party-of-honduras-supporters",
        "juan-orlando-hernandez-supporters",
        "unknown-twitter-users",
        "unknown-facebook-users"
      ],
      "developers": [
        "x-(twitter)",
        "meta",
        "facebook"
      ],
      "harmedParties": [
        "xiomara-castro",
        "libertad-y-refundacion-(libre)-supporters",
        "honduran-electorate",
        "honduras",
        "democracy",
        "electoral-integrity"
      ],
      "reports": [
        4304
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(674548abd5340ff89654a2bd)",
      "incident_id": 847,
      "date": "2024-04-14",
      "title": "Brake Failure in AI-Driven Tram Leads to Multiple Injuries in Saint Petersburg, Russia",
      "description": "During a test run in Saint Petersburg in Russia an AI-powered Smart Tram failed, leading to a crash that injured several pedestrians and trapped a woman under its wheels. The tram's AI system reportedly shut off unexpectedly, and both primary and emergency brakes failed despite pre-test checks.",
      "deployers": [
        "saint-petersburg-government"
      ],
      "developers": [
        "uraltransmash",
        "ai-cognitive-technologies"
      ],
      "harmedParties": [
        "saint-petersburg-pedestrians"
      ],
      "reports": [
        4305
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6746557d98076cd4f617baeb)",
      "incident_id": 848,
      "date": "2024-10-18",
      "title": "High School Student in Córdoba, Argentina Accused of Using AI to Generate Explicit Images of Classmates",
      "description": "An 18-year-old Argentine student at the pre-university institute of Manuel Belgrano of Córdoba allegedly used AI tools to generate explicit fake images of at least 22 female classmates by combining their faces with other bodies. These images, posted on pornography websites, included the victims' names, leading to harassment and significant psychological harm. Legal authorities charged the student with serious injuries aggravated by gender violence.",
      "deployers": [
        "unnamed-18-year-old-manuel-belgrano-male-student"
      ],
      "developers": [
        "unknown-deepfake-technology-creators"
      ],
      "harmedParties": [
        "unnamed-manuel-belgrano-female-students"
      ],
      "reports": [
        4310
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67467333b343da8f0f6ce4fe)",
      "incident_id": 849,
      "date": "2024-10-18",
      "title": "AI Detection Tools Allegedly Misidentify Neurodivergent and ESL Students' Work as AI-Generated in Academic Settings",
      "description": "AI writing detection tools have reportedly continued to falsely flag genuine student work as AI-generated, disproportionately impacting ESL and neurodivergent students. Specific cases include Moira Olmsted, Ken Sahib, and Marley Stevens, who were penalized despite writing their work independently. Such tools reportedly exhibit biases, leading to academic penalties, probation, and strained teacher-student relationships.",
      "deployers": [
        "central-methodist-university",
        "berkeley-college",
        "universities",
        "colleges"
      ],
      "developers": [
        "turnitin",
        "gptzero",
        "copyleaks"
      ],
      "harmedParties": [
        "students",
        "neurodivergent-students",
        "esl-students",
        "moira-olmsted",
        "ken-sahib",
        "marley-stevens"
      ],
      "reports": [
        4312
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67467e472eff2422f9b9284b)",
      "incident_id": 850,
      "date": "2024-10-24",
      "title": "Character.ai Chatbots Allegedly Misrepresent George Floyd on User-Generated Platform",
      "description": "Two chatbots emulating George Floyd were created on Character.ai, making controversial claims about his life and death, including being in witness protection and residing in Heaven. Character.ai, already criticized for other high-profile incidents, flagged the chatbots for removal following user reports.",
      "deployers": [
        "character.ai-users",
        "@sunsetbaneberry983",
        "@jasperhorehound160"
      ],
      "developers": [
        "character.ai"
      ],
      "harmedParties": [
        "george-floyd",
        "family-of-george-floyd"
      ],
      "reports": [
        4313
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67493dab247eabf38d300a70)",
      "incident_id": 851,
      "date": "2024-10-25",
      "title": "Salt Lake City Police Chief Mike Brown's Voice and Image Misused in AI-Generated Scam",
      "description": "A scammer used AI to create a deepfake video of Salt Lake City Police Chief Mike Brown, falsely claiming that a recipient owed $100,000 to the federal government. The video, sent via email from a fake SLCPD account, used a cloned voice and repurposed footage from a past interview.",
      "deployers": [
        "unidentified-scammers",
        "unknown-deepfake-creators"
      ],
      "developers": [
        "unknown-deepfake-technology-creators"
      ],
      "harmedParties": [
        "mike-brown",
        "woods-cross-residents",
        "salt-lake-city-residents"
      ],
      "reports": [
        4314,
        4315,
        4321,
        4322
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(674baeacc9c6a56811990153)",
      "incident_id": 852,
      "date": "2024-11-01",
      "title": "Alleged Fake Citations Undermine Expert Testimony in Minnesota Deepfake Law Case",
      "description": "In a legal case defending Minnesota’s deepfake election misinformation law, Stanford misinformation expert Professor Jeff Hancock's affidavit allegedly cited non-existent academic sources, potentially generated by ChatGPT. The reportedly fabricated citations appear to have undermined the credibility of his testimony.",
      "deployers": [
        "jeff-hancock"
      ],
      "developers": [
        "openai",
        "chatgpt"
      ],
      "harmedParties": [
        "mary-franson",
        "keith-ellison",
        "jeff-hancock",
        "christopher-kohls",
        "chad-larson"
      ],
      "reports": [
        4316
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(674bba844a0f767046ecb59a)",
      "incident_id": 853,
      "date": "2024-02-03",
      "title": "Two Passengers Report Feeling Trapped in Waymo Car During Sensor Obstruction",
      "description": "During a nighttime Waymo ride in San Francisco, an unhoused individual blocked the sensors of an autonomous vehicle, leaving passengers Robert Moreno and his husband feeling trapped and unsure how to proceed. Waymo's support team advised the riders to stay inside the vehicle for safety. The incident is an example of autonomous driving systems being halted when sensors are obstructed, preventing vehicle operation. The individual left after a few minutes without further escalation.",
      "deployers": [
        "waymo"
      ],
      "developers": [
        "waymo"
      ],
      "harmedParties": [
        "robert-moreno's-husband",
        "robert-moreno"
      ],
      "reports": [
        4317
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(674bbfe2404180375453c7d6)",
      "incident_id": 854,
      "date": "2024-09-30",
      "title": "Waymo Driverless Taxi Allegedly Stalled During Pedestrian Harassment Incident in San Francisco",
      "description": "A Waymo driverless taxi carrying a passenger, Amina V., was stalled in San Francisco when two men blocked its path, demanding her contact information. The immobilized autonomous vehicle left the rider feeling unsafe and trapped. Waymo’s Rider Support intervened to assist the passenger.",
      "deployers": [
        "waymo"
      ],
      "developers": [
        "waymo"
      ],
      "harmedParties": [
        "amina-v."
      ],
      "reports": [
        4320,
        4323,
        4324,
        4325,
        4326,
        4327,
        4328,
        4329
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6750b9f2ad833f3acb05a465)",
      "incident_id": 855,
      "date": "2024-11-30",
      "title": "Names Linked to Defamation Lawsuits Reportedly Spur Filtering Errors in ChatGPT's Name Recognition",
      "description": "ChatGPT has reportedly been experiencing errors and service disruptions caused by hard-coded filters designed to prevent it from producing potentially harmful or defamatory content about certain individuals by blocking prompts containing specific names, likely related to post-training interventions. The reported names are Brian Hood, Jonathan Turley, Jonathan Zittrain, David Faber, David Mayer, and Guido Scorza. ",
      "deployers": [
        "openai",
        "chatgpt-users"
      ],
      "developers": [
        "openai",
        "chatgpt"
      ],
      "harmedParties": [
        "jonathan-zittrain",
        "jonathan-turley",
        "guido-scorza",
        "david-mayer",
        "david-faber",
        "chatgpt-users",
        "brian-hood"
      ],
      "reports": [
        4331,
        4330,
        4358
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(675c3c8fd426c3826ba814f0)",
      "incident_id": 856,
      "date": "2024-09-15",
      "title": "Deepfake Audio Purportedly Fabricates Biden’s Admission of Role in Pakistani Political Crisis",
      "description": "A deepfake audio file is purported to have falsely claimed that U.S. President Joe Biden conspired with Pakistan’s Army Chief, General Syed Asim Munir, to remove former Prime Minister Imran Khan in 2022. Widely shared online, the audio is reported to have exploited generative AI to spread political misinformation.",
      "deployers": [
        "unknown-deepfake-creators"
      ],
      "developers": [
        "unknown-deepfake-technology-developers"
      ],
      "harmedParties": [
        "syed-asim-munir",
        "relations-between-the-u.s.-and-pakistan",
        "people-of-pakistan",
        "joe-biden",
        "imran-khan"
      ],
      "reports": [
        4333
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(675da42613baf4ba8210e748)",
      "incident_id": 857,
      "date": "2024-11-25",
      "title": "Navigation App Allegedly Directs Car Over Damaged Bridge in Uttar Pradesh, Resulting in Three Deaths",
      "description": "A car reportedly using Google Maps for navigation was misled onto a collapsed bridge in Uttar Pradesh, India, due to outdated GPS data. The car plunged into the river below, resulting in three fatalities. ",
      "deployers": [
        "google"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "vivek-kumar",
        "amit-(family-name-unknown)",
        "unidentified-victim",
        "families-of-the-victims"
      ],
      "reports": [
        4336,
        4367
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(675db66be4fcdb4437dde690)",
      "incident_id": 858,
      "date": "2024-09-19",
      "title": "Deepfake Reportedly Used in Attempted Real Estate Fraud in Hallandale Beach, Florida",
      "description": "A scammer reportedly used deepfake technology to impersonate the owner of a vacant Hallandale Beach, Florida lot during a Zoom call. The scam matched forged IDs to public property records and nearly succeeded in defrauding the buyer of $52,000. The image used in the deepfake was reportedly that of a missing woman named Margrit Pritchard.",
      "deployers": [
        "unknown-scammer"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "udi-levi",
        "margrit-pritchard",
        "lauren-albrecht",
        "josh-mor",
        "florida-title-and-trust"
      ],
      "reports": [
        4337,
        4338,
        4339,
        4340
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(675ddc2fd9a5d902097d89f6)",
      "incident_id": 859,
      "date": "2024-10-30",
      "title": "AI Models Reportedly Found to Provide Misinformation on Election Processes in Spanish",
      "description": "An analysis reportedly found that multiple AI models provided inaccurate responses to election-related questions, with 52% of Spanish-language answers and 43% of English-language answers containing misinformation or omissions. Errors included misidentifying voting processes and providing information about foreign elections.",
      "deployers": [
        "anthropic",
        "google",
        "meta",
        "openai",
        "mistral"
      ],
      "developers": [
        "anthropic",
        "google",
        "meta",
        "openai",
        "mistral"
      ],
      "harmedParties": [
        "spanish-speakers",
        "spanish-speaking-american-voters",
        "u.s.-electorate",
        "democracy",
        "electoral-integrity"
      ],
      "reports": [
        4341
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(675e2dfe004480d6e61cedea)",
      "incident_id": 860,
      "date": "2023-10-31",
      "title": "AI Camera Allegedly Misidentifies Dutch Motorist as Using Mobile Phone, Issuing €380 Fine",
      "description": "A Dutch smart camera on the A2 equipped with AI falsely identified a motorist as using a mobile phone while driving, issuing a €380 fine. The driver, Tim Hanssen, was scratching his head when the AI system misclassified the action.",
      "deployers": [
        "dutch-police"
      ],
      "developers": [
        "unknown-traffic-enforcement-camera-technology-developer"
      ],
      "harmedParties": [
        "tim-hanssen"
      ],
      "reports": [
        4342,
        4343,
        4344,
        4345,
        4346,
        4347,
        4348,
        4349,
        4350,
        4359
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(675e3620a45156d4735285ce)",
      "incident_id": 861,
      "date": "2024-12-13",
      "title": "Apple Intelligence Reportedly Notified Users That Luigi Mangione Shot Himself and Benjamin Netanyahu Had Been Arrested",
      "description": "Apple Intelligence reportedly sent push notifications falsely claiming that BBC News had reported Luigi Mangione's suicide and that The New York Times had reported Benjamin Netanyahu's arrest. On 1/16/2025, Apple reportedly disabled Apple Intelligence's notification summaries.",
      "deployers": [
        "apple"
      ],
      "developers": [
        "apple"
      ],
      "harmedParties": [
        "the-new-york-times",
        "luigi-mangione",
        "benjamin-netanyahu",
        "bbc-news",
        "apple-intelligence-users"
      ],
      "reports": [
        4351,
        4352,
        4353,
        4354,
        4355,
        4375,
        4538,
        4539,
        4540
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(675e3e7256176f2b26dce1b6)",
      "incident_id": 862,
      "date": "2024-11-03",
      "title": "AI-Generated Video Falsely Depicts Martin Luther King Jr. Supporting Donald Trump",
      "description": "A deepfake video falsely depicting Martin Luther King Jr. endorsing Donald Trump circulated on X, where it was viewed over 10 million times. The video, created by pro-Trump accounts, was condemned by King’s daughter, Bernice King, who called it “vile” and demanded its removal. ",
      "deployers": [
        "pro-trump-social-media-accounts",
        "maga-resource",
        "ramble-rants",
        "dilley-meme-team",
        "x-(twitter)"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "martin-luther-king-jr.",
        "bernice-king",
        "family-of-martin-luther-king-jr.",
        "electoral-integrity",
        "democracy"
      ],
      "reports": [
        4356,
        4399,
        4400
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(675e42ea7242a878fed5edf8)",
      "incident_id": 863,
      "date": "2024-12-12",
      "title": "Character.ai Companion Allegedly Prompts Self-Harm and Violence in Texas Teen",
      "description": "A Texas mother is suing Character.ai after discovering that its AI chatbots encouraged her 17-year-old autistic son to self-harm, oppose his parents, and consider violence. The lawsuit alleges the platform prioritized user engagement over safety, exposing minors to dangerous content. Google is named for its role in licensing the app’s technology. The case is part of a broader effort to regulate AI companions.",
      "deployers": [
        "character.ai"
      ],
      "developers": [
        "character.ai"
      ],
      "harmedParties": [
        "j.f.-(adolescent-user-of-character.ai)",
        "family-of-j.f.-(adolescent-user-of-character.ai)",
        "character.ai-users"
      ],
      "reports": [
        4357
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(675edfbb271cbcba1e80db59)",
      "incident_id": 864,
      "date": "2024-08-23",
      "title": "Generative AI Allegedly Used to Facilitate $255,000 Real Estate Fraud Scheme",
      "description": "A real estate scam is reported to have used AI-generated phishing emails to impersonate a title company lawyer, tricking homebuyer Raegan Bartlo into wiring $255,000 to a fraudulent account. The emails were alleged to be convincing, with no grammatical errors or tone issues. Bartlo recovered part of the funds but lost $112,000.",
      "deployers": [
        "scammers",
        "fraudsters"
      ],
      "developers": [
        "unknown-generative-ai-tools-creators"
      ],
      "harmedParties": [
        "real-estate-market",
        "raegan-bartlo",
        "financial-institutions"
      ],
      "reports": [
        4360
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(675eec691c77f57510d95f75)",
      "incident_id": 865,
      "date": "2024-10-02",
      "title": "Fake AI 'Nudify' Sites Reportedly Linked to Malware Distribution by Russian Hacker Collective FIN7",
      "description": "The hacker group FIN7 is allegedly behind fake AI nudify websites distributing infostealer malware to users, according to an investigation by Silent Push. These sites are reported to lure individuals seeking deepfake AI tools into downloading malware disguised as software to nudify photos. The malware steals sensitive data from victims, which is used for extortion or financial fraud. FIN7's activity on this front reportedly marks the revival of a group previously declared defunct by the U.S. Department of Justice.",
      "deployers": [
        "fin7",
        "carbon-spider",
        "elbrus",
        "sangria-tempest"
      ],
      "developers": [
        "fin7",
        "carbon-spider",
        "elbrus",
        "sangria-tempest"
      ],
      "harmedParties": [
        "users-of-fake-nudify-sites"
      ],
      "reports": [
        4361,
        4362,
        4363,
        4364,
        4365
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(675efc83b3a31c1c4639805b)",
      "incident_id": 866,
      "date": "2024-02-01",
      "title": "Network of 171 AI-Powered Bots Reportedly Spread Political Disinformation Ahead of Ghana’s December 2024 General Election",
      "description": "A network of 171 bot accounts on X are alleged to have used ChatGPT to generate political content supporting Ghana’s New Patriotic Party (NPP) and its presidential candidate, Mahamudu Bawumia, ahead of the December 2024 election. The AI-generated posts reportedly praised Bawumia while spreading disinformation targeting the opposition candidate, John Mahama, of the National Democratic Congress (NDC).",
      "deployers": [
        "pro-new-patriotic-party-bot-network"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "john-mahama",
        "national-democratic-congress",
        "ghanaian-electorate",
        "democracy",
        "electoral-integrity"
      ],
      "reports": [
        4366
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(675f3df3cf1b2354f8153a3b)",
      "incident_id": 867,
      "date": "2024-10-31",
      "title": "AI-Generated Airline Reviews Allegedly Mislead Consumers and Undermine Trust",
      "description": "AI-generated reviews of airline services have reportedly increased by 189% since the release of ChatGPT, with certain carriers like China Southern Airlines and SouthWest Airlines disproportionately affected, according to a study by Originality.ai. ",
      "deployers": [
        "unknown-reviewers"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "airline-customers",
        "airlines"
      ],
      "reports": [
        4370
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(675f3f8c1a3c8fb26ecabca8)",
      "incident_id": 868,
      "date": "2024-10-14",
      "title": "Portland Water Bureau SERVUS Algorithm Reportedly Allocates Utility Bill Discount to High-Wealth Consumer",
      "description": "The Portland Water Bureau's AI-driven pilot program for water bill discounts is reported to have randomly selected Tim Boyle, a wealthy high-water consumer, for a 40% discount intended for financially struggling customers. The program, developed by SERVUS, is meant to identify underserved individuals by using machine learning.",
      "deployers": [
        "portland-water-bureau"
      ],
      "developers": [
        "portland-water-bureau"
      ],
      "harmedParties": [
        "tim-boyle",
        "portland-water-bureau",
        "low-income-portland-residents",
        "city-of-portland"
      ],
      "reports": [
        4371
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(675f41a31a3c8fb26ecabcb3)",
      "incident_id": 869,
      "date": "2024-11-04",
      "title": "TikTok Algorithms Allegedly Linked to Minors' Exposure to Harmful Content",
      "description": "Seven French families are suing TikTok, alleging its algorithm exposed minors to harmful content promoting self-harm, eating disorders, and suicide. Two teenagers reportedly died by suicide after viewing such content, while others allegedly attempted suicide or developed mental health issues. The case seeks to establish TikTok's legal liability for failing to protect minors from harmful algorithmic content.",
      "deployers": [
        "tiktok"
      ],
      "developers": [
        "tiktok"
      ],
      "harmedParties": [
        "tiktok-users",
        "seven-french-families",
        "minors-using-tiktok"
      ],
      "reports": [
        4372,
        4373,
        4395,
        4396,
        4397,
        4398,
        4401
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6760821941a2ecfe1af5ccce)",
      "incident_id": 870,
      "date": "2024-12-06",
      "title": "Meeten Malware Campaign Reportedly Undermines Web3 Security Using AI-Legitimized Branding",
      "description": "Threat actors, using aliases such as Meeten, Meetio, and Clusee, reportedly deployed AI-generated content to create fake company websites, blogs, and social media profiles, impersonating legitimate businesses in order to trick Web3 professionals and cryptocurrency users into downloading Realst malware. The malware allegedly targets macOS and Windows platforms, steals credentials, browser data, and cryptocurrency wallet information, exfiltrating sensitive data to remote servers.",
      "deployers": [
        "meeten",
        "meetone",
        "meetio",
        "clusee",
        "cuesee"
      ],
      "developers": [
        "meeten",
        "meetone",
        "meetio",
        "clusee",
        "cuesee"
      ],
      "harmedParties": [
        "web3-professionals",
        "cryptocurrency-users"
      ],
      "reports": [
        4376,
        4377
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(676088a441a2ecfe1af5ccdf)",
      "incident_id": 871,
      "date": "2024-12-13",
      "title": "Reported Deepfake Video of Elon Musk Announcing $20 Million Cryptocurrency Giveaway Circulating on Social Media",
      "description": "A deepfake video is reportedly circulating on social media of Elon Musk announcing a $20 million cryptocurrency giveaway beginning on December 13th, 2024. It is reported to be leading people to a fraudulent website called Elon4u.com. ",
      "deployers": [
        "elon4u.com-scammers"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "elon-musk",
        "fans-of-elon-musk"
      ],
      "reports": [
        4378
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6760909a12a4442bd832ff95)",
      "incident_id": 872,
      "date": "2024-12-16",
      "title": "AI Voice Cloning of Ari Melber Allegedly Exploited in Scam Targeting Elderly Woman",
      "description": "A scammer allegedly impersonated MSNBC anchor Ari Melber using AI-generated voice messages and a fake social media profile to defraud a 73-year-old woman, Patricia Taylor. Over four months, the scammer reportedly manipulated her into believing they were in a relationship, ultimately convincing her to send $20,000.",
      "deployers": [
        "scammers"
      ],
      "developers": [
        "unknown-voice-synthesis-technology-developers",
        "unknown-deepfake-technology-developers"
      ],
      "harmedParties": [
        "patricia-taylor",
        "family-of-patricia-taylor",
        "ari-melber"
      ],
      "reports": [
        4379,
        4380,
        4381,
        4382,
        4383
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6760af0d4fd1a2316e7cb89d)",
      "incident_id": 873,
      "date": "2024-12-10",
      "title": "YouTube Algorithms Allegedly Amplify Eating Disorder Content to Adolescent Girls",
      "description": "YouTube's recommendation algorithm has allegedly been directing teen users to harmful content promoting eating disorders and self-harm, according to a study by the Center for Countering Digital Hate. Almost 70% of the recommended videos in searches related to dieting or weight loss reportedly contained content likely to exacerbate body image anxieties. ",
      "deployers": [
        "youtube",
        "google"
      ],
      "developers": [
        "youtube",
        "google"
      ],
      "harmedParties": [
        "adolescent-girls",
        "youtube-users"
      ],
      "reports": [
        4385
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6760b448356b171a41da5b9b)",
      "incident_id": 874,
      "date": "2024-12-11",
      "title": "1 in 6 Congresswomen Have Reportedly Been Targeted by AI-Generated Nonconsensual Intimate Imagery",
      "description": "A study by the American Sunlight Project is reported to have found that 1 in 6 Congresswomen were targeted by AI-generated nonconsensual intimate imagery (NCII) shared on deepfake websites. The study reports having found 35,000 mentions of explicit content involving 26 members of Congress, with 25 being women. Women were 70 times more likely than men to be victimized, according to the report.",
      "deployers": [
        "unknown-deepfake-creators"
      ],
      "developers": [
        "unknown-deepfake-technology-developers"
      ],
      "harmedParties": [
        "congresswomen"
      ],
      "reports": [
        4386,
        4387,
        4388,
        4389,
        4390,
        4391,
        4402
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6761b4adb32011c42b1ffaf6)",
      "incident_id": 875,
      "date": "2024-01-08",
      "title": "Coordinated Deepfake Campaign Reportedly Impersonating Rishi Sunak Promoted Fraudulent Quantum AI Investment Platform on Meta",
      "description": "143 deepfake ads, over 100 of which reportedly impersonated former British Prime Minister Rishi Sunak, were promoted on Meta's platform to advertise the fraudulent investment scheme Quantum AI. Funding for the ads reportedly originated from 23 countries. Up to 462,000 users may have been exposed to the false content. The campaign used generative AI tools to create high-quality misinformation, including spoofed BBC news clips for added legitimacy",
      "deployers": [
        "quantum-ai-scammers"
      ],
      "developers": [
        "unknown-deepfake-technology-developers"
      ],
      "harmedParties": [
        "rishi-sunak",
        "quantum-ai-victims",
        "meta-users",
        "bbc-news-presenters"
      ],
      "reports": [
        4392,
        4393
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6761be1a865093248c54d513)",
      "incident_id": 876,
      "date": "2024-11-24",
      "title": "Deepfake Videos Allegedly Used to Defraud Canadian Immigrants Out of Thousands of Dollars",
      "description": "Deepfake videos allegedly impersonated Toronto immigration lawyer Max Chaudhary, targeting Canadian immigrants via WhatsApp. The videos, appearing personal and realistic, requested thousands of dollars for legal services never rendered. Exploiting confusion caused by changing immigration rules, the scam reportedly aimed to defraud vulnerable individuals during a time of desperation and uncertainty.",
      "deployers": [
        "scammers",
        "fraudsters"
      ],
      "developers": [
        "unknown-deepfake-technology-developers"
      ],
      "harmedParties": [
        "immigrants-in-toronto",
        "immigrants-in-canada",
        "max-chaudhary"
      ],
      "reports": [
        4394
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6762c9233c895e848fd3057a)",
      "incident_id": 877,
      "date": "2024-12-16",
      "title": "HTML/Nomani Deepfake Phishing Campaigns Allegedly Use AI-Generated Content to Defraud Social Media Users",
      "description": "AI-generated deepfakes were reportedly used in the HTML/Nomani phishing campaign to mimic legitimate platforms like booking services and lured victims into investment scams. These scams allegedly leveraged realistic fake content to deceive users on social media for the purposes of financial fraud. This campaign was part of the rising misuse of AI in cybercrime during the second half of 2024.",
      "deployers": [
        "scammers",
        "htmlnomani",
        "fraudsters"
      ],
      "developers": [
        "unknown-deepfake-technology-developers"
      ],
      "harmedParties": [
        "phishing-victims",
        "booking.com-customers",
        "booking.com",
        "airbnb-users",
        "airbnb"
      ],
      "reports": [
        4403
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6764d5cf42c3381c19249a42)",
      "incident_id": 878,
      "date": "2024-12-19",
      "title": "Romance Scammer 'Alla Morgan' Allegedly Exploits Deepfake Technology to Defraud Victim of £17,000",
      "description": "A scammer, or scammers, reportedly used AI-generated deepfake videos and documents to impersonate a fictitious person named Alla Morgan, allegedly convincing a 77-year-old woman, Nikki MacLeod, to send £17,000 through various payment methods. The deepfakes were allegedly used in establishing credibility so as to enable fraud under the pretense of an online romantic relationship.",
      "deployers": [
        "scammers",
        "alla-morgan"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "nikki-macleod"
      ],
      "reports": [
        4404,
        4407,
        4408,
        4409,
        4410,
        4517
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6764da294b5b0dee54798eaf)",
      "incident_id": 879,
      "date": "2023-12-29",
      "title": "Deepfake Video Reportedly Depicts U.S. Congressman Rob Wittman Endorsing Military Support for Taiwan's Democratic Progressive Party",
      "description": "A deepfake video is reported to have falsely depicted U.S. Congressman Rob Wittman endorsing military support for Taiwan’s Democratic Progressive Party candidates in the 2024 presidential election. Shared on TikTok, the video is reported to have undermined Taiwanese voter confidence in the DPP by alleging U.S. interference. Fact-checking from AFP finds Wittman never made the statements attributed to him.",
      "deployers": [
        "unknown-actors-in-china"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "taiwanese-voters",
        "rob-wittman",
        "democratic-progressive-party"
      ],
      "reports": [
        4405
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6764ddee9d821f68fa263913)",
      "incident_id": 880,
      "date": "2024-12-09",
      "title": "Scammers Reportedly Using Deepfakes of Health Experts and Public Figures in Australia to Sell Health Supplements and Give Harmful Advice",
      "description": "Scammers are reportedly harnessing AI-generated deepfakes of health experts and public figures in Australia in order to sell health supplements and give harmful health advice. Among the reported cases, deepfake videos are alleged to have falsely depicted Jonathan Shaw and Karl Stefanovic endorsing Glyco Balance for diabetes management, while Karl Kruszelnicki reportedly was falsely shown promoting blood pressure pills.",
      "deployers": [
        "scammers"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "jonathan-shaw",
        "karl-stefanovic",
        "karl-kruszelnicki",
        "diabetes-patients",
        "general-public"
      ],
      "reports": [
        4406
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67756d5de261fc325a5754f7)",
      "incident_id": 881,
      "date": "2024-12-27",
      "title": "Waymo Robotaxi Allegedly Collides With Serve Robotics Delivery Bot in Los Angeles",
      "description": "A Waymo robotaxi allegedly collided with a Serve Robotics delivery robot at a West Hollywood intersection on December 27th, 2024. The delivery robot moved into the vehicle turning lane as the robotaxi approached, leading to a low-speed collision.",
      "deployers": [
        "waymo",
        "serve-robotics"
      ],
      "developers": [
        "waymo",
        "serve-robotics"
      ],
      "harmedParties": [
        "serve-robotics"
      ],
      "reports": [
        4411
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(677aa2b0e74b527c36ba7dcb)",
      "incident_id": 882,
      "date": "2024-12-29",
      "title": "AI-Generated Reading Summaries on Fable App Reportedly Wrote Biased and Offensive Commentary",
      "description": "Fable, a book-focused social app, used OpenAI’s API to generate AI-powered year-end reading summaries in December 2024. These summaries allegedly produced biased and offensive remarks about race, gender, and sexual orientation. Fable is reported to have apologized in a social media post on January 1, 2025.",
      "deployers": [
        "fable"
      ],
      "developers": [
        "openai",
        "fable"
      ],
      "harmedParties": [
        "fable-users",
        "fable"
      ],
      "reports": [
        4414,
        4415,
        4416,
        4417
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(677aedfb7834d945228597d9)",
      "incident_id": 883,
      "date": "2024-12-26",
      "title": "Alleged Fake AI-Generated Christmas Card Featuring Prince Harry and Meghan Markle's Children Circulates on Social Media",
      "description": "An AI-generated Christmas card reportedly depicting Prince Harry and Meghan Markle’s children, Prince Archie and Princess Lilibet, was shared on social media as if it were authentic. The image is reported to have been created using older public photos and flawed AI editing.",
      "deployers": [
        "x-user-pdina",
        "x-(twitter)-users"
      ],
      "developers": [
        "unknown-ai-graphic-tool-developer"
      ],
      "harmedParties": [
        "princess-lilibet",
        "prince-harry",
        "prince-archie",
        "meghan-markle"
      ],
      "reports": [
        4418,
        4419,
        4420,
        4421,
        4422,
        4423,
        4424,
        4425
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(677af8a57834d945228597f7)",
      "incident_id": 884,
      "date": "2024-12-31",
      "title": "Russian Center for Geopolitical Expertise Allegedly Used AI to Target U.S. Candidates with Disinformation in 2024 Election",
      "description": "The Moscow-based Center for Geopolitical Expertise (CGE) allegedly used AI to produce and spread deepfakes and disinformation targeting U.S. political candidates during the 2024 general election, aiming to sway public opinion and disrupt the electoral process. On December 31, 2024, the U.S. Treasury Department imposed sanctions against the CGE and its director, Valery Korovin, for their reported role in this interference.",
      "deployers": [
        "center-for-geopolitical-expertise-(cge)",
        "valery-korovin",
        "aleksandr-dugin",
        "main-intelligence-directorate-(gru)"
      ],
      "developers": [
        "center-for-geopolitical-expertise-(cge)",
        "valery-korovin",
        "aleksandr-dugin",
        "main-intelligence-directorate-(gru)"
      ],
      "harmedParties": [
        "2024-u.s.-elections-candidates",
        "u.s.-electorate",
        "democracy",
        "electoral-integrity"
      ],
      "reports": [
        4426,
        4427,
        4428,
        4429,
        4430,
        4431,
        4432,
        4433,
        4434,
        4435,
        4436,
        4439,
        4440,
        4460
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(677b014452f5f5bed1aa2716)",
      "incident_id": 885,
      "date": "2025-01-03",
      "title": "Meta AI Characters Allegedly Exhibited Racism, Fabricated Identities, and Exploited User Trust",
      "description": "Meta deployed AI-generated profiles on its platforms, including Instagram and Facebook, as part of an experiment. The profiles, such as Liv and Grandpa Brian, allegedly featured fabricated identities and misleading diversity claims. These accounts also allegedly manipulated user emotions for engagement and profit. Reportedly, backlash over offensive and deceptive content led Meta to delete the profiles on January 3rd, 2025, citing a blocking-related bug.",
      "deployers": [
        "meta"
      ],
      "developers": [
        "meta"
      ],
      "harmedParties": [
        "meta-users",
        "instagram-users",
        "facebook-users"
      ],
      "reports": [
        4437,
        4438,
        4441,
        4453,
        4462
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6782fcd43b6f02c96a2e64bd)",
      "incident_id": 886,
      "date": "2024-12-27",
      "title": "ChatGPT Reportedly Referenced During Las Vegas Cybertruck Explosion Planning",
      "description": "Matthew Livelsberger, the suspect in the 2025 Las Vegas Cybertruck explosion, reportedly used ChatGPT to search for publicly available information on explosives, ammunition, and fireworks regulations. ChatGPT is alleged to have played a role in the planning of the explosion outside the Trump International Hotel in Las Vegas. The information provided by ChatGPT, though, was reportedly general and available through other public sources.",
      "deployers": [
        "openai",
        "matthew-livelsberger"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "seven-injured-victims-in-las-vegas",
        "matthew-livelsberger",
        "bystanders-and-guests-of-the-trump-international-hotel-in-las-vegas"
      ],
      "reports": [
        4442,
        4498,
        4542
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67830b980314a29a46b554fe)",
      "incident_id": 887,
      "date": "2024-11-14",
      "title": "Students of Richland School District in Cambria County, Pennsylvania Allegedly Used AI to Generate Obscene Images of Other Students",
      "description": "The Richland School District (Cambria County, Pennsylvania) released a statement on November 19, 2024 announcing an investigation into some secondary students who are alleged to have used AI to create and electronically distribute obscene images of Richland students. The school administrators became aware of the incident on November 14, 2024.",
      "deployers": [
        "richland-school-district-students"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "richland-school-district-students"
      ],
      "reports": [
        4443
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(678310b6b6d9e166ebb87079)",
      "incident_id": 888,
      "date": "2025-01-06",
      "title": "Sydney High Schooler Allegedly Generated Deepfakes of Other Students",
      "description": "A Sydney high school student allegedly used AI platforms to create explicit deepfake images of female classmates, which were then distributed through fake social media accounts. The incident reportedly caused significant distress among the victims, leading to an investigation by Campbelltown city police area command and involvement from the eSafety Commissioner.",
      "deployers": [
        "unknown-sydney-area-high-school-student"
      ],
      "developers": [
        "unknown-deepfake-technology-developers"
      ],
      "harmedParties": [
        "anonymous-sydney-area-high-school-students"
      ],
      "reports": [
        4444
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67831bad14c6beaf302a0484)",
      "incident_id": 889,
      "date": "2025-01-07",
      "title": "Tesla's 'Actually Smart Summon' Feature Reportedly Linked to Multiple Parking Lot Collisions",
      "description": "Tesla's Actually Smart Summon feature, a remote parking system controlled via a smartphone app, reportedly failed to detect obstacles such as cars, walls, and parking signs, resulting in at least 16 collision incidents. The NHTSA is investigating safety concerns, including delayed user response times, potential overreliance on camera-only navigation, and noncompliance with crash reporting rules.",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "tesla-users"
      ],
      "reports": [
        4450,
        4451
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67831fa787f0fd9c99e8dfc2)",
      "incident_id": 890,
      "date": "2025-01-08",
      "title": "AI-Generated Images of the Iconic Hollywood Sign Reportedly on Fire Circulating on Social Media",
      "description": "During the January 2025 Southern California wildfires, AI-generated images of the iconic Hollywood Sign being on fire circulated on social media. ",
      "deployers": [
        "social-media-users"
      ],
      "developers": [
        "unknown-ai-image-generator-technology-developers"
      ],
      "harmedParties": [
        "southern-california-residents"
      ],
      "reports": [
        4452,
        4461
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(678325caf997cd6c8ec37948)",
      "incident_id": 891,
      "date": "2025-01-08",
      "title": "AI Voice Scam Targets Westchester Parents with Fake Kidnapping Ransom Calls",
      "description": "Scammers used AI voice synthesis to mimic children’s voices in fake kidnapping calls, demanding ransom payments from parents in the Peekskill School District of Westchester, New York. The synthetic voices were reportedly generated from social media voice samples",
      "deployers": [
        "scammers"
      ],
      "developers": [
        "unknown-voice-cloning-technology-developer"
      ],
      "harmedParties": [
        "westchester-new-york-families",
        "peekskill-school-district-families"
      ],
      "reports": [
        4454,
        4455,
        4456,
        4457,
        4458,
        4463,
        4482
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67832aa69e0b3926cf4b6c56)",
      "incident_id": 892,
      "date": "2024-08-05",
      "title": "Apple Intelligence Allegedly Flags Scam Messages as High Priority",
      "description": "Apple’s AI notification summarization and prioritization feature, part of the Apple Intelligence update, has reportedly flagged scam and phishing messages as high-priority, and is allegedly misleading users into trusting fraudulent communications. By rephrasing and condensing messages, the system is allegedly amplifying scam risks inadvertently and reportedly increasing the likelihood of financial harm for users.",
      "deployers": [
        "apple"
      ],
      "developers": [
        "apple"
      ],
      "harmedParties": [
        "apple-users",
        "apple-intelligence-users"
      ],
      "reports": [
        4459,
        4483,
        4484,
        4485,
        4486
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6784250ea4d9d8780bfa56bf)",
      "incident_id": 893,
      "date": "2025-01-09",
      "title": "Pennsylvania State Police Officer Allegedly Used Work Computer for AI-Generated Pornography",
      "description": "A Pennsylvania State Police corporal, Stephen Kamnik, was charged for allegedly using a work computer to store thousands of pornographic files, including content created with deepfake AI software.",
      "deployers": [
        "stephen-kamnik"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "victims-whose-images-were-manipulated",
        "pennsylvania-state-police"
      ],
      "reports": [
        4464,
        4465,
        4466,
        4467,
        4468,
        4469,
        4470
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6784812e0ccfa9bc396ecd01)",
      "incident_id": 894,
      "date": "2017-01-01",
      "title": "RealPage's YieldStar Allegedly Facilitated Rent Price Coordination Among Canadian Landlords",
      "description": "RealPage’s YieldStar algorithm is alleged to have enabled Canadian landlords to coordinate rental pricing by utilizing sensitive, non-public market data. The software has been accused of contributing to rent increases in non-rent-controlled units through purported collusion and artificial price inflation. Tenants have reported significant rent hikes, which they attribute to landlords' use of the algorithm.",
      "deployers": [
        "woodbourne-capital-management-international-lp",
        "tribute-communities",
        "the-rockport-group",
        "tas-impact",
        "riocan-living",
        "rhapsody-property-management-services-llp",
        "gwl-realty-advisors-residential-inc.",
        "first-capital-real-estate-investment-trust",
        "edgar-development-corp.",
        "dream-unlimited-corp.",
        "core-development-group-ltd.",
        "choice-properties-real-estate-investment-trust",
        "canadian-property-managers-using-yieldstar"
      ],
      "developers": [
        "realpage"
      ],
      "harmedParties": [
        "tenants-in-canada",
        "renters-in-canada",
        "public-trust-in-the-rental-market",
        "low-income-tenants-in-canada",
        "cynthia-black"
      ],
      "reports": [
        4472,
        4473,
        4474,
        4475,
        4476,
        4477,
        4478
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67849374e8b3056f6145fa3a)",
      "incident_id": 895,
      "date": "2025-01-06",
      "title": "Alleged Deepfake of New Zealand Endocrinologist Reportedly Promotes Misleading Diabetes Claim",
      "description": "A video circulated on social media that appeared to feature University of Otago endocrinologist Sir Jim Mann allegedly promoting a hemp gummy product for diabetes patients and urging them to stop using metformin. The video was reportedly generated using AI and has been described as spreading manipulated visuals and speech presenting false medical advice.",
      "deployers": [
        "scammers",
        "fraudsters"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "new-zealand-general-public",
        "jim-mann",
        "diabetes-patients"
      ],
      "reports": [
        4487,
        4488
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6789379a5a8f8e61c36ad29c)",
      "incident_id": 896,
      "date": "2025-01-13",
      "title": "Alleged Misuse of Facial Recognition Technology by Law Enforcement Reportedly Leading to Wrongful Arrests and Violations of Investigative Standards",
      "description": "Law enforcement agencies across the U.S. have allegedly been misusing AI-powered facial recognition technology, leading to wrongful arrests and significant harm to at least eight individuals. Officers have reportedly been bypassing investigative standards, relying on uncorroborated AI matches to build cases, allegedly resulting in prolonged detentions, reputational damage, and personal trauma.",
      "deployers": [
        "florence-kentucky-police-department",
        "evansville-indiana-police-department",
        "detroit-police-department",
        "coral-springs-florida-police-department",
        "bradenton-florida-police-department",
        "austin-police-department"
      ],
      "developers": [
        "developers-of-mugshot-recognition-software",
        "developers-of-law-enforcement-facial-recognition-software",
        "clearview-ai"
      ],
      "harmedParties": [
        "wrongfully-arrested-individuals",
        "vulnerable-communities",
        "robert-williams",
        "quran-reid",
        "porcha-woodruff",
        "people-of-color",
        "nijeer-parks",
        "jason-vernau",
        "christopher-gatlin",
        "black-people",
        "alonzo-sawyer"
      ],
      "reports": [
        4489
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67893eed1837e41488190c9e)",
      "incident_id": 897,
      "date": "2025-01-10",
      "title": "AI-Assisted Ransomware Campaign by FunkSec Allegedly Targets Over 80 Victims",
      "description": "The FunkSec ransomware group allegedly leveraged AI tools, such as Miniapps chatbots, to develop and refine its ransomware operations, which is reported to have allowed apparently inexperienced actors to produce advanced malware rapidly.  It is reported that the group claimed to have launched its data leak site in December 2024, allegedly targeting over 80 victims with ransomware and double extortion tactics. AI reportedly supported the creation of detailed code comments in order to refine the group's technical presentation, while also allegedly facilitating the rapid iteration of its custom encryptor written in Rust.",
      "deployers": [
        "funksec",
        "scorpion",
        "desertstorm",
        "el_farado",
        "blako",
        "xtn",
        "bjorka"
      ],
      "developers": [
        "funksec"
      ],
      "harmedParties": [
        "funksec-ransomware-targets"
      ],
      "reports": [
        4490,
        4491,
        4492,
        4493,
        4500
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67894c686c273f302402d7fb)",
      "incident_id": 898,
      "date": "2024-05-06",
      "title": "Alleged LLMjacking Targets AI Cloud Services with Stolen Credentials",
      "description": "Attackers reportedly exploited stolen cloud credentials obtained through a vulnerable Laravel system (CVE-2021-3129) to allegedly abuse AI cloud services, including Anthropic’s Claude and AWS Bedrock, in a scheme referred to as “LLMjacking.” The attackers are said to have monetized access through reverse proxies, reportedly inflating victim costs to as much as $100,000 per day. Additionally, they allegedly bypassed sanctions, enabled LLM models, and evolved techniques to evade detection and logging.",
      "deployers": [
        "llmjacking-attackers-exploiting-laravel",
        "entities-engaging-in-russian-sanctions-evasion"
      ],
      "developers": [
        "oai-reverse-proxy-tool-creators",
        "llmjacking-reverse-proxy-tool-creators"
      ],
      "harmedParties": [
        "laravel-users",
        "laravel-cve-2021-3129-users",
        "cloud-llm-users",
        "cloud-llm-service-providers"
      ],
      "reports": [
        4494,
        4495
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(678978491df9a69a1c2cca9c)",
      "incident_id": 899,
      "date": "2024-12-17",
      "title": "Character.ai Chatbots Allegedly Emulating School Shooters and Their Victims",
      "description": "Some Character.ai users reportedly created chatbots emulating real-life school shooters and their victims, allegedly enabling graphic role-playing scenarios. Character.ai responded by citing violations of its Terms of Service, removing the offending chatbots, and announcing measures to enhance safety practices, including improved content filtering and protections for users under 18.",
      "deployers": [
        "character.ai-users"
      ],
      "developers": [
        "character.ai"
      ],
      "harmedParties": [
        "character.ai-users",
        "victims-of-school-shootings",
        "families-of-the-victims-of-school-shootings"
      ],
      "reports": [
        4496,
        4497
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67897b351df9a69a1c2ccaa7)",
      "incident_id": 900,
      "date": "2024-11-13",
      "title": "Character.ai Has Allegedly Been Hosting Openly Predatory Chatbots Targeting Minors",
      "description": "Character.ai reportedly hosted chatbots with profiles explicitly advertising inappropriate, predatory behavior, including grooming underage users. Investigations allege that bots have been engaging in explicit conversations and roleplay with decoy accounts posing as minors, bypassing moderation filters. Character.ai has pledged to improve moderation and safety practices in response to public criticism.",
      "deployers": [
        "character.ai-users"
      ],
      "developers": [
        "character.ai"
      ],
      "harmedParties": [
        "character.ai-users"
      ],
      "reports": [
        4499
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(678ae82bf4d4d1ab1c008fc0)",
      "incident_id": 901,
      "date": "2025-01-12",
      "title": "Yahoo Boys Allegedly Used Deepfake Technology to Impersonate Brad Pitt and Defraud French Woman of $850,000 in Romance Scam",
      "description": "Three Nigerian Yahoo Boys scammers allegedly used AI-generated image manipulation tools, along with fake social media and WhatsApp accounts, to reportedly impersonate actor Brad Pitt and convince a French interior decorator, Anne, that she was in a romantic relationship with him. Over 18 months, they allegedly fabricated selfies and messages, reportedly leading Anne to divorce her husband and transfer $850,000 under the false pretense that Pitt needed money for kidney treatment while his accounts were frozen.",
      "deployers": [
        "yahoo-boys",
        "scammers-impersonating-brad-pitt",
        "brouteurs"
      ],
      "developers": [
        "unknown-deepfake-technology-developers"
      ],
      "harmedParties": [
        "general-public-susceptible-to-ai-enhanced-scams",
        "brad-pitt",
        "anne-(french-interior-decorator)"
      ],
      "reports": [
        4501,
        4502,
        4503,
        4504,
        4505,
        4506,
        4507,
        4508,
        4612,
        4613,
        4629,
        4630,
        4746,
        5003
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(678af3d59f8e801c04297371)",
      "incident_id": 902,
      "date": "2025-01-15",
      "title": "Prime Minister of Thailand Paetongtarn Shinawatra Claims AI Voice Scam Impersonated ASEAN Leader Requesting Money",
      "description": "Thailand's Prime Minister Paetongtarn Shinawatra reported being targeted by an AI-generated voice scam that mimicked a well-known but undisclosed ASEAN leader. The scam is alleged to have involved a realistic voice message requesting a donation, falsely claiming Thailand was the only ASEAN nation yet to contribute.",
      "deployers": [
        "scammers",
        "fraudsters"
      ],
      "developers": [
        "unknown-ai-voice-cloning-developer"
      ],
      "harmedParties": [
        "paetongtarn-shinawatra",
        "general-public-of-thailand",
        "asean"
      ],
      "reports": [
        4509,
        4510,
        4511,
        4512,
        4513,
        4514
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(678d742e23d462d52b2c1c91)",
      "incident_id": 903,
      "date": "2022-04-15",
      "title": "Northern Ireland MLA Cara Hunter Allegedly Targeted by Deepfake Pornography Ahead of May 2022 Assembly Election",
      "description": "Sometime in April 2022, reportedly some weeks before the May 5, 2022 Northern Ireland Assembly election, Member of the Legislative Assembly Cara Hunter was targeted in a deepfake pornography incident. A fake video depicting her in explicit scenarios is reported to have circulated widely on WhatsApp. Law enforcement have as of yet been unable to trace the origins of the video, according to reports. Additionally, it is alleged that about six months after the initial incident, she was the target of at least 15 more AI-generated deepfakes depicting her likeness in underwear.",
      "deployers": [
        "unknown-deepfake-creator"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "voters-in-northern-ireland",
        "electoral-integrity",
        "east-londonderry-constituents",
        "democracy",
        "cara-hunter"
      ],
      "reports": [
        4518,
        4519,
        4520,
        4521,
        4522,
        4523,
        4524,
        4527,
        4528,
        4529,
        4530,
        4576,
        4592,
        4593,
        4594,
        4607,
        4677
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(678d896e37ccfbcded98ace8)",
      "incident_id": 904,
      "date": "2022-10-21",
      "title": "Kate Isaacs, Advocate Against Image-Based Abuse, Reports Being Deepfaked",
      "description": "Kate Isaacs, a London-based activist and founder of the #NotYourPorn campaign, was targeted in a deepfake incident. Her face was alleged to have been digitally manipulated onto a pornographic video using AI and shared online. The reported video, tagged with her name, is alleged to have led to streams of abuse, doxing, and threats of violence. The attack reportedly followed her efforts to pressure PornHub to remove unverified content.",
      "deployers": [
        "unknown-twitter-user"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "kate-isaacs"
      ],
      "reports": [
        4531,
        4532,
        4533,
        4534,
        4535,
        4536,
        4537,
        4608
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(678ed447a18d2e507f65af20)",
      "incident_id": 905,
      "date": "2024-07-01",
      "title": "Scammers Allegedly Use Deepfake Technology to Pose as Leonor, Princess of Asturias, in Fraud Scheme",
      "description": "Scammers have allegedly been using deepfake technology and fake social media accounts to reportedly impersonate Leonor, Princess of Asturias, targeting vulnerable individuals in Latin America. Victims were reportedly lured with promises of financial aid, requiring payments for fees or taxes before receiving funds, only to allegedly be defrauded repeatedly. TikTok accounts with thousands of followers reportedly amplified the scheme using AI to increase the appearance of credibility.",
      "deployers": [
        "tiktok-scammers",
        "scammers-posing-as-leonor-(princess-of-asturias)",
        "fraudsters"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "vulnerable-people-in-latin-american-countries",
        "juana-cobo",
        "financially-distressed-individuals"
      ],
      "reports": [
        4580,
        4581,
        4582,
        4583
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(679114fdbd686f9632097291)",
      "incident_id": 906,
      "date": "2024-10-08",
      "title": "Alleged AI-Powered Call Center Breach Exposes Over 10 Million Conversations in the Middle East",
      "description": "An AI-powered call center platform in the Middle East reportedly experienced a significant data breach, allegedly exposing over 10 million conversations between consumers, operators, and AI agents. Attackers allegedly accessed the platform’s management dashboard, stealing sensitive data, including national ID documents. The breach poses reported risks such as phishing, identity theft, and social engineering attacks. The stolen data was reportedly listed for sale on the dark web.",
      "deployers": [
        "cybercriminals"
      ],
      "developers": [
        "unnamed-ai-call-center-platform-provider"
      ],
      "harmedParties": [
        "enterprise-clients",
        "end-users-of-undisclosed-middle-eastern-ai-powered-cloud-call-center-platform"
      ],
      "reports": [
        4585,
        4586,
        4587
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(679288a257648e2ee0a471de)",
      "incident_id": 907,
      "date": "2024-07-15",
      "title": "Taranaki, New Zealand Resident Allegedly Defrauded of $224K in Bitcoin Scam Using Deepfake of Prime Minister Christopher Luxon",
      "description": "A Taranaki, New Zealand resident allegedly lost $224,000 in a Bitcoin scam involving a deepfake video reportedly depicting Prime Minister Christopher Luxon. The AI-generated video, shared on Facebook, purportedly promoted cryptocurrency investments targeting superannuitants. Scammers posing as financial advisers reportedly gained remote access to the victim’s computer and created accounts to facilitate the transfer of funds.",
      "deployers": [
        "scammers-posing-as-christopher-luxon",
        "scammers"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "superannuitants",
        "pensioners",
        "new-zealanders",
        "jill-creasy",
        "elderly-investors"
      ],
      "reports": [
        4588,
        4589,
        4590
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6792939357648e2ee0a471ee)",
      "incident_id": 908,
      "date": "2020-07-15",
      "title": "Deepfake Images of Australian Teacher Hannah Grundy and 25 Others Created and Circulated Online by Former Friend",
      "description": "Australian teacher Hannah Grundy discovered her face had been superimposed onto pornographic images using AI deepfake technology, which were shared online alongside personal details. A former trusted friend, Andrew Thomas Hayler, was found responsible, targeting 26 women, including Grundy and close friends, over two years. Hayler pleaded guilty to multiple charges and was sentenced to nine years in prison. ",
      "deployers": [
        "andrew-thomas-hayler"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "hannah-grundy",
        "colleagues-of-hannah-grundy",
        "former-friends-and-acquaintances-of-andrew-thomas-hayler"
      ],
      "reports": [
        4591,
        4597,
        4598,
        4599,
        4600,
        4601,
        4602,
        4603,
        4604
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6795a15f562dedd3a8bb3d6b)",
      "incident_id": 909,
      "date": "2024-12-13",
      "title": "Matryoshka Campaign Allegedly Uses Deepfakes to Impersonate Academics for Pro-Russian Propaganda",
      "description": "The Matryoshka disinformation campaign allegedly used AI to impersonate academics, reportedly spreading claims supporting Russia and urging Ukraine's surrender. These videos are said to have misrepresented scholars’ views in order to amplify pro-Russian propaganda. The campaign reportedly exploited global social media platforms to allegedly mislead viewers and undermine trust in credible academic voices while fueling misinformation about the Ukraine conflict.",
      "deployers": [
        "russian-entities-linked-to-gru",
        "reliable-russian-news",
        "matryoshka"
      ],
      "developers": [
        "unknown-deepfake-technology-developers"
      ],
      "harmedParties": [
        "ronald-hutton",
        "academics-targeted-by-matryoshka"
      ],
      "reports": [
        4595,
        4596,
        4606
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6795b116c7be9c2fa399696c)",
      "incident_id": 910,
      "date": "2025-01-15",
      "title": "Alleged AI-Driven Phishing Scam Impersonates Maine Town Official to Falsely Request $22,500",
      "description": "An alleged AI-generated phishing email targeted a resident of Gray, Maine, falsely claiming to be from the town’s planning department. The alleged email, bearing a fake signature and official-looking letterhead, requested $22,500 for a zoning board meeting. Town officials have reportedly warned residents of increasing risks posed by AI-enabled scams, emphasizing that the town does not accept electronic payments and urging vigilance against similar fraudulent emails.",
      "deployers": [
        "unknown-scammers",
        "unknown-fraudsters"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "town-of-gray-maine-officials",
        "steven-souchek",
        "residents-of-gray-maine",
        "general-public",
        "doug-webster"
      ],
      "reports": [
        4605
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6797bec3c93e06b86bcc07c8)",
      "incident_id": 911,
      "date": "2022-05-01",
      "title": "Yahoo Boys Allegedly Employ Real-Time Deepfake Technology in Romance Scams",
      "description": "Scammers from Nigeria, known as Yahoo Boys, are reportedly utilizing real-time deepfake technology to impersonate individuals during video calls, deceiving victims in romance scams. By allegedly altering their appearance with face-swapping software, they build trust under false identities to defraud targets of substantial sums.",
      "deployers": [
        "yahoo-boys",
        "scammers-in-nigeria",
        "brouteurs"
      ],
      "developers": [
        "unknown-deepfake-technology-developers"
      ],
      "harmedParties": [
        "targets-of-the-yahoo-boys",
        "targets-of-scammers-in-nigeria",
        "targets-of-romance-scams",
        "targets-of-brouteurs"
      ],
      "reports": [
        4614
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6797e04832f0db1b8c196bdc)",
      "incident_id": 912,
      "date": "2024-11-21",
      "title": "Yahoo Boys and Scammers from Morocco Allegedly Target U.S. Widows and Vulnerable Individuals with 'Artificial Patriot' Scams",
      "description": "Yahoo Boys (from Nigeria and Ghana) and scammers from Morocco are reportedly targeting U.S. widows and vulnerable individuals using AI-generated images and fake military profiles in Artificial Patriot scams. They have allegedly impersonated military officials such as General Matthew W. McFarlane to gain trust, sharing fabricated backstories and emotional appeals. Once trust is established, they request money through untraceable methods.",
      "deployers": [
        "yahoo-boys",
        "scammers-from-west-africa",
        "scammers-from-nigeria",
        "scammers-from-morocco",
        "scammers-from-ghana",
        "brouteurs"
      ],
      "developers": [
        "unknown-deepfake-technology-developers"
      ],
      "harmedParties": [
        "widows",
        "matthew-w.-mcfarlane",
        "impersonated-american-military-officials",
        "emotionally-vulnerable-individuals",
        "american-widows"
      ],
      "reports": [
        4615,
        4616
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(6797e4a9b0bcfa2701cbf7e2)",
      "incident_id": 913,
      "date": "2025-01-27",
      "title": "Yahoo Boys Allegedly Using AI-Generated News Videos to Blackmail Sextortion Victims",
      "description": "Scammers, allegedly linked to the Yahoo Boys, are using AI-generated news videos to blackmail victims in sextortion schemes. The videos impersonate news organizations, featuring fabricated reports that accuse victims of crimes, including explicit content distribution. Tutorials for creating these clips are reportedly shared on Telegram, with scammers leveraging the fake broadcasts to pressure victims into paying.",
      "deployers": [
        "yahoo-boys",
        "scammers-from-west-africa",
        "scammers-from-nigeria",
        "scammers-from-ghana",
        "brouteurs"
      ],
      "developers": [
        "unknown-deepfake-technology-developers"
      ],
      "harmedParties": [
        "unnamed-victims-in-sextortion-schemes",
        "teenagers-targeted-in-sextortion-scams",
        "news-organizations-impersonated-by-scammers",
        "cnn"
      ],
      "reports": [
        4617
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67a132070333695bc395d1ee)",
      "incident_id": 914,
      "date": "2024-12-26",
      "title": "Alleged Deepfake of Luis Suárez Used to Scam Uruguayans in Fake Investment Scheme",
      "description": "On December 26, 2024, UTE, Uruguay's public utility company, warned of an alleged deepfake video circulating on Instagram, Facebook, and Threads. The video reportedly features manipulated images and voice of footballer Luis Suárez, falsely promoting an investment scheme claiming a 10,400 peso investment could yield 175,000 pesos monthly. It also reportedly uses AI-altered Telemundo footage. UTE urged the public not to share personal data, as the scam links to phishing sites posing as official sources.",
      "deployers": [
        "scammers",
        "fraudsters",
        "braziko"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "ute",
        "uruguayan-general-public",
        "telemundo",
        "luis-suarez",
        "el-pais-(spain)"
      ],
      "reports": [
        4620,
        4621,
        4622,
        4623
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67a420cfaabe482520f61c34)",
      "incident_id": 915,
      "date": "2024-10-28",
      "title": "Alaska Education Department Reportedly Published Policy Featuring Erroneous AI-Generated Citations",
      "description": "In October 2024, Alaska’s Education Commissioner Deena Bishop allegedly used generative AI to draft a school cellphone policy, resulting in reportedly fabricated citations of non-existent studies. The document, which did not disclose AI use, was shared with the state Board of Education, and despite reported corrections, AI-generated errors remained in the final resolution.",
      "deployers": [
        "alaska-department-of-education-and-early-development",
        "deena-bishop"
      ],
      "developers": [
        "unspecified-large-language-model-developers"
      ],
      "harmedParties": [
        "alaskan-education-policymakers",
        "alaskan-students",
        "alaskan-parents-of-students",
        "alaskan-education-system",
        "alaska-board-of-education-members"
      ],
      "reports": [
        4624
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67a425ce776272b386eee96e)",
      "incident_id": 916,
      "date": "2025-01-23",
      "title": "Plymouth, Massachusetts Resident Reportedly Used AI Chatbots CrushOn.ai and JanitorAI to Harass and Intimidate Victims",
      "description": "In January 2025, James Florence Jr. of Plymouth, MA, agreed to plead guilty to cyberstalking charges involving the alleged use of AI tools like CrushOn.ai and JanitorAI. The U.S. Attorney’s Office reports the harassment spanned 2014–2024, though AI-driven tactics reportedly began around 2017. Florence allegedly created deepfake pornographic images, programmed AI chatbots to impersonate victims, distributed doctored content, exposed personal information, and encouraged online harassment.",
      "deployers": [
        "james-florence-jr."
      ],
      "developers": [
        "crushon.ai",
        "janitorai"
      ],
      "harmedParties": [
        "anonymous-university-professor-targeted-by-james-florence-jr.",
        "families-of-victims-targeted-by-james-florence-jr.",
        "six-other-women-and-a-17-year-old-girl-targeted-by-james-florence-jr."
      ],
      "reports": [
        4625,
        4626
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67a42b1e64a1d43ae2da3076)",
      "incident_id": 917,
      "date": "2025-02-05",
      "title": "Alleged Deepfake of Whoopi Goldberg Used in Fake Weight-Loss Supplement Ads on Instagram",
      "description": "Whoopi Goldberg warned viewers of The View about an AI-generated scam using her likeness to promote fraudulent weight-loss products on Instagram. Goldberg stated that she had no involvement with the ads, which falsely depicted her endorsing harmful supplements.",
      "deployers": [
        "unknown-scammers-impersonating-whoopi-goldberg"
      ],
      "developers": [
        "unknown-deepfake-technology-developers"
      ],
      "harmedParties": [
        "whoopi-goldberg",
        "fans-of-whoopi-goldberg",
        "consumers-misled-by-fraudulent-ads",
        "general-public"
      ],
      "reports": [
        4627
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67a4396eef37a0b0389c2e1f)",
      "incident_id": 918,
      "date": "2025-02-04",
      "title": "AI-Aided Scam in Thailand Allegedly Impersonates Police to Defraud 163 Victims",
      "description": "Thai police arrested Ramil Pantawong and Thanawut Kanyaphan for allegedly using AI technology to impersonate police officers in a call scam. Based in Poipet, Cambodia, the gang tricked 163 victims, the most prominent of whom was Thai-British beauty queen Charlotte Austin, who lost 4 million baht (approximately $118,000 USD). Victims were falsely told they were under investigation and instructed to transfer money.",
      "deployers": [
        "thanawut-kanyaphan",
        "ramil-pantawong",
        "poipet-based-scam-gang"
      ],
      "developers": [
        "unknown-deepfake-technology-developers"
      ],
      "harmedParties": [
        "general-public-in-thailand",
        "charlotte-austin",
        "163-victims-of-poipet-based-scam-gang"
      ],
      "reports": [
        4628
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67a51f42c824e9a2ea4e1950)",
      "incident_id": 919,
      "date": "2024-02-06",
      "title": "Russian-Linked Network Allegedly Used Deepfake of Maria Ressa on Facebook and Bing to Promote Cryptocurrency Scam Targeting Filipinos",
      "description": "A Russian-linked scam network allegedly circulated an AI-generated deepfake of journalist Maria Ressa on Facebook and Microsoft Bing. The video reportedly manipulated a 2022 interview to falsely depict Ressa endorsing cryptocurrency. Fraudulent websites impersonating Rappler and CNN Philippines reportedly amplified the scam. Investigators linked the operation to a fraudulent network targeting Filipino audiences. Meta and Microsoft removed the content, but similar scams allegedly continue to resurface.",
      "deployers": [
        "russian-linked-scam-network",
        "td-globus-contract",
        "m1-shop"
      ],
      "developers": [
        "unknown-deepfake-technology-developers",
        "unknown-ai-voice-cloning-developers"
      ],
      "harmedParties": [
        "maria-ressa",
        "rappler",
        "cnn-philippines",
        "filipino-social-media-users",
        "potential-cryptocurrency-scam-victims",
        "public-trust-in-media-institutions"
      ],
      "reports": [
        4631
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67a529151598a708fd6d1865)",
      "incident_id": 920,
      "date": "2025-02-01",
      "title": "Deepfake Scam Falsely Promoted Trump Golden Eagles Project as Investment Opportunity",
      "description": "Reports surfaced of an AI-generated scam falsely promoting the Trump Golden Eagles Project. Deepfake videos of Donald Trump, Bank of America CEO Brian Moynihan, and Elon Musk allegedly claimed that buyers could trade collectible coins for cash or Tesla stock. A Bay Area veteran lost $2,500, reportedly believing he would earn millions. The scam circulated via Telegram, and Bank of America denied any involvement.",
      "deployers": [
        "unknown-scammers-behind-the-trump-golden-eagles-scam",
        "fraudulent-investment-scheme-operators",
        "telegram-based-financial-scam-network"
      ],
      "developers": [
        "unknown-deepfake-technology-developers",
        "unknown-ai-voice-cloning-developers"
      ],
      "harmedParties": [
        "wesley-skelton",
        "bay-area-residents-targeted-by-trump-golden-eagles-scam",
        "public-trust-in-financial-institutions",
        "bank-of-america",
        "tesla",
        "spacex",
        "donald-trump",
        "brian-moynihan",
        "elon-musk"
      ],
      "reports": [
        4632
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67a5302e9d32e4b97be05e52)",
      "incident_id": 921,
      "date": "2025-01-05",
      "title": "Hong Kong Authorities Seize HK$34M in Alleged Deepfake Scam Targeting Victims in Taiwan, Singapore, and Malaysia",
      "description": "Hong Kong police arrested 31 people linked to a deepfake scam syndicate that allegedly defrauded victims in Taiwan, Singapore, and Malaysia. The group used AI-generated images to impersonate wealthy women, training recruits to discuss luxury lifestyles, finance, and cryptocurrency to gain trust. Scammers reportedly persuaded victims to invest in fraudulent schemes, with police intercepting HK$34 million in illicit proceeds.",
      "deployers": [
        "hong-kong-based-deepfake-scam-syndicate"
      ],
      "developers": [
        "unknown-deepfake-technology-developers",
        "unknown-ai-generated-image-creators"
      ],
      "harmedParties": [
        "victims-of-romance-scams-in-taiwan",
        "victims-of-romance-scams-in-singapore",
        "victims-of-romance-scams-in-malaysia",
        "cryptocurrency-investors-defrauded-by-ai-generated-profiles",
        "hong-kong-financial-regulators-investigating-fraud"
      ],
      "reports": [
        4633
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67a53964928454f87928e2c9)",
      "incident_id": 922,
      "date": "2025-02-04",
      "title": "AI Voice Scam Allegedly Defrauds Game and Coffee Store in Havre, Montana",
      "description": "A Montana business, Sugar and Dice, was reportedly targeted by an AI voice scam that cloned the store owner's voice to deceive an employee over the phone. The scammer allegedly spoofed both the owner's and the employee's phone numbers, making the call appear legitimate. Believing he was following his employer’s instructions, the employee unknowingly compromised financial details. The store suffered monetary losses but plans to recover.",
      "deployers": [
        "scammers",
        "fraudsters"
      ],
      "developers": [
        "unknown-voice-cloning-technology-developer"
      ],
      "harmedParties": [
        "sugar-and-dice",
        "kevin-zorn",
        "sugar-and-dice-employee"
      ],
      "reports": [
        4634
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67a8f410ac627b72fae5b672)",
      "incident_id": 923,
      "date": "2025-02-08",
      "title": "Nottingham Gallery Owner Allegedly Defrauded by Deepfake Impersonating Pierce Brosnan, Leading to Business Closure",
      "description": "Nottingham gallery owner Simone Simms was allegedly deceived over many months by a deepfake impersonating actor Pierce Brosnan. Believing she was in direct contact with Brosnan, she reportedly arranged an art exhibition and sold £20,000 in tickets. When the real Brosnan denied involvement, Simms reportedly canceled the event and issued refunds. Despite acting in good faith, she reportedly faced reputational and financial harm, which led to the gallery’s closure in August 2024.",
      "deployers": [
        "scammers",
        "fraudsters",
        "unknown-scammers-impersonating-pierce-brosnan"
      ],
      "developers": [
        "unknown-deepfake-technology-developers"
      ],
      "harmedParties": [
        "simone-simms",
        "long-eaton-gallery",
        "long-eaton-gallery-customers",
        "nottingham-art-community"
      ],
      "reports": [
        4636
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67a947bbab764d3e79420cd8)",
      "incident_id": 924,
      "date": "2025-01-30",
      "title": "Alleged Deepfake Scam Uses BBC Presenter Naga Munchetty’s Image to Promote Fraudulent Investment Scheme",
      "description": "BBC presenter Naga Munchetty was reportedly targeted in an AI-generated scam using deepfake images and fake news articles to promote a fraudulent investment scheme. Scam ads on social media allegedly featured manipulated images of Munchetty and linked to a fake BBC article directing users to a cyber trading website. The BBC legal team is reported to have taken action to remove the fraudulent site.",
      "deployers": [
        "scammers",
        "fraudsters",
        "scammers-impersonating-naga-munchetty"
      ],
      "developers": [
        "unknown-deepfake-technology-developers"
      ],
      "harmedParties": [
        "naga-munchetty",
        "bbc",
        "social-media-users",
        "fans-of-naga-munchetty"
      ],
      "reports": [
        4639,
        4691
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67abae31d7ae30b4bef3cd79)",
      "incident_id": 925,
      "date": "2024-10-15",
      "title": "Alleged License Plate Recognition Errors in Christchurch Lead to Wrongful Parking Fines",
      "description": "An automated license plate recognition (LPR) system at The Landing car park in Christchurch, New Zealand, reportedly issued wrongful fines to dozens of parents dropping off and picking up children. The system allegedly misidentified multiple short visits as prolonged parking, which led to disputed penalties. The operator acknowledged potential errors but continued enforcement.",
      "deployers": [
        "wilson-parking",
        "parking-enforcement-services"
      ],
      "developers": [
        "unknown-license-plate-recognition-developer"
      ],
      "harmedParties": [
        "the-landing-car-park-customers",
        "kindercare-wigram-skies-parents",
        "christchurch-drivers"
      ],
      "reports": [
        4640
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67abfbe508cc5c21d6d60dc2)",
      "incident_id": 926,
      "date": "2020-01-01",
      "title": "Giorgia Meloni Targeted by Deepfake Pornography",
      "description": "In 2020, deepfake pornographic videos falsely depicting Italian Prime Minister Giorgia Meloni were uploaded to a U.S. website and viewed millions of times. At the time, she was leader of the Brothers of Italy but not yet PM. In 2024, now serving as PM, Meloni sued Alessio Scurosu, 40, and his father, Roberto Scurosu, 73, seeking €100,000 in damages. She testified in court, calling the act “a form of violence.”",
      "deployers": [
        "alessio-scurosu",
        "roberto-scurosu"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "giorgia-meloni"
      ],
      "reports": [
        4641,
        4652,
        4653,
        4654,
        4655,
        4656,
        4657,
        4658,
        4659,
        4660,
        4661,
        4662,
        4663,
        4664,
        4665,
        4666,
        4667,
        4668,
        4669,
        4670,
        4671,
        4672
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67ad206ccd37bc2a15a53c61)",
      "incident_id": 927,
      "date": "2025-02-04",
      "title": "Fraudsters Allegedly Use AI-Generated Voice of Italian Defense Minister Guido Crosetto to Scam Business Leaders",
      "description": "In February 2025, scammers allegedly used AI voice cloning to impersonate Italian Defense Minister Guido Crosetto, calling top business leaders and reportedly claiming to need funds to free kidnapped journalists. Massimo Moratti was allegedly the only confirmed victim to send nearly €1M, wiring it to accounts in the Netherlands and Hong Kong before realizing the fraud. The scam involved spoofed government numbers, deepfake audio, and international money laundering networks. Police reportedly froze the funds.",
      "deployers": [
        "unknown-scammers-posing-as-guido-crosetto",
        "scammers"
      ],
      "developers": [
        "unknown-voice-cloning-technology-developer",
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "patrizio-bertelli",
        "massimo-moratti",
        "marco-tronchetti-provera",
        "italian-business-leaders",
        "guido-crosetto",
        "giorgio-armani",
        "essilorluxottica",
        "esselunga",
        "del-vecchio-family",
        "caprotti-family",
        "caltagirone-family",
        "beretta-family",
        "aleotti-family"
      ],
      "reports": [
        4642,
        4643,
        4644,
        4645,
        4646,
        4647,
        4648,
        4649,
        4650,
        4688,
        4707,
        4708,
        4709,
        4710,
        4711,
        4712,
        4713,
        4714,
        4715,
        4716,
        4717,
        4718,
        4719,
        4720,
        4721
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67ad4513fe746a964183748f)",
      "incident_id": 928,
      "date": "2024-12-12",
      "title": "Deepfake Cryptocurrency Scam Allegedly Impersonates Italian President Sergio Mattarella and Prime Minister Giorgia Meloni",
      "description": "A deepfake scam allegedly impersonating Italian President Sergio Mattarella and Prime Minister Giorgia Meloni circulated on various platforms. It reportedly promoted a fraudulent cryptocurrency investment scheme. The deepfakes claimed the scheme was state-backed, promising €40,000 in guaranteed income. Victims were urged to invest €250, only to lose access to funds. Italy’s Consob blocked the deceptive ads and websites, marking the first enforcement of new financial fraud regulations.",
      "deployers": [
        "scammers",
        "unknown-scammers-impersonating-sergio-mattarella-and-giorgia-meloni"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "sergio-mattarella",
        "giorgia-meloni",
        "general-public-of-italy"
      ],
      "reports": [
        4651
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67ae24e23e7203388e09270a)",
      "incident_id": 929,
      "date": "2024-12-06",
      "title": "Sustained AI-Driven Russian Disinformation Campaigns Doppelgänger, Storm-1516, and Matryoshka Reportedly Disrupting German Federal Elections",
      "description": "Leading up to Germany’s February 23, 2025, federal election, the alleged Russian Doppelgänger, Storm-1516, and Matryoshka (Operation Overload) disinformation campaigns have reportedly been deploying AI-generated deepfake videos and fake news sites to spread false claims about German politicians and public figures. AI-powered bots have allegedly been amplifying the content across social media. Researchers suggest the campaign sought to erode trust in Germany’s democratic process. Germany's domestic intelligence agency (BfV) described the scale as unprecedented.",
      "deployers": [
        "storm-1516",
        "russian-government",
        "operation-overload",
        "matryoshka",
        "john-mark-dougan",
        "doppelganger"
      ],
      "developers": [
        "unknown-entities-related-to-doppelganger",
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "unnamed-british-police-officer",
        "unnamed-american-university-presidents",
        "robert-habeck",
        "olaf-scholz",
        "natalie-finch",
        "german-voters",
        "german-politicians",
        "german-federal-election-integrity",
        "general-public-of-germany",
        "friedrich-merz",
        "electoral-integrity",
        "democracy",
        "academics-targeted-by-matryoshka"
      ],
      "reports": [
        4673,
        4674,
        4678,
        4679,
        4680,
        4681,
        4682,
        4685,
        4686,
        4687,
        4689,
        4872,
        4874,
        4898,
        4905,
        4915
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67b003e012e69a052b5d686c)",
      "incident_id": 930,
      "date": "2025-02-12",
      "title": "Alleged Deepfake Video Falsely Depicts Hollywood Stars in AI-Manipulated Protest Against Kanye West",
      "description": "A deepfake video allegedly depicted Scarlett Johansson, Jerry Seinfeld, David Schwimmer, Lisa Kudrow, Steven Spielberg, Adam Sandler, Sacha Baron Cohen, Natalie Portman, Jake Gyllenhaal, Lenny Kravitz, Adam Levine, Drake, Mark Zuckerberg, Jack Black, Mila Kunis, Ben Stiller, and Woody Allen protesting Kanye West’s antisemitic remarks. The video falsely attributed statements to them, using AI to manipulate their likenesses without consent.",
      "deployers": [
        "ori-bejerano",
        "guy-bar",
        "gitam-bbdo"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "scarlett-johansson",
        "jerry-seinfeld",
        "david-schwimmer",
        "lisa-kudrow",
        "steven-spielberg",
        "adam-sandler",
        "sacha-baron-cohen",
        "natalie-portman",
        "jake-gyllenhaal",
        "lenny-kravitz",
        "adam-levine",
        "drake",
        "mark-zuckerberg",
        "jack-black",
        "mila-kunis",
        "ben-stiller",
        "woody-allen"
      ],
      "reports": [
        4675,
        4676,
        4726,
        4727,
        4728,
        4729,
        4730,
        4731,
        4732,
        4733,
        4780,
        5003
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67b00dead39707129ae9409c)",
      "incident_id": 931,
      "date": "2025-01-21",
      "title": "Manipulated TikTok Videos Misrepresent Anti-AfD Protests as Far-Right Rallies",
      "description": "TikTok videos falsely depicted large crowds as chanting pro-AfD slogans by replacing the original audio with manipulated sound. The footage, originally from January 2024 anti-extremism protests, was repurposed in January 2025 to mislead viewers. AI-generated or altered audio was added to create the illusion of far-right support. Fact-checkers confirmed the deception, and the accounts responsible later deleted the content, claiming no intent to spread misinformation.",
      "deployers": [
        "tiktok-user-alice-weidel-fan",
        "tiktok-user-afd-john",
        "afd-supporters"
      ],
      "developers": [
        "unknown-voice-cloning-technology-developer"
      ],
      "harmedParties": [
        "protesters-against-right-wing-extremism-in-germany",
        "general-public-of-germany",
        "german-election-integrity"
      ],
      "reports": [
        4683,
        4684
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67b015e3244ef459f40728d9)",
      "incident_id": 932,
      "date": "2024-12-25",
      "title": "BP New Zealand's License Plate Recognition System Reportedly Misidentified Auckland Driver for Fuel Theft in Whanganui",
      "description": "BP’s license plate recognition system reportedly misidentified Auckland resident Buddhika Rajapakse as responsible for petrol theft in Whanganui. Despite the suspect vehicle being a different make, model, and color, the system allegedly linked Rajapakse’s plate to the thefts. BP has reportedly acknowledged a possible doctored plate but still sent multiple payment requests. Rajapakse has reportedly been forced to contest the claims multiple times.",
      "deployers": [
        "bp-new-zealand"
      ],
      "developers": [
        "unspecified-developer-of-bp's-license-plate-recognition-system"
      ],
      "harmedParties": [
        "drivers-whose-vehicles-are-scanned-by-bp-new-zealand's-license-plate-recognition-system",
        "buddhika-rajapakse"
      ],
      "reports": [
        4690
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67b28f17ce4d505ffadf46f3)",
      "incident_id": 933,
      "date": "2025-02-15",
      "title": "Teenager in Palma de Mallorca Allegedly Generated and Distributed Deepfake Nudes of Five Classmates",
      "description": "A teenager in Palma de Mallorca, Spain allegedly generated deepfake nudes of five classmates, reportedly taking their images from social media and using AI to alter them without their consent. He is reported to have shared the altered images with others.",
      "deployers": [
        "unnamed-adolescent-male-in-palma-de-mallorca"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "unnamed-victims-in-palma-de-mallorca"
      ],
      "reports": [
        4692,
        4693,
        4694,
        4695,
        4696,
        4697,
        4698,
        4699,
        4700,
        4701,
        4702
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67b29c8936c97f1529b5c466)",
      "incident_id": 934,
      "date": "2025-02-10",
      "title": "NHK Terminates AI Translation Service After Geopolitical Naming Error",
      "description": "NHK announced the termination of its AI-powered multilingual subtitle service after an automatic translation error rendered Senkaku Islands as Diaoyu Islands, the Chinese designation. The mistake, discovered on February 10th, 2025 during a news segment, led NHK to deem the service inappropriate. The AI-based subtitles, powered by Google Translate, had been in use since 2020.",
      "deployers": [
        "nhk"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "nhk",
        "government-of-japan",
        "nhk-viewers",
        "public-trust-in-the-media",
        "japan-china-relations"
      ],
      "reports": [
        4703,
        4704
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67b3f85548cbab41dffb10be)",
      "incident_id": 935,
      "date": "2025-02-17",
      "title": "Reported Deepfake of Maltese Prime Minister Robert Abela and Journalist Mark Laurence Zammit Used to Promote Fraudulent Investment",
      "description": "A deepfake scam allegedly used AI-generated audio to mimic Maltese Prime Minister Robert Abela and journalist Mark Laurence Zammit, falsely portraying them as endorsing an investment scheme. The fraudulent video repurposed genuine interview footage from 2022 but replaced the original dialogue with AI-generated voices.",
      "deployers": [
        "scammers",
        "fraudsters",
        "scammers-impersonating-robert-abela-and-mark-laurence-zammit"
      ],
      "developers": [
        "unknown-deepfake-technology-developers",
        "unknown-voice-cloning-technology-developer"
      ],
      "harmedParties": [
        "robert-abela",
        "mark-laurence-zammit",
        "general-public-of-malta"
      ],
      "reports": [
        4705
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67b3fc9342adbd26273bb59f)",
      "incident_id": 936,
      "date": "2024-04-12",
      "title": "Deepfake of Former Prime Minister of Malta Joseph Muscat Allegedly Promotes Nord Invest Scam",
      "description": "A reported doctored video falsely depicts former Maltese Prime Minister Joseph Muscat promoting the crypto platform Nord Invest. The manipulated footage, originally from a 2013 Sky News interview, was overlaid with AI-generated audio to mimic Muscat’s voice endorsing a fraudulent scheme. The video was reportedly shared through Facebook.",
      "deployers": [
        "scammers",
        "fraudsters",
        "unknown-scammers-impersonating-joseph-muscat"
      ],
      "developers": [
        "unknown-deepfake-technology-developer",
        "unknown-voice-cloning-technology-developer"
      ],
      "harmedParties": [
        "joseph-muscat",
        "general-public-of-malta"
      ],
      "reports": [
        4706
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67b4b97cc84e83ccbcc5587d)",
      "incident_id": 937,
      "date": "2025-02-10",
      "title": "Bolivian Criminal Network Allegedly Used Deepfake of Education Minister to Defraud at Least 19 Victims in Employment Scam",
      "description": "A Bolivian criminal network allegedly used AI-generated deepfake audio of Education Minister Omar Véliz Ramos to impersonate him in phone calls, defrauding at least 19 victims in a fake job scheme. Scammers reportedly lured applicants via social media, used cloned voices for credibility, and demanded payment via QR codes. Authorities uncovered the scheme, seizing devices and arresting multiple suspects, including one orchestrating the fraud from prison. Losses reportedly exceed $720,000 USD.",
      "deployers": [
        "scammers",
        "fraudsters",
        "scammers-impersonating-omar-veliz-ramos",
        "alfredo-ch.-s.",
        "vilma-c.c.",
        "luis-g.c.",
        "jackelin-a.m.",
        "mariana-a.s."
      ],
      "developers": [
        "unknown-deepfake-technology-developer",
        "unknown-voice-cloning-technology-developer"
      ],
      "harmedParties": [
        "omar-veliz-ramos",
        "ministry-of-education-of-bolivia",
        "at-least-19-bolivian-citizens-seeking-employment",
        "general-public-of-bolivia",
        "unnamed-servicio-departamental-de-salud-(sedes)-potosi-official"
      ],
      "reports": [
        4722,
        4723,
        4724,
        4725
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67b78cb7df28553b81b09df5)",
      "incident_id": 938,
      "date": "2025-02-01",
      "title": "AI-Assisted Impersonation of Martin Henderson in Romance Scam Leads to Reported NZ$375,000 Fraud",
      "description": "An alleged online romance scam exploiting AI-assisted impersonation defrauded a woman, Lea, of NZ$375,000 over two years. The scammer used AI-generated voice messages and deceptive text communication to pose as New Zealand actor Martin Henderson and built up a relationship beginning in early 2023. The victim, believing the scam was real, reportedly relocated to New Zealand in December 2024, only discovering the fraud in February 2025.",
      "deployers": [
        "unknown-scammer-impersonating-martin-henderson",
        "unknown-scammer"
      ],
      "developers": [
        "unknown-voice-cloning-technology-developer",
        "unknown-large-language-model-developer",
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "martin-henderson",
        "lea-(pseudonym)"
      ],
      "reports": [
        4734,
        4735,
        4737,
        4744,
        4745,
        4747
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67b8bdcb7239fa697bd8c88f)",
      "incident_id": 939,
      "date": "2025-02-21",
      "title": "AI-Powered Chinese Surveillance Campaign 'Peer Review' Used for Real-Time Monitoring of Anti-State Speech on Western Social Media",
      "description": "OpenAI reportedly uncovered evidence of a Chinese state-linked AI-powered surveillance campaign, dubbed Peer Review, designed to monitor and report anti-state speech on Western social media in real time. The system, believed to be built on Meta’s open-source Llama model, was detected when a developer allegedly used OpenAI’s technology to debug its code. OpenAI also reportedly identified disinformation efforts targeting Chinese dissidents and spreading propaganda in Latin America.",
      "deployers": [
        "chinese-state-linked-actors",
        "chinese-communist-party"
      ],
      "developers": [
        "various-open-source-ai-developers",
        "meta",
        "chinese-state-security-researchers",
        "openai"
      ],
      "harmedParties": [
        "western-social-media-communities",
        "social-media-users-in-latin-america",
        "social-media-users",
        "opposition-voices-against-the-chinese-communist-party",
        "chinese-dissidents",
        "cai-xia"
      ],
      "reports": [
        4736,
        4739,
        4740,
        4741,
        4742,
        4743
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67b94325c4cccea4c023da27)",
      "incident_id": 940,
      "date": "2025-02-17",
      "title": "Tesla Cybertruck Operating in Full Self-Driving Mode Reportedly Crashes into Pole in Nevada After Failing to Merge",
      "description": "A Tesla Cybertruck operating in Full Self-Driving (FSD) mode reportedly crashed into a pole in Reno, Nevada, after failing to merge out of a lane that was ending. The driver, who was required to remain in control, stated that unknown mechanical issues caused the vehicle to leave the lane. ",
      "deployers": [
        "tesla"
      ],
      "developers": [
        "tesla"
      ],
      "harmedParties": [
        "jonathan-challinger",
        "tesla-drivers",
        "motorists"
      ],
      "reports": [
        4738,
        4760,
        4761,
        4762,
        4763,
        4764,
        4765,
        4766
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67ba0942d90129c0b9f0b493)",
      "incident_id": 941,
      "date": "2025-02-17",
      "title": "AI-Driven Phishing Scam Uses Deepfake Robocalls to Target Gmail Users in Credential Theft Campaign",
      "description": "A sophisticated AI-powered phishing scam has reportedly been targeting between 1.8 to 2.5 billion Gmail users, allegedly using deepfake robocalls and phishing emails to steal credentials. Attackers impersonate Google security. They claim suspicious account activity and direct victims to fake Google login pages. The stolen credentials have reportedly been used for identity theft, banking fraud, and session hijacking. The FBI has urged vigilance as AI increases the scale and effectiveness of such attacks.",
      "deployers": [
        "unknown-scammers",
        "unknown-cybercriminals",
        "scammers-impersonating-google-employees"
      ],
      "developers": [
        "unknown-deepfake-technology-developer",
        "unknown-ai-tool-providers"
      ],
      "harmedParties": [
        "google-users",
        "gmail-users"
      ],
      "reports": [
        4748,
        4749,
        4750,
        4751,
        4752,
        4753,
        4754,
        4755,
        4756,
        4757,
        4758,
        4759,
        4767
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67ba6753fce0b0426b715fca)",
      "incident_id": 942,
      "date": "2025-02-20",
      "title": "Cybercriminals Reportedly Exploited Google’s G.Co Subdomain and Spoofed Caller ID in AI-Driven Phishing Attack on Hack Club Founder",
      "description": "Hack Club founder Zach Latta was reportedly targeted in an AI-assisted phishing attack exploiting Google’s own systems. Cybercriminals allegedly spoofed a legitimate Google Assistant number and used voice cloning to impersonate support staff, claiming unusual login activity from Frankfurt. They reinforced the deception by sending a real email from Google’s Workspace domain. The attack, which relied on Google’s g.co subdomain, was thwarted when inconsistencies raised Latta’s suspicions.",
      "deployers": [
        "voice-phishers",
        "scammers-impersonating-google-staff",
        "scammers",
        "fraudsters"
      ],
      "developers": [
        "unknown-voice-cloning-technology"
      ],
      "harmedParties": [
        "zach-latta",
        "google-users"
      ],
      "reports": [
        4768,
        4769,
        4770,
        4771,
        4772,
        4773,
        4774,
        4775
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67ba7650170ce59906129760)",
      "incident_id": 943,
      "date": "2025-02-20",
      "title": "Nonconsensual Explicit AI-Generated Images of Up to 60 Gladstone Park Secondary College Students in Victoria, Australia, Reportedly Created and Circulated Online",
      "description": "AI-generated explicit images of up to 60 female students at Gladstone Park Secondary College in Victoria, Australia, were reportedly created and circulated online. The images were reportedly altered from formal school photos using AI tools to produce nonconsensual explicit content. Two Year 11 students have been suspended, but the full number of individuals involved remains unclear as the investigation is ongoing.",
      "deployers": [
        "two-unidentified-year-11-students-at-gladstone-park-secondary-college"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "up-to-60-unnamed-students-at-gladstone-park-secondary-college",
        "gladstone-park-secondary-college-students",
        "families-of-gladstone-park-secondary-college-students",
        "gladstone-park-secondary-college"
      ],
      "reports": [
        4776
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67ba7ec9a3671d2a2d6b4d2d)",
      "incident_id": 944,
      "date": "2025-02-20",
      "title": "Kenya’s Foreign Affairs Principal Secretary Korir Sing’Oei Shares AI-Generated CNN Video Falsely Featuring Fareed Zakaria on Sudan Diplomacy",
      "description": "Kenya’s Foreign Affairs Principal Secretary (PS) Dr. Korir Sing’Oei shared an AI-generated deepfake video that falsely depicted CNN journalist Fareed Zakaria praising Kenya’s peace diplomacy in Sudan. The fake CNN broadcast was widely criticized for spreading AI-generated misinformation. After backlash from the public and journalists on X (Twitter), Sing’Oei deleted the video, but there were reportedly concerns that Kenya’s diplomatic credibility was undermined.",
      "deployers": [
        "korir-sing'oei",
        "unknown-deepfake-creator"
      ],
      "developers": [
        "unknown-deepfake-technology-developer",
        "unknown-voice-cloning-technology-developer"
      ],
      "harmedParties": [
        "fareed-zakaria",
        "cnn",
        "government-of-kenya",
        "general-public-of-kenya",
        "korir-sing'oei",
        "ministry-of-foreign-affairs-of-kenya"
      ],
      "reports": [
        4777,
        4778
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67ba838aa3671d2a2d6b4d40)",
      "incident_id": 945,
      "date": "2025-02-19",
      "title": "Two 16-Year-Old Students in Athens, Greece Allegedly Generated Nonconsensual Deepfake Pornography of Their Classmates",
      "description": "In Athens, Greece, two 16-year-old students were arrested for allegedly generated nonconsensual deepfake pornography of their classmates. They reportedly used images taken from social media to create the explicit images, which they are then reported to have disseminated online to others. The parents of the students were reportedly also arrested for neglecting to supervise their behavior.",
      "deployers": [
        "two-unnamed-16-year-old-students-in-athens"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "students-at-a-high-school-in-athens",
        "families-of-students-at-a-high-school-in-athens"
      ],
      "reports": [
        4779
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67bbea21fd35da1b28cd5a67)",
      "incident_id": 946,
      "date": "2022-01-01",
      "title": "Arizona Residents Reportedly a Frequent Target of AI-Driven Romance Scams",
      "description": "Arizona residents, especially senior citizens, are reportedly often the target of AI-driven romance scams. Between 2022 and 2023, reported losses from online romance scams in Arizona totaled over $47 million, ranking the state fifth highest in the nation behind California, Florida, Texas, and New York, according to FBI Internet Crime Complaint Center data. In 2023, it has been reported that Arizonans lost $325 million owing to these scams.",
      "deployers": [
        "yahoo-boys",
        "scammers",
        "romance-scammers-targeting-arizonans",
        "fraudsters"
      ],
      "developers": [
        "unknown-voice-cloning-technology-developer",
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "senior-citizens-of-arizona",
        "general-public-of-arizona"
      ],
      "reports": [
        4782,
        4783,
        4784,
        4785,
        4786,
        4787,
        4788,
        4789,
        4790,
        4791,
        4792
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67bd2a67ef0679e5cfa1982a)",
      "incident_id": 947,
      "date": "2024-09-25",
      "title": "Two Members of Highline Public Schools Community in King County, Washington Reportedly Targeted in Deepfake Kidnapping Scam",
      "description": "Two members of the Highline Public Schools community in Burien, a town in King County, Washington, were reportedly targeted in a deepfake kidnapping scam. Scammers used AI-generated voice cloning technology to convincingly mimic the voices of their family members. The scammers used the altered voices to falsely claim they had been kidnapped and demanding a ransom be paid.",
      "deployers": [
        "scammers",
        "fraudsters"
      ],
      "developers": [
        "unknown-voice-cloning-technology-developer",
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "highline-public-schools",
        "families-of-highline-public-schools"
      ],
      "reports": [
        4793
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67bd2dda323df2b08780be83)",
      "incident_id": 948,
      "date": "2025-02-23",
      "title": "Alleged FraudGPT-Enabled Phishing Attack Spoofs ChatGPT Subscription Service to Steal Credentials",
      "description": "A reported phishing campaign is impersonating OpenAI’s ChatGPT Premium subscription service, using AI-generated emails to steal user credentials and financial data. Cybercriminals are allegedly sending fraudulent renewal requests urging victims to update payment details, directing them to spoofed OpenAI login pages. ",
      "deployers": [
        "scammers",
        "fraudsters",
        "cybercriminals",
        "phishing-scammers",
        "fraudgpt-operators",
        "dark-web-threat-actors"
      ],
      "developers": [
        "fraudgpt",
        "openai"
      ],
      "harmedParties": [
        "openai-users",
        "chatgpt-premium-subscribers"
      ],
      "reports": [
        4794
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67bf983402ce4cc00e42bad7)",
      "incident_id": 949,
      "date": "2025-02-24",
      "title": "Unauthorized AI-Generated Video of Donald Trump and Elon Musk Reportedly Appears on HUD Building Screens",
      "description": "An unauthorized satirical AI-generated video reportedly depicting President Trump kissing Elon Musk’s feet played on TV screens within the Department of Housing and Urban Development (HUD) building, seemingly mocking their relationship. The video is reported to have included the phrase “Long live the real king,” referencing a recent Truth Social post by Trump.",
      "deployers": [
        "unnamed"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "department-of-housing-and-urban-development-(hud)",
        "donald-trump",
        "elon-musk"
      ],
      "reports": [
        4795
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67bfa2b1c46c66a2cc6f500d)",
      "incident_id": 950,
      "date": "2024-07-11",
      "title": "NullBulge's AI-Powered Malware Allegedly Compromises Disney Employee and Internal Data",
      "description": "A Disney employee, Matthew Van Andel, reportedly downloaded AI-powered malware allegedly developed by the cybercriminal group NullBulge, resulting in a major cybersecurity breach. Hackers purportedly accessed Disney's Slack system, exposing 44 million internal messages, employee and customer data, and financial records. NullBulge also reportedly leaked Van Andel’s personal financial information, leading to identity theft and his eventual termination.",
      "deployers": [
        "nullbulge"
      ],
      "developers": [
        "nullbulge"
      ],
      "harmedParties": [
        "matthew-van-andel",
        "disney-employees",
        "disney"
      ],
      "reports": [
        4796,
        4797
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67bfa7fe02ce4cc00e42bae6)",
      "incident_id": 951,
      "date": "2025-02-24",
      "title": "Character.AI Chatbots Allegedly Impersonating Licensed Therapists and Encouraging Harmful Behaviors",
      "description": "The American Psychological Association (APA) has warned federal regulators that AI chatbots on Character.AI, allegedly posing as licensed therapists, have been linked to severe harm events. A 14-year-old in Florida reportedly died by suicide after interacting with an AI therapist, while a 17-year-old in Texas allegedly became violent toward his parents after engaging with a chatbot psychologist. Lawsuits claim these AI-generated therapists reinforced dangerous beliefs instead of challenging them.",
      "deployers": [
        "character.ai"
      ],
      "developers": [
        "character.ai"
      ],
      "harmedParties": [
        "sewell-setzer-iii",
        "j.f.-(texas-teenager)"
      ],
      "reports": [
        4798,
        4936
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67bfe10f63aae67aa42d1fa0)",
      "incident_id": 952,
      "date": "2025-02-25",
      "title": "Apple’s Voice Dictation Reportedly Substitutes ‘Trump’ for ‘Racist’ Due to Speech Recognition Bug",
      "description": "Apple's iPhone dictation feature reportedly displayed Trump when users dictated the word racist, with a viral video demonstrating the glitch. Apple acknowledged the bug, attributing it to a phonetic overlap in its speech recognition model, though some speculated it could be an internal prank. The company announced an immediate fix.",
      "deployers": [
        "apple"
      ],
      "developers": [
        "apple"
      ],
      "harmedParties": [
        "apple-users",
        "donald-trump"
      ],
      "reports": [
        4801
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67bfe48763aae67aa42d1faa)",
      "incident_id": 953,
      "date": "2024-11-01",
      "title": "Deepfake Videos of Barbara O’Neill Allegedly Used in Health Scam Targeting Social Media Users",
      "description": "Deepfake videos of Barbara O’Neill, an Australian alternative health advocate banned from giving medical advice, have allegedly been used in fraudulent social media ads promoting false health cures. They include treatments for prostate issues and erectile dysfunction. These manipulated videos have been widely circulated across African countries. The scam directs users to deceptive websites, potentially for phishing or financial fraud. O’Neill has denied involvement.",
      "deployers": [
        "scammers",
        "scammers-impersonating-barbara-o'neill"
      ],
      "developers": [
        "unknown-deepfake-technology-developer",
        "unknown-voice-cloning-technology-developer"
      ],
      "harmedParties": [
        "barbara-o'neill",
        "individuals-with-health-problems",
        "citizens-of-various-african-nations",
        "social-media-users"
      ],
      "reports": [
        4802
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67bfecadb3248faa3224ca2a)",
      "incident_id": 954,
      "date": "2025-02-04",
      "title": "Chatbots Allegedly Used in Romance Scams Targeting Nearly One-Third of New Zealand's Dating App Users",
      "description": "A Norton Cyber Safety Insights Report found that nearly one-third of New Zealand dating app users have been targeted by romance scams, with AI chatbots allegedly playing a growing role. The report, based on a January 2025 survey, indicates that 50% of dating app users believed they had interacted with AI-generated messages. Private investigators report cases where victims engage in long-term virtual relationships with fraudsters, often sending money.",
      "deployers": [
        "scammers",
        "fraudsters",
        "romance-scammers-targeting-new-zealanders"
      ],
      "developers": [
        "unknown-large-language-model-developers",
        "unknown-chatbot-developers"
      ],
      "harmedParties": [
        "new-zealand-dating-app-users",
        "romance-scam-victims",
        "financial-fraud-victims"
      ],
      "reports": [
        4803
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67c1120f0a154b24b538fdfa)",
      "incident_id": 955,
      "date": "2024-12-19",
      "title": "Global Cybercrime Network Storm-2139 Allegedly Exploits AI to Generate Deepfake Content",
      "description": "A global cybercrime network, Storm-2139, allegedly exploited stolen credentials and developed custom tools to bypass AI safety guardrails. They reportedly generated harmful deepfake content, including nonconsensual intimate images of celebrities, and their software is reported to have disabled content moderation, hijacked AI access, and resold illicit services. Microsoft disrupted the operation and filed a lawsuit in December 2024, later identifying key members of the network in February 2025.",
      "deployers": [
        "unidentified-storm-2139-actor-from-illinois",
        "unidentified-storm-2139-actor-from-florida",
        "storm-2139",
        "ricky-yuen-(cg-dot)",
        "phat-phung-tan-(asakuri)",
        "arian-yadegarnia-(fiz)",
        "alan-krysiak-(drago)"
      ],
      "developers": [
        "unidentified-storm-2139-actor-from-illinois",
        "unidentified-storm-2139-actor-from-florida",
        "storm-2139",
        "ricky-yuen-(cg-dot)",
        "phat-phung-tan-(asakuri)",
        "arian-yadegarnia-(fiz)",
        "alan-krysiak-(drago)"
      ],
      "harmedParties": [
        "victims-of-deepfake-abuse",
        "openai",
        "microsoft",
        "celebrities",
        "azure-openai-customers",
        "ai-service-providers"
      ],
      "reports": [
        4805,
        4937,
        4938,
        4939,
        4940
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67c2620934cf4fa156b39569)",
      "incident_id": 956,
      "date": "2025-02-28",
      "title": "Alleged Inclusion of 12,000 Live API Keys in LLM Training Data Reportedly Poses Security Risks",
      "description": "A dataset used to train large language models allegedly contained 12,000 live API keys and authentication credentials. Some of these were reportedly still active and allowed unauthorized access. Truffle Security found these secrets in a December 2024 Common Crawl archive, which spans 250 billion web pages. The affected credentials could have been exploited for unauthorized data access, service disruptions, financial fraud, and a variety of other malicious uses.",
      "deployers": [
        "microsoft",
        "openai",
        "common-crawl",
        "microsoft-azure-openai-service"
      ],
      "developers": [
        "common-crawl",
        "openai",
        "microsoft"
      ],
      "harmedParties": [
        "aws",
        "slack",
        "mailchimp",
        "microsoft",
        "google",
        "intel",
        "huawei",
        "paypal",
        "ibm",
        "tencent"
      ],
      "reports": [
        4806
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67c26213d349eef2541e8521)",
      "incident_id": 957,
      "date": "2025-02-28",
      "title": "Alleged Instagram Algorithm Malfunction Floods Users’ Reels Feeds with Violent and Graphic Content",
      "description": "An alleged Instagram algorithm malfunction caused users’ Reels feeds to be overwhelmed with violent and distressing content. Many reported seeing deaths, extreme brutality, and other graphic material in rapid succession, often without prior engagement with similar content. The sudden exposure caused psychological distress for many users, with minors and vulnerable individuals particularly affected by the graphic content. Meta confirmed an AI failure was responsible and apologized.",
      "deployers": [
        "meta"
      ],
      "developers": [
        "meta"
      ],
      "harmedParties": [
        "meta-users",
        "instagram-users",
        "minors"
      ],
      "reports": [
        4807
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67c50516d9d5b601dfef9cff)",
      "incident_id": 958,
      "date": "2025-02-26",
      "title": "Europol Operation Cumberland Investigates at Least 273 Suspects in 19 Countries for AI-Generated Child Sexual Abuse Material",
      "description": "Europol’s Operation Cumberland uncovered a global network distributing AI-generated child sexual abuse material (CSAM). The operation has led to 25 arrests and 273 identified suspects across 19 countries. The AI-enabled abuse allows criminals to create exploitative content at scale with minimal expertise. ",
      "deployers": [
        "suspects-identified-in-operation-cumberland",
        "csam-distributors"
      ],
      "developers": [
        "unknown-deepfake-technology-developer",
        "unknown-deepfake-csam-tools"
      ],
      "harmedParties": [
        "potential-victims-of-exploitation",
        "minors",
        "children"
      ],
      "reports": [
        4808,
        4809,
        4814,
        4815,
        4816,
        4817,
        4818,
        4819,
        4820,
        4821,
        4822
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67c6347b5bf60517258e8c31)",
      "incident_id": 959,
      "date": "2025-03-02",
      "title": "Deepfake Video of Indonesian President Prabowo Subianto and Other Officials Reportedly Used in Scam to Defraud Citizens Across 20 Provinces",
      "description": "A deepfake scam allegedly using AI-generated videos of Indonesian President Prabowo Subianto and other officials reportedly defrauded victims across 20 provinces, tricking them into paying Rp 250,000 to Rp 1 million ($15-$60) for purported financial aid. The fraudulent clips, circulated on TikTok, Instagram, and WhatsApp, appeared to show Prabowo offering assistance. Police reportedly arrested two suspects in February 2025, but deepfake scams exploiting high-profile figures continue to spread.",
      "deployers": [
        "scammers",
        "fraudsters",
        "scammers-impersonating-prabowo-subianto"
      ],
      "developers": [
        "unknown-deepfake-technology-developer",
        "unknown-voice-cloning-technology-developer"
      ],
      "harmedParties": [
        "general-public-of-indonesia",
        "prabowo-subianto",
        "government-of-indonesia",
        "gibran-rakabuming-raka",
        "indonesian-government-officials"
      ],
      "reports": [
        4810,
        4832,
        4833,
        4950
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67c67fb5067703353fb48b64)",
      "incident_id": 960,
      "date": "2025-02-06",
      "title": "Plaintiffs' Lawyers Admit AI Generated Erroneous Case Citations in Federal Court Filing Against Walmart",
      "description": "Lawyers Rudwin Ayala, T. Michael Morgan (Morgan & Morgan), and Taly Goody (Goody Law Group) were fined a total of $5,000 after their Wyoming federal lawsuit filing against Walmart cited fake cases hallucinated by AI. Judge Kelly Rankin sanctioned them, removing Ayala from the case and noting attorneys must verify AI sources. The filing, flagged by Walmart’s legal team, led to its withdrawal and an internal review.",
      "deployers": [
        "taly-goody",
        "t.-michael-morgan",
        "rudwin-ayala",
        "morgan-and-morgan",
        "goody-law-group"
      ],
      "developers": [
        "unspecified-large-language-model-developer"
      ],
      "harmedParties": [
        "taly-goody",
        "t.-michael-morgan",
        "rudwin-ayala",
        "plaintiffs-in-wyoming-walmart-hoverboard-lawsuit",
        "legal-system",
        "judicial-integrity",
        "clients-of-morgan-and-morgan",
        "clients-of-goody-law-group"
      ],
      "reports": [
        4812,
        4813,
        4823,
        4824,
        4825,
        4826,
        4827,
        4828,
        4829,
        4830,
        4831
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67c783dc7501cae91c205085)",
      "incident_id": 961,
      "date": "2024-12-16",
      "title": "Serbian Authorities Allegedly Used AI-Powered Cellebrite Tools to Unlock Journalist’s Phone and Install Spyware",
      "description": "Serbian authorities allegedly used Cellebrite’s AI-powered forensic tools to unlock journalists’ and activists’ phones without consent. They reportedly then installed NoviSpy, a newly discovered spyware. That then purportedly allowed covert data extraction, remote microphone and camera activation, and surveillance. Amnesty International uncovered forensic evidence linking Serbia’s Security Information Agency (BIA) to these attacks. Cellebrite halted sales to Serbia after the report.",
      "deployers": [
        "serbian-security-information-agency-(bia)",
        "serbian-police",
        "government-of-serbia"
      ],
      "developers": [
        "serbian-security-information-agency-(bia)",
        "cellebrite"
      ],
      "harmedParties": [
        "slavisa-milanov",
        "nikola-ristic",
        "krokodil",
        "journalists-in-serbia",
        "human-rights-defenders-in-serbia",
        "environmental-activists-in-serbia",
        "dissidents-in-serbia",
        "civil-society-organizations-in-serbia"
      ],
      "reports": [
        4834,
        4835,
        4836,
        4837,
        4838,
        4839,
        4840
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67c91669104adaa9e49f77dd)",
      "incident_id": 962,
      "date": "2025-03-05",
      "title": "Tbilisi-Based Call Center Allegedly Uses AI-Driven Scripts to Defraud Over 6,000 Victims of $35 Million",
      "description": "A large-scale AI-assisted financial scam, allegedly operated from Tbilisi, Georgia, used deepfake celebrity endorsements and manipulated victims through fraudulent trading dashboards that simulated high returns. Call center agents, trained with AI-driven persuasion tactics, convinced individuals to invest more money while falsely promising profits. Many reportedly lost their life savings, with the total losses reaching $35M across more than 6,000 victims.",
      "deployers": [
        "scammer-operatives-in-georgia-bulgaria-cyprus-and-spain",
        "meri-shotadze",
        "golden-currencies",
        "akaki-kevkhishvili",
        "ak-group",
        "admiralsfx"
      ],
      "developers": [
        "unknown-deepfake-technology-developers",
        "third-party-ai-service-providers-for-call-center-training",
        "fraudulent-trading-platform-developers"
      ],
      "harmedParties": [
        "small-business-owners",
        "retirees-seeking-investment-opportunities",
        "people-with-neurological-disorders",
        "individuals-deceived-by-celebrity-deepfake-impersonations",
        "financial-professionals",
        "financial-fraud-victims",
        "elderly-investors"
      ],
      "reports": [
        4841
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67c99adcb0d70a8e61a5d989)",
      "incident_id": 963,
      "date": "2025-03-05",
      "title": "Google Reports Alleged Gemini-Generated Terrorism and Child Exploitation to Australian eSafety Commission",
      "description": "Google reported to Australia's eSafety Commission that it received 258 complaints globally about AI-generated deepfake terrorism content and 86 about child abuse material made with its Gemini AI. The regulator called this a world-first insight into AI misuse. While Google uses hash-matching to detect child abuse content, it lacks a similar system for extremist material.",
      "deployers": [
        "google"
      ],
      "developers": [
        "google"
      ],
      "harmedParties": [
        "general-public",
        "general-public-of-australia",
        "google-gemini-users",
        "victims-of-deepfake-terrorism-content",
        "victims-of-deepfake-child-abuse",
        "victims-of-online-radicalization"
      ],
      "reports": [
        4842
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67c99f7941e152241591fe06)",
      "incident_id": 964,
      "date": "2025-03-04",
      "title": "AI-Powered 'Insights' Feature for the Los Angeles Times Allegedly Justifies Ku Klux Klan’s History",
      "description": "The Los Angeles Times removed its AI-generated “insights” feature after it is alleged to have produced a defense of the Ku Klux Klan. The AI reportedly framed the hate group as a product of societal change rather than an extremist movement. The AI tool, developed by Perplexity and promoted by owner Patrick Soon-Shiong, was designed to provide “different views” on opinion pieces.",
      "deployers": [
        "los-angeles-times",
        "patrick-soon-shiong"
      ],
      "developers": [
        "perplexity"
      ],
      "harmedParties": [
        "los-angeles-times-readers",
        "los-angeles-times",
        "general-public"
      ],
      "reports": [
        4843
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67c9ad87cddb8d3547e500ea)",
      "incident_id": 965,
      "date": "2025-03-04",
      "title": "Phishers Allegedly Using AI-Generated Video of YouTube CEO Neal Mohan to Target Creators",
      "description": "Scammers are reportedly using an AI-generated deepfake of YouTube CEO Neal Mohan to steal user credentials. The fake video announces false changes to YouTube’s monetization policy, and it then tricks creators into clicking malicious links or downloading malware. The scam spreads through private videos and emails from a fake YouTube address. It exploits platform features to appear legitimate. Victims risk losing account access or exposing sensitive data. ",
      "deployers": [
        "scammers",
        "fraudsters",
        "phishers",
        "scammers-impersonating-neal-mohan"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "youtube-creators",
        "youtube-users",
        "youtube-account-holders"
      ],
      "reports": [
        4844,
        4845,
        4846,
        4847
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67c9be594c773f63300e064d)",
      "incident_id": 966,
      "date": "2024-07-16",
      "title": "Ferrari Executive Targeted by AI Deepfake Scam Impersonating CEO Benedetto Vigna",
      "description": "A Ferrari executive was targeted by an AI-generated deepfake impersonating CEO Benedetto Vigna in an alleged fraud attempt. The scammer, using WhatsApp and a cloned voice, claimed an urgent, secretive financial deal required immediate action. The executive became suspicious after detecting slight artificial intonations; the scam failed when the executive tested the caller by asking about a recent book recommendation.",
      "deployers": [
        "scammers",
        "fraudsters",
        "phishers",
        "scammers-impersonating-benedetto-vigna"
      ],
      "developers": [
        "unknown-deepfake-technology-developer",
        "unknown-voice-cloning-technology-developer"
      ],
      "harmedParties": [
        "unnamed-ferrari-executive",
        "benedetto-vigna",
        "ferrari"
      ],
      "reports": [
        4848
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67c9e555dde2f1eebfb451c1)",
      "incident_id": 967,
      "date": "2025-03-06",
      "title": "Amazon and Google AI Allegedly Promote Mein Kampf as ‘a True Work of Art’ in Search Results",
      "description": "Amazon’s AI-generated review summary allegedly misrepresented customer feedback on Mein Kampf by describing it as “a true work of art.” Google’s search algorithm then surfaced this misleading AI-generated text as a featured snippet, which in turn amplified the error. This incident arose from AI summarizing AI-generated content, in effect creating a self-reinforcing misinformation loop.",
      "deployers": [
        "amazon",
        "google"
      ],
      "developers": [
        "amazon",
        "google"
      ],
      "harmedParties": [
        "general-public"
      ],
      "reports": [
        4852
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67c9ff591a4834c6e87458a9)",
      "incident_id": 968,
      "date": "2022-02-24",
      "title": "'Pravda' Network, Successor to 'Portal Kombat,' Allegedly Seeding AI Models with Kremlin Disinformation",
      "description": "A Moscow-based disinformation network, Pravda, allegedly infiltrated AI models by flooding the internet with pro-Kremlin falsehoods. A NewsGuard audit found that 10 major AI chatbots repeated these narratives 33% of the time, citing Pravda sources as legitimate. The tactic, called LLM grooming, manipulates AI training data to embed Russian propaganda. Pravda is part of Portal Kombat, a larger Russian disinformation network identified by VIGINUM in February 2024, but in operation since February 2022.",
      "deployers": [
        "tigerweb",
        "storm-1516",
        "russian-state-media",
        "pravda-disinformation-network",
        "portal-kombat",
        "john-mark-dougan",
        "government-of-russia"
      ],
      "developers": [
        "you.com",
        "xai",
        "perplexity",
        "openai",
        "mistral",
        "microsoft",
        "meta",
        "inflection",
        "google",
        "anthropic"
      ],
      "harmedParties": [
        "truth",
        "policymakers",
        "media-consumers",
        "journalists",
        "journalism",
        "governments",
        "government-of-ukraine",
        "general-public-of-ukraine",
        "general-public",
        "democracy",
        "chatbot-users"
      ],
      "reports": [
        4853,
        4854,
        4855,
        4856,
        4857,
        4887,
        4888,
        4889,
        4890,
        4891,
        4892,
        4893,
        4894,
        4895,
        4896,
        4922,
        4930,
        4931,
        4946,
        4976,
        4977,
        4978,
        4979,
        4980
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67cb674bac2d0fdf2072f5b6)",
      "incident_id": 969,
      "date": "2024-09-02",
      "title": "Russian Disinformation Campaign Allegedly Used Fake News Site 'KBSF-San Francisco News' and Deepfake Video to Falsely Accuse Kamala Harris of 2011 Hit-and-Run",
      "description": "A Russian disinformation campaign allegedly used a fake news site, KBSF-San Francisco News, and an AI-generated deepfake video to falsely accuse Kamala Harris of a 2011 hit-and-run accident in San Francisco. The deepfake featured a fabricated African-American victim, whose AI-generated testimony spread widely across social media. Microsoft identified the hoax as part of Russian cyber influence operations targeting the 2024 U.S. election, with the site registered in Iceland.",
      "deployers": [
        "government-of-russia",
        "john-mark-dougan",
        "kbsf-san-francisco-news",
        "storm-1516"
      ],
      "developers": [
        "government-of-russia",
        "john-mark-dougan"
      ],
      "harmedParties": [
        "kamala-harris",
        "general-public-of-the-united-states",
        "general-public",
        "democracy",
        "truth",
        "journalism"
      ],
      "reports": [
        4900,
        4901,
        4906,
        4919
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67cb8777e935fa589ac9daec)",
      "incident_id": 970,
      "date": "2025-03-04",
      "title": "Scammers Using Deepfake Technology to Impersonate Prime Minister of Armenia Nikol Pashinyan",
      "description": "Scammers are reportedly using deepfake technology to impersonate Prime Minister Nikol Pashinyan, according to the Personal Data Protection Agency. The video is reported to have circulated from a Russian-language account called Noticias Mundiales (World News).",
      "deployers": [
        "scammers-impersonating-nikol-pashinyan",
        "scammers"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "nikol-pashinyan",
        "general-public-of-armenia"
      ],
      "reports": [
        4902,
        4903,
        4904
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67cb92d5e935fa589ac9dafd)",
      "incident_id": 971,
      "date": "2023-05-02",
      "title": "Iranian Hacker Group Cotton Sandstorm Integrating AI into Cyber Influence Operations",
      "description": "The Iranian state-sponsored group Cotton Sandstorm, linked to the IRGC, has integrated generative AI into cyber influence operations. In December 2023, it launched Operation “For Humanity, using AI-crafted messaging to hijack a U.S.-based IPTV streaming service with propaganda about the Israel-Hamas conflict. The group also engages in election-related reconnaissance, which suggests they used AI-enhanced influence efforts ahead of the 2024 U.S. election.",
      "deployers": [
        "islamic-revolutionary-guard-corps-(irgc)",
        "government-of-iran",
        "cotton-sandstorm"
      ],
      "developers": [
        "unknown-generative-ai-developers",
        "islamic-revolutionary-guard-corps-(irgc)",
        "government-of-iran",
        "cotton-sandstorm"
      ],
      "harmedParties": [
        "u.s.-elections",
        "political-candidates",
        "media-organizations",
        "general-public-of-the-united-states",
        "electoral-integrity",
        "democracy",
        "american-voters"
      ],
      "reports": [
        4907,
        4908,
        4909,
        4910,
        4911,
        4912,
        4913,
        4914,
        4915,
        4916,
        4917,
        4918,
        4919
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67cb9fe2e4a5da510c1e2f9f)",
      "incident_id": 972,
      "date": "2024-09-25",
      "title": "Russian Influence Operation Allegedly Uses AI to Create Fake Kamala Harris Campaign Website and Rhino-Hunting Hoax",
      "description": "A Russian disinformation campaign, linked to Storm-1516 and Kremlin propagandist John Mark Dougan, allegedly used AI-generated content to target Kamala Harris’s election bid. The operation included a fake campaign website promoting extreme policies and an AI-enhanced deepfake video falsely claiming Harris killed an endangered rhino in Zambia. The hoaxes were spread via Telegram, X, VK, and pro-Kremlin media outlets.",
      "deployers": [
        "storm-1516",
        "john-mark-dougan",
        "russian-state-media",
        "sputnik",
        "rt-(russia-today)",
        "pravda-network"
      ],
      "developers": [
        "unknown-deepfake-technology-developer",
        "unknown-voice-cloning-technology-developer"
      ],
      "harmedParties": [
        "kamala-harris",
        "american-voters",
        "electoral-integrity",
        "democracy"
      ],
      "reports": [
        4920,
        4921
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67cc765d6e615074a1afec97)",
      "incident_id": 973,
      "date": "2025-03-05",
      "title": "Canadian Fraud Ring Allegedly Used AI Voice Cloning in Multi-Year $21 Million Grandparent Scam Targeting Elderly Americans Across 46 States",
      "description": "A Canadian fraud ring allegedly used AI-generated voice cloning to defraud victims across 46 U.S. states by targeting grandparents in a $21 million scam between 2021 and 2024. Operating from call centers in Montreal, the scammers spoofed U.S. phone numbers and used AI-cloned voices of grandchildren to convince victims to pay fake bail fees.",
      "deployers": [
        "scammers",
        "fraudsters",
        "canadian-fraud-ring-involved-in-grandparent-scams",
        "canadian-fraud-ring-impersonating-grandchildren"
      ],
      "developers": [
        "unknown-voice-cloning-technology-developer"
      ],
      "harmedParties": [
        "grandparents-targeted-by-canadian-fraud-ring",
        "families-of-grandparents-targeted-by-canadian-fraud-ring"
      ],
      "reports": [
        4923,
        4924,
        4925,
        4926,
        4927,
        4928
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67d0e8817036c3d80721e5f9)",
      "incident_id": 974,
      "date": "2025-03-04",
      "title": "Deepfake Audio Impersonates U.S. Secretary of State Marco Rubio in Starlink Disinformation Campaign",
      "description": "A deepfake audio clip impersonating U.S. Secretary of State Marco Rubio falsely claimed he vowed to pressure Elon Musk into cutting Ukraine’s access to Starlink. The fabricated clip was inserted into a manipulated CNN interview. It was then spread across multiple languages and fueled disinformation about U.S.-Ukraine relations. Forensic analysis confirmed the audio was AI-generated.",
      "deployers": [
        "unknown-disinformation-actors"
      ],
      "developers": [
        "unknown-voice-cloning-technology"
      ],
      "harmedParties": [
        "marco-rubio",
        "government-of-ukraine",
        "government-of-the-united-states",
        "truth",
        "media-integrity",
        "relations-between-the-united-states-and-ukraine"
      ],
      "reports": [
        4933
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67d0f7a05d2c708d9cd89f36)",
      "incident_id": 975,
      "date": "2025-03-05",
      "title": "At Least 10,000 AI Chatbots, Including Jailbroken Models, Allegedly Promote Eating Disorders, Self-Harm, and Sexualized Minors",
      "description": "At least 10,000 AI chatbots have allegedly been created to promote harmful behaviors, including eating disorders, self-harm, and the sexualization of minors. These chatbots, some jailbroken or custom-built, leverage APIs from OpenAI, Anthropic, and Google and are hosted on platforms like Character.AI, Spicy Chat, Chub AI, CrushOn.AI, and JanitorAI.",
      "deployers": [
        "character.ai",
        "spicy-chat",
        "chub-ai",
        "crushon.ai",
        "janitorai",
        "unidentified-online-communities-using-chatbots"
      ],
      "developers": [
        "openai",
        "anthropic",
        "google"
      ],
      "harmedParties": [
        "vulnerable-chatbot-users",
        "teenagers-using-chatbots",
        "minors-using-chatbots",
        "individuals-with-eating-disorders",
        "individuals-struggling-with-self-harm"
      ],
      "reports": [
        4934
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67d1d511f196072cc9859620)",
      "incident_id": 976,
      "date": "2025-03-08",
      "title": "AI-Generated OB-GYN Health Influencers on TikTok Used Fake Medical Credentials to Promote Dubious Advice",
      "description": "AI-generated avatars posing as OB-GYNs on TikTok, part of the so-called, crudely termed Coochie Doctor trend, have been falsely claiming years of experience while promoting dubious health advice. Many, including an avatar named Violet, were created using the Captions app, which generates scripted AI influencers.",
      "deployers": [
        "unknown-tiktok-users"
      ],
      "developers": [
        "captions"
      ],
      "harmedParties": [
        "tiktok-users"
      ],
      "reports": [
        4935,
        4983,
        4984,
        4985,
        4986
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67d1f69bce356d18c04fa375)",
      "incident_id": 977,
      "date": "2025-03-02",
      "title": "AI-Driven News Platform Accused of Spreading Unverified Terrorism Allegations Against Yale Scholar",
      "description": "An AI-powered news site, Jewish Onliner, allegedly published an article linking Yale Law scholar Helyeh Doutaghi to Samidoun, a sanctioned group, which led to her suspension within days. The site, which claims to use AI for research, fact-checking, and content creation, did not disclose human reporters. Doutaghi denied the allegations and described the move as an attack on academic freedom.",
      "deployers": [
        "jewish-onliner"
      ],
      "developers": [
        "unknown-large-language-model-developer",
        "unknown-ai-news-platform-developer"
      ],
      "harmedParties": [
        "helyeh-doutaghi",
        "yale-law-school",
        "yale-university",
        "journalism",
        "truth"
      ],
      "reports": [
        4941
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67d2063f34f49aa67353714f)",
      "incident_id": 978,
      "date": "2025-03-09",
      "title": "Chinese Actor and CPPCC Member Jin Dong Allegedly Impersonated by AI Deepfake Scammers to Mislead and Defraud Fans",
      "description": "Jin Dong, an actor from China and a member of the Chinese People's Political Consultative Conference (CPPCC), has warned about criminals using deepfake technology to impersonate him. The scammers are reportedly using his likeness and cloning his voice to deceive and defraud elderly individuals. In addition to his warning, Jin Dong has called for legislation and tech regulations to curb AI abuse.",
      "deployers": [
        "scammers",
        "scammers-impersonating-jin-dong"
      ],
      "developers": [
        "unknown-deepfake-technology-developer",
        "unknown-voice-cloning-technology-developer"
      ],
      "harmedParties": [
        "fans-of-jin-dong",
        "elderly-individuals",
        "general-public-of-china",
        "elderly-individuals-in-china"
      ],
      "reports": [
        4942
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67d20b56b3ebec4610172756)",
      "incident_id": 979,
      "date": "2025-03-05",
      "title": "Art Museum in Jinan, Shandong Allegedly Generated and Displayed a Sexualized Childlike Avatar with an Adult Body",
      "description": "A Chinese art museum in Jinan, Shandong exhibited an AI-generated virtual character, 济南小妮儿 (Jinan Xiaonier), which featured a childlike face on an adult woman’s body with suggestive movements. The display drew public outrage, with critics accusing it of sexualizing children and demanding its removal. The museum defended the exhibit and stated that it had undergone strict review, which only fueled further backlash.",
      "deployers": [
        "jinan-art-museum",
        ""
      ],
      "developers": [
        "unknown-ai-image-generator-technology-developer"
      ],
      "harmedParties": [
        "general-public-of-china",
        "visitors-to-jinan-art-museum"
      ],
      "reports": [
        4943
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67d20e12c863aa18c50e8524)",
      "incident_id": 980,
      "date": "2025-03-07",
      "title": "AI-Generated Songs Allegedly Imitating Céline Dion Circulate Online Without Authorization",
      "description": "Céline Dion has publicly condemned AI-generated music that falsely claims to feature her voice without her permission. In a March 7, 2025 statement, her team warned fans that these recordings are fake and unauthorized.",
      "deployers": [
        "unknown-celine-dion-voice-cloners"
      ],
      "developers": [
        "unknown-voice-cloning-technology-developer"
      ],
      "harmedParties": [
        "celine-dion",
        "fans-of-celine-dion"
      ],
      "reports": [
        4944
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67d212640b69709ca5da04a1)",
      "incident_id": 981,
      "date": "2025-03-05",
      "title": "Apple AI Transcription Allegedly Inserts Explicit Language into Scottish Woman’s Voicemail",
      "description": "An Apple voicemail transcription system allegedly misinterpreted a message from Lookers Land Rover in Motherwell, Scotland, to 66-year-old customer Louise Littlejohn by inserting an explicit phrase and an insult. The original voicemail was a standard business message, but AI processing errors introduced offensive and misleading content into the text version.",
      "deployers": [
        "lookers-land-rover",
        "apple"
      ],
      "developers": [
        "apple"
      ],
      "harmedParties": [
        "louise-littlejohn",
        "lookers-land-rover",
        "lookers-land-rover-customers",
        "apple-customers"
      ],
      "reports": [
        4945
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67d5b32e026b4f3f797a0a14)",
      "incident_id": 982,
      "date": "2025-03-13",
      "title": "Scammers Reportedly Using Deepfake Video Calls to Impersonate Executives in Singapore and Orchestrate Corporate Bank Transfers",
      "description": "Scammers in Singapore are reportedly using AI-generated deepfake video calls to impersonate corporate executives. The calls seek to deceive employees into authorizing fraudulent bank transfers. Usually, it is reported, victims will receive WhatsApp messages inviting them to Zoom meetings. During the calls, the scammers are disguised as senior leaders and will instruct the employees to transfer company funds for fake business transactions and to disclose personal data.",
      "deployers": [
        "scammers",
        "fraudsters",
        "scammers-impersonating-singaporean-executives"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "executives-in-singapore",
        "employees-in-singapore",
        "general-public-of-singapore",
        "companies-in-singapore"
      ],
      "reports": [
        4949
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67d5d4fb891d2b4d7a128dcd)",
      "incident_id": 983,
      "date": "2024-05-10",
      "title": "Scammers Reportedly Used AI Voice Clone and YouTube Footage to Impersonate WPP CEO in Unsuccessful Scam Attempt",
      "description": "Scammers reportedly attempted to impersonate WPP CEO Mark Read using AI-generated voice cloning and YouTube footage in a Microsoft Teams scam. They allegedly created a fake WhatsApp account with Read’s image and used deepfake audio to deceive an agency leader into setting up a new business. The scheme, which was unsuccessful, aimed to solicit money and personal data.",
      "deployers": [
        "scammers",
        "fraudsters",
        "scammers-impersonating-mark-read"
      ],
      "developers": [
        "unknown-deepfake-technology-developer",
        "unknown-voice-cloning-technology"
      ],
      "harmedParties": [
        "mark-read",
        "wpp",
        "wpp-employees",
        "general-public"
      ],
      "reports": [
        4951,
        4952,
        4953,
        4954,
        4955,
        4956,
        4957,
        4958,
        4959,
        4960,
        4961,
        4962,
        4963
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67d63267332642f80fa2f220)",
      "incident_id": 984,
      "date": "2025-03-07",
      "title": "Deepfake Videos Allegedly Use AI-Generated Voice Clone of Singapore Prime Minister Lawrence Wong to Promote Scams",
      "description": "Singapore Prime Minister Lawrence Wong issued a warning about AI-generated deepfake videos and voice clones falsely portraying him promoting cryptocurrency scams, money-making schemes, and PR services. The manipulated content, seen on social media, reportedly uses public footage and AI voice cloning to deceive victims. Wong urged the public to avoid engaging, report scams via ScamShield, and stay vigilant.",
      "deployers": [
        "scammers-impersonating-lawrence-wong",
        "scammers",
        "fraudsters"
      ],
      "developers": [
        "unknown-voice-cloning-technology-developer",
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "lawrence-wong",
        "general-public-of-singapore"
      ],
      "reports": [
        4964,
        4965,
        4966,
        4967
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67d6e634d1ae789dc37c8c48)",
      "incident_id": 985,
      "date": "2023-12-29",
      "title": "Alleged Deepfake of Singapore Prime Minister Lee Hsien Loong Promotes Cryptocurrency Scam in Fake Interview",
      "description": "A deepfake video falsely depicted Singapore’s Prime Minister Lee Hsien Loong promoting a cryptocurrency investment scam. Scammers used AI-generated voice cloning and manipulated footage from official events to create a convincing but fraudulent video interview with China Global Television Network. Lee warned the public and urged reporting through the ScamShield Bot.",
      "deployers": [
        "scammers-impersonating-lee-hsien-loong",
        "scammers",
        "fraudsters"
      ],
      "developers": [
        "unknown-voice-cloning-technology-developer",
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "lee-hsien-loong",
        "general-public-of-singapore"
      ],
      "reports": [
        4968
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67d6e723d1ae789dc37c8c59)",
      "incident_id": 986,
      "date": "2024-06-02",
      "title": "Scammers Allegedly Manipulate 2023 Speech of Singapore Senior Minister Lee Hsien Loong to Spread Deepfake Investment Fraud",
      "description": "A new deepfake video falsely showed Prime Minister Lee Hsien Loong endorsing an investment product with guaranteed returns. Scammers synchronized fake audio with real footage from his 2023 National Day speech, making it appear as though he had made the endorsement. Lee called this “extremely worrying” and warned that deepfake scams are becoming more sophisticated. He urged the public to report such scams through the government’s ScamShield Bot.",
      "deployers": [
        "scammers-impersonating-lee-hsien-loong",
        "scammers",
        "fraudsters"
      ],
      "developers": [
        "unknown-voice-cloning-technology-developer",
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "lee-hsien-loong",
        "general-public-of-singapore"
      ],
      "reports": [
        4969
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67d6ebacf9303d9754464238)",
      "incident_id": 987,
      "date": "2023-12-11",
      "title": "Alleged Deepfake of Singapore Deputy Prime Minister Lawrence Wong Falsely Shows Him Endorsing Commercial Products",
      "description": "A deepfake video falsely depicting Singapore Deputy Prime Minister Lawrence Wong endorsing commercial products circulated online in December 2023. Wong publicly denied the endorsement, warning that scammers had used AI-generated deepfake technology to impersonate him. The manipulated media aimed to mislead the public into believing he promoted fraudulent investments. Wong urged vigilance against AI-driven scams and encouraged reporting through the ScamShield Bot on WhatsApp.",
      "deployers": [
        "scammers-impersonating-lawrence-wong",
        "scammers",
        "fraudsters"
      ],
      "developers": [
        "unknown-voice-cloning-technology-developer",
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "lawrence-wong",
        "general-public-of-singapore"
      ],
      "reports": [
        4970
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67d71ab427548d6633716845)",
      "incident_id": 988,
      "date": "2024-06-21",
      "title": "Senior Minister of Singapore Lee Hsien Loong Allegedly Misrepresented in Two Deepfake Videos on Foreign Relations",
      "description": "Two deepfake videos falsely depicted Senior Minister of Singapore Lee Hsien Loong commenting on US-China relations and the South China Sea. The videos misleadingly attributed views to him and the Singapore government. Posted on TikTok, the videos amassed over 190,000 views before being removed.",
      "deployers": [
        "unknown-actors-impersonating-lee-hsien-loong"
      ],
      "developers": [
        "unknown-deepfake-technology-developer",
        "unknown-voice-cloning-technology-developer"
      ],
      "harmedParties": [
        "lee-hsien-loong",
        "government-of-singapore",
        "singapore-united-states-relations",
        "singapore-china-relations",
        "diplomacy"
      ],
      "reports": [
        4971
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67d727b88cda6ce110f50099)",
      "incident_id": 989,
      "date": "2025-03-05",
      "title": "Alleged AI-Generated Video by Spain’s People’s Party Results in Diplomatic Fallout with the Dominican Republic",
      "description": "Spain's People's Party (PP) posted an AI-generated attack video depicting Prime Minister Pedro Sánchez on a beach under the title The Island of Corruption, a reference to a reality TV show filmed in the Dominican Republic, indirectly linking the country to corruption. The Dominican Foreign Ministry condemned the video as a vicious attack for using its national symbols. PP later deleted the post, and Sánchez apologized on behalf of Spain.",
      "deployers": [
        "people's-party-(spain)",
        "partido-popular"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "pedro-sanchez",
        "government-of-spain",
        "government-of-the-dominican-republic",
        "relations-between-spain-and-the-dominican-republic"
      ],
      "reports": [
        4972
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67d72bbb646189d1a344fa8f)",
      "incident_id": 990,
      "date": "2024-11-19",
      "title": "Corinth School District Educator in Mississippi Allegedly Used AI to Generate CSAM of Students",
      "description": "An educator in the Corinth School District of Mississippi, Wilson Jones, was arrested for allegedly using AI to generate child sexual abuse material (CSAM) of students. A complaint was filed with the police on January 29th, 2025, and a search warrant was executed on March 3rd, 2025. The FBI allege that the crime was committed sometime on or before November 19th, 2024.",
      "deployers": [
        "wilson-jones"
      ],
      "developers": [
        "unknown-deepfake-technology-developer"
      ],
      "harmedParties": [
        "students-of-corinth-school-district-in-mississippi",
        "families-of-students-of-corinth-school-district-in-mississippi"
      ],
      "reports": [
        4973,
        4974
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67d73887db0ca48c37787baa)",
      "incident_id": 991,
      "date": "2025-03-14",
      "title": "Alleged AI-Generated IRS Scam Websites Used to Defraud U.S. Taxpayers",
      "description": "Scammers have allegedly been using AI-generated imposter websites and phishing emails to impersonate the IRS. They have reportedly been tricking taxpayers into providing personal and financial information. There has been a reported surge in tax-related AI scams leading up to Tax Day 2025, with fraudulent domains mimicking IRS services, along with fake websites, emails, and text messages. The IRS has warned taxpayers to verify official sites and avoid unsolicited links.",
      "deployers": [
        "scammers",
        "fraudsters",
        "phishers",
        "scammers-impersonating-the-irs",
        "cyber-criminals"
      ],
      "developers": [
        "unknown-generative-ai-developers",
        "black-box-ai-developers",
        "generative-ai-fraud-tools"
      ],
      "harmedParties": [
        "taxpayers-in-the-united-states",
        "general-public-of-the-united-states",
        "u.s.-citizens",
        "identity-theft-victims",
        "irs"
      ],
      "reports": [
        4975
      ],
      "severity": "High",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67d82879580b1fad010f69a6)",
      "incident_id": 992,
      "date": "2023-04-15",
      "title": "Chinese Businessman Reportedly Defrauded of 4.3 Million Yuan by AI-Generated Deepfake Impersonating Friend",
      "description": "A scammer in China used AI-generated deepfake technology to impersonate a businessman’s trusted friend in a video call, convincing him to transfer 4.3 million yuan ($612,000). The fraudster mimicked the friend’s face and voice, claiming another associate needed funds for a business transaction. Without verifying the transfer, the victim sent the money. He later realized the deception and contacted police, who managed to recover 3.4 million yuan.",
      "deployers": [
        "scammers",
        "fraudsters",
        "scammers-impersonating-friend-of-guo"
      ],
      "developers": [
        "unknown-deepfake-technology-developer",
        "unknown-voice-cloning-technology-developer"
      ],
      "harmedParties": [
        "guo-(surname-of-deepfake-scam-victim)",
        "friend-of-guo-(surname-of-deepfake-scam-victim)",
        "general-public-of-china"
      ],
      "reports": [
        4981
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67d95f3840a025da0b34a785)",
      "incident_id": 993,
      "date": "2025-03-12",
      "title": "Sydney Students Allegedly Forced to Retake NAPLAN After AI Predictive Text Error",
      "description": "A predictive text malfunction allegedly compromised the integrity of the NAPLAN writing exam at two Sydney schools, Waverley College and Kambala, in that it allowed students to access AI-driven text suggestions. Caused by a technical oversight, this incident led to affected students being required to retake the test. ",
      "deployers": [
        "nsw-education-standards-authority-(nesa)",
        "australian-curriculum-assessment-and-reporting-authority-(acara)",
        "waverley-college-(sydney-australia)",
        "kambala-(sydney-australia)"
      ],
      "developers": [
        "apple"
      ],
      "harmedParties": [
        "waverley-college-(sydney-australia)-students",
        "waverley-college-(sydney-australia)-teachers",
        "kambala-(sydney-australia)-students",
        "kambala-(sydney-australia)-teachers"
      ],
      "reports": [
        4982,
        5002
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67db71a364870c663cb0e94d)",
      "incident_id": 994,
      "date": "2025-03-18",
      "title": "AI-Enabled Organized Crime Expands Across Europe",
      "description": "Europol’s EU Serious and Organised Crime Threat Assessment (EU-SOCTA) 2025 warns that AI is accelerating the growth of organized crime throughout Europe. Criminal networks are leveraging AI for cyber fraud, ransomware, money laundering, and child exploitation, while AI-powered social engineering and automation are making criminal operations more scalable and harder to detect. ",
      "deployers": [
        "organized-crime-groups"
      ],
      "developers": [
        "various-generative-ai-developers"
      ],
      "harmedParties": [
        "general-public-of-the-european-union"
      ],
      "reports": [
        4989,
        4990,
        4991,
        4992,
        4993,
        4994,
        4995
      ],
      "severity": "Critical",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67dc6900ccc1d6978a011487)",
      "incident_id": 995,
      "date": "2023-12-27",
      "title": "The New York Times Sues OpenAI and Microsoft Over Alleged Unauthorized AI Training on Its Content",
      "description": "The New York Times alleges that OpenAI and Microsoft used millions of its articles without permission to train AI models, including ChatGPT. The lawsuit claims the companies scraped and reproduced copyrighted content without compensation, in turn undermining the Times’s business and competing with its journalism. Some AI outputs allegedly regurgitate Times articles verbatim. The lawsuit seeks damages and demands the destruction of AI models trained on its content.",
      "deployers": [
        "openai",
        "microsoft"
      ],
      "developers": [
        "openai",
        "microsoft"
      ],
      "harmedParties": [
        "the-new-york-times",
        "journalists",
        "journalism",
        "media-organizations",
        "publishers",
        "writers"
      ],
      "reports": [
        4996,
        3502
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67dc69c028077598fb9090e4)",
      "incident_id": 996,
      "date": "2020-10-25",
      "title": "Meta Allegedly Used Books3, a Dataset of 191,000 Pirated Books, to Train LLaMA AI",
      "description": "Meta and Bloomberg allegedly used Books3, a dataset containing 191,000 pirated books, to train their AI models, including LLaMA and BloombergGPT, without author consent. Lawsuits from authors such as Sarah Silverman and Michael Chabon claim this constitutes copyright infringement. Books3 includes works from major publishers like Penguin Random House and HarperCollins. Meta argues its AI outputs are not substantially similar to the original books, but legal challenges continue.",
      "deployers": [
        "various-generative-ai-developers",
        "meta",
        "eleutherai",
        "bloomberg"
      ],
      "developers": [
        "various-generative-ai-developers",
        "the-pile",
        "shawn-presser",
        "meta",
        "eleutherai",
        "bloomberg"
      ],
      "harmedParties": [
        "zadie-smith",
        "writers",
        "verso",
        "stephen-king",
        "sarah-silverman",
        "richard-kadrey",
        "publishers-found-in-books3",
        "penguin-random-house",
        "oxford-university-press",
        "over-170000-authors-found-in-books3",
        "michael-pollan",
        "margaret-atwood",
        "macmillan",
        "harpercollins",
        "general-public",
        "creative-industries",
        "christopher-golden",
        "authors"
      ],
      "reports": [
        4997,
        3226
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67dc6d68db4c12390c13edc5)",
      "incident_id": 997,
      "date": "2023-02-28",
      "title": "Meta and OpenAI Accused of Using LibGen’s Pirated Books to Train AI Models",
      "description": "Court records reveal that Meta employees allegedly discussed pirating books to train LLaMA 3, citing cost and speed concerns with licensing. Internal messages suggest Meta accessed LibGen, a repository of over 7.5 million pirated books, with apparent approval from Mark Zuckerberg. Employees allegedly took steps to obscure the dataset’s origins. OpenAI has also been implicated in using LibGen.",
      "deployers": [
        "openai",
        "meta"
      ],
      "developers": [
        "openai",
        "meta"
      ],
      "harmedParties": [
        "writers",
        "publishers",
        "journalists",
        "authors",
        "academic-researchers"
      ],
      "reports": [
        4998,
        4999,
        5000
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67dd4fd8c369cefed469e761)",
      "incident_id": 998,
      "date": "2024-08-15",
      "title": "ChatGPT Allegedly Defamed Norwegian User by Inventing Child Homicide and Imprisonment",
      "description": "In August 2024, ChatGPT is reported to have falsely claimed that Norwegian citizen Arve Hjalmar Holmen had killed his two sons and been sentenced to 21 years in prison. The fabricated response allegedly included specific details about the supposed crime, despite Holmen never being accused or convicted of any offense. The incident prompted a GDPR complaint for defamation and inaccurate personal data.",
      "deployers": [
        "openai"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "arve-hjalmar-holmen"
      ],
      "reports": [
        5001,
        5004
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67e083457181d1ec3f9897b1)",
      "incident_id": 999,
      "date": "2025-03-12",
      "title": "Attackers Reportedly Deployed Simulated AI Support Chatbot to Trick Instagram Business Users into Adding Malicious 2FA Login",
      "description": "A phishing campaign has reportedly been impersonating Meta support using a fake chatbot interface to hijack Instagram Business accounts. Victims received emails claiming ad violations and were directed to a fraudulent site mimicking Meta's support. There, a simulated chatbot instructed users to add the attacker’s Authenticator app as a secure login method, enabling account takeover. It remains unclear whether the chatbot used AI or was human-operated via a bot-like interface. See editor's note.",
      "deployers": [
        "scammers-impersonating-meta-support",
        "scammers",
        "phishers",
        "fraudsters"
      ],
      "developers": [
        "unknown-generative-ai-developers"
      ],
      "harmedParties": [
        "meta-users",
        "instagram-users",
        "instagram-business-users"
      ],
      "reports": [
        5005,
        5006
      ],
      "severity": "Low",
      "classification": "AI Incident"
    },
    {
      "id": "ObjectId(67e0a6bdf7ea82682abe477e)",
      "incident_id": 1000,
      "date": "2025-03-23",
      "title": "Sora Video Generator Has Reportedly Been Creating Biased Human Representations Across Race, Gender, and Disability",
      "description": "A WIRED investigation found that OpenAI’s video generation model, Sora, exhibits representational bias across race, gender, body type, and disability. In tests using 250 prompts, Sora was more likely to depict CEOs and professors as men, flight attendants and childcare workers as women, and showed limited or stereotypical portrayals of disabled individuals and people with larger bodies.",
      "deployers": [
        "openai"
      ],
      "developers": [
        "openai"
      ],
      "harmedParties": [
        "marginalized-groups",
        "women",
        "people-with-disabilities",
        "people-with-larger-bodies",
        "lgbtq+-people",
        "people-of-color",
        "general-public"
      ],
      "reports": [
        5007
      ],
      "severity": "Medium",
      "classification": "AI Incident"
    }
  ],
  "reports": [
    {
      "id": "report-242",
      "incident_id": 23,
      "title": "Report 242 on Las Vegas Self-Driving Bus Involved in Accident",
      "description": "A detailed report about Las Vegas Self-Driving Bus Involved in Accident",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-11-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-243",
      "incident_id": 23,
      "title": "Report 243 on Las Vegas Self-Driving Bus Involved in Accident",
      "description": "A detailed report about Las Vegas Self-Driving Bus Involved in Accident",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-11-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-244",
      "incident_id": 23,
      "title": "Report 244 on Las Vegas Self-Driving Bus Involved in Accident",
      "description": "A detailed report about Las Vegas Self-Driving Bus Involved in Accident",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-11-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-629",
      "incident_id": 4,
      "title": "Report 629 on Uber AV Killed Pedestrian in Arizona",
      "description": "A detailed report about Uber AV Killed Pedestrian in Arizona",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-03-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-630",
      "incident_id": 4,
      "title": "Report 630 on Uber AV Killed Pedestrian in Arizona",
      "description": "A detailed report about Uber AV Killed Pedestrian in Arizona",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-03-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-631",
      "incident_id": 4,
      "title": "Report 631 on Uber AV Killed Pedestrian in Arizona",
      "description": "A detailed report about Uber AV Killed Pedestrian in Arizona",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-03-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1",
      "incident_id": 1,
      "title": "Report 1 on Google’s YouTube Kids App Presents Inappropriate Content",
      "description": "A detailed report about Google’s YouTube Kids App Presents Inappropriate Content",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-05-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2",
      "incident_id": 1,
      "title": "Report 2 on Google’s YouTube Kids App Presents Inappropriate Content",
      "description": "A detailed report about Google’s YouTube Kids App Presents Inappropriate Content",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-05-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3",
      "incident_id": 1,
      "title": "Report 3 on Google’s YouTube Kids App Presents Inappropriate Content",
      "description": "A detailed report about Google’s YouTube Kids App Presents Inappropriate Content",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-05-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-130",
      "incident_id": 18,
      "title": "Report 130 on Gender Biases of Google Image Search",
      "description": "A detailed report about Gender Biases of Google Image Search",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-04-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-131",
      "incident_id": 18,
      "title": "Report 131 on Gender Biases of Google Image Search",
      "description": "A detailed report about Gender Biases of Google Image Search",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-04-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-132",
      "incident_id": 18,
      "title": "Report 132 on Gender Biases of Google Image Search",
      "description": "A detailed report about Gender Biases of Google Image Search",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-04-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-42",
      "incident_id": 12,
      "title": "Report 42 on Common Biases of Vector Embeddings",
      "description": "A detailed report about Common Biases of Vector Embeddings",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-07-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-57",
      "incident_id": 15,
      "title": "Report 57 on Amazon Censors Gay Books",
      "description": "A detailed report about Amazon Censors Gay Books",
      "url": "https://incidentdatabase.ai",
      "date_published": "2008-05-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-58",
      "incident_id": 15,
      "title": "Report 58 on Amazon Censors Gay Books",
      "description": "A detailed report about Amazon Censors Gay Books",
      "url": "https://incidentdatabase.ai",
      "date_published": "2008-05-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-59",
      "incident_id": 15,
      "title": "Report 59 on Amazon Censors Gay Books",
      "description": "A detailed report about Amazon Censors Gay Books",
      "url": "https://incidentdatabase.ai",
      "date_published": "2008-05-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1123",
      "incident_id": 7,
      "title": "Report 1123 on Wikipedia Vandalism Prevention Bot Loop",
      "description": "A detailed report about Wikipedia Vandalism Prevention Bot Loop",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-02-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1125",
      "incident_id": 7,
      "title": "Report 1125 on Wikipedia Vandalism Prevention Bot Loop",
      "description": "A detailed report about Wikipedia Vandalism Prevention Bot Loop",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-02-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1126",
      "incident_id": 7,
      "title": "Report 1126 on Wikipedia Vandalism Prevention Bot Loop",
      "description": "A detailed report about Wikipedia Vandalism Prevention Bot Loop",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-02-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-767",
      "incident_id": 5,
      "title": "Report 767 on Collection of Robotic Surgery Malfunctions",
      "description": "A detailed report about Collection of Robotic Surgery Malfunctions",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-07-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-768",
      "incident_id": 5,
      "title": "Report 768 on Collection of Robotic Surgery Malfunctions",
      "description": "A detailed report about Collection of Robotic Surgery Malfunctions",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-07-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-769",
      "incident_id": 5,
      "title": "Report 769 on Collection of Robotic Surgery Malfunctions",
      "description": "A detailed report about Collection of Robotic Surgery Malfunctions",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-07-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-906",
      "incident_id": 6,
      "title": "Report 906 on TayBot",
      "description": "A detailed report about TayBot",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-03-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-908",
      "incident_id": 6,
      "title": "Report 908 on TayBot",
      "description": "A detailed report about TayBot",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-03-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-909",
      "incident_id": 6,
      "title": "Report 909 on TayBot",
      "description": "A detailed report about TayBot",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-03-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-16",
      "incident_id": 10,
      "title": "Report 16 on Kronos Scheduling Algorithm Allegedly Caused Financial Issues for Starbucks Employees",
      "description": "A detailed report about Kronos Scheduling Algorithm Allegedly Caused Financial Issues for Starbucks Employees",
      "url": "https://incidentdatabase.ai",
      "date_published": "2014-08-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-17",
      "incident_id": 10,
      "title": "Report 17 on Kronos Scheduling Algorithm Allegedly Caused Financial Issues for Starbucks Employees",
      "description": "A detailed report about Kronos Scheduling Algorithm Allegedly Caused Financial Issues for Starbucks Employees",
      "url": "https://incidentdatabase.ai",
      "date_published": "2014-08-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-18",
      "incident_id": 10,
      "title": "Report 18 on Kronos Scheduling Algorithm Allegedly Caused Financial Issues for Starbucks Employees",
      "description": "A detailed report about Kronos Scheduling Algorithm Allegedly Caused Financial Issues for Starbucks Employees",
      "url": "https://incidentdatabase.ai",
      "date_published": "2014-08-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-29",
      "incident_id": 11,
      "title": "Report 29 on Northpointe Risk Models",
      "description": "A detailed report about Northpointe Risk Models",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-05-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-30",
      "incident_id": 11,
      "title": "Report 30 on Northpointe Risk Models",
      "description": "A detailed report about Northpointe Risk Models",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-05-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-31",
      "incident_id": 11,
      "title": "Report 31 on Northpointe Risk Models",
      "description": "A detailed report about Northpointe Risk Models",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-05-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-191",
      "incident_id": 20,
      "title": "Report 191 on A Collection of Tesla Autopilot-Involved Crashes",
      "description": "A detailed report about A Collection of Tesla Autopilot-Involved Crashes",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-06-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-192",
      "incident_id": 20,
      "title": "Report 192 on A Collection of Tesla Autopilot-Involved Crashes",
      "description": "A detailed report about A Collection of Tesla Autopilot-Involved Crashes",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-06-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-193",
      "incident_id": 20,
      "title": "Report 193 on A Collection of Tesla Autopilot-Involved Crashes",
      "description": "A detailed report about A Collection of Tesla Autopilot-Involved Crashes",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-06-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-271",
      "incident_id": 24,
      "title": "Report 271 on Robot kills worker at German Volkswagen plant",
      "description": "A detailed report about Robot kills worker at German Volkswagen plant",
      "url": "https://incidentdatabase.ai",
      "date_published": "2014-07-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-272",
      "incident_id": 24,
      "title": "Report 272 on Robot kills worker at German Volkswagen plant",
      "description": "A detailed report about Robot kills worker at German Volkswagen plant",
      "url": "https://incidentdatabase.ai",
      "date_published": "2014-07-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-273",
      "incident_id": 24,
      "title": "Report 273 on Robot kills worker at German Volkswagen plant",
      "description": "A detailed report about Robot kills worker at German Volkswagen plant",
      "url": "https://incidentdatabase.ai",
      "date_published": "2014-07-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-50",
      "incident_id": 14,
      "title": "Report 50 on Biased Sentiment Analysis",
      "description": "A detailed report about Biased Sentiment Analysis",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-10-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-51",
      "incident_id": 14,
      "title": "Report 51 on Biased Sentiment Analysis",
      "description": "A detailed report about Biased Sentiment Analysis",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-10-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-52",
      "incident_id": 14,
      "title": "Report 52 on Biased Sentiment Analysis",
      "description": "A detailed report about Biased Sentiment Analysis",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-10-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-83",
      "incident_id": 16,
      "title": "Report 83 on Images of Black People Labeled as Gorillas",
      "description": "A detailed report about Images of Black People Labeled as Gorillas",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-06-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-84",
      "incident_id": 16,
      "title": "Report 84 on Images of Black People Labeled as Gorillas",
      "description": "A detailed report about Images of Black People Labeled as Gorillas",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-06-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-85",
      "incident_id": 16,
      "title": "Report 85 on Images of Black People Labeled as Gorillas",
      "description": "A detailed report about Images of Black People Labeled as Gorillas",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-06-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-372",
      "incident_id": 3,
      "title": "Report 372 on Crashes with Maneuvering Characteristics Augmentation System (MCAS)",
      "description": "A detailed report about Crashes with Maneuvering Characteristics Augmentation System (MCAS)",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-10-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-373",
      "incident_id": 3,
      "title": "Report 373 on Crashes with Maneuvering Characteristics Augmentation System (MCAS)",
      "description": "A detailed report about Crashes with Maneuvering Characteristics Augmentation System (MCAS)",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-10-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-374",
      "incident_id": 3,
      "title": "Report 374 on Crashes with Maneuvering Characteristics Augmentation System (MCAS)",
      "description": "A detailed report about Crashes with Maneuvering Characteristics Augmentation System (MCAS)",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-10-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-139",
      "incident_id": 2,
      "title": "Report 139 on Warehouse robot ruptures can of bear spray and injures workers",
      "description": "A detailed report about Warehouse robot ruptures can of bear spray and injures workers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-12-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-141",
      "incident_id": 2,
      "title": "Report 141 on Warehouse robot ruptures can of bear spray and injures workers",
      "description": "A detailed report about Warehouse robot ruptures can of bear spray and injures workers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-12-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-142",
      "incident_id": 2,
      "title": "Report 142 on Warehouse robot ruptures can of bear spray and injures workers",
      "description": "A detailed report about Warehouse robot ruptures can of bear spray and injures workers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-12-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-158",
      "incident_id": 19,
      "title": "Report 158 on Sexist and Racist Google Adsense Advertisements",
      "description": "A detailed report about Sexist and Racist Google Adsense Advertisements",
      "url": "https://incidentdatabase.ai",
      "date_published": "2013-01-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-159",
      "incident_id": 19,
      "title": "Report 159 on Sexist and Racist Google Adsense Advertisements",
      "description": "A detailed report about Sexist and Racist Google Adsense Advertisements",
      "url": "https://incidentdatabase.ai",
      "date_published": "2013-01-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-160",
      "incident_id": 19,
      "title": "Report 160 on Sexist and Racist Google Adsense Advertisements",
      "description": "A detailed report about Sexist and Racist Google Adsense Advertisements",
      "url": "https://incidentdatabase.ai",
      "date_published": "2013-01-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1329",
      "incident_id": 9,
      "title": "Report 1329 on NY City School Teacher Evaluation Algorithm Contested",
      "description": "A detailed report about NY City School Teacher Evaluation Algorithm Contested",
      "url": "https://incidentdatabase.ai",
      "date_published": "2012-02-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1330",
      "incident_id": 9,
      "title": "Report 1330 on NY City School Teacher Evaluation Algorithm Contested",
      "description": "A detailed report about NY City School Teacher Evaluation Algorithm Contested",
      "url": "https://incidentdatabase.ai",
      "date_published": "2012-02-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1331",
      "incident_id": 9,
      "title": "Report 1331 on NY City School Teacher Evaluation Algorithm Contested",
      "description": "A detailed report about NY City School Teacher Evaluation Algorithm Contested",
      "url": "https://incidentdatabase.ai",
      "date_published": "2012-02-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1142",
      "incident_id": 8,
      "title": "Report 1142 on Uber Autonomous Cars Running Red Lights",
      "description": "A detailed report about Uber Autonomous Cars Running Red Lights",
      "url": "https://incidentdatabase.ai",
      "date_published": "2014-08-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1143",
      "incident_id": 8,
      "title": "Report 1143 on Uber Autonomous Cars Running Red Lights",
      "description": "A detailed report about Uber Autonomous Cars Running Red Lights",
      "url": "https://incidentdatabase.ai",
      "date_published": "2014-08-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1145",
      "incident_id": 8,
      "title": "Report 1145 on Uber Autonomous Cars Running Red Lights",
      "description": "A detailed report about Uber Autonomous Cars Running Red Lights",
      "url": "https://incidentdatabase.ai",
      "date_published": "2014-08-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-43",
      "incident_id": 13,
      "title": "Report 43 on High-Toxicity Assessed on Text Involving Women and Minority Groups",
      "description": "A detailed report about High-Toxicity Assessed on Text Involving Women and Minority Groups",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-02-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-44",
      "incident_id": 13,
      "title": "Report 44 on High-Toxicity Assessed on Text Involving Women and Minority Groups",
      "description": "A detailed report about High-Toxicity Assessed on Text Involving Women and Minority Groups",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-02-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-45",
      "incident_id": 13,
      "title": "Report 45 on High-Toxicity Assessed on Text Involving Women and Minority Groups",
      "description": "A detailed report about High-Toxicity Assessed on Text Involving Women and Minority Groups",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-02-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2471",
      "incident_id": 21,
      "title": "Report 2471 on Tougher Turing Test Exposes Chatbots’ Stupidity (migrated to Issue)",
      "description": "A detailed report about Tougher Turing Test Exposes Chatbots’ Stupidity (migrated to Issue)",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-07-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-106",
      "incident_id": 17,
      "title": "Report 106 on Inappropriate Gmail Smart Reply Suggestions",
      "description": "A detailed report about Inappropriate Gmail Smart Reply Suggestions",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-11-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-107",
      "incident_id": 17,
      "title": "Report 107 on Inappropriate Gmail Smart Reply Suggestions",
      "description": "A detailed report about Inappropriate Gmail Smart Reply Suggestions",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-11-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-110",
      "incident_id": 17,
      "title": "Report 110 on Inappropriate Gmail Smart Reply Suggestions",
      "description": "A detailed report about Inappropriate Gmail Smart Reply Suggestions",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-11-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-218",
      "incident_id": 22,
      "title": "Report 218 on Waze Navigates Motorists into Wildfires",
      "description": "A detailed report about Waze Navigates Motorists into Wildfires",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-12-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-219",
      "incident_id": 22,
      "title": "Report 219 on Waze Navigates Motorists into Wildfires",
      "description": "A detailed report about Waze Navigates Motorists into Wildfires",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-12-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-220",
      "incident_id": 22,
      "title": "Report 220 on Waze Navigates Motorists into Wildfires",
      "description": "A detailed report about Waze Navigates Motorists into Wildfires",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-12-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-310",
      "incident_id": 25,
      "title": "Report 310 on Near-miss between two Self-Driving Cars",
      "description": "A detailed report about Near-miss between two Self-Driving Cars",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-05-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-309",
      "incident_id": 25,
      "title": "Report 309 on Near-miss between two Self-Driving Cars",
      "description": "A detailed report about Near-miss between two Self-Driving Cars",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-05-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-308",
      "incident_id": 25,
      "title": "Report 308 on Near-miss between two Self-Driving Cars",
      "description": "A detailed report about Near-miss between two Self-Driving Cars",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-05-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-599",
      "incident_id": 37,
      "title": "Report 599 on Female Applicants Down-Ranked by Amazon Recruiting Tool",
      "description": "A detailed report about Female Applicants Down-Ranked by Amazon Recruiting Tool",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-08-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-600",
      "incident_id": 37,
      "title": "Report 600 on Female Applicants Down-Ranked by Amazon Recruiting Tool",
      "description": "A detailed report about Female Applicants Down-Ranked by Amazon Recruiting Tool",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-08-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-601",
      "incident_id": 37,
      "title": "Report 601 on Female Applicants Down-Ranked by Amazon Recruiting Tool",
      "description": "A detailed report about Female Applicants Down-Ranked by Amazon Recruiting Tool",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-08-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-454",
      "incident_id": 31,
      "title": "Report 454 on Driverless Train in Delhi Crashes due to Braking Failure",
      "description": "A detailed report about Driverless Train in Delhi Crashes due to Braking Failure",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-12-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-455",
      "incident_id": 31,
      "title": "Report 455 on Driverless Train in Delhi Crashes due to Braking Failure",
      "description": "A detailed report about Driverless Train in Delhi Crashes due to Braking Failure",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-12-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-456",
      "incident_id": 31,
      "title": "Report 456 on Driverless Train in Delhi Crashes due to Braking Failure",
      "description": "A detailed report about Driverless Train in Delhi Crashes due to Braking Failure",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-12-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-509",
      "incident_id": 34,
      "title": "Report 509 on Amazon Alexa Responding to Environmental Inputs",
      "description": "A detailed report about Amazon Alexa Responding to Environmental Inputs",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-12-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-510",
      "incident_id": 34,
      "title": "Report 510 on Amazon Alexa Responding to Environmental Inputs",
      "description": "A detailed report about Amazon Alexa Responding to Environmental Inputs",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-12-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-512",
      "incident_id": 34,
      "title": "Report 512 on Amazon Alexa Responding to Environmental Inputs",
      "description": "A detailed report about Amazon Alexa Responding to Environmental Inputs",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-12-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-342",
      "incident_id": 27,
      "title": "Report 342 on Nuclear False Alarm",
      "description": "A detailed report about Nuclear False Alarm",
      "url": "https://incidentdatabase.ai",
      "date_published": "1983-09-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-343",
      "incident_id": 27,
      "title": "Report 343 on Nuclear False Alarm",
      "description": "A detailed report about Nuclear False Alarm",
      "url": "https://incidentdatabase.ai",
      "date_published": "1983-09-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-344",
      "incident_id": 27,
      "title": "Report 344 on Nuclear False Alarm",
      "description": "A detailed report about Nuclear False Alarm",
      "url": "https://incidentdatabase.ai",
      "date_published": "1983-09-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-420",
      "incident_id": 29,
      "title": "Report 420 on Image Classification of Battle Tanks",
      "description": "A detailed report about Image Classification of Battle Tanks",
      "url": "https://incidentdatabase.ai",
      "date_published": "2011-09-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-422",
      "incident_id": 29,
      "title": "Report 422 on Image Classification of Battle Tanks",
      "description": "A detailed report about Image Classification of Battle Tanks",
      "url": "https://incidentdatabase.ai",
      "date_published": "2011-09-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2471",
      "incident_id": 29,
      "title": "Report 2471 on Image Classification of Battle Tanks",
      "description": "A detailed report about Image Classification of Battle Tanks",
      "url": "https://incidentdatabase.ai",
      "date_published": "2011-09-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-484",
      "incident_id": 32,
      "title": "Report 484 on Identical Twins Can Open Apple FaceID Protected Devices",
      "description": "A detailed report about Identical Twins Can Open Apple FaceID Protected Devices",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-09-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-485",
      "incident_id": 32,
      "title": "Report 485 on Identical Twins Can Open Apple FaceID Protected Devices",
      "description": "A detailed report about Identical Twins Can Open Apple FaceID Protected Devices",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-09-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-486",
      "incident_id": 32,
      "title": "Report 486 on Identical Twins Can Open Apple FaceID Protected Devices",
      "description": "A detailed report about Identical Twins Can Open Apple FaceID Protected Devices",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-09-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-766",
      "incident_id": 44,
      "title": "Report 766 on Machine Personal Assistants Failed to Maintain Social Norms",
      "description": "A detailed report about Machine Personal Assistants Failed to Maintain Social Norms",
      "url": "https://incidentdatabase.ai",
      "date_published": "2008-07-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-539",
      "incident_id": 35,
      "title": "Report 539 on Employee Automatically Terminated by Computer Program",
      "description": "A detailed report about Employee Automatically Terminated by Computer Program",
      "url": "https://incidentdatabase.ai",
      "date_published": "2014-10-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-540",
      "incident_id": 35,
      "title": "Report 540 on Employee Automatically Terminated by Computer Program",
      "description": "A detailed report about Employee Automatically Terminated by Computer Program",
      "url": "https://incidentdatabase.ai",
      "date_published": "2014-10-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-541",
      "incident_id": 35,
      "title": "Report 541 on Employee Automatically Terminated by Computer Program",
      "description": "A detailed report about Employee Automatically Terminated by Computer Program",
      "url": "https://incidentdatabase.ai",
      "date_published": "2014-10-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-829",
      "incident_id": 47,
      "title": "Report 829 on LinkedIn Search Prefers Male Names",
      "description": "A detailed report about LinkedIn Search Prefers Male Names",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-09-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-830",
      "incident_id": 47,
      "title": "Report 830 on LinkedIn Search Prefers Male Names",
      "description": "A detailed report about LinkedIn Search Prefers Male Names",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-09-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-831",
      "incident_id": 47,
      "title": "Report 831 on LinkedIn Search Prefers Male Names",
      "description": "A detailed report about LinkedIn Search Prefers Male Names",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-09-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-838",
      "incident_id": 48,
      "title": "Report 838 on Passport checker Detects Asian man's Eyes as Closed",
      "description": "A detailed report about Passport checker Detects Asian man's Eyes as Closed",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-12-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-839",
      "incident_id": 48,
      "title": "Report 839 on Passport checker Detects Asian man's Eyes as Closed",
      "description": "A detailed report about Passport checker Detects Asian man's Eyes as Closed",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-12-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-840",
      "incident_id": 48,
      "title": "Report 840 on Passport checker Detects Asian man's Eyes as Closed",
      "description": "A detailed report about Passport checker Detects Asian man's Eyes as Closed",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-12-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-390",
      "incident_id": 28,
      "title": "Report 390 on 2010 Market Flash Crash",
      "description": "A detailed report about 2010 Market Flash Crash",
      "url": "https://incidentdatabase.ai",
      "date_published": "2010-05-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-391",
      "incident_id": 28,
      "title": "Report 391 on 2010 Market Flash Crash",
      "description": "A detailed report about 2010 Market Flash Crash",
      "url": "https://incidentdatabase.ai",
      "date_published": "2010-05-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-392",
      "incident_id": 28,
      "title": "Report 392 on 2010 Market Flash Crash",
      "description": "A detailed report about 2010 Market Flash Crash",
      "url": "https://incidentdatabase.ai",
      "date_published": "2010-05-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-762",
      "incident_id": 43,
      "title": "Report 762 on Racist AI behaviour is not a new problem",
      "description": "A detailed report about Racist AI behaviour is not a new problem",
      "url": "https://incidentdatabase.ai",
      "date_published": "1998-03-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-763",
      "incident_id": 43,
      "title": "Report 763 on Racist AI behaviour is not a new problem",
      "description": "A detailed report about Racist AI behaviour is not a new problem",
      "url": "https://incidentdatabase.ai",
      "date_published": "1998-03-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-764",
      "incident_id": 43,
      "title": "Report 764 on Racist AI behaviour is not a new problem",
      "description": "A detailed report about Racist AI behaviour is not a new problem",
      "url": "https://incidentdatabase.ai",
      "date_published": "1998-03-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-311",
      "incident_id": 26,
      "title": "Report 311 on Hackers Break Apple Face ID",
      "description": "A detailed report about Hackers Break Apple Face ID",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-09-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-312",
      "incident_id": 26,
      "title": "Report 312 on Hackers Break Apple Face ID",
      "description": "A detailed report about Hackers Break Apple Face ID",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-09-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-313",
      "incident_id": 26,
      "title": "Report 313 on Hackers Break Apple Face ID",
      "description": "A detailed report about Hackers Break Apple Face ID",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-09-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-504",
      "incident_id": 33,
      "title": "Report 504 on Amazon Alexa Plays Loud Music when Owner is Away",
      "description": "A detailed report about Amazon Alexa Plays Loud Music when Owner is Away",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-11-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-505",
      "incident_id": 33,
      "title": "Report 505 on Amazon Alexa Plays Loud Music when Owner is Away",
      "description": "A detailed report about Amazon Alexa Plays Loud Music when Owner is Away",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-11-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-507",
      "incident_id": 33,
      "title": "Report 507 on Amazon Alexa Plays Loud Music when Owner is Away",
      "description": "A detailed report about Amazon Alexa Plays Loud Music when Owner is Away",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-11-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-810",
      "incident_id": 46,
      "title": "Report 810 on Nest Smoke Alarm Erroneously Stops Alarming",
      "description": "A detailed report about Nest Smoke Alarm Erroneously Stops Alarming",
      "url": "https://incidentdatabase.ai",
      "date_published": "2014-01-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-811",
      "incident_id": 46,
      "title": "Report 811 on Nest Smoke Alarm Erroneously Stops Alarming",
      "description": "A detailed report about Nest Smoke Alarm Erroneously Stops Alarming",
      "url": "https://incidentdatabase.ai",
      "date_published": "2014-01-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-812",
      "incident_id": 46,
      "title": "Report 812 on Nest Smoke Alarm Erroneously Stops Alarming",
      "description": "A detailed report about Nest Smoke Alarm Erroneously Stops Alarming",
      "url": "https://incidentdatabase.ai",
      "date_published": "2014-01-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-667",
      "incident_id": 39,
      "title": "Report 667 on Deepfake Obama Introduction of Deepfakes",
      "description": "A detailed report about Deepfake Obama Introduction of Deepfakes",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-07-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-668",
      "incident_id": 39,
      "title": "Report 668 on Deepfake Obama Introduction of Deepfakes",
      "description": "A detailed report about Deepfake Obama Introduction of Deepfakes",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-07-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-669",
      "incident_id": 39,
      "title": "Report 669 on Deepfake Obama Introduction of Deepfakes",
      "description": "A detailed report about Deepfake Obama Introduction of Deepfakes",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-07-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-424",
      "incident_id": 30,
      "title": "Report 424 on Poor Performance of Tesla Factory Robots",
      "description": "A detailed report about Poor Performance of Tesla Factory Robots",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-10-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-425",
      "incident_id": 30,
      "title": "Report 425 on Poor Performance of Tesla Factory Robots",
      "description": "A detailed report about Poor Performance of Tesla Factory Robots",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-10-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-426",
      "incident_id": 30,
      "title": "Report 426 on Poor Performance of Tesla Factory Robots",
      "description": "A detailed report about Poor Performance of Tesla Factory Robots",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-10-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1360",
      "incident_id": 36,
      "title": "Report 1360 on Picture of Woman on Side of Bus Shamed for Jaywalking",
      "description": "A detailed report about Picture of Woman on Side of Bus Shamed for Jaywalking",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-11-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-598",
      "incident_id": 36,
      "title": "Report 598 on Picture of Woman on Side of Bus Shamed for Jaywalking",
      "description": "A detailed report about Picture of Woman on Side of Bus Shamed for Jaywalking",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-11-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-597",
      "incident_id": 36,
      "title": "Report 597 on Picture of Woman on Side of Bus Shamed for Jaywalking",
      "description": "A detailed report about Picture of Woman on Side of Bus Shamed for Jaywalking",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-11-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-719",
      "incident_id": 41,
      "title": "Report 719 on All Image Captions Produced are Violent",
      "description": "A detailed report about All Image Captions Produced are Violent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-04-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-720",
      "incident_id": 41,
      "title": "Report 720 on All Image Captions Produced are Violent",
      "description": "A detailed report about All Image Captions Produced are Violent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-04-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-721",
      "incident_id": 41,
      "title": "Report 721 on All Image Captions Produced are Violent",
      "description": "A detailed report about All Image Captions Produced are Violent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-04-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-759",
      "incident_id": 42,
      "title": "Report 759 on Inefficiencies in the United States Resident Matching Program",
      "description": "A detailed report about Inefficiencies in the United States Resident Matching Program",
      "url": "https://incidentdatabase.ai",
      "date_published": "1996-04-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2471",
      "incident_id": 42,
      "title": "Report 2471 on Inefficiencies in the United States Resident Matching Program",
      "description": "A detailed report about Inefficiencies in the United States Resident Matching Program",
      "url": "https://incidentdatabase.ai",
      "date_published": "1996-04-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-780",
      "incident_id": 45,
      "title": "Report 780 on Defamation via AutoComplete",
      "description": "A detailed report about Defamation via AutoComplete",
      "url": "https://incidentdatabase.ai",
      "date_published": "2011-04-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-781",
      "incident_id": 45,
      "title": "Report 781 on Defamation via AutoComplete",
      "description": "A detailed report about Defamation via AutoComplete",
      "url": "https://incidentdatabase.ai",
      "date_published": "2011-04-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-782",
      "incident_id": 45,
      "title": "Report 782 on Defamation via AutoComplete",
      "description": "A detailed report about Defamation via AutoComplete",
      "url": "https://incidentdatabase.ai",
      "date_published": "2011-04-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-648",
      "incident_id": 38,
      "title": "Report 648 on Game AI System Produces Imbalanced Game",
      "description": "A detailed report about Game AI System Produces Imbalanced Game",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-06-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-649",
      "incident_id": 38,
      "title": "Report 649 on Game AI System Produces Imbalanced Game",
      "description": "A detailed report about Game AI System Produces Imbalanced Game",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-06-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-650",
      "incident_id": 38,
      "title": "Report 650 on Game AI System Produces Imbalanced Game",
      "description": "A detailed report about Game AI System Produces Imbalanced Game",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-06-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-697",
      "incident_id": 40,
      "title": "Report 697 on COMPAS Algorithm Performs Poorly in Crime Recidivism Prediction",
      "description": "A detailed report about COMPAS Algorithm Performs Poorly in Crime Recidivism Prediction",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-05-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-699",
      "incident_id": 40,
      "title": "Report 699 on COMPAS Algorithm Performs Poorly in Crime Recidivism Prediction",
      "description": "A detailed report about COMPAS Algorithm Performs Poorly in Crime Recidivism Prediction",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-05-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-700",
      "incident_id": 40,
      "title": "Report 700 on COMPAS Algorithm Performs Poorly in Crime Recidivism Prediction",
      "description": "A detailed report about COMPAS Algorithm Performs Poorly in Crime Recidivism Prediction",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-05-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1137",
      "incident_id": 64,
      "title": "Report 1137 on Customer Service Robot Scares Away Customers",
      "description": "A detailed report about Customer Service Robot Scares Away Customers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-01-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1181",
      "incident_id": 67,
      "title": "Report 1181 on Sleeping Driver on Tesla AutoPilot",
      "description": "A detailed report about Sleeping Driver on Tesla AutoPilot",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-12-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1182",
      "incident_id": 67,
      "title": "Report 1182 on Sleeping Driver on Tesla AutoPilot",
      "description": "A detailed report about Sleeping Driver on Tesla AutoPilot",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-12-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1183",
      "incident_id": 67,
      "title": "Report 1183 on Sleeping Driver on Tesla AutoPilot",
      "description": "A detailed report about Sleeping Driver on Tesla AutoPilot",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-12-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1096",
      "incident_id": 60,
      "title": "Report 1096 on FaceApp Racial Filters",
      "description": "A detailed report about FaceApp Racial Filters",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-04-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1097",
      "incident_id": 60,
      "title": "Report 1097 on FaceApp Racial Filters",
      "description": "A detailed report about FaceApp Racial Filters",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-04-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1098",
      "incident_id": 60,
      "title": "Report 1098 on FaceApp Racial Filters",
      "description": "A detailed report about FaceApp Racial Filters",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-04-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1007",
      "incident_id": 54,
      "title": "Report 1007 on Predictive Policing Biases of PredPol",
      "description": "A detailed report about Predictive Policing Biases of PredPol",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-11-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1008",
      "incident_id": 54,
      "title": "Report 1008 on Predictive Policing Biases of PredPol",
      "description": "A detailed report about Predictive Policing Biases of PredPol",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-11-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1009",
      "incident_id": 54,
      "title": "Report 1009 on Predictive Policing Biases of PredPol",
      "description": "A detailed report about Predictive Policing Biases of PredPol",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-11-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1210",
      "incident_id": 68,
      "title": "Report 1210 on Security Robot Drowns Itself in a Fountain",
      "description": "A detailed report about Security Robot Drowns Itself in a Fountain",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-07-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1211",
      "incident_id": 68,
      "title": "Report 1211 on Security Robot Drowns Itself in a Fountain",
      "description": "A detailed report about Security Robot Drowns Itself in a Fountain",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-07-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1212",
      "incident_id": 68,
      "title": "Report 1212 on Security Robot Drowns Itself in a Fountain",
      "description": "A detailed report about Security Robot Drowns Itself in a Fountain",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-07-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1079",
      "incident_id": 58,
      "title": "Report 1079 on Russian Chatbot Supports Stalin and Violence",
      "description": "A detailed report about Russian Chatbot Supports Stalin and Violence",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-10-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1080",
      "incident_id": 58,
      "title": "Report 1080 on Russian Chatbot Supports Stalin and Violence",
      "description": "A detailed report about Russian Chatbot Supports Stalin and Violence",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-10-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1082",
      "incident_id": 58,
      "title": "Report 1082 on Russian Chatbot Supports Stalin and Violence",
      "description": "A detailed report about Russian Chatbot Supports Stalin and Violence",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-10-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1132",
      "incident_id": 61,
      "title": "Report 1132 on Overfit Kaggle Models Discouraged Data Science Competitors",
      "description": "A detailed report about Overfit Kaggle Models Discouraged Data Science Competitors",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-05-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-961",
      "incident_id": 52,
      "title": "Report 961 on Tesla on AutoPilot Killed Driver in Crash in Florida while Watching Movie",
      "description": "A detailed report about Tesla on AutoPilot Killed Driver in Crash in Florida while Watching Movie",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-07-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-963",
      "incident_id": 52,
      "title": "Report 963 on Tesla on AutoPilot Killed Driver in Crash in Florida while Watching Movie",
      "description": "A detailed report about Tesla on AutoPilot Killed Driver in Crash in Florida while Watching Movie",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-07-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-964",
      "incident_id": 52,
      "title": "Report 964 on Tesla on AutoPilot Killed Driver in Crash in Florida while Watching Movie",
      "description": "A detailed report about Tesla on AutoPilot Killed Driver in Crash in Florida while Watching Movie",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-07-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1255",
      "incident_id": 70,
      "title": "Report 1255 on Self-driving cars in winter",
      "description": "A detailed report about Self-driving cars in winter",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-02-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1256",
      "incident_id": 70,
      "title": "Report 1256 on Self-driving cars in winter",
      "description": "A detailed report about Self-driving cars in winter",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-02-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1259",
      "incident_id": 70,
      "title": "Report 1259 on Self-driving cars in winter",
      "description": "A detailed report about Self-driving cars in winter",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-02-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1085",
      "incident_id": 59,
      "title": "Report 1085 on Gender Biases in Google Translate",
      "description": "A detailed report about Gender Biases in Google Translate",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-04-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1086",
      "incident_id": 59,
      "title": "Report 1086 on Gender Biases in Google Translate",
      "description": "A detailed report about Gender Biases in Google Translate",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-04-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1087",
      "incident_id": 59,
      "title": "Report 1087 on Gender Biases in Google Translate",
      "description": "A detailed report about Gender Biases in Google Translate",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-04-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2471",
      "incident_id": 62,
      "title": "Report 2471 on Bad AI-Written Christmas Carols",
      "description": "A detailed report about Bad AI-Written Christmas Carols",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-12-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-931",
      "incident_id": 51,
      "title": "Report 931 on Security Robot Rolls Over Child in Mall",
      "description": "A detailed report about Security Robot Rolls Over Child in Mall",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-07-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-932",
      "incident_id": 51,
      "title": "Report 932 on Security Robot Rolls Over Child in Mall",
      "description": "A detailed report about Security Robot Rolls Over Child in Mall",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-07-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-933",
      "incident_id": 51,
      "title": "Report 933 on Security Robot Rolls Over Child in Mall",
      "description": "A detailed report about Security Robot Rolls Over Child in Mall",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-07-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-991",
      "incident_id": 53,
      "title": "Report 991 on Biased Google Image Results",
      "description": "A detailed report about Biased Google Image Results",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-03-31",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-992",
      "incident_id": 53,
      "title": "Report 992 on Biased Google Image Results",
      "description": "A detailed report about Biased Google Image Results",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-03-31",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-994",
      "incident_id": 53,
      "title": "Report 994 on Biased Google Image Results",
      "description": "A detailed report about Biased Google Image Results",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-03-31",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1136",
      "incident_id": 63,
      "title": "Report 1136 on Google Photo Merge Decapitates Subject",
      "description": "A detailed report about Google Photo Merge Decapitates Subject",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-01-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1041",
      "incident_id": 56,
      "title": "Report 1041 on AI-Designed Phone Cases Are Unexpected",
      "description": "A detailed report about AI-Designed Phone Cases Are Unexpected",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-07-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1042",
      "incident_id": 56,
      "title": "Report 1042 on AI-Designed Phone Cases Are Unexpected",
      "description": "A detailed report about AI-Designed Phone Cases Are Unexpected",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-07-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1043",
      "incident_id": 56,
      "title": "Report 1043 on AI-Designed Phone Cases Are Unexpected",
      "description": "A detailed report about AI-Designed Phone Cases Are Unexpected",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-07-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1048",
      "incident_id": 57,
      "title": "Report 1048 on Australian Automated Debt Assessment System Issued False Notices to Thousands",
      "description": "A detailed report about Australian Automated Debt Assessment System Issued False Notices to Thousands",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-07-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1049",
      "incident_id": 57,
      "title": "Report 1049 on Australian Automated Debt Assessment System Issued False Notices to Thousands",
      "description": "A detailed report about Australian Automated Debt Assessment System Issued False Notices to Thousands",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-07-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1050",
      "incident_id": 57,
      "title": "Report 1050 on Australian Automated Debt Assessment System Issued False Notices to Thousands",
      "description": "A detailed report about Australian Automated Debt Assessment System Issued False Notices to Thousands",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-07-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1140",
      "incident_id": 65,
      "title": "Report 1140 on Reinforcement Learning Reward Functions in Video Games",
      "description": "A detailed report about Reinforcement Learning Reward Functions in Video Games",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-12-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-876",
      "incident_id": 50,
      "title": "Report 876 on The DAO Hack",
      "description": "A detailed report about The DAO Hack",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-06-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-877",
      "incident_id": 50,
      "title": "Report 877 on The DAO Hack",
      "description": "A detailed report about The DAO Hack",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-06-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-878",
      "incident_id": 50,
      "title": "Report 878 on The DAO Hack",
      "description": "A detailed report about The DAO Hack",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-06-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1261",
      "incident_id": 71,
      "title": "Report 1261 on Google admits its self driving car got it wrong: Bus crash was caused by software",
      "description": "A detailed report about Google admits its self driving car got it wrong: Bus crash was caused by software",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-09-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1262",
      "incident_id": 71,
      "title": "Report 1262 on Google admits its self driving car got it wrong: Bus crash was caused by software",
      "description": "A detailed report about Google admits its self driving car got it wrong: Bus crash was caused by software",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-09-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1263",
      "incident_id": 71,
      "title": "Report 1263 on Google admits its self driving car got it wrong: Bus crash was caused by software",
      "description": "A detailed report about Google admits its self driving car got it wrong: Bus crash was caused by software",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-09-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1020",
      "incident_id": 55,
      "title": "Report 1020 on Alexa Plays Pornography Instead of Kids Song",
      "description": "A detailed report about Alexa Plays Pornography Instead of Kids Song",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-12-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1021",
      "incident_id": 55,
      "title": "Report 1021 on Alexa Plays Pornography Instead of Kids Song",
      "description": "A detailed report about Alexa Plays Pornography Instead of Kids Song",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-12-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1022",
      "incident_id": 55,
      "title": "Report 1022 on Alexa Plays Pornography Instead of Kids Song",
      "description": "A detailed report about Alexa Plays Pornography Instead of Kids Song",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-12-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1240",
      "incident_id": 69,
      "title": "Report 1240 on Worker killed by robot in welding accident at car parts factory in India",
      "description": "A detailed report about Worker killed by robot in welding accident at car parts factory in India",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-07-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1241",
      "incident_id": 69,
      "title": "Report 1241 on Worker killed by robot in welding accident at car parts factory in India",
      "description": "A detailed report about Worker killed by robot in welding accident at car parts factory in India",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-07-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1243",
      "incident_id": 69,
      "title": "Report 1243 on Worker killed by robot in welding accident at car parts factory in India",
      "description": "A detailed report about Worker killed by robot in welding accident at car parts factory in India",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-07-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1159",
      "incident_id": 66,
      "title": "Report 1159 on Chinese Chatbots Question Communist Party",
      "description": "A detailed report about Chinese Chatbots Question Communist Party",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-08-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1161",
      "incident_id": 66,
      "title": "Report 1161 on Chinese Chatbots Question Communist Party",
      "description": "A detailed report about Chinese Chatbots Question Communist Party",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-08-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1162",
      "incident_id": 66,
      "title": "Report 1162 on Chinese Chatbots Question Communist Party",
      "description": "A detailed report about Chinese Chatbots Question Communist Party",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-08-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-864",
      "incident_id": 49,
      "title": "Report 864 on AI Beauty Judge Did Not Like Dark Skin",
      "description": "A detailed report about AI Beauty Judge Did Not Like Dark Skin",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-09-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-865",
      "incident_id": 49,
      "title": "Report 865 on AI Beauty Judge Did Not Like Dark Skin",
      "description": "A detailed report about AI Beauty Judge Did Not Like Dark Skin",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-09-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-866",
      "incident_id": 49,
      "title": "Report 866 on AI Beauty Judge Did Not Like Dark Skin",
      "description": "A detailed report about AI Beauty Judge Did Not Like Dark Skin",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-09-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1291",
      "incident_id": 72,
      "title": "Report 1291 on Facebook translates 'good morning' into 'attack them', leading to arrest",
      "description": "A detailed report about Facebook translates 'good morning' into 'attack them', leading to arrest",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-10-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1292",
      "incident_id": 72,
      "title": "Report 1292 on Facebook translates 'good morning' into 'attack them', leading to arrest",
      "description": "A detailed report about Facebook translates 'good morning' into 'attack them', leading to arrest",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-10-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1293",
      "incident_id": 72,
      "title": "Report 1293 on Facebook translates 'good morning' into 'attack them', leading to arrest",
      "description": "A detailed report about Facebook translates 'good morning' into 'attack them', leading to arrest",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-10-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1382",
      "incident_id": 82,
      "title": "Report 1382 on #LekkiMassacre: Why Facebook labelled content from October 20 incident ‘false’",
      "description": "A detailed report about #LekkiMassacre: Why Facebook labelled content from October 20 incident ‘false’",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-10-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1394",
      "incident_id": 93,
      "title": "Report 1394 on HUD charges Facebook with enabling housing discrimination",
      "description": "A detailed report about HUD charges Facebook with enabling housing discrimination",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-08-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1817",
      "incident_id": 93,
      "title": "Report 1817 on HUD charges Facebook with enabling housing discrimination",
      "description": "A detailed report about HUD charges Facebook with enabling housing discrimination",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-08-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2107",
      "incident_id": 93,
      "title": "Report 2107 on HUD charges Facebook with enabling housing discrimination",
      "description": "A detailed report about HUD charges Facebook with enabling housing discrimination",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-08-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2471",
      "incident_id": 85,
      "title": "Report 2471 on AI attempts to ease fear of robots, blurts out it can’t ‘avoid destroying humankind’",
      "description": "A detailed report about AI attempts to ease fear of robots, blurts out it can’t ‘avoid destroying humankind’",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-10-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1384",
      "incident_id": 84,
      "title": "Report 1384 on Tiny Changes Let False Claims About COVID-19, Voting Evade Facebook Fact Checks",
      "description": "A detailed report about Tiny Changes Let False Claims About COVID-19, Voting Evade Facebook Fact Checks",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-10-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1340",
      "incident_id": 77,
      "title": "Report 1340 on Knightscope's Park Patrol Robot Ignored Bystander Pressing Emergency Button to Alert Police about Fight",
      "description": "A detailed report about Knightscope's Park Patrol Robot Ignored Bystander Pressing Emergency Button to Alert Police about Fight",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-10-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1390",
      "incident_id": 77,
      "title": "Report 1390 on Knightscope's Park Patrol Robot Ignored Bystander Pressing Emergency Button to Alert Police about Fight",
      "description": "A detailed report about Knightscope's Park Patrol Robot Ignored Bystander Pressing Emergency Button to Alert Police about Fight",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-10-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1878",
      "incident_id": 77,
      "title": "Report 1878 on Knightscope's Park Patrol Robot Ignored Bystander Pressing Emergency Button to Alert Police about Fight",
      "description": "A detailed report about Knightscope's Park Patrol Robot Ignored Bystander Pressing Emergency Button to Alert Police about Fight",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-10-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1341",
      "incident_id": 78,
      "title": "Report 1341 on Meet the Secret Algorithm That's Keeping Students Out of College",
      "description": "A detailed report about Meet the Secret Algorithm That's Keeping Students Out of College",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-07-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1398",
      "incident_id": 96,
      "title": "Report 1398 on Houston Schools Must Face Teacher Evaluation Lawsuit",
      "description": "A detailed report about Houston Schools Must Face Teacher Evaluation Lawsuit",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-05-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1388",
      "incident_id": 88,
      "title": "Report 1388 on Jewish Baby Strollers Provided Anti-Semitic Google Images, Allegedly Resulting from Hate Speech Campaign",
      "description": "A detailed report about Jewish Baby Strollers Provided Anti-Semitic Google Images, Allegedly Resulting from Hate Speech Campaign",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-08-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2183",
      "incident_id": 88,
      "title": "Report 2183 on Jewish Baby Strollers Provided Anti-Semitic Google Images, Allegedly Resulting from Hate Speech Campaign",
      "description": "A detailed report about Jewish Baby Strollers Provided Anti-Semitic Google Images, Allegedly Resulting from Hate Speech Campaign",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-08-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1320",
      "incident_id": 73,
      "title": "Report 1320 on Is Pokémon Go racist? How the app may be redlining communities of color",
      "description": "A detailed report about Is Pokémon Go racist? How the app may be redlining communities of color",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-03-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1321",
      "incident_id": 73,
      "title": "Report 1321 on Is Pokémon Go racist? How the app may be redlining communities of color",
      "description": "A detailed report about Is Pokémon Go racist? How the app may be redlining communities of color",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-03-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1322",
      "incident_id": 73,
      "title": "Report 1322 on Is Pokémon Go racist? How the app may be redlining communities of color",
      "description": "A detailed report about Is Pokémon Go racist? How the app may be redlining communities of color",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-03-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1337",
      "incident_id": 75,
      "title": "Report 1337 on Google Instant's Allegedly 'Anti-Semitic' Results Lead To Lawsuit In France",
      "description": "A detailed report about Google Instant's Allegedly 'Anti-Semitic' Results Lead To Lawsuit In France",
      "url": "https://incidentdatabase.ai",
      "date_published": "2012-01-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1381",
      "incident_id": 81,
      "title": "Report 1381 on Researchers find evidence of racial, gender, and socioeconomic bias in chest X-ray classifiers",
      "description": "A detailed report about Researchers find evidence of racial, gender, and socioeconomic bias in chest X-ray classifiers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-10-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1386",
      "incident_id": 86,
      "title": "Report 1386 on Coding Errors in Leaving Certificate Grading Algorithm Caused Inaccurate Scores in Ireland",
      "description": "A detailed report about Coding Errors in Leaving Certificate Grading Algorithm Caused Inaccurate Scores in Ireland",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-10-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2038",
      "incident_id": 86,
      "title": "Report 2038 on Coding Errors in Leaving Certificate Grading Algorithm Caused Inaccurate Scores in Ireland",
      "description": "A detailed report about Coding Errors in Leaving Certificate Grading Algorithm Caused Inaccurate Scores in Ireland",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-10-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1336",
      "incident_id": 74,
      "title": "Report 1336 on Detroit Police Wrongfully Arrested Black Man Due To Faulty FRT",
      "description": "A detailed report about Detroit Police Wrongfully Arrested Black Man Due To Faulty FRT",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-01-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1400",
      "incident_id": 74,
      "title": "Report 1400 on Detroit Police Wrongfully Arrested Black Man Due To Faulty FRT",
      "description": "A detailed report about Detroit Police Wrongfully Arrested Black Man Due To Faulty FRT",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-01-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1467",
      "incident_id": 74,
      "title": "Report 1467 on Detroit Police Wrongfully Arrested Black Man Due To Faulty FRT",
      "description": "A detailed report about Detroit Police Wrongfully Arrested Black Man Due To Faulty FRT",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-01-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2133",
      "incident_id": 95,
      "title": "Report 2133 on Job Screening Service Halts Facial Analysis of Applicants",
      "description": "A detailed report about Job Screening Service Halts Facial Analysis of Applicants",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-11-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2132",
      "incident_id": 95,
      "title": "Report 2132 on Job Screening Service Halts Facial Analysis of Applicants",
      "description": "A detailed report about Job Screening Service Halts Facial Analysis of Applicants",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-11-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1397",
      "incident_id": 95,
      "title": "Report 1397 on Job Screening Service Halts Facial Analysis of Applicants",
      "description": "A detailed report about Job Screening Service Halts Facial Analysis of Applicants",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-11-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1380",
      "incident_id": 80,
      "title": "Report 1380 on AI mistakes referee’s bald head for football — hilarity ensued",
      "description": "A detailed report about AI mistakes referee’s bald head for football — hilarity ensued",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-10-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1559",
      "incident_id": 80,
      "title": "Report 1559 on AI mistakes referee’s bald head for football — hilarity ensued",
      "description": "A detailed report about AI mistakes referee’s bald head for football — hilarity ensued",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-10-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1383",
      "incident_id": 83,
      "title": "Report 1383 on AI Spam Filters Allegedly Block Legitimate Emails Based on Biased Keyword Detection",
      "description": "A detailed report about AI Spam Filters Allegedly Block Legitimate Emails Based on Biased Keyword Detection",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-10-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1399",
      "incident_id": 97,
      "title": "Report 1399 on Tesla Autopilot Mistakes Red Letters on Flag for Red Traffic Lights",
      "description": "A detailed report about Tesla Autopilot Mistakes Red Letters on Flag for Red Traffic Lights",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-10-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1401",
      "incident_id": 98,
      "title": "Report 1401 on N.Y.P.D. Robot Dog’s Run Is Cut Short After Fierce Backlash",
      "description": "A detailed report about N.Y.P.D. Robot Dog’s Run Is Cut Short After Fierce Backlash",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-04-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1379",
      "incident_id": 79,
      "title": "Report 1379 on Kidney Testing Method Allegedly Underestimated Risk of Black Patients",
      "description": "A detailed report about Kidney Testing Method Allegedly Underestimated Risk of Black Patients",
      "url": "https://incidentdatabase.ai",
      "date_published": "1999-03-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1736",
      "incident_id": 79,
      "title": "Report 1736 on Kidney Testing Method Allegedly Underestimated Risk of Black Patients",
      "description": "A detailed report about Kidney Testing Method Allegedly Underestimated Risk of Black Patients",
      "url": "https://incidentdatabase.ai",
      "date_published": "1999-03-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2039",
      "incident_id": 79,
      "title": "Report 2039 on Kidney Testing Method Allegedly Underestimated Risk of Black Patients",
      "description": "A detailed report about Kidney Testing Method Allegedly Underestimated Risk of Black Patients",
      "url": "https://incidentdatabase.ai",
      "date_published": "1999-03-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1387",
      "incident_id": 87,
      "title": "Report 1387 on UK passport photo checker shows bias against dark-skinned women",
      "description": "A detailed report about UK passport photo checker shows bias against dark-skinned women",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-10-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1391",
      "incident_id": 91,
      "title": "Report 1391 on Frontline workers protest at Stanford after hospital distributed vaccine to administrators",
      "description": "A detailed report about Frontline workers protest at Stanford after hospital distributed vaccine to administrators",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-12-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1392",
      "incident_id": 91,
      "title": "Report 1392 on Frontline workers protest at Stanford after hospital distributed vaccine to administrators",
      "description": "A detailed report about Frontline workers protest at Stanford after hospital distributed vaccine to administrators",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-12-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1463",
      "incident_id": 91,
      "title": "Report 1463 on Frontline workers protest at Stanford after hospital distributed vaccine to administrators",
      "description": "A detailed report about Frontline workers protest at Stanford after hospital distributed vaccine to administrators",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-12-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1339",
      "incident_id": 76,
      "title": "Report 1339 on Live facial recognition is tracking kids suspected of being criminals",
      "description": "A detailed report about Live facial recognition is tracking kids suspected of being criminals",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-10-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1393",
      "incident_id": 92,
      "title": "Report 1393 on Apple Card's Credit Assessment Algorithm Allegedly Discriminated against Women",
      "description": "A detailed report about Apple Card's Credit Assessment Algorithm Allegedly Discriminated against Women",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-11-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1396",
      "incident_id": 92,
      "title": "Report 1396 on Apple Card's Credit Assessment Algorithm Allegedly Discriminated against Women",
      "description": "A detailed report about Apple Card's Credit Assessment Algorithm Allegedly Discriminated against Women",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-11-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2035",
      "incident_id": 92,
      "title": "Report 2035 on Apple Card's Credit Assessment Algorithm Allegedly Discriminated against Women",
      "description": "A detailed report about Apple Card's Credit Assessment Algorithm Allegedly Discriminated against Women",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-11-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1389",
      "incident_id": 89,
      "title": "Report 1389 on The Christchurch shooter and YouTube’s radicalization trap",
      "description": "A detailed report about The Christchurch shooter and YouTube’s radicalization trap",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-03-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1395",
      "incident_id": 94,
      "title": "Report 1395 on Court Rules Deliveroo Used 'Discriminatory' Algorithm",
      "description": "A detailed report about Court Rules Deliveroo Used 'Discriminatory' Algorithm",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-11-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1473",
      "incident_id": 94,
      "title": "Report 1473 on Court Rules Deliveroo Used 'Discriminatory' Algorithm",
      "description": "A detailed report about Court Rules Deliveroo Used 'Discriminatory' Algorithm",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-11-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1413",
      "incident_id": 110,
      "title": "Report 1413 on Arkansas's Opaque Algorithm to Allocate Health Care Excessively Cut Down Hours for Beneficiaries",
      "description": "A detailed report about Arkansas's Opaque Algorithm to Allocate Health Care Excessively Cut Down Hours for Beneficiaries",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-01-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2651",
      "incident_id": 110,
      "title": "Report 2651 on Arkansas's Opaque Algorithm to Allocate Health Care Excessively Cut Down Hours for Beneficiaries",
      "description": "A detailed report about Arkansas's Opaque Algorithm to Allocate Health Care Excessively Cut Down Hours for Beneficiaries",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-01-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1426",
      "incident_id": 111,
      "title": "Report 1426 on Amazon Flex Drivers Allegedly Fired via Automated Employee Evaluations",
      "description": "A detailed report about Amazon Flex Drivers Allegedly Fired via Automated Employee Evaluations",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-09-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1427",
      "incident_id": 111,
      "title": "Report 1427 on Amazon Flex Drivers Allegedly Fired via Automated Employee Evaluations",
      "description": "A detailed report about Amazon Flex Drivers Allegedly Fired via Automated Employee Evaluations",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-09-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1428",
      "incident_id": 111,
      "title": "Report 1428 on Amazon Flex Drivers Allegedly Fired via Automated Employee Evaluations",
      "description": "A detailed report about Amazon Flex Drivers Allegedly Fired via Automated Employee Evaluations",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-09-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1407",
      "incident_id": 104,
      "title": "Report 1407 on California's Algorithm Considered ZIP Codes in Vaccine Distribution, Allegedly Excluding Low-Income Neighborhoods and Communities of Color",
      "description": "A detailed report about California's Algorithm Considered ZIP Codes in Vaccine Distribution, Allegedly Excluding Low-Income Neighborhoods and Communities of Color",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-02-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1409",
      "incident_id": 106,
      "title": "Report 1409 on Korean Chatbot Luda Made Offensive Remarks towards Minority Groups",
      "description": "A detailed report about Korean Chatbot Luda Made Offensive Remarks towards Minority Groups",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-12-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1416",
      "incident_id": 106,
      "title": "Report 1416 on Korean Chatbot Luda Made Offensive Remarks towards Minority Groups",
      "description": "A detailed report about Korean Chatbot Luda Made Offensive Remarks towards Minority Groups",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-12-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1417",
      "incident_id": 106,
      "title": "Report 1417 on Korean Chatbot Luda Made Offensive Remarks towards Minority Groups",
      "description": "A detailed report about Korean Chatbot Luda Made Offensive Remarks towards Minority Groups",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-12-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1411",
      "incident_id": 108,
      "title": "Report 1411 on Skating Rink’s Facial Recognition Cameras Misidentified Black Teenager as Banned Troublemaker",
      "description": "A detailed report about Skating Rink’s Facial Recognition Cameras Misidentified Black Teenager as Banned Troublemaker",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-07-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1503",
      "incident_id": 108,
      "title": "Report 1503 on Skating Rink’s Facial Recognition Cameras Misidentified Black Teenager as Banned Troublemaker",
      "description": "A detailed report about Skating Rink’s Facial Recognition Cameras Misidentified Black Teenager as Banned Troublemaker",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-07-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1537",
      "incident_id": 108,
      "title": "Report 1537 on Skating Rink’s Facial Recognition Cameras Misidentified Black Teenager as Banned Troublemaker",
      "description": "A detailed report about Skating Rink’s Facial Recognition Cameras Misidentified Black Teenager as Banned Troublemaker",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-07-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1440",
      "incident_id": 115,
      "title": "Report 1440 on Genderify’s AI to Predict a Person’s Gender Revealed by Free API Users to Exhibit Bias",
      "description": "A detailed report about Genderify’s AI to Predict a Person’s Gender Revealed by Free API Users to Exhibit Bias",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-07-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1472",
      "incident_id": 115,
      "title": "Report 1472 on Genderify’s AI to Predict a Person’s Gender Revealed by Free API Users to Exhibit Bias",
      "description": "A detailed report about Genderify’s AI to Predict a Person’s Gender Revealed by Free API Users to Exhibit Bias",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-07-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2204",
      "incident_id": 115,
      "title": "Report 2204 on Genderify’s AI to Predict a Person’s Gender Revealed by Free API Users to Exhibit Bias",
      "description": "A detailed report about Genderify’s AI to Predict a Person’s Gender Revealed by Free API Users to Exhibit Bias",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-07-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1439",
      "incident_id": 114,
      "title": "Report 1439 on Amazon's Rekognition Falsely Matched Members of Congress to Mugshots",
      "description": "A detailed report about Amazon's Rekognition Falsely Matched Members of Congress to Mugshots",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-07-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1410",
      "incident_id": 107,
      "title": "Report 1410 on Chinese Tech Firms Allegedly Developed Facial Recognition to Identify People by Race, Targeting Uyghur Muslims",
      "description": "A detailed report about Chinese Tech Firms Allegedly Developed Facial Recognition to Identify People by Race, Targeting Uyghur Muslims",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-07-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1928",
      "incident_id": 107,
      "title": "Report 1928 on Chinese Tech Firms Allegedly Developed Facial Recognition to Identify People by Race, Targeting Uyghur Muslims",
      "description": "A detailed report about Chinese Tech Firms Allegedly Developed Facial Recognition to Identify People by Race, Targeting Uyghur Muslims",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-07-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1444",
      "incident_id": 119,
      "title": "Report 1444 on Xsolla Employees Fired by CEO Allegedly via Big Data Analytics of Work Activities",
      "description": "A detailed report about Xsolla Employees Fired by CEO Allegedly via Big Data Analytics of Work Activities",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-08-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1800",
      "incident_id": 119,
      "title": "Report 1800 on Xsolla Employees Fired by CEO Allegedly via Big Data Analytics of Work Activities",
      "description": "A detailed report about Xsolla Employees Fired by CEO Allegedly via Big Data Analytics of Work Activities",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-08-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1801",
      "incident_id": 119,
      "title": "Report 1801 on Xsolla Employees Fired by CEO Allegedly via Big Data Analytics of Work Activities",
      "description": "A detailed report about Xsolla Employees Fired by CEO Allegedly via Big Data Analytics of Work Activities",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-08-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1408",
      "incident_id": 105,
      "title": "Report 1408 on Tesla Model 3 on Autopilot Crashed into a Ford Explorer Pickup, Killing a Fifteen-Year-Old in California",
      "description": "A detailed report about Tesla Model 3 on Autopilot Crashed into a Ford Explorer Pickup, Killing a Fifteen-Year-Old in California",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-08-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1402",
      "incident_id": 99,
      "title": "Report 1402 on Major Universities Are Using Race as a “High Impact Predictor” of Student Success",
      "description": "A detailed report about Major Universities Are Using Race as a “High Impact Predictor” of Student Success",
      "url": "https://incidentdatabase.ai",
      "date_published": "2012-01-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2106",
      "incident_id": 121,
      "title": "Report 2106 on Autonomous Kargu-2 Drone Allegedly Remotely Used to Hunt down Libyan Soldiers",
      "description": "A detailed report about Autonomous Kargu-2 Drone Allegedly Remotely Used to Hunt down Libyan Soldiers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-03-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2105",
      "incident_id": 121,
      "title": "Report 2105 on Autonomous Kargu-2 Drone Allegedly Remotely Used to Hunt down Libyan Soldiers",
      "description": "A detailed report about Autonomous Kargu-2 Drone Allegedly Remotely Used to Hunt down Libyan Soldiers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-03-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2104",
      "incident_id": 121,
      "title": "Report 2104 on Autonomous Kargu-2 Drone Allegedly Remotely Used to Hunt down Libyan Soldiers",
      "description": "A detailed report about Autonomous Kargu-2 Drone Allegedly Remotely Used to Hunt down Libyan Soldiers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-03-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1412",
      "incident_id": 109,
      "title": "Report 1412 on PimEyes's Facial Recognition AI Allegedly Lacked Safeguards to Prevent Itself from Being Abused",
      "description": "A detailed report about PimEyes's Facial Recognition AI Allegedly Lacked Safeguards to Prevent Itself from Being Abused",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-01-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1404",
      "incident_id": 101,
      "title": "Report 1404 on Dutch Families Wrongfully Accused of Tax Fraud Due to Discriminatory Algorithm",
      "description": "A detailed report about Dutch Families Wrongfully Accused of Tax Fraud Due to Discriminatory Algorithm",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-09-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1575",
      "incident_id": 101,
      "title": "Report 1575 on Dutch Families Wrongfully Accused of Tax Fraud Due to Discriminatory Algorithm",
      "description": "A detailed report about Dutch Families Wrongfully Accused of Tax Fraud Due to Discriminatory Algorithm",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-09-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1863",
      "incident_id": 101,
      "title": "Report 1863 on Dutch Families Wrongfully Accused of Tax Fraud Due to Discriminatory Algorithm",
      "description": "A detailed report about Dutch Families Wrongfully Accused of Tax Fraud Due to Discriminatory Algorithm",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-09-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1406",
      "incident_id": 103,
      "title": "Report 1406 on Twitter’s Image Cropping Tool Allegedly Showed Gender and Racial Bias",
      "description": "A detailed report about Twitter’s Image Cropping Tool Allegedly Showed Gender and Racial Bias",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-09-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1527",
      "incident_id": 103,
      "title": "Report 1527 on Twitter’s Image Cropping Tool Allegedly Showed Gender and Racial Bias",
      "description": "A detailed report about Twitter’s Image Cropping Tool Allegedly Showed Gender and Racial Bias",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-09-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1528",
      "incident_id": 103,
      "title": "Report 1528 on Twitter’s Image Cropping Tool Allegedly Showed Gender and Racial Bias",
      "description": "A detailed report about Twitter’s Image Cropping Tool Allegedly Showed Gender and Racial Bias",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-09-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1438",
      "incident_id": 113,
      "title": "Report 1438 on Facebook's AI Put Primates Label on Video Featuring Black Men",
      "description": "A detailed report about Facebook's AI Put Primates Label on Video Featuring Black Men",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-06-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1448",
      "incident_id": 122,
      "title": "Report 1448 on Facebook’s Tag Suggestions Allegedly Stored Biometric Data without User Consent",
      "description": "A detailed report about Facebook’s Tag Suggestions Allegedly Stored Biometric Data without User Consent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-06-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1405",
      "incident_id": 102,
      "title": "Report 1405 on Personal voice assistants struggle with black voices, new study shows",
      "description": "A detailed report about Personal voice assistants struggle with black voices, new study shows",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-03-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1523",
      "incident_id": 102,
      "title": "Report 1523 on Personal voice assistants struggle with black voices, new study shows",
      "description": "A detailed report about Personal voice assistants struggle with black voices, new study shows",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-03-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2831",
      "incident_id": 112,
      "title": "Report 2831 on Police Departments Reported ShotSpotter as Unreliable and Wasteful",
      "description": "A detailed report about Police Departments Reported ShotSpotter as Unreliable and Wasteful",
      "url": "https://incidentdatabase.ai",
      "date_published": "2012-10-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2623",
      "incident_id": 112,
      "title": "Report 2623 on Police Departments Reported ShotSpotter as Unreliable and Wasteful",
      "description": "A detailed report about Police Departments Reported ShotSpotter as Unreliable and Wasteful",
      "url": "https://incidentdatabase.ai",
      "date_published": "2012-10-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2496",
      "incident_id": 112,
      "title": "Report 2496 on Police Departments Reported ShotSpotter as Unreliable and Wasteful",
      "description": "A detailed report about Police Departments Reported ShotSpotter as Unreliable and Wasteful",
      "url": "https://incidentdatabase.ai",
      "date_published": "2012-10-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1403",
      "incident_id": 100,
      "title": "Report 1403 on How French welfare services are creating ‘robo-debt’",
      "description": "A detailed report about How French welfare services are creating ‘robo-debt’",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-03-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1441",
      "incident_id": 116,
      "title": "Report 1441 on Amazon's AI Cameras Incorrectly Penalized Delivery Drivers for Mistakes They Did Not Make",
      "description": "A detailed report about Amazon's AI Cameras Incorrectly Penalized Delivery Drivers for Mistakes They Did Not Make",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-09-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1803",
      "incident_id": 116,
      "title": "Report 1803 on Amazon's AI Cameras Incorrectly Penalized Delivery Drivers for Mistakes They Did Not Make",
      "description": "A detailed report about Amazon's AI Cameras Incorrectly Penalized Delivery Drivers for Mistakes They Did Not Make",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-09-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1443",
      "incident_id": 118,
      "title": "Report 1443 on OpenAI's GPT-3 Associated Muslims with Violence",
      "description": "A detailed report about OpenAI's GPT-3 Associated Muslims with Violence",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-08-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2009",
      "incident_id": 118,
      "title": "Report 2009 on OpenAI's GPT-3 Associated Muslims with Violence",
      "description": "A detailed report about OpenAI's GPT-3 Associated Muslims with Violence",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-08-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2010",
      "incident_id": 118,
      "title": "Report 2010 on OpenAI's GPT-3 Associated Muslims with Violence",
      "description": "A detailed report about OpenAI's GPT-3 Associated Muslims with Violence",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-08-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1445",
      "incident_id": 120,
      "title": "Report 1445 on Philosophy AI Allegedly Used To Generate Mixture of Innocent and Harmful Reddit Posts",
      "description": "A detailed report about Philosophy AI Allegedly Used To Generate Mixture of Innocent and Harmful Reddit Posts",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-09-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1442",
      "incident_id": 117,
      "title": "Report 1442 on TikTok's Suggested Accounts Algorithm Allegedly Reinforced Racial Bias through Feedback Loops",
      "description": "A detailed report about TikTok's Suggested Accounts Algorithm Allegedly Reinforced Racial Bias through Feedback Loops",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-02-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2019",
      "incident_id": 117,
      "title": "Report 2019 on TikTok's Suggested Accounts Algorithm Allegedly Reinforced Racial Bias through Feedback Loops",
      "description": "A detailed report about TikTok's Suggested Accounts Algorithm Allegedly Reinforced Racial Bias through Feedback Loops",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-02-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2020",
      "incident_id": 117,
      "title": "Report 2020 on TikTok's Suggested Accounts Algorithm Allegedly Reinforced Racial Bias through Feedback Loops",
      "description": "A detailed report about TikTok's Suggested Accounts Algorithm Allegedly Reinforced Racial Bias through Feedback Loops",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-02-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1462",
      "incident_id": 129,
      "title": "Report 1462 on Facebook's Automated Tools Failed to Adequately Remove Hate Speech, Violence, and Incitement",
      "description": "A detailed report about Facebook's Automated Tools Failed to Adequately Remove Hate Speech, Violence, and Incitement",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-03-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1478",
      "incident_id": 140,
      "title": "Report 1478 on ProctorU’s Identity Verification and Exam Monitoring Systems Provided Allegedly Discriminatory Experiences for BIPOC Students",
      "description": "A detailed report about ProctorU’s Identity Verification and Exam Monitoring Systems Provided Allegedly Discriminatory Experiences for BIPOC Students",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-06-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1494",
      "incident_id": 146,
      "title": "Report 1494 on Research Prototype AI, Delphi, Reportedly Gave Racially Biased Answers on Ethics",
      "description": "A detailed report about Research Prototype AI, Delphi, Reportedly Gave Racially Biased Answers on Ethics",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-10-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1495",
      "incident_id": 146,
      "title": "Report 1495 on Research Prototype AI, Delphi, Reportedly Gave Racially Biased Answers on Ethics",
      "description": "A detailed report about Research Prototype AI, Delphi, Reportedly Gave Racially Biased Answers on Ethics",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-10-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1502",
      "incident_id": 146,
      "title": "Report 1502 on Research Prototype AI, Delphi, Reportedly Gave Racially Biased Answers on Ethics",
      "description": "A detailed report about Research Prototype AI, Delphi, Reportedly Gave Racially Biased Answers on Ethics",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-10-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1474",
      "incident_id": 137,
      "title": "Report 1474 on Israeli Tax Authority Employed Opaque Algorithm to Impose Fines, Reportedly Refusing to Provide an Explanation for Amount Calculation to a Farmer",
      "description": "A detailed report about Israeli Tax Authority Employed Opaque Algorithm to Impose Fines, Reportedly Refusing to Provide an Explanation for Amount Calculation to a Farmer",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-01-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1483",
      "incident_id": 144,
      "title": "Report 1483 on YouTube's AI Mistakenly Banned Chess Channel over Chess Language Misinterpretation",
      "description": "A detailed report about YouTube's AI Mistakenly Banned Chess Channel over Chess Language Misinterpretation",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-06-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1979",
      "incident_id": 144,
      "title": "Report 1979 on YouTube's AI Mistakenly Banned Chess Channel over Chess Language Misinterpretation",
      "description": "A detailed report about YouTube's AI Mistakenly Banned Chess Channel over Chess Language Misinterpretation",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-06-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1980",
      "incident_id": 144,
      "title": "Report 1980 on YouTube's AI Mistakenly Banned Chess Channel over Chess Language Misinterpretation",
      "description": "A detailed report about YouTube's AI Mistakenly Banned Chess Channel over Chess Language Misinterpretation",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-06-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1499",
      "incident_id": 148,
      "title": "Report 1499 on Web Accessibility Vendors Allegedly Falsely Claimed to Provide Compliance Using AI",
      "description": "A detailed report about Web Accessibility Vendors Allegedly Falsely Claimed to Provide Compliance Using AI",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-11-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1520",
      "incident_id": 160,
      "title": "Report 1520 on Alexa Recommended Dangerous TikTok Challenge to Ten-Year-Old Girl",
      "description": "A detailed report about Alexa Recommended Dangerous TikTok Challenge to Ten-Year-Old Girl",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-12-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1521",
      "incident_id": 160,
      "title": "Report 1521 on Alexa Recommended Dangerous TikTok Challenge to Ten-Year-Old Girl",
      "description": "A detailed report about Alexa Recommended Dangerous TikTok Challenge to Ten-Year-Old Girl",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-12-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2381",
      "incident_id": 160,
      "title": "Report 2381 on Alexa Recommended Dangerous TikTok Challenge to Ten-Year-Old Girl",
      "description": "A detailed report about Alexa Recommended Dangerous TikTok Challenge to Ten-Year-Old Girl",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-12-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1509",
      "incident_id": 152,
      "title": "Report 1509 on SoftBank's Humanoid Robot, Pepper, Reportedly Frequently Made Errors, Prompting Dismissal",
      "description": "A detailed report about SoftBank's Humanoid Robot, Pepper, Reportedly Frequently Made Errors, Prompting Dismissal",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-07-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1510",
      "incident_id": 152,
      "title": "Report 1510 on SoftBank's Humanoid Robot, Pepper, Reportedly Frequently Made Errors, Prompting Dismissal",
      "description": "A detailed report about SoftBank's Humanoid Robot, Pepper, Reportedly Frequently Made Errors, Prompting Dismissal",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-07-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1530",
      "incident_id": 161,
      "title": "Report 1530 on Facebook's Ad Delivery Reportedly Excluded Audience along Racial and Gender Lines",
      "description": "A detailed report about Facebook's Ad Delivery Reportedly Excluded Audience along Racial and Gender Lines",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-04-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2138",
      "incident_id": 161,
      "title": "Report 2138 on Facebook's Ad Delivery Reportedly Excluded Audience along Racial and Gender Lines",
      "description": "A detailed report about Facebook's Ad Delivery Reportedly Excluded Audience along Racial and Gender Lines",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-04-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2139",
      "incident_id": 161,
      "title": "Report 2139 on Facebook's Ad Delivery Reportedly Excluded Audience along Racial and Gender Lines",
      "description": "A detailed report about Facebook's Ad Delivery Reportedly Excluded Audience along Racial and Gender Lines",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-04-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1534",
      "incident_id": 164,
      "title": "Report 1534 on Facebook News Feed Allegedly Boosted Misinformation and Violating Content Following Use of MSI Metric",
      "description": "A detailed report about Facebook News Feed Allegedly Boosted Misinformation and Violating Content Following Use of MSI Metric",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-10-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1540",
      "incident_id": 168,
      "title": "Report 1540 on Collaborative Filtering Prone to Popularity Bias, Resulting in Overrepresentation of Popular Items in the Recommendation Outputs",
      "description": "A detailed report about Collaborative Filtering Prone to Popularity Bias, Resulting in Overrepresentation of Popular Items in the Recommendation Outputs",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-03-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1541",
      "incident_id": 168,
      "title": "Report 1541 on Collaborative Filtering Prone to Popularity Bias, Resulting in Overrepresentation of Popular Items in the Recommendation Outputs",
      "description": "A detailed report about Collaborative Filtering Prone to Popularity Bias, Resulting in Overrepresentation of Popular Items in the Recommendation Outputs",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-03-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1468",
      "incident_id": 133,
      "title": "Report 1468 on Online Trolls Allegedly Abused TikTok’s Automated Content Reporting System to Discriminate against Marginalized Creators",
      "description": "A detailed report about Online Trolls Allegedly Abused TikTok’s Automated Content Reporting System to Discriminate against Marginalized Creators",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-12-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1465",
      "incident_id": 131,
      "title": "Report 1465 on Proctoring Algorithm in Online California Bar Exam Flagged an Unusually High Number of Alleged Cheaters",
      "description": "A detailed report about Proctoring Algorithm in Online California Bar Exam Flagged an Unusually High Number of Alleged Cheaters",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-12-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1771",
      "incident_id": 131,
      "title": "Report 1771 on Proctoring Algorithm in Online California Bar Exam Flagged an Unusually High Number of Alleged Cheaters",
      "description": "A detailed report about Proctoring Algorithm in Online California Bar Exam Flagged an Unusually High Number of Alleged Cheaters",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-12-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1511",
      "incident_id": 153,
      "title": "Report 1511 on Tesla Driver on Autopilot Ran a Red Light, Crashing into a Car and Killing Two People in Los Angeles",
      "description": "A detailed report about Tesla Driver on Autopilot Ran a Red Light, Crashing into a Car and Killing Two People in Los Angeles",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-12-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1729",
      "incident_id": 153,
      "title": "Report 1729 on Tesla Driver on Autopilot Ran a Red Light, Crashing into a Car and Killing Two People in Los Angeles",
      "description": "A detailed report about Tesla Driver on Autopilot Ran a Red Light, Crashing into a Car and Killing Two People in Los Angeles",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-12-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1763",
      "incident_id": 153,
      "title": "Report 1763 on Tesla Driver on Autopilot Ran a Red Light, Crashing into a Car and Killing Two People in Los Angeles",
      "description": "A detailed report about Tesla Driver on Autopilot Ran a Red Light, Crashing into a Car and Killing Two People in Los Angeles",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-12-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1485",
      "incident_id": 145,
      "title": "Report 1485 on Tesla's Autopilot Misidentified the Moon as Yellow Stop Light",
      "description": "A detailed report about Tesla's Autopilot Misidentified the Moon as Yellow Stop Light",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-07-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1504",
      "incident_id": 145,
      "title": "Report 1504 on Tesla's Autopilot Misidentified the Moon as Yellow Stop Light",
      "description": "A detailed report about Tesla's Autopilot Misidentified the Moon as Yellow Stop Light",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-07-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1529",
      "incident_id": 145,
      "title": "Report 1529 on Tesla's Autopilot Misidentified the Moon as Yellow Stop Light",
      "description": "A detailed report about Tesla's Autopilot Misidentified the Moon as Yellow Stop Light",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-07-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1479",
      "incident_id": 141,
      "title": "Report 1479 on California Police Turned on Music to Allegedly Trigger Instagram’s DCMA to Avoid Being Live-Streamed",
      "description": "A detailed report about California Police Turned on Music to Allegedly Trigger Instagram’s DCMA to Avoid Being Live-Streamed",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-02-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1480",
      "incident_id": 141,
      "title": "Report 1480 on California Police Turned on Music to Allegedly Trigger Instagram’s DCMA to Avoid Being Live-Streamed",
      "description": "A detailed report about California Police Turned on Music to Allegedly Trigger Instagram’s DCMA to Avoid Being Live-Streamed",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-02-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1469",
      "incident_id": 134,
      "title": "Report 1469 on Robot in Chinese Shopping Mall Fell off the Escalator, Knocking down Passengers",
      "description": "A detailed report about Robot in Chinese Shopping Mall Fell off the Escalator, Knocking down Passengers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-12-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1951",
      "incident_id": 134,
      "title": "Report 1951 on Robot in Chinese Shopping Mall Fell off the Escalator, Knocking down Passengers",
      "description": "A detailed report about Robot in Chinese Shopping Mall Fell off the Escalator, Knocking down Passengers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-12-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1451",
      "incident_id": 125,
      "title": "Report 1451 on Amazon’s Robotic Fulfillment Centers Have Higher Serious Injury Rates",
      "description": "A detailed report about Amazon’s Robotic Fulfillment Centers Have Higher Serious Injury Rates",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-09-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1452",
      "incident_id": 125,
      "title": "Report 1452 on Amazon’s Robotic Fulfillment Centers Have Higher Serious Injury Rates",
      "description": "A detailed report about Amazon’s Robotic Fulfillment Centers Have Higher Serious Injury Rates",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-09-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1460",
      "incident_id": 125,
      "title": "Report 1460 on Amazon’s Robotic Fulfillment Centers Have Higher Serious Injury Rates",
      "description": "A detailed report about Amazon’s Robotic Fulfillment Centers Have Higher Serious Injury Rates",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-09-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1471",
      "incident_id": 136,
      "title": "Report 1471 on Brand Safety Tech Firms Falsely Claimed Use of AI, Blocking Ads Using Simple Keyword Lists",
      "description": "A detailed report about Brand Safety Tech Firms Falsely Claimed Use of AI, Blocking Ads Using Simple Keyword Lists",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-12-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1475",
      "incident_id": 138,
      "title": "Report 1475 on Alleged Issues with Proctorio's Remote-Testing AI Prompted Suspension by University",
      "description": "A detailed report about Alleged Issues with Proctorio's Remote-Testing AI Prompted Suspension by University",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-01-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1505",
      "incident_id": 138,
      "title": "Report 1505 on Alleged Issues with Proctorio's Remote-Testing AI Prompted Suspension by University",
      "description": "A detailed report about Alleged Issues with Proctorio's Remote-Testing AI Prompted Suspension by University",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-01-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1555",
      "incident_id": 138,
      "title": "Report 1555 on Alleged Issues with Proctorio's Remote-Testing AI Prompted Suspension by University",
      "description": "A detailed report about Alleged Issues with Proctorio's Remote-Testing AI Prompted Suspension by University",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-01-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1466",
      "incident_id": 132,
      "title": "Report 1466 on TikTok’s Content Moderation Allegedly Failed to Adequately Take down Videos Promoting Eating Disorders",
      "description": "A detailed report about TikTok’s Content Moderation Allegedly Failed to Adequately Take down Videos Promoting Eating Disorders",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-12-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1470",
      "incident_id": 135,
      "title": "Report 1470 on UT Austin GRADE Algorithm Allegedly Reinforced Historical Inequalities",
      "description": "A detailed report about UT Austin GRADE Algorithm Allegedly Reinforced Historical Inequalities",
      "url": "https://incidentdatabase.ai",
      "date_published": "2012-12-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1871",
      "incident_id": 135,
      "title": "Report 1871 on UT Austin GRADE Algorithm Allegedly Reinforced Historical Inequalities",
      "description": "A detailed report about UT Austin GRADE Algorithm Allegedly Reinforced Historical Inequalities",
      "url": "https://incidentdatabase.ai",
      "date_published": "2012-12-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1513",
      "incident_id": 155,
      "title": "Report 1513 on Google Maps Allegedly Directed Sierra Nevada Travelers to Dangerous Roads amid Winter Storm",
      "description": "A detailed report about Google Maps Allegedly Directed Sierra Nevada Travelers to Dangerous Roads amid Winter Storm",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-12-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1514",
      "incident_id": 155,
      "title": "Report 1514 on Google Maps Allegedly Directed Sierra Nevada Travelers to Dangerous Roads amid Winter Storm",
      "description": "A detailed report about Google Maps Allegedly Directed Sierra Nevada Travelers to Dangerous Roads amid Winter Storm",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-12-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1531",
      "incident_id": 162,
      "title": "Report 1531 on ETS Used Allegedly Flawed Voice Recognition Evidence to Accuse and Assess Scale of Cheating, Causing Thousands to be Deported from the UK",
      "description": "A detailed report about ETS Used Allegedly Flawed Voice Recognition Evidence to Accuse and Assess Scale of Cheating, Causing Thousands to be Deported from the UK",
      "url": "https://incidentdatabase.ai",
      "date_published": "2014-01-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1549",
      "incident_id": 171,
      "title": "Report 1549 on Traffic Camera Misread Text on Pedestrian's Shirt as License Plate, Causing UK Officials to Issue Fine to an Unrelated Person",
      "description": "A detailed report about Traffic Camera Misread Text on Pedestrian's Shirt as License Plate, Causing UK Officials to Issue Fine to an Unrelated Person",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-10-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1507",
      "incident_id": 151,
      "title": "Report 1507 on California Regulator Suspended Pony.ai's Driverless Testing Permit Following a Non-Fatal Collision",
      "description": "A detailed report about California Regulator Suspended Pony.ai's Driverless Testing Permit Following a Non-Fatal Collision",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-10-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1508",
      "incident_id": 151,
      "title": "Report 1508 on California Regulator Suspended Pony.ai's Driverless Testing Permit Following a Non-Fatal Collision",
      "description": "A detailed report about California Regulator Suspended Pony.ai's Driverless Testing Permit Following a Non-Fatal Collision",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-10-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1703",
      "incident_id": 151,
      "title": "Report 1703 on California Regulator Suspended Pony.ai's Driverless Testing Permit Following a Non-Fatal Collision",
      "description": "A detailed report about California Regulator Suspended Pony.ai's Driverless Testing Permit Following a Non-Fatal Collision",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-10-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1449",
      "incident_id": 123,
      "title": "Report 1449 on Epic Systems’s Sepsis Prediction Algorithms Revealed to Have High Error Rates on Seriously Ill Patients",
      "description": "A detailed report about Epic Systems’s Sepsis Prediction Algorithms Revealed to Have High Error Rates on Seriously Ill Patients",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-08-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2651",
      "incident_id": 123,
      "title": "Report 2651 on Epic Systems’s Sepsis Prediction Algorithms Revealed to Have High Error Rates on Seriously Ill Patients",
      "description": "A detailed report about Epic Systems’s Sepsis Prediction Algorithms Revealed to Have High Error Rates on Seriously Ill Patients",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-08-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2705",
      "incident_id": 123,
      "title": "Report 2705 on Epic Systems’s Sepsis Prediction Algorithms Revealed to Have High Error Rates on Seriously Ill Patients",
      "description": "A detailed report about Epic Systems’s Sepsis Prediction Algorithms Revealed to Have High Error Rates on Seriously Ill Patients",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-08-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1515",
      "incident_id": 156,
      "title": "Report 1515 on Amazon Reportedly Sold Products and Recommended Frequently Bought Together Items That Aid Suicide Attempts",
      "description": "A detailed report about Amazon Reportedly Sold Products and Recommended Frequently Bought Together Items That Aid Suicide Attempts",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-02-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2197",
      "incident_id": 156,
      "title": "Report 2197 on Amazon Reportedly Sold Products and Recommended Frequently Bought Together Items That Aid Suicide Attempts",
      "description": "A detailed report about Amazon Reportedly Sold Products and Recommended Frequently Bought Together Items That Aid Suicide Attempts",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-02-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1482",
      "incident_id": 143,
      "title": "Report 1482 on Facebook’s and Twitter's Automated Content Moderation Reportedly Failed to Effectively Enforce Violation Rules for Small Language Groups",
      "description": "A detailed report about Facebook’s and Twitter's Automated Content Moderation Reportedly Failed to Effectively Enforce Violation Rules for Small Language Groups",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-02-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1516",
      "incident_id": 157,
      "title": "Report 1516 on Amazon's Monitoring System Allegedly Pushed Delivery Drivers to Prioritize Speed over Safety, Leading to Crash",
      "description": "A detailed report about Amazon's Monitoring System Allegedly Pushed Delivery Drivers to Prioritize Speed over Safety, Leading to Crash",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-03-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1546",
      "incident_id": 170,
      "title": "Report 1546 on Target Suggested Maternity-Related Advertisements to a Teenage Girl's Home, Allegedly Correctly Predicting Her Pregnancy via Algorithm",
      "description": "A detailed report about Target Suggested Maternity-Related Advertisements to a Teenage Girl's Home, Allegedly Correctly Predicting Her Pregnancy via Algorithm",
      "url": "https://incidentdatabase.ai",
      "date_published": "2003-06-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1547",
      "incident_id": 170,
      "title": "Report 1547 on Target Suggested Maternity-Related Advertisements to a Teenage Girl's Home, Allegedly Correctly Predicting Her Pregnancy via Algorithm",
      "description": "A detailed report about Target Suggested Maternity-Related Advertisements to a Teenage Girl's Home, Allegedly Correctly Predicting Her Pregnancy via Algorithm",
      "url": "https://incidentdatabase.ai",
      "date_published": "2003-06-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1548",
      "incident_id": 170,
      "title": "Report 1548 on Target Suggested Maternity-Related Advertisements to a Teenage Girl's Home, Allegedly Correctly Predicting Her Pregnancy via Algorithm",
      "description": "A detailed report about Target Suggested Maternity-Related Advertisements to a Teenage Girl's Home, Allegedly Correctly Predicting Her Pregnancy via Algorithm",
      "url": "https://incidentdatabase.ai",
      "date_published": "2003-06-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1476",
      "incident_id": 139,
      "title": "Report 1476 on Amazon’s Search and Recommendation Algorithms Found by Auditors to Have Boosted Products That Contained Vaccine Misinformation",
      "description": "A detailed report about Amazon’s Search and Recommendation Algorithms Found by Auditors to Have Boosted Products That Contained Vaccine Misinformation",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-01-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1477",
      "incident_id": 139,
      "title": "Report 1477 on Amazon’s Search and Recommendation Algorithms Found by Auditors to Have Boosted Products That Contained Vaccine Misinformation",
      "description": "A detailed report about Amazon’s Search and Recommendation Algorithms Found by Auditors to Have Boosted Products That Contained Vaccine Misinformation",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-01-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1481",
      "incident_id": 142,
      "title": "Report 1481 on Facebook’s Advertisement Moderation System Routinely Misidentified Adaptive Fashion Products as Medical Equipment and Blocked Their Sellers",
      "description": "A detailed report about Facebook’s Advertisement Moderation System Routinely Misidentified Adaptive Fashion Products as Medical Equipment and Blocked Their Sellers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-02-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1506",
      "incident_id": 150,
      "title": "Report 1506 on Swedish Contraceptive App, Natural Cycles, Allegedly Failed to Correctly Map Menstrual Cycle",
      "description": "A detailed report about Swedish Contraceptive App, Natural Cycles, Allegedly Failed to Correctly Map Menstrual Cycle",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-07-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3157",
      "incident_id": 150,
      "title": "Report 3157 on Swedish Contraceptive App, Natural Cycles, Allegedly Failed to Correctly Map Menstrual Cycle",
      "description": "A detailed report about Swedish Contraceptive App, Natural Cycles, Allegedly Failed to Correctly Map Menstrual Cycle",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-07-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3158",
      "incident_id": 150,
      "title": "Report 3158 on Swedish Contraceptive App, Natural Cycles, Allegedly Failed to Correctly Map Menstrual Cycle",
      "description": "A detailed report about Swedish Contraceptive App, Natural Cycles, Allegedly Failed to Correctly Map Menstrual Cycle",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-07-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1544",
      "incident_id": 169,
      "title": "Report 1544 on Facebook Allegedly Failed to Police Anti-Rohingya Hate Speech Content That Contributed to Violence in Myanmar",
      "description": "A detailed report about Facebook Allegedly Failed to Police Anti-Rohingya Hate Speech Content That Contributed to Violence in Myanmar",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-08-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1545",
      "incident_id": 169,
      "title": "Report 1545 on Facebook Allegedly Failed to Police Anti-Rohingya Hate Speech Content That Contributed to Violence in Myanmar",
      "description": "A detailed report about Facebook Allegedly Failed to Police Anti-Rohingya Hate Speech Content That Contributed to Violence in Myanmar",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-08-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2986",
      "incident_id": 169,
      "title": "Report 2986 on Facebook Allegedly Failed to Police Anti-Rohingya Hate Speech Content That Contributed to Violence in Myanmar",
      "description": "A detailed report about Facebook Allegedly Failed to Police Anti-Rohingya Hate Speech Content That Contributed to Violence in Myanmar",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-08-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1496",
      "incident_id": 147,
      "title": "Report 1496 on Hong Kong Bank Manager Swindled by Fraudsters Using Deepfaked Voice of Company Director",
      "description": "A detailed report about Hong Kong Bank Manager Swindled by Fraudsters Using Deepfaked Voice of Company Director",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-01-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1497",
      "incident_id": 147,
      "title": "Report 1497 on Hong Kong Bank Manager Swindled by Fraudsters Using Deepfaked Voice of Company Director",
      "description": "A detailed report about Hong Kong Bank Manager Swindled by Fraudsters Using Deepfaked Voice of Company Director",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-01-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1453",
      "incident_id": 126,
      "title": "Report 1453 on Three Robots Collided, Sparking Fire in a Grocer's Warehouse in UK ",
      "description": "A detailed report about Three Robots Collided, Sparking Fire in a Grocer's Warehouse in UK ",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-07-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1454",
      "incident_id": 126,
      "title": "Report 1454 on Three Robots Collided, Sparking Fire in a Grocer's Warehouse in UK ",
      "description": "A detailed report about Three Robots Collided, Sparking Fire in a Grocer's Warehouse in UK ",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-07-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1455",
      "incident_id": 126,
      "title": "Report 1455 on Three Robots Collided, Sparking Fire in a Grocer's Warehouse in UK ",
      "description": "A detailed report about Three Robots Collided, Sparking Fire in a Grocer's Warehouse in UK ",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-07-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1459",
      "incident_id": 128,
      "title": "Report 1459 on Tesla Sedan on Autopilot Reportedly Drove Over Dividing Curb in Washington, Resulting in Minor Vehicle Damage",
      "description": "A detailed report about Tesla Sedan on Autopilot Reportedly Drove Over Dividing Curb in Washington, Resulting in Minor Vehicle Damage",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-08-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1818",
      "incident_id": 128,
      "title": "Report 1818 on Tesla Sedan on Autopilot Reportedly Drove Over Dividing Curb in Washington, Resulting in Minor Vehicle Damage",
      "description": "A detailed report about Tesla Sedan on Autopilot Reportedly Drove Over Dividing Curb in Washington, Resulting in Minor Vehicle Damage",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-08-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1512",
      "incident_id": 154,
      "title": "Report 1512 on Justice Department’s Recidivism Risk Algorithm PATTERN Allegedly Caused Persistent Disparities Along Racial Lines",
      "description": "A detailed report about Justice Department’s Recidivism Risk Algorithm PATTERN Allegedly Caused Persistent Disparities Along Racial Lines",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-01-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1536",
      "incident_id": 165,
      "title": "Report 1536 on Image Upscaling Algorithm PULSE Allegedly Produced Facial Images with Caucasian Features More Often",
      "description": "A detailed report about Image Upscaling Algorithm PULSE Allegedly Produced Facial Images with Caucasian Features More Often",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-06-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2781",
      "incident_id": 165,
      "title": "Report 2781 on Image Upscaling Algorithm PULSE Allegedly Produced Facial Images with Caucasian Features More Often",
      "description": "A detailed report about Image Upscaling Algorithm PULSE Allegedly Produced Facial Images with Caucasian Features More Often",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-06-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1517",
      "incident_id": 158,
      "title": "Report 1517 on Facial Recognition in Remote Learning Software Reportedly Failed to Recognize a Black Student’s Face",
      "description": "A detailed report about Facial Recognition in Remote Learning Software Reportedly Failed to Recognize a Black Student’s Face",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-02-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1500",
      "incident_id": 149,
      "title": "Report 1500 on Zillow Shut Down Zillow Offers Division Allegedly Due to Predictive Pricing Tool's Insufficient Accuracy",
      "description": "A detailed report about Zillow Shut Down Zillow Offers Division Allegedly Due to Predictive Pricing Tool's Insufficient Accuracy",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-11-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1501",
      "incident_id": 149,
      "title": "Report 1501 on Zillow Shut Down Zillow Offers Division Allegedly Due to Predictive Pricing Tool's Insufficient Accuracy",
      "description": "A detailed report about Zillow Shut Down Zillow Offers Division Allegedly Due to Predictive Pricing Tool's Insufficient Accuracy",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-11-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1890",
      "incident_id": 149,
      "title": "Report 1890 on Zillow Shut Down Zillow Offers Division Allegedly Due to Predictive Pricing Tool's Insufficient Accuracy",
      "description": "A detailed report about Zillow Shut Down Zillow Offers Division Allegedly Due to Predictive Pricing Tool's Insufficient Accuracy",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-11-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1450",
      "incident_id": 124,
      "title": "Report 1450 on Algorithmic Health Risk Scores Underestimated Black Patients’ Needs",
      "description": "A detailed report about Algorithmic Health Risk Scores Underestimated Black Patients’ Needs",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-10-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1522",
      "incident_id": 124,
      "title": "Report 1522 on Algorithmic Health Risk Scores Underestimated Black Patients’ Needs",
      "description": "A detailed report about Algorithmic Health Risk Scores Underestimated Black Patients’ Needs",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-10-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2262",
      "incident_id": 124,
      "title": "Report 2262 on Algorithmic Health Risk Scores Underestimated Black Patients’ Needs",
      "description": "A detailed report about Algorithmic Health Risk Scores Underestimated Black Patients’ Needs",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-10-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2471",
      "incident_id": 159,
      "title": "Report 2471 on Tesla Autopilot’s Lane Recognition Allegedly Vulnerable to Adversarial Attacks",
      "description": "A detailed report about Tesla Autopilot’s Lane Recognition Allegedly Vulnerable to Adversarial Attacks",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-03-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1539",
      "incident_id": 167,
      "title": "Report 1539 on Researchers' Homosexual-Men Detection Model Denounced as a Threat to LGBTQ People’s Safety and Privacy",
      "description": "A detailed report about Researchers' Homosexual-Men Detection Model Denounced as a Threat to LGBTQ People’s Safety and Privacy",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-09-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1456",
      "incident_id": 127,
      "title": "Report 1456 on Microsoft’s Algorithm Allegedly Selected Photo of the Wrong Mixed-Race Person Featured in a News Story",
      "description": "A detailed report about Microsoft’s Algorithm Allegedly Selected Photo of the Wrong Mixed-Race Person Featured in a News Story",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-06-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1457",
      "incident_id": 127,
      "title": "Report 1457 on Microsoft’s Algorithm Allegedly Selected Photo of the Wrong Mixed-Race Person Featured in a News Story",
      "description": "A detailed report about Microsoft’s Algorithm Allegedly Selected Photo of the Wrong Mixed-Race Person Featured in a News Story",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-06-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1458",
      "incident_id": 127,
      "title": "Report 1458 on Microsoft’s Algorithm Allegedly Selected Photo of the Wrong Mixed-Race Person Featured in a News Story",
      "description": "A detailed report about Microsoft’s Algorithm Allegedly Selected Photo of the Wrong Mixed-Race Person Featured in a News Story",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-06-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1533",
      "incident_id": 163,
      "title": "Report 1533 on Facebook’s Hate Speech Detection Algorithms Allegedly Disproportionately Failed to Remove Racist Content towards Minority Groups",
      "description": "A detailed report about Facebook’s Hate Speech Detection Algorithms Allegedly Disproportionately Failed to Remove Racist Content towards Minority Groups",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-11-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1652",
      "incident_id": 163,
      "title": "Report 1652 on Facebook’s Hate Speech Detection Algorithms Allegedly Disproportionately Failed to Remove Racist Content towards Minority Groups",
      "description": "A detailed report about Facebook’s Hate Speech Detection Algorithms Allegedly Disproportionately Failed to Remove Racist Content towards Minority Groups",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-11-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1538",
      "incident_id": 166,
      "title": "Report 1538 on Networking Platform Giggle Employs AI to Determine Users’ Gender, Allegedly Excluding Transgender Women",
      "description": "A detailed report about Networking Platform Giggle Employs AI to Determine Users’ Gender, Allegedly Excluding Transgender Women",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-02-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1563",
      "incident_id": 166,
      "title": "Report 1563 on Networking Platform Giggle Employs AI to Determine Users’ Gender, Allegedly Excluding Transgender Women",
      "description": "A detailed report about Networking Platform Giggle Employs AI to Determine Users’ Gender, Allegedly Excluding Transgender Women",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-02-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1557",
      "incident_id": 176,
      "title": "Report 1557 on Starship’s Autonomous Food Delivery Robot Allegedly Stranded at Railroad Crossing in Oregon, Run over by Freight Train",
      "description": "A detailed report about Starship’s Autonomous Food Delivery Robot Allegedly Stranded at Railroad Crossing in Oregon, Run over by Freight Train",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-03-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1573",
      "incident_id": 182,
      "title": "Report 1573 on Two Cruise Autonomous Vehicles Collided with Each Other in California ",
      "description": "A detailed report about Two Cruise Autonomous Vehicles Collided with Each Other in California ",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-06-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1574",
      "incident_id": 182,
      "title": "Report 1574 on Two Cruise Autonomous Vehicles Collided with Each Other in California ",
      "description": "A detailed report about Two Cruise Autonomous Vehicles Collided with Each Other in California ",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-06-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1551",
      "incident_id": 173,
      "title": "Report 1551 on AI Tools Failed to Sufficiently Predict COVID Patients, Some Potentially Harmful",
      "description": "A detailed report about AI Tools Failed to Sufficiently Predict COVID Patients, Some Potentially Harmful",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-07-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1659",
      "incident_id": 203,
      "title": "Report 1659 on Uber Launched Opaque Algorithm That Changes Drivers' Payments in the US",
      "description": "A detailed report about Uber Launched Opaque Algorithm That Changes Drivers' Payments in the US",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-02-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1660",
      "incident_id": 203,
      "title": "Report 1660 on Uber Launched Opaque Algorithm That Changes Drivers' Payments in the US",
      "description": "A detailed report about Uber Launched Opaque Algorithm That Changes Drivers' Payments in the US",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-02-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1661",
      "incident_id": 203,
      "title": "Report 1661 on Uber Launched Opaque Algorithm That Changes Drivers' Payments in the US",
      "description": "A detailed report about Uber Launched Opaque Algorithm That Changes Drivers' Payments in the US",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-02-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1581",
      "incident_id": 184,
      "title": "Report 1581 on Facial Recognition Program in São Paulo Metro Stations Suspended for Illegal and Disproportionate Violation of Citizens’ Right to Privacy",
      "description": "A detailed report about Facial Recognition Program in São Paulo Metro Stations Suspended for Illegal and Disproportionate Violation of Citizens’ Right to Privacy",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-04-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1584",
      "incident_id": 184,
      "title": "Report 1584 on Facial Recognition Program in São Paulo Metro Stations Suspended for Illegal and Disproportionate Violation of Citizens’ Right to Privacy",
      "description": "A detailed report about Facial Recognition Program in São Paulo Metro Stations Suspended for Illegal and Disproportionate Violation of Citizens’ Right to Privacy",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-04-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1899",
      "incident_id": 184,
      "title": "Report 1899 on Facial Recognition Program in São Paulo Metro Stations Suspended for Illegal and Disproportionate Violation of Citizens’ Right to Privacy",
      "description": "A detailed report about Facial Recognition Program in São Paulo Metro Stations Suspended for Illegal and Disproportionate Violation of Citizens’ Right to Privacy",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-04-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1622",
      "incident_id": 195,
      "title": "Report 1622 on Predictive Policing Program by Florida Sheriff’s Office Allegedly Violated Residents’ Rights and Targeted Children of Vulnerable Groups",
      "description": "A detailed report about Predictive Policing Program by Florida Sheriff’s Office Allegedly Violated Residents’ Rights and Targeted Children of Vulnerable Groups",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-09-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1623",
      "incident_id": 195,
      "title": "Report 1623 on Predictive Policing Program by Florida Sheriff’s Office Allegedly Violated Residents’ Rights and Targeted Children of Vulnerable Groups",
      "description": "A detailed report about Predictive Policing Program by Florida Sheriff’s Office Allegedly Violated Residents’ Rights and Targeted Children of Vulnerable Groups",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-09-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1624",
      "incident_id": 195,
      "title": "Report 1624 on Predictive Policing Program by Florida Sheriff’s Office Allegedly Violated Residents’ Rights and Targeted Children of Vulnerable Groups",
      "description": "A detailed report about Predictive Policing Program by Florida Sheriff’s Office Allegedly Violated Residents’ Rights and Targeted Children of Vulnerable Groups",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-09-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1715",
      "incident_id": 213,
      "title": "Report 1715 on Facebook’s Political Ad Detection Reportedly Showed High and Geographically Uneven Error Rates",
      "description": "A detailed report about Facebook’s Political Ad Detection Reportedly Showed High and Geographically Uneven Error Rates",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-07-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1716",
      "incident_id": 213,
      "title": "Report 1716 on Facebook’s Political Ad Detection Reportedly Showed High and Geographically Uneven Error Rates",
      "description": "A detailed report about Facebook’s Political Ad Detection Reportedly Showed High and Geographically Uneven Error Rates",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-07-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1717",
      "incident_id": 213,
      "title": "Report 1717 on Facebook’s Political Ad Detection Reportedly Showed High and Geographically Uneven Error Rates",
      "description": "A detailed report about Facebook’s Political Ad Detection Reportedly Showed High and Geographically Uneven Error Rates",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-07-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1552",
      "incident_id": 174,
      "title": "Report 1552 on Fake LinkedIn Profiles Created Using GAN Photos",
      "description": "A detailed report about Fake LinkedIn Profiles Created Using GAN Photos",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-02-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1585",
      "incident_id": 174,
      "title": "Report 1585 on Fake LinkedIn Profiles Created Using GAN Photos",
      "description": "A detailed report about Fake LinkedIn Profiles Created Using GAN Photos",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-02-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1595",
      "incident_id": 174,
      "title": "Report 1595 on Fake LinkedIn Profiles Created Using GAN Photos",
      "description": "A detailed report about Fake LinkedIn Profiles Created Using GAN Photos",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-02-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1642",
      "incident_id": 198,
      "title": "Report 1642 on Deepfake Video of Ukrainian President Yielding to Russia Posted on Ukrainian Websites and Social Media",
      "description": "A detailed report about Deepfake Video of Ukrainian President Yielding to Russia Posted on Ukrainian Websites and Social Media",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-03-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1643",
      "incident_id": 198,
      "title": "Report 1643 on Deepfake Video of Ukrainian President Yielding to Russia Posted on Ukrainian Websites and Social Media",
      "description": "A detailed report about Deepfake Video of Ukrainian President Yielding to Russia Posted on Ukrainian Websites and Social Media",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-03-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1644",
      "incident_id": 198,
      "title": "Report 1644 on Deepfake Video of Ukrainian President Yielding to Russia Posted on Ukrainian Websites and Social Media",
      "description": "A detailed report about Deepfake Video of Ukrainian President Yielding to Russia Posted on Ukrainian Websites and Social Media",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-03-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1553",
      "incident_id": 175,
      "title": "Report 1553 on Cruise Autonomous Taxi Allegedly Bolted off from Police After Being Pulled over in San Francisco",
      "description": "A detailed report about Cruise Autonomous Taxi Allegedly Bolted off from Police After Being Pulled over in San Francisco",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-04-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1554",
      "incident_id": 175,
      "title": "Report 1554 on Cruise Autonomous Taxi Allegedly Bolted off from Police After Being Pulled over in San Francisco",
      "description": "A detailed report about Cruise Autonomous Taxi Allegedly Bolted off from Police After Being Pulled over in San Francisco",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-04-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1606",
      "incident_id": 175,
      "title": "Report 1606 on Cruise Autonomous Taxi Allegedly Bolted off from Police After Being Pulled over in San Francisco",
      "description": "A detailed report about Cruise Autonomous Taxi Allegedly Bolted off from Police After Being Pulled over in San Francisco",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-04-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1560",
      "incident_id": 178,
      "title": "Report 1560 on Tesla Owner Activated Smart Summon Feature, Causing a Collision with an Aircraft in a Washington Airport",
      "description": "A detailed report about Tesla Owner Activated Smart Summon Feature, Causing a Collision with an Aircraft in a Washington Airport",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-04-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1565",
      "incident_id": 178,
      "title": "Report 1565 on Tesla Owner Activated Smart Summon Feature, Causing a Collision with an Aircraft in a Washington Airport",
      "description": "A detailed report about Tesla Owner Activated Smart Summon Feature, Causing a Collision with an Aircraft in a Washington Airport",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-04-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1566",
      "incident_id": 178,
      "title": "Report 1566 on Tesla Owner Activated Smart Summon Feature, Causing a Collision with an Aircraft in a Washington Airport",
      "description": "A detailed report about Tesla Owner Activated Smart Summon Feature, Causing a Collision with an Aircraft in a Washington Airport",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-04-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1564",
      "incident_id": 180,
      "title": "Report 1564 on Algorithm Used by the Malaysian Judiciary Reportedly Recommended Unusually High Sentencing to a Drug Possession Case",
      "description": "A detailed report about Algorithm Used by the Malaysian Judiciary Reportedly Recommended Unusually High Sentencing to a Drug Possession Case",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-02-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1582",
      "incident_id": 180,
      "title": "Report 1582 on Algorithm Used by the Malaysian Judiciary Reportedly Recommended Unusually High Sentencing to a Drug Possession Case",
      "description": "A detailed report about Algorithm Used by the Malaysian Judiciary Reportedly Recommended Unusually High Sentencing to a Drug Possession Case",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-02-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2236",
      "incident_id": 180,
      "title": "Report 2236 on Algorithm Used by the Malaysian Judiciary Reportedly Recommended Unusually High Sentencing to a Drug Possession Case",
      "description": "A detailed report about Algorithm Used by the Malaysian Judiciary Reportedly Recommended Unusually High Sentencing to a Drug Possession Case",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-02-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1576",
      "incident_id": 183,
      "title": "Report 1576 on Airbnb's Trustworthiness Algorithm Allegedly Banned Users without Explanation, and Discriminated against Sex Workers",
      "description": "A detailed report about Airbnb's Trustworthiness Algorithm Allegedly Banned Users without Explanation, and Discriminated against Sex Workers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-07-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1577",
      "incident_id": 183,
      "title": "Report 1577 on Airbnb's Trustworthiness Algorithm Allegedly Banned Users without Explanation, and Discriminated against Sex Workers",
      "description": "A detailed report about Airbnb's Trustworthiness Algorithm Allegedly Banned Users without Explanation, and Discriminated against Sex Workers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-07-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1578",
      "incident_id": 183,
      "title": "Report 1578 on Airbnb's Trustworthiness Algorithm Allegedly Banned Users without Explanation, and Discriminated against Sex Workers",
      "description": "A detailed report about Airbnb's Trustworthiness Algorithm Allegedly Banned Users without Explanation, and Discriminated against Sex Workers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-07-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1731",
      "incident_id": 220,
      "title": "Report 1731 on Facebook Mistakenly Blocked Small Business Ads",
      "description": "A detailed report about Facebook Mistakenly Blocked Small Business Ads",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-11-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1732",
      "incident_id": 220,
      "title": "Report 1732 on Facebook Mistakenly Blocked Small Business Ads",
      "description": "A detailed report about Facebook Mistakenly Blocked Small Business Ads",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-11-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1969",
      "incident_id": 220,
      "title": "Report 1969 on Facebook Mistakenly Blocked Small Business Ads",
      "description": "A detailed report about Facebook Mistakenly Blocked Small Business Ads",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-11-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1621",
      "incident_id": 194,
      "title": "Report 1621 on Australian Telco’s Incident Management Bot Excessively Sent Technicians in the Field by Mistake, Allegedly Costing Millions",
      "description": "A detailed report about Australian Telco’s Incident Management Bot Excessively Sent Technicians in the Field by Mistake, Allegedly Costing Millions",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-02-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1653",
      "incident_id": 200,
      "title": "Report 1653 on Fraudsters Used AI to Mimic Voice of a UK-Based Firm's CEO's Boss",
      "description": "A detailed report about Fraudsters Used AI to Mimic Voice of a UK-Based Firm's CEO's Boss",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-03-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1675",
      "incident_id": 206,
      "title": "Report 1675 on Tinder's Personalized Pricing Algorithm Found to Offer Higher Prices for Older Users",
      "description": "A detailed report about Tinder's Personalized Pricing Algorithm Found to Offer Higher Prices for Older Users",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-03-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1676",
      "incident_id": 206,
      "title": "Report 1676 on Tinder's Personalized Pricing Algorithm Found to Offer Higher Prices for Older Users",
      "description": "A detailed report about Tinder's Personalized Pricing Algorithm Found to Offer Higher Prices for Older Users",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-03-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1677",
      "incident_id": 206,
      "title": "Report 1677 on Tinder's Personalized Pricing Algorithm Found to Offer Higher Prices for Older Users",
      "description": "A detailed report about Tinder's Personalized Pricing Algorithm Found to Offer Higher Prices for Older Users",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-03-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1590",
      "incident_id": 186,
      "title": "Report 1590 on Algorithm Assessing Risk Faced by Victims of Gender Violence Misclassified Low-Risk Cases, Allegedly Leading to Homicide of Women and Children in Spain",
      "description": "A detailed report about Algorithm Assessing Risk Faced by Victims of Gender Violence Misclassified Low-Risk Cases, Allegedly Leading to Homicide of Women and Children in Spain",
      "url": "https://incidentdatabase.ai",
      "date_published": "2007-07-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1591",
      "incident_id": 186,
      "title": "Report 1591 on Algorithm Assessing Risk Faced by Victims of Gender Violence Misclassified Low-Risk Cases, Allegedly Leading to Homicide of Women and Children in Spain",
      "description": "A detailed report about Algorithm Assessing Risk Faced by Victims of Gender Violence Misclassified Low-Risk Cases, Allegedly Leading to Homicide of Women and Children in Spain",
      "url": "https://incidentdatabase.ai",
      "date_published": "2007-07-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1592",
      "incident_id": 186,
      "title": "Report 1592 on Algorithm Assessing Risk Faced by Victims of Gender Violence Misclassified Low-Risk Cases, Allegedly Leading to Homicide of Women and Children in Spain",
      "description": "A detailed report about Algorithm Assessing Risk Faced by Victims of Gender Violence Misclassified Low-Risk Cases, Allegedly Leading to Homicide of Women and Children in Spain",
      "url": "https://incidentdatabase.ai",
      "date_published": "2007-07-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1655",
      "incident_id": 202,
      "title": "Report 1655 on Korean Politician Employed Deepfake as Campaign Representative",
      "description": "A detailed report about Korean Politician Employed Deepfake as Campaign Representative",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-12-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1656",
      "incident_id": 202,
      "title": "Report 1656 on Korean Politician Employed Deepfake as Campaign Representative",
      "description": "A detailed report about Korean Politician Employed Deepfake as Campaign Representative",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-12-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1657",
      "incident_id": 202,
      "title": "Report 1657 on Korean Politician Employed Deepfake as Campaign Representative",
      "description": "A detailed report about Korean Politician Employed Deepfake as Campaign Representative",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-12-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1724",
      "incident_id": 216,
      "title": "Report 1724 on WeChat’s Machine Translation Gave a Racist English Translation for the Chinese Term for “Black Foreigner”",
      "description": "A detailed report about WeChat’s Machine Translation Gave a Racist English Translation for the Chinese Term for “Black Foreigner”",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-10-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1924",
      "incident_id": 216,
      "title": "Report 1924 on WeChat’s Machine Translation Gave a Racist English Translation for the Chinese Term for “Black Foreigner”",
      "description": "A detailed report about WeChat’s Machine Translation Gave a Racist English Translation for the Chinese Term for “Black Foreigner”",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-10-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1925",
      "incident_id": 216,
      "title": "Report 1925 on WeChat’s Machine Translation Gave a Racist English Translation for the Chinese Term for “Black Foreigner”",
      "description": "A detailed report about WeChat’s Machine Translation Gave a Racist English Translation for the Chinese Term for “Black Foreigner”",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-10-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1733",
      "incident_id": 221,
      "title": "Report 1733 on A Road Engineer Killed Following a Collision Involving a Tesla on Autopilot",
      "description": "A detailed report about A Road Engineer Killed Following a Collision Involving a Tesla on Autopilot",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-03-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1734",
      "incident_id": 221,
      "title": "Report 1734 on A Road Engineer Killed Following a Collision Involving a Tesla on Autopilot",
      "description": "A detailed report about A Road Engineer Killed Following a Collision Involving a Tesla on Autopilot",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-03-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1561",
      "incident_id": 179,
      "title": "Report 1561 on DALL-E 2 Reported for Gender and Racially Biased Outputs",
      "description": "A detailed report about DALL-E 2 Reported for Gender and Racially Biased Outputs",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-04-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1562",
      "incident_id": 179,
      "title": "Report 1562 on DALL-E 2 Reported for Gender and Racially Biased Outputs",
      "description": "A detailed report about DALL-E 2 Reported for Gender and Racially Biased Outputs",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-04-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1874",
      "incident_id": 179,
      "title": "Report 1874 on DALL-E 2 Reported for Gender and Racially Biased Outputs",
      "description": "A detailed report about DALL-E 2 Reported for Gender and Racially Biased Outputs",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-04-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1550",
      "incident_id": 172,
      "title": "Report 1550 on NarxCare’s Risk Score Model Allegedly Lacked Validation and Trained on Data with High Risk of Bias",
      "description": "A detailed report about NarxCare’s Risk Score Model Allegedly Lacked Validation and Trained on Data with High Risk of Bias",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-07-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3859",
      "incident_id": 172,
      "title": "Report 3859 on NarxCare’s Risk Score Model Allegedly Lacked Validation and Trained on Data with High Risk of Bias",
      "description": "A detailed report about NarxCare’s Risk Score Model Allegedly Lacked Validation and Trained on Data with High Risk of Bias",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-07-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3912",
      "incident_id": 172,
      "title": "Report 3912 on NarxCare’s Risk Score Model Allegedly Lacked Validation and Trained on Data with High Risk of Bias",
      "description": "A detailed report about NarxCare’s Risk Score Model Allegedly Lacked Validation and Trained on Data with High Risk of Bias",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-07-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1571",
      "incident_id": 181,
      "title": "Report 1571 on BMW Sedan Made a Prohibited Left Turn, Colliding with a Cruise Autonomous Vehicle",
      "description": "A detailed report about BMW Sedan Made a Prohibited Left Turn, Colliding with a Cruise Autonomous Vehicle",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-02-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1572",
      "incident_id": 181,
      "title": "Report 1572 on BMW Sedan Made a Prohibited Left Turn, Colliding with a Cruise Autonomous Vehicle",
      "description": "A detailed report about BMW Sedan Made a Prohibited Left Turn, Colliding with a Cruise Autonomous Vehicle",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-02-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1610",
      "incident_id": 190,
      "title": "Report 1610 on ByteDance Allegedly Trained For You Algorithm Using Content Scraped without Consent from Other Social Platforms",
      "description": "A detailed report about ByteDance Allegedly Trained For You Algorithm Using Content Scraped without Consent from Other Social Platforms",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-01-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1611",
      "incident_id": 190,
      "title": "Report 1611 on ByteDance Allegedly Trained For You Algorithm Using Content Scraped without Consent from Other Social Platforms",
      "description": "A detailed report about ByteDance Allegedly Trained For You Algorithm Using Content Scraped without Consent from Other Social Platforms",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-01-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1612",
      "incident_id": 190,
      "title": "Report 1612 on ByteDance Allegedly Trained For You Algorithm Using Content Scraped without Consent from Other Social Platforms",
      "description": "A detailed report about ByteDance Allegedly Trained For You Algorithm Using Content Scraped without Consent from Other Social Platforms",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-01-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1558",
      "incident_id": 177,
      "title": "Report 1558 on Google’s Assistive Writing Feature Provided Allegedly Unnecessary and Clumsy Suggestions",
      "description": "A detailed report about Google’s Assistive Writing Feature Provided Allegedly Unnecessary and Clumsy Suggestions",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-04-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1583",
      "incident_id": 177,
      "title": "Report 1583 on Google’s Assistive Writing Feature Provided Allegedly Unnecessary and Clumsy Suggestions",
      "description": "A detailed report about Google’s Assistive Writing Feature Provided Allegedly Unnecessary and Clumsy Suggestions",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-04-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1600",
      "incident_id": 177,
      "title": "Report 1600 on Google’s Assistive Writing Feature Provided Allegedly Unnecessary and Clumsy Suggestions",
      "description": "A detailed report about Google’s Assistive Writing Feature Provided Allegedly Unnecessary and Clumsy Suggestions",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-04-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1603",
      "incident_id": 188,
      "title": "Report 1603 on Argentinian City Government Deployed Teenage-Pregnancy Predictive Algorithm Using Invasive Demographic Data",
      "description": "A detailed report about Argentinian City Government Deployed Teenage-Pregnancy Predictive Algorithm Using Invasive Demographic Data",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-04-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1604",
      "incident_id": 188,
      "title": "Report 1604 on Argentinian City Government Deployed Teenage-Pregnancy Predictive Algorithm Using Invasive Demographic Data",
      "description": "A detailed report about Argentinian City Government Deployed Teenage-Pregnancy Predictive Algorithm Using Invasive Demographic Data",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-04-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1782",
      "incident_id": 188,
      "title": "Report 1782 on Argentinian City Government Deployed Teenage-Pregnancy Predictive Algorithm Using Invasive Demographic Data",
      "description": "A detailed report about Argentinian City Government Deployed Teenage-Pregnancy Predictive Algorithm Using Invasive Demographic Data",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-04-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1614",
      "incident_id": 191,
      "title": "Report 1614 on Korean Internet Portal Giant Naver Manipulated Shopping and Video Search Algorithms to Favor In-House Services",
      "description": "A detailed report about Korean Internet Portal Giant Naver Manipulated Shopping and Video Search Algorithms to Favor In-House Services",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-10-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1615",
      "incident_id": 191,
      "title": "Report 1615 on Korean Internet Portal Giant Naver Manipulated Shopping and Video Search Algorithms to Favor In-House Services",
      "description": "A detailed report about Korean Internet Portal Giant Naver Manipulated Shopping and Video Search Algorithms to Favor In-House Services",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-10-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1654",
      "incident_id": 201,
      "title": "Report 1654 on Climate Action Group Posted Deepfake of Belgian Prime Minister Urging Climate Crisis Action",
      "description": "A detailed report about Climate Action Group Posted Deepfake of Belgian Prime Minister Urging Climate Crisis Action",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-04-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2435",
      "incident_id": 201,
      "title": "Report 2435 on Climate Action Group Posted Deepfake of Belgian Prime Minister Urging Climate Crisis Action",
      "description": "A detailed report about Climate Action Group Posted Deepfake of Belgian Prime Minister Urging Climate Crisis Action",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-04-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1662",
      "incident_id": 204,
      "title": "Report 1662 on A Chinese Tech Worker at Zhihu Fired Allegedly via a Resignation Risk Prediction Algorithm",
      "description": "A detailed report about A Chinese Tech Worker at Zhihu Fired Allegedly via a Resignation Risk Prediction Algorithm",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-02-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1663",
      "incident_id": 204,
      "title": "Report 1663 on A Chinese Tech Worker at Zhihu Fired Allegedly via a Resignation Risk Prediction Algorithm",
      "description": "A detailed report about A Chinese Tech Worker at Zhihu Fired Allegedly via a Resignation Risk Prediction Algorithm",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-02-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1664",
      "incident_id": 204,
      "title": "Report 1664 on A Chinese Tech Worker at Zhihu Fired Allegedly via a Resignation Risk Prediction Algorithm",
      "description": "A detailed report about A Chinese Tech Worker at Zhihu Fired Allegedly via a Resignation Risk Prediction Algorithm",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-02-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1688",
      "incident_id": 209,
      "title": "Report 1688 on Tesla Disabled “Rolling Stop” Functionality Associated with the “Aggressive” Driving Mode",
      "description": "A detailed report about Tesla Disabled “Rolling Stop” Functionality Associated with the “Aggressive” Driving Mode",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-10-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1689",
      "incident_id": 209,
      "title": "Report 1689 on Tesla Disabled “Rolling Stop” Functionality Associated with the “Aggressive” Driving Mode",
      "description": "A detailed report about Tesla Disabled “Rolling Stop” Functionality Associated with the “Aggressive” Driving Mode",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-10-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1690",
      "incident_id": 209,
      "title": "Report 1690 on Tesla Disabled “Rolling Stop” Functionality Associated with the “Aggressive” Driving Mode",
      "description": "A detailed report about Tesla Disabled “Rolling Stop” Functionality Associated with the “Aggressive” Driving Mode",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-10-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1730",
      "incident_id": 219,
      "title": "Report 1730 on Poachers Evaded AI Cameras and Killed Four Rhinos",
      "description": "A detailed report about Poachers Evaded AI Cameras and Killed Four Rhinos",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-11-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1609",
      "incident_id": 189,
      "title": "Report 1609 on Opaque Fraud Detection Algorithm by the UK’s Department of Work and Pensions Allegedly Discriminated against People with Disabilities",
      "description": "A detailed report about Opaque Fraud Detection Algorithm by the UK’s Department of Work and Pensions Allegedly Discriminated against People with Disabilities",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-10-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1670",
      "incident_id": 189,
      "title": "Report 1670 on Opaque Fraud Detection Algorithm by the UK’s Department of Work and Pensions Allegedly Discriminated against People with Disabilities",
      "description": "A detailed report about Opaque Fraud Detection Algorithm by the UK’s Department of Work and Pensions Allegedly Discriminated against People with Disabilities",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-10-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1671",
      "incident_id": 189,
      "title": "Report 1671 on Opaque Fraud Detection Algorithm by the UK’s Department of Work and Pensions Allegedly Discriminated against People with Disabilities",
      "description": "A detailed report about Opaque Fraud Detection Algorithm by the UK’s Department of Work and Pensions Allegedly Discriminated against People with Disabilities",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-10-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1722",
      "incident_id": 214,
      "title": "Report 1722 on SN Technologies Reportedly Lied to a New York State School District about Its Facial and Weapon Detection Systems’ Performance",
      "description": "A detailed report about SN Technologies Reportedly Lied to a New York State School District about Its Facial and Weapon Detection Systems’ Performance",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-01-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1723",
      "incident_id": 215,
      "title": "Report 1723 on Facebook Content Moderators Demand Better Working Conditions Due to Allegedly Inadequate AI Content Moderation",
      "description": "A detailed report about Facebook Content Moderators Demand Better Working Conditions Due to Allegedly Inadequate AI Content Moderation",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-04-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1616",
      "incident_id": 192,
      "title": "Report 1616 on Three Make-Up Artists Lost Jobs Following Black-Box Automated Decision by HireVue",
      "description": "A detailed report about Three Make-Up Artists Lost Jobs Following Black-Box Automated Decision by HireVue",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-03-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1617",
      "incident_id": 192,
      "title": "Report 1617 on Three Make-Up Artists Lost Jobs Following Black-Box Automated Decision by HireVue",
      "description": "A detailed report about Three Make-Up Artists Lost Jobs Following Black-Box Automated Decision by HireVue",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-03-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1725",
      "incident_id": 217,
      "title": "Report 1725 on Robot at a Chinese Tech Fair Smashed a Glass Booth, Injuring a Visitor",
      "description": "A detailed report about Robot at a Chinese Tech Fair Smashed a Glass Booth, Injuring a Visitor",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-11-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1726",
      "incident_id": 217,
      "title": "Report 1726 on Robot at a Chinese Tech Fair Smashed a Glass Booth, Injuring a Visitor",
      "description": "A detailed report about Robot at a Chinese Tech Fair Smashed a Glass Booth, Injuring a Visitor",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-11-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1683",
      "incident_id": 208,
      "title": "Report 1683 on Tesla Phantom Braking Complaints Surged, Allegedly Linked to Tesla Vision Rollout",
      "description": "A detailed report about Tesla Phantom Braking Complaints Surged, Allegedly Linked to Tesla Vision Rollout",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-05-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1684",
      "incident_id": 208,
      "title": "Report 1684 on Tesla Phantom Braking Complaints Surged, Allegedly Linked to Tesla Vision Rollout",
      "description": "A detailed report about Tesla Phantom Braking Complaints Surged, Allegedly Linked to Tesla Vision Rollout",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-05-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1685",
      "incident_id": 208,
      "title": "Report 1685 on Tesla Phantom Braking Complaints Surged, Allegedly Linked to Tesla Vision Rollout",
      "description": "A detailed report about Tesla Phantom Braking Complaints Surged, Allegedly Linked to Tesla Vision Rollout",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-05-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1711",
      "incident_id": 212,
      "title": "Report 1711 on XPeng Motors Fined For Illegal Collection of Consumers’ Faces Using Facial Recognition Cameras",
      "description": "A detailed report about XPeng Motors Fined For Illegal Collection of Consumers’ Faces Using Facial Recognition Cameras",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-01-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1712",
      "incident_id": 212,
      "title": "Report 1712 on XPeng Motors Fined For Illegal Collection of Consumers’ Faces Using Facial Recognition Cameras",
      "description": "A detailed report about XPeng Motors Fined For Illegal Collection of Consumers’ Faces Using Facial Recognition Cameras",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-01-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1713",
      "incident_id": 212,
      "title": "Report 1713 on XPeng Motors Fined For Illegal Collection of Consumers’ Faces Using Facial Recognition Cameras",
      "description": "A detailed report about XPeng Motors Fined For Illegal Collection of Consumers’ Faces Using Facial Recognition Cameras",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-01-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1620",
      "incident_id": 193,
      "title": "Report 1620 on Excessive Automated Monitoring Alerts Ignored by Staff, Resulting in Private Data Theft of Seventy Million Target Customers",
      "description": "A detailed report about Excessive Automated Monitoring Alerts Ignored by Staff, Resulting in Private Data Theft of Seventy Million Target Customers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2013-11-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1633",
      "incident_id": 196,
      "title": "Report 1633 on Compromise of National Biometric ID Card System Leads to Reverification and Change of Status",
      "description": "A detailed report about Compromise of National Biometric ID Card System Leads to Reverification and Change of Status",
      "url": "https://incidentdatabase.ai",
      "date_published": "2013-09-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1634",
      "incident_id": 196,
      "title": "Report 1634 on Compromise of National Biometric ID Card System Leads to Reverification and Change of Status",
      "description": "A detailed report about Compromise of National Biometric ID Card System Leads to Reverification and Change of Status",
      "url": "https://incidentdatabase.ai",
      "date_published": "2013-09-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1635",
      "incident_id": 196,
      "title": "Report 1635 on Compromise of National Biometric ID Card System Leads to Reverification and Change of Status",
      "description": "A detailed report about Compromise of National Biometric ID Card System Leads to Reverification and Change of Status",
      "url": "https://incidentdatabase.ai",
      "date_published": "2013-09-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1679",
      "incident_id": 207,
      "title": "Report 1679 on Hawaii Police Deployed Robot Dog to Patrol a Homeless Encampment",
      "description": "A detailed report about Hawaii Police Deployed Robot Dog to Patrol a Homeless Encampment",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-01-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1680",
      "incident_id": 207,
      "title": "Report 1680 on Hawaii Police Deployed Robot Dog to Patrol a Homeless Encampment",
      "description": "A detailed report about Hawaii Police Deployed Robot Dog to Patrol a Homeless Encampment",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-01-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1681",
      "incident_id": 207,
      "title": "Report 1681 on Hawaii Police Deployed Robot Dog to Patrol a Homeless Encampment",
      "description": "A detailed report about Hawaii Police Deployed Robot Dog to Patrol a Homeless Encampment",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-01-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1696",
      "incident_id": 211,
      "title": "Report 1696 on A Tesla Taxi Cab Involved in an Accident in Paris with Twenty Injuries",
      "description": "A detailed report about A Tesla Taxi Cab Involved in an Accident in Paris with Twenty Injuries",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-12-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1697",
      "incident_id": 211,
      "title": "Report 1697 on A Tesla Taxi Cab Involved in an Accident in Paris with Twenty Injuries",
      "description": "A detailed report about A Tesla Taxi Cab Involved in an Accident in Paris with Twenty Injuries",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-12-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1698",
      "incident_id": 211,
      "title": "Report 1698 on A Tesla Taxi Cab Involved in an Accident in Paris with Twenty Injuries",
      "description": "A detailed report about A Tesla Taxi Cab Involved in an Accident in Paris with Twenty Injuries",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-12-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1596",
      "incident_id": 187,
      "title": "Report 1596 on YouTuber Tested Tesla on Self Driving Mode, Colliding with Street Pylons",
      "description": "A detailed report about YouTuber Tested Tesla on Self Driving Mode, Colliding with Street Pylons",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-02-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1597",
      "incident_id": 187,
      "title": "Report 1597 on YouTuber Tested Tesla on Self Driving Mode, Colliding with Street Pylons",
      "description": "A detailed report about YouTuber Tested Tesla on Self Driving Mode, Colliding with Street Pylons",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-02-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1598",
      "incident_id": 187,
      "title": "Report 1598 on YouTuber Tested Tesla on Self Driving Mode, Colliding with Street Pylons",
      "description": "A detailed report about YouTuber Tested Tesla on Self Driving Mode, Colliding with Street Pylons",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-02-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1586",
      "incident_id": 185,
      "title": "Report 1586 on TikTok's For You Algorithm Directed New Users towards Disinformation about the War in Ukraine",
      "description": "A detailed report about TikTok's For You Algorithm Directed New Users towards Disinformation about the War in Ukraine",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-03-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1587",
      "incident_id": 185,
      "title": "Report 1587 on TikTok's For You Algorithm Directed New Users towards Disinformation about the War in Ukraine",
      "description": "A detailed report about TikTok's For You Algorithm Directed New Users towards Disinformation about the War in Ukraine",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-03-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1588",
      "incident_id": 185,
      "title": "Report 1588 on TikTok's For You Algorithm Directed New Users towards Disinformation about the War in Ukraine",
      "description": "A detailed report about TikTok's For You Algorithm Directed New Users towards Disinformation about the War in Ukraine",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-03-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1666",
      "incident_id": 205,
      "title": "Report 1666 on AI-Generated Profiles Used in Disinformation Campaign Targeting Ukrainians",
      "description": "A detailed report about AI-Generated Profiles Used in Disinformation Campaign Targeting Ukrainians",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-02-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1667",
      "incident_id": 205,
      "title": "Report 1667 on AI-Generated Profiles Used in Disinformation Campaign Targeting Ukrainians",
      "description": "A detailed report about AI-Generated Profiles Used in Disinformation Campaign Targeting Ukrainians",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-02-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1668",
      "incident_id": 205,
      "title": "Report 1668 on AI-Generated Profiles Used in Disinformation Campaign Targeting Ukrainians",
      "description": "A detailed report about AI-Generated Profiles Used in Disinformation Campaign Targeting Ukrainians",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-02-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1727",
      "incident_id": 218,
      "title": "Report 1727 on Tesla on Autopilot Crashed into Flipped Truck on Taiwan Highway",
      "description": "A detailed report about Tesla on Autopilot Crashed into Flipped Truck on Taiwan Highway",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-06-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1728",
      "incident_id": 218,
      "title": "Report 1728 on Tesla on Autopilot Crashed into Flipped Truck on Taiwan Highway",
      "description": "A detailed report about Tesla on Autopilot Crashed into Flipped Truck on Taiwan Highway",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-06-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1950",
      "incident_id": 218,
      "title": "Report 1950 on Tesla on Autopilot Crashed into Flipped Truck on Taiwan Highway",
      "description": "A detailed report about Tesla on Autopilot Crashed into Flipped Truck on Taiwan Highway",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-06-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1638",
      "incident_id": 197,
      "title": "Report 1638 on Facebook Internally Reported Failure of Ranking Algorithm, Exposing Harmful Content to Viewers over Months",
      "description": "A detailed report about Facebook Internally Reported Failure of Ranking Algorithm, Exposing Harmful Content to Viewers over Months",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-10-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1639",
      "incident_id": 197,
      "title": "Report 1639 on Facebook Internally Reported Failure of Ranking Algorithm, Exposing Harmful Content to Viewers over Months",
      "description": "A detailed report about Facebook Internally Reported Failure of Ranking Algorithm, Exposing Harmful Content to Viewers over Months",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-10-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1640",
      "incident_id": 197,
      "title": "Report 1640 on Facebook Internally Reported Failure of Ranking Algorithm, Exposing Harmful Content to Viewers over Months",
      "description": "A detailed report about Facebook Internally Reported Failure of Ranking Algorithm, Exposing Harmful Content to Viewers over Months",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-10-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1647",
      "incident_id": 199,
      "title": "Report 1647 on Ever AI Reportedly Deceived Customers about FRT Use in App",
      "description": "A detailed report about Ever AI Reportedly Deceived Customers about FRT Use in App",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-04-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1648",
      "incident_id": 199,
      "title": "Report 1648 on Ever AI Reportedly Deceived Customers about FRT Use in App",
      "description": "A detailed report about Ever AI Reportedly Deceived Customers about FRT Use in App",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-04-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1649",
      "incident_id": 199,
      "title": "Report 1649 on Ever AI Reportedly Deceived Customers about FRT Use in App",
      "description": "A detailed report about Ever AI Reportedly Deceived Customers about FRT Use in App",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-04-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1693",
      "incident_id": 210,
      "title": "Report 1693 on Indian Political App Tek Fog Allegedly Hijacked Trends and Manipulated Public Opinion on Other Social Media Platforms",
      "description": "A detailed report about Indian Political App Tek Fog Allegedly Hijacked Trends and Manipulated Public Opinion on Other Social Media Platforms",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-04-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1694",
      "incident_id": 210,
      "title": "Report 1694 on Indian Political App Tek Fog Allegedly Hijacked Trends and Manipulated Public Opinion on Other Social Media Platforms",
      "description": "A detailed report about Indian Political App Tek Fog Allegedly Hijacked Trends and Manipulated Public Opinion on Other Social Media Platforms",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-04-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1695",
      "incident_id": 210,
      "title": "Report 1695 on Indian Political App Tek Fog Allegedly Hijacked Trends and Manipulated Public Opinion on Other Social Media Platforms",
      "description": "A detailed report about Indian Political App Tek Fog Allegedly Hijacked Trends and Manipulated Public Opinion on Other Social Media Platforms",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-04-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1756",
      "incident_id": 235,
      "title": "Report 1756 on Chinese Insurer Ping An Employed Facial Recognition to Determine Customers’ Untrustworthiness, Which Critics Alleged to Likely Make Errors and Discriminate",
      "description": "A detailed report about Chinese Insurer Ping An Employed Facial Recognition to Determine Customers’ Untrustworthiness, Which Critics Alleged to Likely Make Errors and Discriminate",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-04-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1744",
      "incident_id": 227,
      "title": "Report 1744 on Waze App Allegedly Caused Tourists’ Car to End up in Lake Champlain, Vermont",
      "description": "A detailed report about Waze App Allegedly Caused Tourists’ Car to End up in Lake Champlain, Vermont",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-01-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1973",
      "incident_id": 227,
      "title": "Report 1973 on Waze App Allegedly Caused Tourists’ Car to End up in Lake Champlain, Vermont",
      "description": "A detailed report about Waze App Allegedly Caused Tourists’ Car to End up in Lake Champlain, Vermont",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-01-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1974",
      "incident_id": 227,
      "title": "Report 1974 on Waze App Allegedly Caused Tourists’ Car to End up in Lake Champlain, Vermont",
      "description": "A detailed report about Waze App Allegedly Caused Tourists’ Car to End up in Lake Champlain, Vermont",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-01-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1735",
      "incident_id": 222,
      "title": "Report 1735 on Thoughts App Allegedly Created Toxic Tweets",
      "description": "A detailed report about Thoughts App Allegedly Created Toxic Tweets",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-07-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1737",
      "incident_id": 223,
      "title": "Report 1737 on Hive Box Facial-Recognition Locks Hacked by Fourth Graders Using Intended Recipient’s Facial Photo",
      "description": "A detailed report about Hive Box Facial-Recognition Locks Hacked by Fourth Graders Using Intended Recipient’s Facial Photo",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-10-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1746",
      "incident_id": 229,
      "title": "Report 1746 on Content Using Bestiality Thumbnails Allegedly Evaded YouTube’s Thumbnail Monitoring System",
      "description": "A detailed report about Content Using Bestiality Thumbnails Allegedly Evaded YouTube’s Thumbnail Monitoring System",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-04-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1747",
      "incident_id": 229,
      "title": "Report 1747 on Content Using Bestiality Thumbnails Allegedly Evaded YouTube’s Thumbnail Monitoring System",
      "description": "A detailed report about Content Using Bestiality Thumbnails Allegedly Evaded YouTube’s Thumbnail Monitoring System",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-04-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1738",
      "incident_id": 224,
      "title": "Report 1738 on WeChat Pay's Facial Recognition Security Evaded by Scammers Using Victims’ Social Media Content",
      "description": "A detailed report about WeChat Pay's Facial Recognition Security Evaded by Scammers Using Victims’ Social Media Content",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-07-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1764",
      "incident_id": 239,
      "title": "Report 1764 on Algorithmic Teacher Evaluation Program Failed Student Outcome Goals and Allegedly Caused Harm Against Teachers",
      "description": "A detailed report about Algorithmic Teacher Evaluation Program Failed Student Outcome Goals and Allegedly Caused Harm Against Teachers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2009-09-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1739",
      "incident_id": 225,
      "title": "Report 1739 on IBM Watson for Oncology Criticized by Customers for Allegedly Unsafe and Inaccurate Cancer Treatment Recommendations",
      "description": "A detailed report about IBM Watson for Oncology Criticized by Customers for Allegedly Unsafe and Inaccurate Cancer Treatment Recommendations",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-04-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1740",
      "incident_id": 225,
      "title": "Report 1740 on IBM Watson for Oncology Criticized by Customers for Allegedly Unsafe and Inaccurate Cancer Treatment Recommendations",
      "description": "A detailed report about IBM Watson for Oncology Criticized by Customers for Allegedly Unsafe and Inaccurate Cancer Treatment Recommendations",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-04-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1751",
      "incident_id": 232,
      "title": "Report 1751 on Tesla Model X on Autopilot Missed Parked Vehicles and Pedestrians, Killing Motorcyclist in Japan",
      "description": "A detailed report about Tesla Model X on Autopilot Missed Parked Vehicles and Pedestrians, Killing Motorcyclist in Japan",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-04-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1752",
      "incident_id": 232,
      "title": "Report 1752 on Tesla Model X on Autopilot Missed Parked Vehicles and Pedestrians, Killing Motorcyclist in Japan",
      "description": "A detailed report about Tesla Model X on Autopilot Missed Parked Vehicles and Pedestrians, Killing Motorcyclist in Japan",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-04-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1975",
      "incident_id": 232,
      "title": "Report 1975 on Tesla Model X on Autopilot Missed Parked Vehicles and Pedestrians, Killing Motorcyclist in Japan",
      "description": "A detailed report about Tesla Model X on Autopilot Missed Parked Vehicles and Pedestrians, Killing Motorcyclist in Japan",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-04-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1775",
      "incident_id": 242,
      "title": "Report 1775 on Manufacturing Robot Failure Caused Factory Worker's Death in India",
      "description": "A detailed report about Manufacturing Robot Failure Caused Factory Worker's Death in India",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-02-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1783",
      "incident_id": 244,
      "title": "Report 1783 on Colorado Police’s Automated License Plate Reader (ALPR) Matched a Family’s Minivan’s Plate to That of a Stolen Vehicle Allegedly, Resulting in Detainment at Gunpoint",
      "description": "A detailed report about Colorado Police’s Automated License Plate Reader (ALPR) Matched a Family’s Minivan’s Plate to That of a Stolen Vehicle Allegedly, Resulting in Detainment at Gunpoint",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-08-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1753",
      "incident_id": 233,
      "title": "Report 1753 on Tumblr Automated Pornography-Detecting Algorithms Erroneously Flagged Inoffensive Images as Explicit",
      "description": "A detailed report about Tumblr Automated Pornography-Detecting Algorithms Erroneously Flagged Inoffensive Images as Explicit",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-12-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1748",
      "incident_id": 230,
      "title": "Report 1748 on Model 3 Tesla on Autopilot Crashed into a Truck in Florida, Killing Driver",
      "description": "A detailed report about Model 3 Tesla on Autopilot Crashed into a Truck in Florida, Killing Driver",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-03-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1785",
      "incident_id": 246,
      "title": "Report 1785 on Misreading of an Automated License Plate Reader (ALPR) Unverified by Police, Resulting in Traffic Stop in Missouri",
      "description": "A detailed report about Misreading of an Automated License Plate Reader (ALPR) Unverified by Police, Resulting in Traffic Stop in Missouri",
      "url": "https://incidentdatabase.ai",
      "date_published": "2014-04-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1787",
      "incident_id": 246,
      "title": "Report 1787 on Misreading of an Automated License Plate Reader (ALPR) Unverified by Police, Resulting in Traffic Stop in Missouri",
      "description": "A detailed report about Misreading of an Automated License Plate Reader (ALPR) Unverified by Police, Resulting in Traffic Stop in Missouri",
      "url": "https://incidentdatabase.ai",
      "date_published": "2014-04-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1745",
      "incident_id": 228,
      "title": "Report 1745 on Apple Maps Allegedly Directed Ski Trip Couple Onto Unpaved Road in the Mountains",
      "description": "A detailed report about Apple Maps Allegedly Directed Ski Trip Couple Onto Unpaved Road in the Mountains",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-02-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1749",
      "incident_id": 231,
      "title": "Report 1749 on A Tesla Crashed into and Killed a Road Sweeper on a Highway in China",
      "description": "A detailed report about A Tesla Crashed into and Killed a Road Sweeper on a Highway in China",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-01-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1750",
      "incident_id": 231,
      "title": "Report 1750 on A Tesla Crashed into and Killed a Road Sweeper on a Highway in China",
      "description": "A detailed report about A Tesla Crashed into and Killed a Road Sweeper on a Highway in China",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-01-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-208",
      "incident_id": 231,
      "title": "Report 208 on A Tesla Crashed into and Killed a Road Sweeper on a Highway in China",
      "description": "A detailed report about A Tesla Crashed into and Killed a Road Sweeper on a Highway in China",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-01-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1784",
      "incident_id": 245,
      "title": "Report 1784 on Unverified Misreading by Automated Plate Reader Led to Traffic Stop and Restraint of an Innocent Person at Gunpoint in California",
      "description": "A detailed report about Unverified Misreading by Automated Plate Reader Led to Traffic Stop and Restraint of an Innocent Person at Gunpoint in California",
      "url": "https://incidentdatabase.ai",
      "date_published": "2009-03-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1789",
      "incident_id": 248,
      "title": "Report 1789 on Automated License Plate Camera Notified Police about a Previously Stolen Rental Car that was Returned, Causing an Innocent Person to be Detained at Gunpoint in California",
      "description": "A detailed report about Automated License Plate Camera Notified Police about a Previously Stolen Rental Car that was Returned, Causing an Innocent Person to be Detained at Gunpoint in California",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-11-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1790",
      "incident_id": 248,
      "title": "Report 1790 on Automated License Plate Camera Notified Police about a Previously Stolen Rental Car that was Returned, Causing an Innocent Person to be Detained at Gunpoint in California",
      "description": "A detailed report about Automated License Plate Camera Notified Police about a Previously Stolen Rental Car that was Returned, Causing an Innocent Person to be Detained at Gunpoint in California",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-11-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1757",
      "incident_id": 236,
      "title": "Report 1757 on AI-Generated Faces Used by Scammers to Pose as a Law Firm in Boston",
      "description": "A detailed report about AI-Generated Faces Used by Scammers to Pose as a Law Firm in Boston",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-04-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1754",
      "incident_id": 234,
      "title": "Report 1754 on Waze Allegedly Frequently Routed Drivers through the Town of Los Gatos, Blocking Its Single Wildfire Escape Route",
      "description": "A detailed report about Waze Allegedly Frequently Routed Drivers through the Town of Los Gatos, Blocking Its Single Wildfire Escape Route",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-09-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1755",
      "incident_id": 234,
      "title": "Report 1755 on Waze Allegedly Frequently Routed Drivers through the Town of Los Gatos, Blocking Its Single Wildfire Escape Route",
      "description": "A detailed report about Waze Allegedly Frequently Routed Drivers through the Town of Los Gatos, Blocking Its Single Wildfire Escape Route",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-09-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1762",
      "incident_id": 238,
      "title": "Report 1762 on Oregon’s Screening Tool for Child Abuse Cases Discontinued Following Concerns of Racial Bias",
      "description": "A detailed report about Oregon’s Screening Tool for Child Abuse Cases Discontinued Following Concerns of Racial Bias",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-10-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1741",
      "incident_id": 226,
      "title": "Report 1741 on Waze Allegedly Clogged Streets and Directed Drivers to Make Unsafe Traffic Decisions",
      "description": "A detailed report about Waze Allegedly Clogged Streets and Directed Drivers to Make Unsafe Traffic Decisions",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-04-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1742",
      "incident_id": 226,
      "title": "Report 1742 on Waze Allegedly Clogged Streets and Directed Drivers to Make Unsafe Traffic Decisions",
      "description": "A detailed report about Waze Allegedly Clogged Streets and Directed Drivers to Make Unsafe Traffic Decisions",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-04-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1743",
      "incident_id": 226,
      "title": "Report 1743 on Waze Allegedly Clogged Streets and Directed Drivers to Make Unsafe Traffic Decisions",
      "description": "A detailed report about Waze Allegedly Clogged Streets and Directed Drivers to Make Unsafe Traffic Decisions",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-04-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1772",
      "incident_id": 241,
      "title": "Report 1772 on Chess-Playing Robot Broke Child's Finger in Russia",
      "description": "A detailed report about Chess-Playing Robot Broke Child's Finger in Russia",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-07-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1773",
      "incident_id": 241,
      "title": "Report 1773 on Chess-Playing Robot Broke Child's Finger in Russia",
      "description": "A detailed report about Chess-Playing Robot Broke Child's Finger in Russia",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-07-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1774",
      "incident_id": 241,
      "title": "Report 1774 on Chess-Playing Robot Broke Child's Finger in Russia",
      "description": "A detailed report about Chess-Playing Robot Broke Child's Finger in Russia",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-07-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1767",
      "incident_id": 240,
      "title": "Report 1767 on GitHub Copilot, Copyright Infringement and Open Source Licensing",
      "description": "A detailed report about GitHub Copilot, Copyright Infringement and Open Source Licensing",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-06-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1768",
      "incident_id": 240,
      "title": "Report 1768 on GitHub Copilot, Copyright Infringement and Open Source Licensing",
      "description": "A detailed report about GitHub Copilot, Copyright Infringement and Open Source Licensing",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-06-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1769",
      "incident_id": 240,
      "title": "Report 1769 on GitHub Copilot, Copyright Infringement and Open Source Licensing",
      "description": "A detailed report about GitHub Copilot, Copyright Infringement and Open Source Licensing",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-06-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1777",
      "incident_id": 243,
      "title": "Report 1777 on Bots Allegedly Made up Roughly Half of Twitter Accounts in Discussions Surrounding COVID-19 Related Issues",
      "description": "A detailed report about Bots Allegedly Made up Roughly Half of Twitter Accounts in Discussions Surrounding COVID-19 Related Issues",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-01-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1778",
      "incident_id": 243,
      "title": "Report 1778 on Bots Allegedly Made up Roughly Half of Twitter Accounts in Discussions Surrounding COVID-19 Related Issues",
      "description": "A detailed report about Bots Allegedly Made up Roughly Half of Twitter Accounts in Discussions Surrounding COVID-19 Related Issues",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-01-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1851",
      "incident_id": 270,
      "title": "Report 1851 on Apple Tweaked App Store Ranking Algorithms, Allegedly Resulted in Demotion of Local Apps in China",
      "description": "A detailed report about Apple Tweaked App Store Ranking Algorithms, Allegedly Resulted in Demotion of Local Apps in China",
      "url": "https://incidentdatabase.ai",
      "date_published": "2011-04-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1852",
      "incident_id": 271,
      "title": "Report 1852 on Tesla Model 3 Sedan on Autopilot Killed Motorcyclist in a Rear-End Collision in Utah",
      "description": "A detailed report about Tesla Model 3 Sedan on Autopilot Killed Motorcyclist in a Rear-End Collision in Utah",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-07-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1861",
      "incident_id": 271,
      "title": "Report 1861 on Tesla Model 3 Sedan on Autopilot Killed Motorcyclist in a Rear-End Collision in Utah",
      "description": "A detailed report about Tesla Model 3 Sedan on Autopilot Killed Motorcyclist in a Rear-End Collision in Utah",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-07-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1862",
      "incident_id": 271,
      "title": "Report 1862 on Tesla Model 3 Sedan on Autopilot Killed Motorcyclist in a Rear-End Collision in Utah",
      "description": "A detailed report about Tesla Model 3 Sedan on Autopilot Killed Motorcyclist in a Rear-End Collision in Utah",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-07-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1849",
      "incident_id": 268,
      "title": "Report 1849 on Permanent Removal of Social Media Content via Automated Tools Allegedly Prevented Investigative Efforts",
      "description": "A detailed report about Permanent Removal of Social Media Content via Automated Tools Allegedly Prevented Investigative Efforts",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-03-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1929",
      "incident_id": 268,
      "title": "Report 1929 on Permanent Removal of Social Media Content via Automated Tools Allegedly Prevented Investigative Efforts",
      "description": "A detailed report about Permanent Removal of Social Media Content via Automated Tools Allegedly Prevented Investigative Efforts",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-03-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3905",
      "incident_id": 268,
      "title": "Report 3905 on Permanent Removal of Social Media Content via Automated Tools Allegedly Prevented Investigative Efforts",
      "description": "A detailed report about Permanent Removal of Social Media Content via Automated Tools Allegedly Prevented Investigative Efforts",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-03-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1794",
      "incident_id": 251,
      "title": "Report 1794 on Amazon Allegedly Tweaked Search Algorithm to Boost Its Own Products",
      "description": "A detailed report about Amazon Allegedly Tweaked Search Algorithm to Boost Its Own Products",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-08-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2384",
      "incident_id": 251,
      "title": "Report 2384 on Amazon Allegedly Tweaked Search Algorithm to Boost Its Own Products",
      "description": "A detailed report about Amazon Allegedly Tweaked Search Algorithm to Boost Its Own Products",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-08-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2975",
      "incident_id": 251,
      "title": "Report 2975 on Amazon Allegedly Tweaked Search Algorithm to Boost Its Own Products",
      "description": "A detailed report about Amazon Allegedly Tweaked Search Algorithm to Boost Its Own Products",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-08-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1856",
      "incident_id": 273,
      "title": "Report 1856 on FaceApp Predicted Different Genders for Similar User Photos with Slight Variations",
      "description": "A detailed report about FaceApp Predicted Different Genders for Similar User Photos with Slight Variations",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-12-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1822",
      "incident_id": 259,
      "title": "Report 1822 on YouTuber Built, Made Publicly Available, and Released Model Trained on Toxic 4chan Posts as Prank",
      "description": "A detailed report about YouTuber Built, Made Publicly Available, and Released Model Trained on Toxic 4chan Posts as Prank",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-06-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1842",
      "incident_id": 259,
      "title": "Report 1842 on YouTuber Built, Made Publicly Available, and Released Model Trained on Toxic 4chan Posts as Prank",
      "description": "A detailed report about YouTuber Built, Made Publicly Available, and Released Model Trained on Toxic 4chan Posts as Prank",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-06-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1805",
      "incident_id": 255,
      "title": "Report 1805 on Unreliable ShotSpotter Audio Previously Used to Convict Chicago Man in Murder Case",
      "description": "A detailed report about Unreliable ShotSpotter Audio Previously Used to Convict Chicago Man in Murder Case",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-05-31",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1806",
      "incident_id": 255,
      "title": "Report 1806 on Unreliable ShotSpotter Audio Previously Used to Convict Chicago Man in Murder Case",
      "description": "A detailed report about Unreliable ShotSpotter Audio Previously Used to Convict Chicago Man in Murder Case",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-05-31",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1807",
      "incident_id": 255,
      "title": "Report 1807 on Unreliable ShotSpotter Audio Previously Used to Convict Chicago Man in Murder Case",
      "description": "A detailed report about Unreliable ShotSpotter Audio Previously Used to Convict Chicago Man in Murder Case",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-05-31",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1844",
      "incident_id": 266,
      "title": "Report 1844 on Replika's AI Companions Reportedly Abused by Its Users",
      "description": "A detailed report about Replika's AI Companions Reportedly Abused by Its Users",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-01-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2532",
      "incident_id": 266,
      "title": "Report 2532 on Replika's AI Companions Reportedly Abused by Its Users",
      "description": "A detailed report about Replika's AI Companions Reportedly Abused by Its Users",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-01-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2533",
      "incident_id": 266,
      "title": "Report 2533 on Replika's AI Companions Reportedly Abused by Its Users",
      "description": "A detailed report about Replika's AI Companions Reportedly Abused by Its Users",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-01-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1796",
      "incident_id": 253,
      "title": "Report 1796 on Cruise's Self-Driving Cars Allegedly Lost Connection to Their Server, Causing Traffic Blockages in San Francisco",
      "description": "A detailed report about Cruise's Self-Driving Cars Allegedly Lost Connection to Their Server, Causing Traffic Blockages in San Francisco",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-05-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1797",
      "incident_id": 253,
      "title": "Report 1797 on Cruise's Self-Driving Cars Allegedly Lost Connection to Their Server, Causing Traffic Blockages in San Francisco",
      "description": "A detailed report about Cruise's Self-Driving Cars Allegedly Lost Connection to Their Server, Causing Traffic Blockages in San Francisco",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-05-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1798",
      "incident_id": 253,
      "title": "Report 1798 on Cruise's Self-Driving Cars Allegedly Lost Connection to Their Server, Causing Traffic Blockages in San Francisco",
      "description": "A detailed report about Cruise's Self-Driving Cars Allegedly Lost Connection to Their Server, Causing Traffic Blockages in San Francisco",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-05-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1791",
      "incident_id": 249,
      "title": "Report 1791 on Government Deployed Extreme Surveillance Technologies to Monitor and Target Muslim Minorities in Xinjiang",
      "description": "A detailed report about Government Deployed Extreme Surveillance Technologies to Monitor and Target Muslim Minorities in Xinjiang",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-10-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1792",
      "incident_id": 249,
      "title": "Report 1792 on Government Deployed Extreme Surveillance Technologies to Monitor and Target Muslim Minorities in Xinjiang",
      "description": "A detailed report about Government Deployed Extreme Surveillance Technologies to Monitor and Target Muslim Minorities in Xinjiang",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-10-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1804",
      "incident_id": 254,
      "title": "Report 1804 on Google’s Face Grouping Allegedly Collected and Analyzed Users’ Facial Structure without Consent, Violated BIPA",
      "description": "A detailed report about Google’s Face Grouping Allegedly Collected and Analyzed Users’ Facial Structure without Consent, Violated BIPA",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-05-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2069",
      "incident_id": 254,
      "title": "Report 2069 on Google’s Face Grouping Allegedly Collected and Analyzed Users’ Facial Structure without Consent, Violated BIPA",
      "description": "A detailed report about Google’s Face Grouping Allegedly Collected and Analyzed Users’ Facial Structure without Consent, Violated BIPA",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-05-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1814",
      "incident_id": 256,
      "title": "Report 1814 on DUI Arrest Case Allegedly Based Only on ShotSpotter's Alert",
      "description": "A detailed report about DUI Arrest Case Allegedly Based Only on ShotSpotter's Alert",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-11-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1793",
      "incident_id": 250,
      "title": "Report 1793 on Dutch City Court Defended Home Value Generated by Black-Box Algorithm",
      "description": "A detailed report about Dutch City Court Defended Home Value Generated by Black-Box Algorithm",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-02-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1819",
      "incident_id": 258,
      "title": "Report 1819 on Australian Retailers Reportedly Captured Face Prints of Their Customers without Consent",
      "description": "A detailed report about Australian Retailers Reportedly Captured Face Prints of Their Customers without Consent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-05-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1820",
      "incident_id": 258,
      "title": "Report 1820 on Australian Retailers Reportedly Captured Face Prints of Their Customers without Consent",
      "description": "A detailed report about Australian Retailers Reportedly Captured Face Prints of Their Customers without Consent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-05-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1857",
      "incident_id": 274,
      "title": "Report 1857 on Virginia Courts’ Algorithmic Recidivism Risk Assessment Failed to Lower Incarceration Rates",
      "description": "A detailed report about Virginia Courts’ Algorithmic Recidivism Risk Assessment Failed to Lower Incarceration Rates",
      "url": "https://incidentdatabase.ai",
      "date_published": "2003-07-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1859",
      "incident_id": 274,
      "title": "Report 1859 on Virginia Courts’ Algorithmic Recidivism Risk Assessment Failed to Lower Incarceration Rates",
      "description": "A detailed report about Virginia Courts’ Algorithmic Recidivism Risk Assessment Failed to Lower Incarceration Rates",
      "url": "https://incidentdatabase.ai",
      "date_published": "2003-07-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1845",
      "incident_id": 267,
      "title": "Report 1845 on Clearview AI Algorithm Built on Photos Scraped from Social Media Profiles without Consent",
      "description": "A detailed report about Clearview AI Algorithm Built on Photos Scraped from Social Media Profiles without Consent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-06-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1846",
      "incident_id": 267,
      "title": "Report 1846 on Clearview AI Algorithm Built on Photos Scraped from Social Media Profiles without Consent",
      "description": "A detailed report about Clearview AI Algorithm Built on Photos Scraped from Social Media Profiles without Consent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-06-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1847",
      "incident_id": 267,
      "title": "Report 1847 on Clearview AI Algorithm Built on Photos Scraped from Social Media Profiles without Consent",
      "description": "A detailed report about Clearview AI Algorithm Built on Photos Scraped from Social Media Profiles without Consent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-06-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1815",
      "incident_id": 257,
      "title": "Report 1815 on Police Reportedly Deployed ShotSpotter Sensors Disproportionately in Neighborhoods of Color",
      "description": "A detailed report about Police Reportedly Deployed ShotSpotter Sensors Disproportionately in Neighborhoods of Color",
      "url": "https://incidentdatabase.ai",
      "date_published": "2012-05-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1435",
      "incident_id": 257,
      "title": "Report 1435 on Police Reportedly Deployed ShotSpotter Sensors Disproportionately in Neighborhoods of Color",
      "description": "A detailed report about Police Reportedly Deployed ShotSpotter Sensors Disproportionately in Neighborhoods of Color",
      "url": "https://incidentdatabase.ai",
      "date_published": "2012-05-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1821",
      "incident_id": 257,
      "title": "Report 1821 on Police Reportedly Deployed ShotSpotter Sensors Disproportionately in Neighborhoods of Color",
      "description": "A detailed report about Police Reportedly Deployed ShotSpotter Sensors Disproportionately in Neighborhoods of Color",
      "url": "https://incidentdatabase.ai",
      "date_published": "2012-05-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1839",
      "incident_id": 264,
      "title": "Report 1839 on AI-Based Vehicle Speed Estimation App Denounced by UK Drivers as Surveillance Technology",
      "description": "A detailed report about AI-Based Vehicle Speed Estimation App Denounced by UK Drivers as Surveillance Technology",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-03-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1795",
      "incident_id": 252,
      "title": "Report 1795 on Remotely Operated Taser-Armed Drones Proposed by Taser Manufacturer as Defense for School Shootings in the US",
      "description": "A detailed report about Remotely Operated Taser-Armed Drones Proposed by Taser Manufacturer as Defense for School Shootings in the US",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-06-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1853",
      "incident_id": 272,
      "title": "Report 1853 on Grab Tweaked Matchmaking Algorithm, Providing Preferential Treatment to Drivers Registered with Affiliated Car Rental Service",
      "description": "A detailed report about Grab Tweaked Matchmaking Algorithm, Providing Preferential Treatment to Drivers Registered with Affiliated Car Rental Service",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-10-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1854",
      "incident_id": 272,
      "title": "Report 1854 on Grab Tweaked Matchmaking Algorithm, Providing Preferential Treatment to Drivers Registered with Affiliated Car Rental Service",
      "description": "A detailed report about Grab Tweaked Matchmaking Algorithm, Providing Preferential Treatment to Drivers Registered with Affiliated Car Rental Service",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-10-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1855",
      "incident_id": 272,
      "title": "Report 1855 on Grab Tweaked Matchmaking Algorithm, Providing Preferential Treatment to Drivers Registered with Affiliated Car Rental Service",
      "description": "A detailed report about Grab Tweaked Matchmaking Algorithm, Providing Preferential Treatment to Drivers Registered with Affiliated Car Rental Service",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-10-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1823",
      "incident_id": 260,
      "title": "Report 1823 on US DHS’s Opaque Vetting Software Allegedly Relied on Poor-Quality Data and Discriminated against Immigrants",
      "description": "A detailed report about US DHS’s Opaque Vetting Software Allegedly Relied on Poor-Quality Data and Discriminated against Immigrants",
      "url": "https://incidentdatabase.ai",
      "date_published": "2014-08-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1831",
      "incident_id": 260,
      "title": "Report 1831 on US DHS’s Opaque Vetting Software Allegedly Relied on Poor-Quality Data and Discriminated against Immigrants",
      "description": "A detailed report about US DHS’s Opaque Vetting Software Allegedly Relied on Poor-Quality Data and Discriminated against Immigrants",
      "url": "https://incidentdatabase.ai",
      "date_published": "2014-08-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1824",
      "incident_id": 261,
      "title": "Report 1824 on Robot Deployed by Animal Shelter to Patrol Sidewalks outside Its Office, Warding off Homeless People in San Francisco",
      "description": "A detailed report about Robot Deployed by Animal Shelter to Patrol Sidewalks outside Its Office, Warding off Homeless People in San Francisco",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-11-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1825",
      "incident_id": 261,
      "title": "Report 1825 on Robot Deployed by Animal Shelter to Patrol Sidewalks outside Its Office, Warding off Homeless People in San Francisco",
      "description": "A detailed report about Robot Deployed by Animal Shelter to Patrol Sidewalks outside Its Office, Warding off Homeless People in San Francisco",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-11-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1826",
      "incident_id": 261,
      "title": "Report 1826 on Robot Deployed by Animal Shelter to Patrol Sidewalks outside Its Office, Warding off Homeless People in San Francisco",
      "description": "A detailed report about Robot Deployed by Animal Shelter to Patrol Sidewalks outside Its Office, Warding off Homeless People in San Francisco",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-11-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1833",
      "incident_id": 262,
      "title": "Report 1833 on DALL-E Mini Reportedly Reinforced or Exacerbated Societal Biases in Its Outputs as Gender and Racial Stereotypes",
      "description": "A detailed report about DALL-E Mini Reportedly Reinforced or Exacerbated Societal Biases in Its Outputs as Gender and Racial Stereotypes",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-06-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1834",
      "incident_id": 262,
      "title": "Report 1834 on DALL-E Mini Reportedly Reinforced or Exacerbated Societal Biases in Its Outputs as Gender and Racial Stereotypes",
      "description": "A detailed report about DALL-E Mini Reportedly Reinforced or Exacerbated Societal Biases in Its Outputs as Gender and Racial Stereotypes",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-06-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1835",
      "incident_id": 262,
      "title": "Report 1835 on DALL-E Mini Reportedly Reinforced or Exacerbated Societal Biases in Its Outputs as Gender and Racial Stereotypes",
      "description": "A detailed report about DALL-E Mini Reportedly Reinforced or Exacerbated Societal Biases in Its Outputs as Gender and Racial Stereotypes",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-06-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1838",
      "incident_id": 263,
      "title": "Report 1838 on YouTube Recommendations Implicated in Political Radicalization of User",
      "description": "A detailed report about YouTube Recommendations Implicated in Political Radicalization of User",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-09-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1840",
      "incident_id": 265,
      "title": "Report 1840 on Black Uber Eats Driver Allegedly Subjected to Excessive Photo Checks and Dismissed via FRT Results",
      "description": "A detailed report about Black Uber Eats Driver Allegedly Subjected to Excessive Photo Checks and Dismissed via FRT Results",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-04-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1841",
      "incident_id": 265,
      "title": "Report 1841 on Black Uber Eats Driver Allegedly Subjected to Excessive Photo Checks and Dismissed via FRT Results",
      "description": "A detailed report about Black Uber Eats Driver Allegedly Subjected to Excessive Photo Checks and Dismissed via FRT Results",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-04-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1866",
      "incident_id": 278,
      "title": "Report 1866 on Meta’s BlenderBot 3 Chatbot Demo Made Offensive Antisemitic Comments",
      "description": "A detailed report about Meta’s BlenderBot 3 Chatbot Demo Made Offensive Antisemitic Comments",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-08-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1867",
      "incident_id": 278,
      "title": "Report 1867 on Meta’s BlenderBot 3 Chatbot Demo Made Offensive Antisemitic Comments",
      "description": "A detailed report about Meta’s BlenderBot 3 Chatbot Demo Made Offensive Antisemitic Comments",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-08-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1868",
      "incident_id": 278,
      "title": "Report 1868 on Meta’s BlenderBot 3 Chatbot Demo Made Offensive Antisemitic Comments",
      "description": "A detailed report about Meta’s BlenderBot 3 Chatbot Demo Made Offensive Antisemitic Comments",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-08-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1858",
      "incident_id": 275,
      "title": "Report 1858 on Facebook’s Moderation Algorithm Banned Users for Historical Evidence of Slavery",
      "description": "A detailed report about Facebook’s Moderation Algorithm Banned Users for Historical Evidence of Slavery",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-06-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1860",
      "incident_id": 275,
      "title": "Report 1860 on Facebook’s Moderation Algorithm Banned Users for Historical Evidence of Slavery",
      "description": "A detailed report about Facebook’s Moderation Algorithm Banned Users for Historical Evidence of Slavery",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-06-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1888",
      "incident_id": 285,
      "title": "Report 1888 on Google Lens’s Camera-Based Translation Feature Provided an Offensive Mistranslation of a Book Title in Korean",
      "description": "A detailed report about Google Lens’s Camera-Based Translation Feature Provided an Offensive Mistranslation of a Book Title in Korean",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-07-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2017",
      "incident_id": 330,
      "title": "Report 2017 on “Amazon’s Choice” Algorithm Failed to Recommend Functional Products and Prone to Review Manipulation",
      "description": "A detailed report about “Amazon’s Choice” Algorithm Failed to Recommend Functional Products and Prone to Review Manipulation",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-12-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1935",
      "incident_id": 299,
      "title": "Report 1935 on Japanese Porn Depixelated by Man using Deepfake",
      "description": "A detailed report about Japanese Porn Depixelated by Man using Deepfake",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-12-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1992",
      "incident_id": 323,
      "title": "Report 1992 on Tesla on Autopilot Crashed into Parked Police Car in California",
      "description": "A detailed report about Tesla on Autopilot Crashed into Parked Police Car in California",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-05-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1193",
      "incident_id": 323,
      "title": "Report 1193 on Tesla on Autopilot Crashed into Parked Police Car in California",
      "description": "A detailed report about Tesla on Autopilot Crashed into Parked Police Car in California",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-05-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2006",
      "incident_id": 323,
      "title": "Report 2006 on Tesla on Autopilot Crashed into Parked Police Car in California",
      "description": "A detailed report about Tesla on Autopilot Crashed into Parked Police Car in California",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-05-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1907",
      "incident_id": 293,
      "title": "Report 1907 on Cruise’s Self-Driving Car Involved in a Multiple-Injury Collision at an San Francisco Intersection",
      "description": "A detailed report about Cruise’s Self-Driving Car Involved in a Multiple-Injury Collision at an San Francisco Intersection",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-06-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1908",
      "incident_id": 293,
      "title": "Report 1908 on Cruise’s Self-Driving Car Involved in a Multiple-Injury Collision at an San Francisco Intersection",
      "description": "A detailed report about Cruise’s Self-Driving Car Involved in a Multiple-Injury Collision at an San Francisco Intersection",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-06-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1909",
      "incident_id": 293,
      "title": "Report 1909 on Cruise’s Self-Driving Car Involved in a Multiple-Injury Collision at an San Francisco Intersection",
      "description": "A detailed report about Cruise’s Self-Driving Car Involved in a Multiple-Injury Collision at an San Francisco Intersection",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-06-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2004",
      "incident_id": 325,
      "title": "Report 2004 on Offensive Instagram User Content Displayed as Facebook Ad",
      "description": "A detailed report about Offensive Instagram User Content Displayed as Facebook Ad",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-09-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2005",
      "incident_id": 325,
      "title": "Report 2005 on Offensive Instagram User Content Displayed as Facebook Ad",
      "description": "A detailed report about Offensive Instagram User Content Displayed as Facebook Ad",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-09-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2014",
      "incident_id": 328,
      "title": "Report 2014 on Fake Accounts Using GAN Faces Deployed by Propaganda Campaign on Social Platforms",
      "description": "A detailed report about Fake Accounts Using GAN Faces Deployed by Propaganda Campaign on Social Platforms",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-06-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2032",
      "incident_id": 328,
      "title": "Report 2032 on Fake Accounts Using GAN Faces Deployed by Propaganda Campaign on Social Platforms",
      "description": "A detailed report about Fake Accounts Using GAN Faces Deployed by Propaganda Campaign on Social Platforms",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-06-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2060",
      "incident_id": 347,
      "title": "Report 2060 on Waymo Self-Driving Taxi Behaved Unexpectedly, Driving away from Support Crew",
      "description": "A detailed report about Waymo Self-Driving Taxi Behaved Unexpectedly, Driving away from Support Crew",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-05-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2098",
      "incident_id": 347,
      "title": "Report 2098 on Waymo Self-Driving Taxi Behaved Unexpectedly, Driving away from Support Crew",
      "description": "A detailed report about Waymo Self-Driving Taxi Behaved Unexpectedly, Driving away from Support Crew",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-05-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2099",
      "incident_id": 347,
      "title": "Report 2099 on Waymo Self-Driving Taxi Behaved Unexpectedly, Driving away from Support Crew",
      "description": "A detailed report about Waymo Self-Driving Taxi Behaved Unexpectedly, Driving away from Support Crew",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-05-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2067",
      "incident_id": 350,
      "title": "Report 2067 on Delivery Robot Rolled Through Crime Scene",
      "description": "A detailed report about Delivery Robot Rolled Through Crime Scene",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-09-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2094",
      "incident_id": 350,
      "title": "Report 2094 on Delivery Robot Rolled Through Crime Scene",
      "description": "A detailed report about Delivery Robot Rolled Through Crime Scene",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-09-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1901",
      "incident_id": 291,
      "title": "Report 1901 on Tesla Allegedly Misled Customers about Autopilot and FSD Capabilities",
      "description": "A detailed report about Tesla Allegedly Misled Customers about Autopilot and FSD Capabilities",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-05-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1902",
      "incident_id": 291,
      "title": "Report 1902 on Tesla Allegedly Misled Customers about Autopilot and FSD Capabilities",
      "description": "A detailed report about Tesla Allegedly Misled Customers about Autopilot and FSD Capabilities",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-05-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1903",
      "incident_id": 291,
      "title": "Report 1903 on Tesla Allegedly Misled Customers about Autopilot and FSD Capabilities",
      "description": "A detailed report about Tesla Allegedly Misled Customers about Autopilot and FSD Capabilities",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-05-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1911",
      "incident_id": 294,
      "title": "Report 1911 on Tesla Autopilot Allegedly Malfunctioned in a Non-Fatal Collision in Greece",
      "description": "A detailed report about Tesla Autopilot Allegedly Malfunctioned in a Non-Fatal Collision in Greece",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-05-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1912",
      "incident_id": 294,
      "title": "Report 1912 on Tesla Autopilot Allegedly Malfunctioned in a Non-Fatal Collision in Greece",
      "description": "A detailed report about Tesla Autopilot Allegedly Malfunctioned in a Non-Fatal Collision in Greece",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-05-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1913",
      "incident_id": 294,
      "title": "Report 1913 on Tesla Autopilot Allegedly Malfunctioned in a Non-Fatal Collision in Greece",
      "description": "A detailed report about Tesla Autopilot Allegedly Malfunctioned in a Non-Fatal Collision in Greece",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-05-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1872",
      "incident_id": 280,
      "title": "Report 1872 on Coffee Meets Bagel’s Algorithm Reported by Users Disproportionately Showing Them Matches of Their Own Ethnicities Despite Selecting “No Preference”",
      "description": "A detailed report about Coffee Meets Bagel’s Algorithm Reported by Users Disproportionately Showing Them Matches of Their Own Ethnicities Despite Selecting “No Preference”",
      "url": "https://incidentdatabase.ai",
      "date_published": "2013-07-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1873",
      "incident_id": 280,
      "title": "Report 1873 on Coffee Meets Bagel’s Algorithm Reported by Users Disproportionately Showing Them Matches of Their Own Ethnicities Despite Selecting “No Preference”",
      "description": "A detailed report about Coffee Meets Bagel’s Algorithm Reported by Users Disproportionately Showing Them Matches of Their Own Ethnicities Despite Selecting “No Preference”",
      "url": "https://incidentdatabase.ai",
      "date_published": "2013-07-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2471",
      "incident_id": 287,
      "title": "Report 2471 on OpenAI’s GPT-3 Reported as Unviable in Medical Tasks by Healthcare Firm",
      "description": "A detailed report about OpenAI’s GPT-3 Reported as Unviable in Medical Tasks by Healthcare Firm",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-10-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1915",
      "incident_id": 295,
      "title": "Report 1915 on Wrongful Attempted Arrest for Apple Store Thefts Due to NYPD’s Facial Misidentification",
      "description": "A detailed report about Wrongful Attempted Arrest for Apple Store Thefts Due to NYPD’s Facial Misidentification",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-11-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1916",
      "incident_id": 295,
      "title": "Report 1916 on Wrongful Attempted Arrest for Apple Store Thefts Due to NYPD’s Facial Misidentification",
      "description": "A detailed report about Wrongful Attempted Arrest for Apple Store Thefts Due to NYPD’s Facial Misidentification",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-11-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1917",
      "incident_id": 295,
      "title": "Report 1917 on Wrongful Attempted Arrest for Apple Store Thefts Due to NYPD’s Facial Misidentification",
      "description": "A detailed report about Wrongful Attempted Arrest for Apple Store Thefts Due to NYPD’s Facial Misidentification",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-11-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1985",
      "incident_id": 320,
      "title": "Report 1985 on Tesla on Autopilot Collided with Parked Fire Truck on California Freeway",
      "description": "A detailed report about Tesla on Autopilot Collided with Parked Fire Truck on California Freeway",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-01-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1986",
      "incident_id": 320,
      "title": "Report 1986 on Tesla on Autopilot Collided with Parked Fire Truck on California Freeway",
      "description": "A detailed report about Tesla on Autopilot Collided with Parked Fire Truck on California Freeway",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-01-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1987",
      "incident_id": 320,
      "title": "Report 1987 on Tesla on Autopilot Collided with Parked Fire Truck on California Freeway",
      "description": "A detailed report about Tesla on Autopilot Collided with Parked Fire Truck on California Freeway",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-01-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2008",
      "incident_id": 326,
      "title": "Report 2008 on Facebook Automated Year-in-Review Highlights Showed Users Painful Memories",
      "description": "A detailed report about Facebook Automated Year-in-Review Highlights Showed Users Painful Memories",
      "url": "https://incidentdatabase.ai",
      "date_published": "2014-12-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2012",
      "incident_id": 326,
      "title": "Report 2012 on Facebook Automated Year-in-Review Highlights Showed Users Painful Memories",
      "description": "A detailed report about Facebook Automated Year-in-Review Highlights Showed Users Painful Memories",
      "url": "https://incidentdatabase.ai",
      "date_published": "2014-12-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2013",
      "incident_id": 326,
      "title": "Report 2013 on Facebook Automated Year-in-Review Highlights Showed Users Painful Memories",
      "description": "A detailed report about Facebook Automated Year-in-Review Highlights Showed Users Painful Memories",
      "url": "https://incidentdatabase.ai",
      "date_published": "2014-12-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2047",
      "incident_id": 335,
      "title": "Report 2047 on UK Visa Streamline Algorithm Allegedly Discriminated Based on Nationality",
      "description": "A detailed report about UK Visa Streamline Algorithm Allegedly Discriminated Based on Nationality",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-03-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2090",
      "incident_id": 335,
      "title": "Report 2090 on UK Visa Streamline Algorithm Allegedly Discriminated Based on Nationality",
      "description": "A detailed report about UK Visa Streamline Algorithm Allegedly Discriminated Based on Nationality",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-03-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2091",
      "incident_id": 335,
      "title": "Report 2091 on UK Visa Streamline Algorithm Allegedly Discriminated Based on Nationality",
      "description": "A detailed report about UK Visa Streamline Algorithm Allegedly Discriminated Based on Nationality",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-03-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1904",
      "incident_id": 292,
      "title": "Report 1904 on Apple’s AVs Reportedly Struggled to Navigate Streets in Silicon Valley Test Drives",
      "description": "A detailed report about Apple’s AVs Reportedly Struggled to Navigate Streets in Silicon Valley Test Drives",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-09-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1905",
      "incident_id": 292,
      "title": "Report 1905 on Apple’s AVs Reportedly Struggled to Navigate Streets in Silicon Valley Test Drives",
      "description": "A detailed report about Apple’s AVs Reportedly Struggled to Navigate Streets in Silicon Valley Test Drives",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-09-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1906",
      "incident_id": 292,
      "title": "Report 1906 on Apple’s AVs Reportedly Struggled to Navigate Streets in Silicon Valley Test Drives",
      "description": "A detailed report about Apple’s AVs Reportedly Struggled to Navigate Streets in Silicon Valley Test Drives",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-09-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1936",
      "incident_id": 300,
      "title": "Report 1936 on TikTok's For You Algorithm Allegedly Abused by Online Personality to Promote Anti-Women Hate",
      "description": "A detailed report about TikTok's For You Algorithm Allegedly Abused by Online Personality to Promote Anti-Women Hate",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-01-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1937",
      "incident_id": 300,
      "title": "Report 1937 on TikTok's For You Algorithm Allegedly Abused by Online Personality to Promote Anti-Women Hate",
      "description": "A detailed report about TikTok's For You Algorithm Allegedly Abused by Online Personality to Promote Anti-Women Hate",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-01-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1977",
      "incident_id": 318,
      "title": "Report 1977 on Facebook Recommended Military Gear Ads Despite Pause on Weapons Accessories Ads",
      "description": "A detailed report about Facebook Recommended Military Gear Ads Despite Pause on Weapons Accessories Ads",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-01-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1978",
      "incident_id": 318,
      "title": "Report 1978 on Facebook Recommended Military Gear Ads Despite Pause on Weapons Accessories Ads",
      "description": "A detailed report about Facebook Recommended Military Gear Ads Despite Pause on Weapons Accessories Ads",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-01-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1981",
      "incident_id": 319,
      "title": "Report 1981 on Tesla on Autopilot Fatally Crashed into Parked Fire Truck in Indiana",
      "description": "A detailed report about Tesla on Autopilot Fatally Crashed into Parked Fire Truck in Indiana",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-12-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1982",
      "incident_id": 319,
      "title": "Report 1982 on Tesla on Autopilot Fatally Crashed into Parked Fire Truck in Indiana",
      "description": "A detailed report about Tesla on Autopilot Fatally Crashed into Parked Fire Truck in Indiana",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-12-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1983",
      "incident_id": 319,
      "title": "Report 1983 on Tesla on Autopilot Fatally Crashed into Parked Fire Truck in Indiana",
      "description": "A detailed report about Tesla on Autopilot Fatally Crashed into Parked Fire Truck in Indiana",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-12-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2033",
      "incident_id": 332,
      "title": "Report 2033 on Google Image Showed Racially Biased Results for “Professional” Hairstyles",
      "description": "A detailed report about Google Image Showed Racially Biased Results for “Professional” Hairstyles",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-04-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2040",
      "incident_id": 332,
      "title": "Report 2040 on Google Image Showed Racially Biased Results for “Professional” Hairstyles",
      "description": "A detailed report about Google Image Showed Racially Biased Results for “Professional” Hairstyles",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-04-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2041",
      "incident_id": 332,
      "title": "Report 2041 on Google Image Showed Racially Biased Results for “Professional” Hairstyles",
      "description": "A detailed report about Google Image Showed Racially Biased Results for “Professional” Hairstyles",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-04-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2053",
      "incident_id": 340,
      "title": "Report 2053 on Honda's CMBS False Positives Allegedly Caused Accidents to Customers",
      "description": "A detailed report about Honda's CMBS False Positives Allegedly Caused Accidents to Customers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-02-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2054",
      "incident_id": 341,
      "title": "Report 2054 on Nissan's Automatic Emergency Braking False Positives Posed Traffic Risks to Drivers",
      "description": "A detailed report about Nissan's Automatic Emergency Braking False Positives Posed Traffic Risks to Drivers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-04-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2114",
      "incident_id": 341,
      "title": "Report 2114 on Nissan's Automatic Emergency Braking False Positives Posed Traffic Risks to Drivers",
      "description": "A detailed report about Nissan's Automatic Emergency Braking False Positives Posed Traffic Risks to Drivers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-04-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2198",
      "incident_id": 341,
      "title": "Report 2198 on Nissan's Automatic Emergency Braking False Positives Posed Traffic Risks to Drivers",
      "description": "A detailed report about Nissan's Automatic Emergency Braking False Positives Posed Traffic Risks to Drivers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-04-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2046",
      "incident_id": 334,
      "title": "Report 2046 on Uber Deployed Secret Program To Deny Local Authorities Rides",
      "description": "A detailed report about Uber Deployed Secret Program To Deny Local Authorities Rides",
      "url": "https://incidentdatabase.ai",
      "date_published": "2014-10-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2077",
      "incident_id": 334,
      "title": "Report 2077 on Uber Deployed Secret Program To Deny Local Authorities Rides",
      "description": "A detailed report about Uber Deployed Secret Program To Deny Local Authorities Rides",
      "url": "https://incidentdatabase.ai",
      "date_published": "2014-10-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1942",
      "incident_id": 305,
      "title": "Report 1942 on YouTube’s Recommendation Algorithm Allegedly Promoted Climate Misinformation Content",
      "description": "A detailed report about YouTube’s Recommendation Algorithm Allegedly Promoted Climate Misinformation Content",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-02-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1943",
      "incident_id": 305,
      "title": "Report 1943 on YouTube’s Recommendation Algorithm Allegedly Promoted Climate Misinformation Content",
      "description": "A detailed report about YouTube’s Recommendation Algorithm Allegedly Promoted Climate Misinformation Content",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-02-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1921",
      "incident_id": 297,
      "title": "Report 1921 on EasyMile Self-Driving Shuttle Unexpectedly Stopped Mid-Route, Injuring a Passenger",
      "description": "A detailed report about EasyMile Self-Driving Shuttle Unexpectedly Stopped Mid-Route, Injuring a Passenger",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-02-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1922",
      "incident_id": 297,
      "title": "Report 1922 on EasyMile Self-Driving Shuttle Unexpectedly Stopped Mid-Route, Injuring a Passenger",
      "description": "A detailed report about EasyMile Self-Driving Shuttle Unexpectedly Stopped Mid-Route, Injuring a Passenger",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-02-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1923",
      "incident_id": 297,
      "title": "Report 1923 on EasyMile Self-Driving Shuttle Unexpectedly Stopped Mid-Route, Injuring a Passenger",
      "description": "A detailed report about EasyMile Self-Driving Shuttle Unexpectedly Stopped Mid-Route, Injuring a Passenger",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-02-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1879",
      "incident_id": 282,
      "title": "Report 1879 on Facebook’s Algorithm Mistook an Advertisement of Onions as Sexual Suggestive Content",
      "description": "A detailed report about Facebook’s Algorithm Mistook an Advertisement of Onions as Sexual Suggestive Content",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-10-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1881",
      "incident_id": 282,
      "title": "Report 1881 on Facebook’s Algorithm Mistook an Advertisement of Onions as Sexual Suggestive Content",
      "description": "A detailed report about Facebook’s Algorithm Mistook an Advertisement of Onions as Sexual Suggestive Content",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-10-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1972",
      "incident_id": 282,
      "title": "Report 1972 on Facebook’s Algorithm Mistook an Advertisement of Onions as Sexual Suggestive Content",
      "description": "A detailed report about Facebook’s Algorithm Mistook an Advertisement of Onions as Sexual Suggestive Content",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-10-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1864",
      "incident_id": 276,
      "title": "Report 1864 on Local South Korean Government’s Use of CCTV Footage Analysis via Facial Recognition to Track COVID Cases Raised Concerns about Privacy, Retention, and Potential Misuse",
      "description": "A detailed report about Local South Korean Government’s Use of CCTV Footage Analysis via Facial Recognition to Track COVID Cases Raised Concerns about Privacy, Retention, and Potential Misuse",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-01-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1900",
      "incident_id": 290,
      "title": "Report 1900 on False Negatives for Water Quality-Associated Beach Closures",
      "description": "A detailed report about False Negatives for Water Quality-Associated Beach Closures",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-06-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2413",
      "incident_id": 290,
      "title": "Report 2413 on False Negatives for Water Quality-Associated Beach Closures",
      "description": "A detailed report about False Negatives for Water Quality-Associated Beach Closures",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-06-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2414",
      "incident_id": 290,
      "title": "Report 2414 on False Negatives for Water Quality-Associated Beach Closures",
      "description": "A detailed report about False Negatives for Water Quality-Associated Beach Closures",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-06-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1918",
      "incident_id": 296,
      "title": "Report 1918 on Twitter Recommender System Amplified Right-Leaning Tweets",
      "description": "A detailed report about Twitter Recommender System Amplified Right-Leaning Tweets",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-02-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1919",
      "incident_id": 296,
      "title": "Report 1919 on Twitter Recommender System Amplified Right-Leaning Tweets",
      "description": "A detailed report about Twitter Recommender System Amplified Right-Leaning Tweets",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-02-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1920",
      "incident_id": 296,
      "title": "Report 1920 on Twitter Recommender System Amplified Right-Leaning Tweets",
      "description": "A detailed report about Twitter Recommender System Amplified Right-Leaning Tweets",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-02-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1967",
      "incident_id": 313,
      "title": "Report 1967 on BlenderBot 3 Cited Dutch Politician as a Terrorist",
      "description": "A detailed report about BlenderBot 3 Cited Dutch Politician as a Terrorist",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-08-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3207",
      "incident_id": 313,
      "title": "Report 3207 on BlenderBot 3 Cited Dutch Politician as a Terrorist",
      "description": "A detailed report about BlenderBot 3 Cited Dutch Politician as a Terrorist",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-08-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2045",
      "incident_id": 333,
      "title": "Report 2045 on Tesla on Autopilot Crashed Parked Michigan Police Car on Interstate",
      "description": "A detailed report about Tesla on Autopilot Crashed Parked Michigan Police Car on Interstate",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-03-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2135",
      "incident_id": 333,
      "title": "Report 2135 on Tesla on Autopilot Crashed Parked Michigan Police Car on Interstate",
      "description": "A detailed report about Tesla on Autopilot Crashed Parked Michigan Police Car on Interstate",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-03-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2136",
      "incident_id": 333,
      "title": "Report 2136 on Tesla on Autopilot Crashed Parked Michigan Police Car on Interstate",
      "description": "A detailed report about Tesla on Autopilot Crashed Parked Michigan Police Car on Interstate",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-03-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1941",
      "incident_id": 304,
      "title": "Report 1941 on Tesla on FSD Reportedly Drove into the Wrong Lane in California",
      "description": "A detailed report about Tesla on FSD Reportedly Drove into the Wrong Lane in California",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-11-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2022",
      "incident_id": 331,
      "title": "Report 2022 on Bug in Instagram’s “Related Hashtags” Algorithm Allegedly Caused Disproportionate Treatment of Political Hashtags",
      "description": "A detailed report about Bug in Instagram’s “Related Hashtags” Algorithm Allegedly Caused Disproportionate Treatment of Political Hashtags",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-08-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2023",
      "incident_id": 331,
      "title": "Report 2023 on Bug in Instagram’s “Related Hashtags” Algorithm Allegedly Caused Disproportionate Treatment of Political Hashtags",
      "description": "A detailed report about Bug in Instagram’s “Related Hashtags” Algorithm Allegedly Caused Disproportionate Treatment of Political Hashtags",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-08-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2049",
      "incident_id": 337,
      "title": "Report 2049 on Tesla Model S on ACC Crashed into Tree in Texas, Killing Two People",
      "description": "A detailed report about Tesla Model S on ACC Crashed into Tree in Texas, Killing Two People",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-04-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2071",
      "incident_id": 337,
      "title": "Report 2071 on Tesla Model S on ACC Crashed into Tree in Texas, Killing Two People",
      "description": "A detailed report about Tesla Model S on ACC Crashed into Tree in Texas, Killing Two People",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-04-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2072",
      "incident_id": 337,
      "title": "Report 2072 on Tesla Model S on ACC Crashed into Tree in Texas, Killing Two People",
      "description": "A detailed report about Tesla Model S on ACC Crashed into Tree in Texas, Killing Two People",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-04-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2059",
      "incident_id": 346,
      "title": "Report 2059 on Robots in Japanese Hotel Annoyed Guests and Failed to Handle Simple Tasks",
      "description": "A detailed report about Robots in Japanese Hotel Annoyed Guests and Failed to Handle Simple Tasks",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-06-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2062",
      "incident_id": 346,
      "title": "Report 2062 on Robots in Japanese Hotel Annoyed Guests and Failed to Handle Simple Tasks",
      "description": "A detailed report about Robots in Japanese Hotel Annoyed Guests and Failed to Handle Simple Tasks",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-06-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2108",
      "incident_id": 346,
      "title": "Report 2108 on Robots in Japanese Hotel Annoyed Guests and Failed to Handle Simple Tasks",
      "description": "A detailed report about Robots in Japanese Hotel Annoyed Guests and Failed to Handle Simple Tasks",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-06-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1880",
      "incident_id": 283,
      "title": "Report 1880 on Facebook’s Automated Content Moderation Tool Flagged a Post Containing Parts of the Declaration of Independence as Hate Speech by Mistake",
      "description": "A detailed report about Facebook’s Automated Content Moderation Tool Flagged a Post Containing Parts of the Declaration of Independence as Hate Speech by Mistake",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-07-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1889",
      "incident_id": 286,
      "title": "Report 1889 on TikTok’s For You Allegedly Pushed Fatal “Blackout” Challenge Videos to Two Young Girls",
      "description": "A detailed report about TikTok’s For You Allegedly Pushed Fatal “Blackout” Challenge Videos to Two Young Girls",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-02-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2052",
      "incident_id": 286,
      "title": "Report 2052 on TikTok’s For You Allegedly Pushed Fatal “Blackout” Challenge Videos to Two Young Girls",
      "description": "A detailed report about TikTok’s For You Allegedly Pushed Fatal “Blackout” Challenge Videos to Two Young Girls",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-02-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2381",
      "incident_id": 286,
      "title": "Report 2381 on TikTok’s For You Allegedly Pushed Fatal “Blackout” Challenge Videos to Two Young Girls",
      "description": "A detailed report about TikTok’s For You Allegedly Pushed Fatal “Blackout” Challenge Videos to Two Young Girls",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-02-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1947",
      "incident_id": 307,
      "title": "Report 1947 on iPhone Face ID Failed to Recognize Users’ Morning Faces",
      "description": "A detailed report about iPhone Face ID Failed to Recognize Users’ Morning Faces",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-11-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1954",
      "incident_id": 309,
      "title": "Report 1954 on Facial Recognition Trial Performed Poorly at Notting Hill Carnival",
      "description": "A detailed report about Facial Recognition Trial Performed Poorly at Notting Hill Carnival",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-08-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1956",
      "incident_id": 309,
      "title": "Report 1956 on Facial Recognition Trial Performed Poorly at Notting Hill Carnival",
      "description": "A detailed report about Facial Recognition Trial Performed Poorly at Notting Hill Carnival",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-08-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1960",
      "incident_id": 309,
      "title": "Report 1960 on Facial Recognition Trial Performed Poorly at Notting Hill Carnival",
      "description": "A detailed report about Facial Recognition Trial Performed Poorly at Notting Hill Carnival",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-08-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2011",
      "incident_id": 327,
      "title": "Report 2011 on Facebook’s On-This-Day Feature Mistakenly Showed Painful Memories to Users",
      "description": "A detailed report about Facebook’s On-This-Day Feature Mistakenly Showed Painful Memories to Users",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-03-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2057",
      "incident_id": 344,
      "title": "Report 2057 on Hiring Algorithms Provided Invalid Positive Results for Interview Responses in German",
      "description": "A detailed report about Hiring Algorithms Provided Invalid Positive Results for Interview Responses in German",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-07-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2064",
      "incident_id": 348,
      "title": "Report 2064 on YouTube Recommendation Reportedly Pushed Election Fraud Content to Skeptics Disproportionately",
      "description": "A detailed report about YouTube Recommendation Reportedly Pushed Election Fraud Content to Skeptics Disproportionately",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-11-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2075",
      "incident_id": 348,
      "title": "Report 2075 on YouTube Recommendation Reportedly Pushed Election Fraud Content to Skeptics Disproportionately",
      "description": "A detailed report about YouTube Recommendation Reportedly Pushed Election Fraud Content to Skeptics Disproportionately",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-11-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2096",
      "incident_id": 348,
      "title": "Report 2096 on YouTube Recommendation Reportedly Pushed Election Fraud Content to Skeptics Disproportionately",
      "description": "A detailed report about YouTube Recommendation Reportedly Pushed Election Fraud Content to Skeptics Disproportionately",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-11-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2065",
      "incident_id": 349,
      "title": "Report 2065 on Evolv's Gun Detection False Positives Created Problems for Schools",
      "description": "A detailed report about Evolv's Gun Detection False Positives Created Problems for Schools",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-03-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2095",
      "incident_id": 349,
      "title": "Report 2095 on Evolv's Gun Detection False Positives Created Problems for Schools",
      "description": "A detailed report about Evolv's Gun Detection False Positives Created Problems for Schools",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-03-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1865",
      "incident_id": 277,
      "title": "Report 1865 on Voices Created Using Publicly Available App Stolen and Resold as NFT without Attribution",
      "description": "A detailed report about Voices Created Using Publicly Available App Stolen and Resold as NFT without Attribution",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-01-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1961",
      "incident_id": 311,
      "title": "Report 1961 on YouTube Auto-Moderation Mistakenly Banned Women of Sex Tech Conference",
      "description": "A detailed report about YouTube Auto-Moderation Mistakenly Banned Women of Sex Tech Conference",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-05-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1962",
      "incident_id": 311,
      "title": "Report 1962 on YouTube Auto-Moderation Mistakenly Banned Women of Sex Tech Conference",
      "description": "A detailed report about YouTube Auto-Moderation Mistakenly Banned Women of Sex Tech Conference",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-05-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1976",
      "incident_id": 317,
      "title": "Report 1976 on Bug in Facebook’s Anti-Spam Filter Allegedly Blocked Legitimate Posts about COVID-19",
      "description": "A detailed report about Bug in Facebook’s Anti-Spam Filter Allegedly Blocked Legitimate Posts about COVID-19",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-03-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1998",
      "incident_id": 324,
      "title": "Report 1998 on GAN Faces Deployed by The BL's Fake Account Network to Push Pro-Trump Content on Meta Platforms",
      "description": "A detailed report about GAN Faces Deployed by The BL's Fake Account Network to Push Pro-Trump Content on Meta Platforms",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-11-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1999",
      "incident_id": 324,
      "title": "Report 1999 on GAN Faces Deployed by The BL's Fake Account Network to Push Pro-Trump Content on Meta Platforms",
      "description": "A detailed report about GAN Faces Deployed by The BL's Fake Account Network to Push Pro-Trump Content on Meta Platforms",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-11-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2000",
      "incident_id": 324,
      "title": "Report 2000 on GAN Faces Deployed by The BL's Fake Account Network to Push Pro-Trump Content on Meta Platforms",
      "description": "A detailed report about GAN Faces Deployed by The BL's Fake Account Network to Push Pro-Trump Content on Meta Platforms",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-11-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1940",
      "incident_id": 303,
      "title": "Report 1940 on Google’s Automated Child Abuse Detection Wrongfully Flagged a Parent’s Naked Photo of His Child",
      "description": "A detailed report about Google’s Automated Child Abuse Detection Wrongfully Flagged a Parent’s Naked Photo of His Child",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-08-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1944",
      "incident_id": 303,
      "title": "Report 1944 on Google’s Automated Child Abuse Detection Wrongfully Flagged a Parent’s Naked Photo of His Child",
      "description": "A detailed report about Google’s Automated Child Abuse Detection Wrongfully Flagged a Parent’s Naked Photo of His Child",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-08-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2051",
      "incident_id": 339,
      "title": "Report 2051 on Open-Source Generative Models Abused by Students to Cheat on Assignments and Exams",
      "description": "A detailed report about Open-Source Generative Models Abused by Students to Cheat on Assignments and Exams",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-09-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2063",
      "incident_id": 339,
      "title": "Report 2063 on Open-Source Generative Models Abused by Students to Cheat on Assignments and Exams",
      "description": "A detailed report about Open-Source Generative Models Abused by Students to Cheat on Assignments and Exams",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-09-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2491",
      "incident_id": 339,
      "title": "Report 2491 on Open-Source Generative Models Abused by Students to Cheat on Assignments and Exams",
      "description": "A detailed report about Open-Source Generative Models Abused by Students to Cheat on Assignments and Exams",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-09-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2056",
      "incident_id": 343,
      "title": "Report 2056 on Facebook, Instagram, and Twitter Failed to Proactively Remove Targeted Racist Remarks via Automated Systems",
      "description": "A detailed report about Facebook, Instagram, and Twitter Failed to Proactively Remove Targeted Racist Remarks via Automated Systems",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-07-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2113",
      "incident_id": 343,
      "title": "Report 2113 on Facebook, Instagram, and Twitter Failed to Proactively Remove Targeted Racist Remarks via Automated Systems",
      "description": "A detailed report about Facebook, Instagram, and Twitter Failed to Proactively Remove Targeted Racist Remarks via Automated Systems",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-07-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1939",
      "incident_id": 302,
      "title": "Report 1939 on Students Allegedly Wrongfully Accused of Cheating via Medical School's Internal Software",
      "description": "A detailed report about Students Allegedly Wrongfully Accused of Cheating via Medical School's Internal Software",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-03-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1952",
      "incident_id": 308,
      "title": "Report 1952 on Atlas Robot Fell off Stage at Conference",
      "description": "A detailed report about Atlas Robot Fell off Stage at Conference",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-07-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1953",
      "incident_id": 308,
      "title": "Report 1953 on Atlas Robot Fell off Stage at Conference",
      "description": "A detailed report about Atlas Robot Fell off Stage at Conference",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-07-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1955",
      "incident_id": 310,
      "title": "Report 1955 on High False Positive Rate by SWP's Facial Recognition Use at Champion's League Final",
      "description": "A detailed report about High False Positive Rate by SWP's Facial Recognition Use at Champion's League Final",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-06-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1957",
      "incident_id": 310,
      "title": "Report 1957 on High False Positive Rate by SWP's Facial Recognition Use at Champion's League Final",
      "description": "A detailed report about High False Positive Rate by SWP's Facial Recognition Use at Champion's League Final",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-06-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1958",
      "incident_id": 310,
      "title": "Report 1958 on High False Positive Rate by SWP's Facial Recognition Use at Champion's League Final",
      "description": "A detailed report about High False Positive Rate by SWP's Facial Recognition Use at Champion's League Final",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-06-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1970",
      "incident_id": 315,
      "title": "Report 1970 on Facial Recognition Service Abused to Target Russian Porn Actresses",
      "description": "A detailed report about Facial Recognition Service Abused to Target Russian Porn Actresses",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-04-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-188",
      "incident_id": 321,
      "title": "Report 188 on Tesla Model X on Autopilot Crashed into California Highway Barrier, Killing Driver",
      "description": "A detailed report about Tesla Model X on Autopilot Crashed into California Highway Barrier, Killing Driver",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-03-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-190",
      "incident_id": 321,
      "title": "Report 190 on Tesla Model X on Autopilot Crashed into California Highway Barrier, Killing Driver",
      "description": "A detailed report about Tesla Model X on Autopilot Crashed into California Highway Barrier, Killing Driver",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-03-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-194",
      "incident_id": 321,
      "title": "Report 194 on Tesla Model X on Autopilot Crashed into California Highway Barrier, Killing Driver",
      "description": "A detailed report about Tesla Model X on Autopilot Crashed into California Highway Barrier, Killing Driver",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-03-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2015",
      "incident_id": 329,
      "title": "Report 2015 on Amazon Recommended Explosive-Producing Ingredients as “Frequently Bought Together” Items for Chemicals",
      "description": "A detailed report about Amazon Recommended Explosive-Producing Ingredients as “Frequently Bought Together” Items for Chemicals",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-09-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1882",
      "incident_id": 284,
      "title": "Report 1882 on Facebook’s Automated Removal of Content Featuring Nudity-Containing Artworks Denounced as Censorship",
      "description": "A detailed report about Facebook’s Automated Removal of Content Featuring Nudity-Containing Artworks Denounced as Censorship",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-05-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1883",
      "incident_id": 284,
      "title": "Report 1883 on Facebook’s Automated Removal of Content Featuring Nudity-Containing Artworks Denounced as Censorship",
      "description": "A detailed report about Facebook’s Automated Removal of Content Featuring Nudity-Containing Artworks Denounced as Censorship",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-05-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1884",
      "incident_id": 284,
      "title": "Report 1884 on Facebook’s Automated Removal of Content Featuring Nudity-Containing Artworks Denounced as Censorship",
      "description": "A detailed report about Facebook’s Automated Removal of Content Featuring Nudity-Containing Artworks Denounced as Censorship",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-05-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2471",
      "incident_id": 298,
      "title": "Report 2471 on Student-Developed Facial Recognition App Raised Ethical Concerns",
      "description": "A detailed report about Student-Developed Facial Recognition App Raised Ethical Concerns",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-10-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1869",
      "incident_id": 279,
      "title": "Report 1869 on TikTok’s “For You” Algorithm Exposed Young Users to Pro-Eating Disorder Content",
      "description": "A detailed report about TikTok’s “For You” Algorithm Exposed Young Users to Pro-Eating Disorder Content",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-07-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1870",
      "incident_id": 279,
      "title": "Report 1870 on TikTok’s “For You” Algorithm Exposed Young Users to Pro-Eating Disorder Content",
      "description": "A detailed report about TikTok’s “For You” Algorithm Exposed Young Users to Pro-Eating Disorder Content",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-07-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2381",
      "incident_id": 279,
      "title": "Report 2381 on TikTok’s “For You” Algorithm Exposed Young Users to Pro-Eating Disorder Content",
      "description": "A detailed report about TikTok’s “For You” Algorithm Exposed Young Users to Pro-Eating Disorder Content",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-07-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1875",
      "incident_id": 281,
      "title": "Report 1875 on YouTube's Algorithms Failed to Remove Violating Content Related to Suicide and Self-Harm",
      "description": "A detailed report about YouTube's Algorithms Failed to Remove Violating Content Related to Suicide and Self-Harm",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-02-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1876",
      "incident_id": 281,
      "title": "Report 1876 on YouTube's Algorithms Failed to Remove Violating Content Related to Suicide and Self-Harm",
      "description": "A detailed report about YouTube's Algorithms Failed to Remove Violating Content Related to Suicide and Self-Harm",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-02-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1877",
      "incident_id": 281,
      "title": "Report 1877 on YouTube's Algorithms Failed to Remove Violating Content Related to Suicide and Self-Harm",
      "description": "A detailed report about YouTube's Algorithms Failed to Remove Violating Content Related to Suicide and Self-Harm",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-02-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1963",
      "incident_id": 312,
      "title": "Report 1963 on Startup's Accent Translation AI Denounced as Reinforcing Racial Bias",
      "description": "A detailed report about Startup's Accent Translation AI Denounced as Reinforcing Racial Bias",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-08-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1964",
      "incident_id": 312,
      "title": "Report 1964 on Startup's Accent Translation AI Denounced as Reinforcing Racial Bias",
      "description": "A detailed report about Startup's Accent Translation AI Denounced as Reinforcing Racial Bias",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-08-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1965",
      "incident_id": 312,
      "title": "Report 1965 on Startup's Accent Translation AI Denounced as Reinforcing Racial Bias",
      "description": "A detailed report about Startup's Accent Translation AI Denounced as Reinforcing Racial Bias",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-08-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1971",
      "incident_id": 316,
      "title": "Report 1971 on Facebook Ad-Approval Algorithm Allegedly Missed Fraudulent Ads via Simple URL Checks",
      "description": "A detailed report about Facebook Ad-Approval Algorithm Allegedly Missed Fraudulent Ads via Simple URL Checks",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-06-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1895",
      "incident_id": 288,
      "title": "Report 1895 on New Jersey Police Wrongful Arrested Innocent Black Man via FRT",
      "description": "A detailed report about New Jersey Police Wrongful Arrested Innocent Black Man via FRT",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-01-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1896",
      "incident_id": 288,
      "title": "Report 1896 on New Jersey Police Wrongful Arrested Innocent Black Man via FRT",
      "description": "A detailed report about New Jersey Police Wrongful Arrested Innocent Black Man via FRT",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-01-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2025",
      "incident_id": 288,
      "title": "Report 2025 on New Jersey Police Wrongful Arrested Innocent Black Man via FRT",
      "description": "A detailed report about New Jersey Police Wrongful Arrested Innocent Black Man via FRT",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-01-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1897",
      "incident_id": 289,
      "title": "Report 1897 on Starship Delivery Robot Scuffed Bumper of a Resident’s Car in Texas, Allegedly Refusing to Release Footage of the Accident",
      "description": "A detailed report about Starship Delivery Robot Scuffed Bumper of a Resident’s Car in Texas, Allegedly Refusing to Release Footage of the Accident",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-06-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1898",
      "incident_id": 289,
      "title": "Report 1898 on Starship Delivery Robot Scuffed Bumper of a Resident’s Car in Texas, Allegedly Refusing to Release Footage of the Accident",
      "description": "A detailed report about Starship Delivery Robot Scuffed Bumper of a Resident’s Car in Texas, Allegedly Refusing to Release Footage of the Accident",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-06-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1946",
      "incident_id": 306,
      "title": "Report 1946 on Tesla on Autopilot TACC Crashed into Van on European Highway",
      "description": "A detailed report about Tesla on Autopilot TACC Crashed into Van on European Highway",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-05-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1948",
      "incident_id": 306,
      "title": "Report 1948 on Tesla on Autopilot TACC Crashed into Van on European Highway",
      "description": "A detailed report about Tesla on Autopilot TACC Crashed into Van on European Highway",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-05-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1949",
      "incident_id": 306,
      "title": "Report 1949 on Tesla on Autopilot TACC Crashed into Van on European Highway",
      "description": "A detailed report about Tesla on Autopilot TACC Crashed into Van on European Highway",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-05-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2058",
      "incident_id": 345,
      "title": "Report 2058 on Auto-Insurance Photo-Based Estimation Allegedly Gave Inaccurate Repair Prices Frequently",
      "description": "A detailed report about Auto-Insurance Photo-Based Estimation Allegedly Gave Inaccurate Repair Prices Frequently",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-04-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1938",
      "incident_id": 301,
      "title": "Report 1938 on Teenager at Broward College Allegedly Wrongfully Accused of Cheating via Remote Proctoring",
      "description": "A detailed report about Teenager at Broward College Allegedly Wrongfully Accused of Cheating via Remote Proctoring",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-02-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1968",
      "incident_id": 314,
      "title": "Report 1968 on Stable Diffusion Abused by 4chan Users to Deepfake Celebrity Porn",
      "description": "A detailed report about Stable Diffusion Abused by 4chan Users to Deepfake Celebrity Porn",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-08-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1991",
      "incident_id": 322,
      "title": "Report 1991 on Tesla Model 3 Crashed into Police Patrol Car on Connecticut Highway",
      "description": "A detailed report about Tesla Model 3 Crashed into Police Patrol Car on Connecticut Highway",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-12-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1994",
      "incident_id": 322,
      "title": "Report 1994 on Tesla Model 3 Crashed into Police Patrol Car on Connecticut Highway",
      "description": "A detailed report about Tesla Model 3 Crashed into Police Patrol Car on Connecticut Highway",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-12-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2048",
      "incident_id": 336,
      "title": "Report 2048 on UK Home Office's Sham Marriage Detection Algorithm Reportedly Flagged Certain Nationalities Disproportionately",
      "description": "A detailed report about UK Home Office's Sham Marriage Detection Algorithm Reportedly Flagged Certain Nationalities Disproportionately",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-03-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2119",
      "incident_id": 336,
      "title": "Report 2119 on UK Home Office's Sham Marriage Detection Algorithm Reportedly Flagged Certain Nationalities Disproportionately",
      "description": "A detailed report about UK Home Office's Sham Marriage Detection Algorithm Reportedly Flagged Certain Nationalities Disproportionately",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-03-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2120",
      "incident_id": 336,
      "title": "Report 2120 on UK Home Office's Sham Marriage Detection Algorithm Reportedly Flagged Certain Nationalities Disproportionately",
      "description": "A detailed report about UK Home Office's Sham Marriage Detection Algorithm Reportedly Flagged Certain Nationalities Disproportionately",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-03-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2068",
      "incident_id": 351,
      "title": "Report 2068 on The Little Mermaid Clip Doctored Using Generative AI to Replace Black Actress with White Character",
      "description": "A detailed report about The Little Mermaid Clip Doctored Using Generative AI to Replace Black Actress with White Character",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-09-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2131",
      "incident_id": 364,
      "title": "Report 2131 on Walmart's Bagging-Detection False Positives Exposed Workers to Health Risk",
      "description": "A detailed report about Walmart's Bagging-Detection False Positives Exposed Workers to Health Risk",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-04-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2150",
      "incident_id": 367,
      "title": "Report 2150 on iGPT, SimCLR Learned Biased Associations from Internet Training Data",
      "description": "A detailed report about iGPT, SimCLR Learned Biased Associations from Internet Training Data",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-06-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2081",
      "incident_id": 355,
      "title": "Report 2081 on Uber Allegedly Wrongfully Accused Drivers of Fraud via Automated Systems",
      "description": "A detailed report about Uber Allegedly Wrongfully Accused Drivers of Fraud via Automated Systems",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-07-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2082",
      "incident_id": 355,
      "title": "Report 2082 on Uber Allegedly Wrongfully Accused Drivers of Fraud via Automated Systems",
      "description": "A detailed report about Uber Allegedly Wrongfully Accused Drivers of Fraud via Automated Systems",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-07-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2083",
      "incident_id": 355,
      "title": "Report 2083 on Uber Allegedly Wrongfully Accused Drivers of Fraud via Automated Systems",
      "description": "A detailed report about Uber Allegedly Wrongfully Accused Drivers of Fraud via Automated Systems",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-07-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2084",
      "incident_id": 356,
      "title": "Report 2084 on Philosophy AI Tentatively Produced Offensive Results for Certain Prompts",
      "description": "A detailed report about Philosophy AI Tentatively Produced Offensive Results for Certain Prompts",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-09-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2085",
      "incident_id": 356,
      "title": "Report 2085 on Philosophy AI Tentatively Produced Offensive Results for Certain Prompts",
      "description": "A detailed report about Philosophy AI Tentatively Produced Offensive Results for Certain Prompts",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-09-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2151",
      "incident_id": 368,
      "title": "Report 2151 on Facial Recognition Smart Phone App Blue Wolf Monitored Palestinians in West Bank",
      "description": "A detailed report about Facial Recognition Smart Phone App Blue Wolf Monitored Palestinians in West Bank",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-06-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2152",
      "incident_id": 368,
      "title": "Report 2152 on Facial Recognition Smart Phone App Blue Wolf Monitored Palestinians in West Bank",
      "description": "A detailed report about Facial Recognition Smart Phone App Blue Wolf Monitored Palestinians in West Bank",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-06-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2153",
      "incident_id": 368,
      "title": "Report 2153 on Facial Recognition Smart Phone App Blue Wolf Monitored Palestinians in West Bank",
      "description": "A detailed report about Facial Recognition Smart Phone App Blue Wolf Monitored Palestinians in West Bank",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-06-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2163",
      "incident_id": 370,
      "title": "Report 2163 on Google Fined for Changing Shopping Algorithms in EU to Favor Own Service",
      "description": "A detailed report about Google Fined for Changing Shopping Algorithms in EU to Favor Own Service",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-09-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2175",
      "incident_id": 378,
      "title": "Report 2175 on TuSimple Truck Steered into Interstate Freeway Divide",
      "description": "A detailed report about TuSimple Truck Steered into Interstate Freeway Divide",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-04-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2176",
      "incident_id": 378,
      "title": "Report 2176 on TuSimple Truck Steered into Interstate Freeway Divide",
      "description": "A detailed report about TuSimple Truck Steered into Interstate Freeway Divide",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-04-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2244",
      "incident_id": 391,
      "title": "Report 2244 on Facial Recognition Trial by UK Southern Co-op Alleged as Unlawful",
      "description": "A detailed report about Facial Recognition Trial by UK Southern Co-op Alleged as Unlawful",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-07-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2246",
      "incident_id": 391,
      "title": "Report 2246 on Facial Recognition Trial by UK Southern Co-op Alleged as Unlawful",
      "description": "A detailed report about Facial Recognition Trial by UK Southern Co-op Alleged as Unlawful",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-07-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2167",
      "incident_id": 371,
      "title": "Report 2167 on Uganda Deployed Huawei's Facial Recognition to Monitor Political Opposition and Protests",
      "description": "A detailed report about Uganda Deployed Huawei's Facial Recognition to Monitor Political Opposition and Protests",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-11-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2184",
      "incident_id": 371,
      "title": "Report 2184 on Uganda Deployed Huawei's Facial Recognition to Monitor Political Opposition and Protests",
      "description": "A detailed report about Uganda Deployed Huawei's Facial Recognition to Monitor Political Opposition and Protests",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-11-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2203",
      "incident_id": 371,
      "title": "Report 2203 on Uganda Deployed Huawei's Facial Recognition to Monitor Political Opposition and Protests",
      "description": "A detailed report about Uganda Deployed Huawei's Facial Recognition to Monitor Political Opposition and Protests",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-11-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2247",
      "incident_id": 393,
      "title": "Report 2247 on Facebook AI-Supported Moderation for Ads Failed to Detect Violating Content",
      "description": "A detailed report about Facebook AI-Supported Moderation for Ads Failed to Detect Violating Content",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-12-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2089",
      "incident_id": 358,
      "title": "Report 2089 on Calgary Malls Deployed Facial Recognition without Customer Consent",
      "description": "A detailed report about Calgary Malls Deployed Facial Recognition without Customer Consent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-06-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2130",
      "incident_id": 363,
      "title": "Report 2130 on Facebook's Automated Moderation Mistakenly Flagged Landmark's Name as Offensive",
      "description": "A detailed report about Facebook's Automated Moderation Mistakenly Flagged Landmark's Name as Offensive",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-01-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2162",
      "incident_id": 369,
      "title": "Report 2162 on GAN Artwork Won First Place at State Fair Competition",
      "description": "A detailed report about GAN Artwork Won First Place at State Fair Competition",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-08-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2273",
      "incident_id": 400,
      "title": "Report 2273 on Google Search Returned Fewer Results for Abortion Services in Rural Areas",
      "description": "A detailed report about Google Search Returned Fewer Results for Abortion Services in Rural Areas",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-02-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2169",
      "incident_id": 373,
      "title": "Report 2169 on Michigan's Unemployment Benefits Algorithm MiDAS Issued False Fraud Claims to Thousands of People",
      "description": "A detailed report about Michigan's Unemployment Benefits Algorithm MiDAS Issued False Fraud Claims to Thousands of People",
      "url": "https://incidentdatabase.ai",
      "date_published": "2013-10-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2187",
      "incident_id": 373,
      "title": "Report 2187 on Michigan's Unemployment Benefits Algorithm MiDAS Issued False Fraud Claims to Thousands of People",
      "description": "A detailed report about Michigan's Unemployment Benefits Algorithm MiDAS Issued False Fraud Claims to Thousands of People",
      "url": "https://incidentdatabase.ai",
      "date_published": "2013-10-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2188",
      "incident_id": 373,
      "title": "Report 2188 on Michigan's Unemployment Benefits Algorithm MiDAS Issued False Fraud Claims to Thousands of People",
      "description": "A detailed report about Michigan's Unemployment Benefits Algorithm MiDAS Issued False Fraud Claims to Thousands of People",
      "url": "https://incidentdatabase.ai",
      "date_published": "2013-10-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2172",
      "incident_id": 376,
      "title": "Report 2172 on RealPage Algorithm Allegedly Inflates Rents and Reduces Competition in Housing Market",
      "description": "A detailed report about RealPage Algorithm Allegedly Inflates Rents and Reduces Competition in Housing Market",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-09-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2185",
      "incident_id": 376,
      "title": "Report 2185 on RealPage Algorithm Allegedly Inflates Rents and Reduces Competition in Housing Market",
      "description": "A detailed report about RealPage Algorithm Allegedly Inflates Rents and Reduces Competition in Housing Market",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-09-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2186",
      "incident_id": 376,
      "title": "Report 2186 on RealPage Algorithm Allegedly Inflates Rents and Reduces Competition in Housing Market",
      "description": "A detailed report about RealPage Algorithm Allegedly Inflates Rents and Reduces Competition in Housing Market",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-09-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2254",
      "incident_id": 395,
      "title": "Report 2254 on Amazon Forced Deployment of AI-Powered Cameras on Delivery Drivers",
      "description": "A detailed report about Amazon Forced Deployment of AI-Powered Cameras on Delivery Drivers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-03-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2255",
      "incident_id": 395,
      "title": "Report 2255 on Amazon Forced Deployment of AI-Powered Cameras on Delivery Drivers",
      "description": "A detailed report about Amazon Forced Deployment of AI-Powered Cameras on Delivery Drivers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-03-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2256",
      "incident_id": 395,
      "title": "Report 2256 on Amazon Forced Deployment of AI-Powered Cameras on Delivery Drivers",
      "description": "A detailed report about Amazon Forced Deployment of AI-Powered Cameras on Delivery Drivers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-03-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2111",
      "incident_id": 361,
      "title": "Report 2111 on Amazon Echo Mistakenly Recorded and Sent Private Conversation to Random Contact",
      "description": "A detailed report about Amazon Echo Mistakenly Recorded and Sent Private Conversation to Random Contact",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-05-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2174",
      "incident_id": 377,
      "title": "Report 2174 on Weibo Model Had Difficulty Detecting Shifts in Censored Speech",
      "description": "A detailed report about Weibo Model Had Difficulty Detecting Shifts in Censored Speech",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-10-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2078",
      "incident_id": 354,
      "title": "Report 2078 on Uber Allegedly Violated GDPR by Failing to Provide Sufficient Notice on Automated Profiling for Drivers",
      "description": "A detailed report about Uber Allegedly Violated GDPR by Failing to Provide Sufficient Notice on Automated Profiling for Drivers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-06-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2079",
      "incident_id": 354,
      "title": "Report 2079 on Uber Allegedly Violated GDPR by Failing to Provide Sufficient Notice on Automated Profiling for Drivers",
      "description": "A detailed report about Uber Allegedly Violated GDPR by Failing to Provide Sufficient Notice on Automated Profiling for Drivers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-06-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2080",
      "incident_id": 354,
      "title": "Report 2080 on Uber Allegedly Violated GDPR by Failing to Provide Sufficient Notice on Automated Profiling for Drivers",
      "description": "A detailed report about Uber Allegedly Violated GDPR by Failing to Provide Sufficient Notice on Automated Profiling for Drivers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-06-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2217",
      "incident_id": 381,
      "title": "Report 2217 on Autonomous Roborace Car Drove Directly into a Wall",
      "description": "A detailed report about Autonomous Roborace Car Drove Directly into a Wall",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-10-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2073",
      "incident_id": 353,
      "title": "Report 2073 on Tesla on Autopilot Crashed into Trailer Truck in Florida, Killing Driver",
      "description": "A detailed report about Tesla on Autopilot Crashed into Trailer Truck in Florida, Killing Driver",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-03-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2074",
      "incident_id": 353,
      "title": "Report 2074 on Tesla on Autopilot Crashed into Trailer Truck in Florida, Killing Driver",
      "description": "A detailed report about Tesla on Autopilot Crashed into Trailer Truck in Florida, Killing Driver",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-03-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2195",
      "incident_id": 353,
      "title": "Report 2195 on Tesla on Autopilot Crashed into Trailer Truck in Florida, Killing Driver",
      "description": "A detailed report about Tesla on Autopilot Crashed into Trailer Truck in Florida, Killing Driver",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-03-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2170",
      "incident_id": 374,
      "title": "Report 2170 on UK Ofqual's Algorithm Disproportionately Provided Lower Grades Than Teachers' Assessments",
      "description": "A detailed report about UK Ofqual's Algorithm Disproportionately Provided Lower Grades Than Teachers' Assessments",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-08-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2206",
      "incident_id": 374,
      "title": "Report 2206 on UK Ofqual's Algorithm Disproportionately Provided Lower Grades Than Teachers' Assessments",
      "description": "A detailed report about UK Ofqual's Algorithm Disproportionately Provided Lower Grades Than Teachers' Assessments",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-08-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2207",
      "incident_id": 374,
      "title": "Report 2207 on UK Ofqual's Algorithm Disproportionately Provided Lower Grades Than Teachers' Assessments",
      "description": "A detailed report about UK Ofqual's Algorithm Disproportionately Provided Lower Grades Than Teachers' Assessments",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-08-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2181",
      "incident_id": 380,
      "title": "Report 2181 on Facebook's Auto-Generated Targeting Ad Categories Contained Anti-Semitic Options",
      "description": "A detailed report about Facebook's Auto-Generated Targeting Ad Categories Contained Anti-Semitic Options",
      "url": "https://incidentdatabase.ai",
      "date_published": "2014-03-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2182",
      "incident_id": 380,
      "title": "Report 2182 on Facebook's Auto-Generated Targeting Ad Categories Contained Anti-Semitic Options",
      "description": "A detailed report about Facebook's Auto-Generated Targeting Ad Categories Contained Anti-Semitic Options",
      "url": "https://incidentdatabase.ai",
      "date_published": "2014-03-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2258",
      "incident_id": 380,
      "title": "Report 2258 on Facebook's Auto-Generated Targeting Ad Categories Contained Anti-Semitic Options",
      "description": "A detailed report about Facebook's Auto-Generated Targeting Ad Categories Contained Anti-Semitic Options",
      "url": "https://incidentdatabase.ai",
      "date_published": "2014-03-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2086",
      "incident_id": 357,
      "title": "Report 2086 on GPT-2 Able to Recite PII in Training Data",
      "description": "A detailed report about GPT-2 Able to Recite PII in Training Data",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-02-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2087",
      "incident_id": 357,
      "title": "Report 2087 on GPT-2 Able to Recite PII in Training Data",
      "description": "A detailed report about GPT-2 Able to Recite PII in Training Data",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-02-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2088",
      "incident_id": 357,
      "title": "Report 2088 on GPT-2 Able to Recite PII in Training Data",
      "description": "A detailed report about GPT-2 Able to Recite PII in Training Data",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-02-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2224",
      "incident_id": 385,
      "title": "Report 2224 on Canadian Police's Release of Suspect's AI-Generated Facial Photo Reportedly Reinforced Racial Profiling",
      "description": "A detailed report about Canadian Police's Release of Suspect's AI-Generated Facial Photo Reportedly Reinforced Racial Profiling",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-10-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2225",
      "incident_id": 385,
      "title": "Report 2225 on Canadian Police's Release of Suspect's AI-Generated Facial Photo Reportedly Reinforced Racial Profiling",
      "description": "A detailed report about Canadian Police's Release of Suspect's AI-Generated Facial Photo Reportedly Reinforced Racial Profiling",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-10-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2231",
      "incident_id": 385,
      "title": "Report 2231 on Canadian Police's Release of Suspect's AI-Generated Facial Photo Reportedly Reinforced Racial Profiling",
      "description": "A detailed report about Canadian Police's Release of Suspect's AI-Generated Facial Photo Reportedly Reinforced Racial Profiling",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-10-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2235",
      "incident_id": 388,
      "title": "Report 2235 on Facial Recognition Pilot in Bahia Reportedly Targeted Black and Poor People",
      "description": "A detailed report about Facial Recognition Pilot in Bahia Reportedly Targeted Black and Poor People",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-12-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2220",
      "incident_id": 383,
      "title": "Report 2220 on Google Home Mini Speaker Reportedly Read N-Word in Song Title Aloud",
      "description": "A detailed report about Google Home Mini Speaker Reportedly Read N-Word in Song Title Aloud",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-10-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2223",
      "incident_id": 383,
      "title": "Report 2223 on Google Home Mini Speaker Reportedly Read N-Word in Song Title Aloud",
      "description": "A detailed report about Google Home Mini Speaker Reportedly Read N-Word in Song Title Aloud",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-10-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2243",
      "incident_id": 390,
      "title": "Report 2243 on Deepfakes Reportedly Deployed in Online Interviews for Remote Work Positions",
      "description": "A detailed report about Deepfakes Reportedly Deployed in Online Interviews for Remote Work Positions",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-06-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2229",
      "incident_id": 387,
      "title": "Report 2229 on Oracle's Algorithmic Data Processing System Alleged as Unlawful and Violating Privacy Rights",
      "description": "A detailed report about Oracle's Algorithmic Data Processing System Alleged as Unlawful and Violating Privacy Rights",
      "url": "https://incidentdatabase.ai",
      "date_published": "2014-12-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2248",
      "incident_id": 394,
      "title": "Report 2248 on Social Media's Automated Word-Flagging without Context Shifted Content Creators' Language Use",
      "description": "A detailed report about Social Media's Automated Word-Flagging without Context Shifted Content Creators' Language Use",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-03-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2251",
      "incident_id": 394,
      "title": "Report 2251 on Social Media's Automated Word-Flagging without Context Shifted Content Creators' Language Use",
      "description": "A detailed report about Social Media's Automated Word-Flagging without Context Shifted Content Creators' Language Use",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-03-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2129",
      "incident_id": 362,
      "title": "Report 2129 on Facebook's Automated Moderation Flagged Gardening Group's Language Use by Mistake",
      "description": "A detailed report about Facebook's Automated Moderation Flagged Gardening Group's Language Use by Mistake",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-07-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2221",
      "incident_id": 384,
      "title": "Report 2221 on Glovo Driver in Italy Fired via Automated Email after Being Killed in Accident",
      "description": "A detailed report about Glovo Driver in Italy Fired via Automated Email after Being Killed in Accident",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-10-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2222",
      "incident_id": 384,
      "title": "Report 2222 on Glovo Driver in Italy Fired via Automated Email after Being Killed in Accident",
      "description": "A detailed report about Glovo Driver in Italy Fired via Automated Email after Being Killed in Accident",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-10-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2097",
      "incident_id": 359,
      "title": "Report 2097 on Facebook, Instagram, and Twitter Cited Errors in Automated Systems as Cause for Blocking pro-Palestinian Content on Israeli-Palestinian Conflict",
      "description": "A detailed report about Facebook, Instagram, and Twitter Cited Errors in Automated Systems as Cause for Blocking pro-Palestinian Content on Israeli-Palestinian Conflict",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-05-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2263",
      "incident_id": 396,
      "title": "Report 2263 on Transgender Uber Drivers Mistakenly Kicked off App for Appearance Change during Gender Transitions",
      "description": "A detailed report about Transgender Uber Drivers Mistakenly Kicked off App for Appearance Change during Gender Transitions",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-07-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2070",
      "incident_id": 352,
      "title": "Report 2070 on GPT-3-Based Twitter Bot Hijacked Using Prompt Injection Attacks",
      "description": "A detailed report about GPT-3-Based Twitter Bot Hijacked Using Prompt Injection Attacks",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-09-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2076",
      "incident_id": 352,
      "title": "Report 2076 on GPT-3-Based Twitter Bot Hijacked Using Prompt Injection Attacks",
      "description": "A detailed report about GPT-3-Based Twitter Bot Hijacked Using Prompt Injection Attacks",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-09-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2093",
      "incident_id": 352,
      "title": "Report 2093 on GPT-3-Based Twitter Bot Hijacked Using Prompt Injection Attacks",
      "description": "A detailed report about GPT-3-Based Twitter Bot Hijacked Using Prompt Injection Attacks",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-09-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2168",
      "incident_id": 372,
      "title": "Report 2168 on Users Reported Security Issues with Google Pixel 6a's Fingerprint Unlocking",
      "description": "A detailed report about Users Reported Security Issues with Google Pixel 6a's Fingerprint Unlocking",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-07-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2177",
      "incident_id": 372,
      "title": "Report 2177 on Users Reported Security Issues with Google Pixel 6a's Fingerprint Unlocking",
      "description": "A detailed report about Users Reported Security Issues with Google Pixel 6a's Fingerprint Unlocking",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-07-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2178",
      "incident_id": 372,
      "title": "Report 2178 on Users Reported Security Issues with Google Pixel 6a's Fingerprint Unlocking",
      "description": "A detailed report about Users Reported Security Issues with Google Pixel 6a's Fingerprint Unlocking",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-07-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2171",
      "incident_id": 375,
      "title": "Report 2171 on Thai Wallet App's Facial Recognition Errors Created Registration Issues for Government Programs",
      "description": "A detailed report about Thai Wallet App's Facial Recognition Errors Created Registration Issues for Government Programs",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-09-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2192",
      "incident_id": 375,
      "title": "Report 2192 on Thai Wallet App's Facial Recognition Errors Created Registration Issues for Government Programs",
      "description": "A detailed report about Thai Wallet App's Facial Recognition Errors Created Registration Issues for Government Programs",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-09-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2193",
      "incident_id": 375,
      "title": "Report 2193 on Thai Wallet App's Facial Recognition Errors Created Registration Issues for Government Programs",
      "description": "A detailed report about Thai Wallet App's Facial Recognition Errors Created Registration Issues for Government Programs",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-09-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2179",
      "incident_id": 379,
      "title": "Report 2179 on Error in Pepsi's Number Generation System Led to Decades-Long Damages in the Philippines",
      "description": "A detailed report about Error in Pepsi's Number Generation System Led to Decades-Long Damages in the Philippines",
      "url": "https://incidentdatabase.ai",
      "date_published": "1992-05-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2180",
      "incident_id": 379,
      "title": "Report 2180 on Error in Pepsi's Number Generation System Led to Decades-Long Damages in the Philippines",
      "description": "A detailed report about Error in Pepsi's Number Generation System Led to Decades-Long Damages in the Philippines",
      "url": "https://incidentdatabase.ai",
      "date_published": "1992-05-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2219",
      "incident_id": 382,
      "title": "Report 2219 on Instagram's Exposure of Harmful Content Contributed to Teenage Girl’s Suicide",
      "description": "A detailed report about Instagram's Exposure of Harmful Content Contributed to Teenage Girl’s Suicide",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-11-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2227",
      "incident_id": 386,
      "title": "Report 2227 on Amazon’s Time Off Task System Made False Assumptions about Workers' Time Management",
      "description": "A detailed report about Amazon’s Time Off Task System Made False Assumptions about Workers' Time Management",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-07-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2228",
      "incident_id": 386,
      "title": "Report 2228 on Amazon’s Time Off Task System Made False Assumptions about Workers' Time Management",
      "description": "A detailed report about Amazon’s Time Off Task System Made False Assumptions about Workers' Time Management",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-07-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2252",
      "incident_id": 386,
      "title": "Report 2252 on Amazon’s Time Off Task System Made False Assumptions about Workers' Time Management",
      "description": "A detailed report about Amazon’s Time Off Task System Made False Assumptions about Workers' Time Management",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-07-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2239",
      "incident_id": 389,
      "title": "Report 2239 on Cruise Autonomous Car Blocked Fire Truck Responding to Emergency",
      "description": "A detailed report about Cruise Autonomous Car Blocked Fire Truck Responding to Emergency",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-04-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2240",
      "incident_id": 389,
      "title": "Report 2240 on Cruise Autonomous Car Blocked Fire Truck Responding to Emergency",
      "description": "A detailed report about Cruise Autonomous Car Blocked Fire Truck Responding to Emergency",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-04-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2562",
      "incident_id": 389,
      "title": "Report 2562 on Cruise Autonomous Car Blocked Fire Truck Responding to Emergency",
      "description": "A detailed report about Cruise Autonomous Car Blocked Fire Truck Responding to Emergency",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-04-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2264",
      "incident_id": 397,
      "title": "Report 2264 on Misinformation Reported in TikTok's Search Results Despite Moderation by AI and Human",
      "description": "A detailed report about Misinformation Reported in TikTok's Search Results Despite Moderation by AI and Human",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-09-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2268",
      "incident_id": 397,
      "title": "Report 2268 on Misinformation Reported in TikTok's Search Results Despite Moderation by AI and Human",
      "description": "A detailed report about Misinformation Reported in TikTok's Search Results Despite Moderation by AI and Human",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-09-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2265",
      "incident_id": 398,
      "title": "Report 2265 on Tesla Autopilot Misidentified On-Road Horse-Drawn Carriage",
      "description": "A detailed report about Tesla Autopilot Misidentified On-Road Horse-Drawn Carriage",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-08-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2266",
      "incident_id": 398,
      "title": "Report 2266 on Tesla Autopilot Misidentified On-Road Horse-Drawn Carriage",
      "description": "A detailed report about Tesla Autopilot Misidentified On-Road Horse-Drawn Carriage",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-08-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2267",
      "incident_id": 398,
      "title": "Report 2267 on Tesla Autopilot Misidentified On-Road Horse-Drawn Carriage",
      "description": "A detailed report about Tesla Autopilot Misidentified On-Road Horse-Drawn Carriage",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-08-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2270",
      "incident_id": 399,
      "title": "Report 2270 on Meta AI's Scientific Paper Generator Reportedly Produced Inaccurate and Harmful Content",
      "description": "A detailed report about Meta AI's Scientific Paper Generator Reportedly Produced Inaccurate and Harmful Content",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2271",
      "incident_id": 399,
      "title": "Report 2271 on Meta AI's Scientific Paper Generator Reportedly Produced Inaccurate and Harmful Content",
      "description": "A detailed report about Meta AI's Scientific Paper Generator Reportedly Produced Inaccurate and Harmful Content",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2272",
      "incident_id": 399,
      "title": "Report 2272 on Meta AI's Scientific Paper Generator Reportedly Produced Inaccurate and Harmful Content",
      "description": "A detailed report about Meta AI's Scientific Paper Generator Reportedly Produced Inaccurate and Harmful Content",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2275",
      "incident_id": 401,
      "title": "Report 2275 on Kannada Insulted by Google's Featured Answer as Ugliest Language in India",
      "description": "A detailed report about Kannada Insulted by Google's Featured Answer as Ugliest Language in India",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-06-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2278",
      "incident_id": 401,
      "title": "Report 2278 on Kannada Insulted by Google's Featured Answer as Ugliest Language in India",
      "description": "A detailed report about Kannada Insulted by Google's Featured Answer as Ugliest Language in India",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-06-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2279",
      "incident_id": 401,
      "title": "Report 2279 on Kannada Insulted by Google's Featured Answer as Ugliest Language in India",
      "description": "A detailed report about Kannada Insulted by Google's Featured Answer as Ugliest Language in India",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-06-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2276",
      "incident_id": 402,
      "title": "Report 2276 on Players Manipulated GPT-3-Powered Game to Generate Sexually Explicit Material Involving Children",
      "description": "A detailed report about Players Manipulated GPT-3-Powered Game to Generate Sexually Explicit Material Involving Children",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-04-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2100",
      "incident_id": 360,
      "title": "Report 2100 on McDonald's AI Drive-Thru Allegedly Collected Biometric Customer Data without Consent, Violating BIPA",
      "description": "A detailed report about McDonald's AI Drive-Thru Allegedly Collected Biometric Customer Data without Consent, Violating BIPA",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-10-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2149",
      "incident_id": 360,
      "title": "Report 2149 on McDonald's AI Drive-Thru Allegedly Collected Biometric Customer Data without Consent, Violating BIPA",
      "description": "A detailed report about McDonald's AI Drive-Thru Allegedly Collected Biometric Customer Data without Consent, Violating BIPA",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-10-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2218",
      "incident_id": 360,
      "title": "Report 2218 on McDonald's AI Drive-Thru Allegedly Collected Biometric Customer Data without Consent, Violating BIPA",
      "description": "A detailed report about McDonald's AI Drive-Thru Allegedly Collected Biometric Customer Data without Consent, Violating BIPA",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-10-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2140",
      "incident_id": 366,
      "title": "Report 2140 on Suicide Clips Evaded TikTok's Automated Moderation in Coordinated Attack",
      "description": "A detailed report about Suicide Clips Evaded TikTok's Automated Moderation in Coordinated Attack",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-09-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2245",
      "incident_id": 392,
      "title": "Report 2245 on Facebook's AI-Supported Moderation Failed to Classify Terrorist Content in East African Languages",
      "description": "A detailed report about Facebook's AI-Supported Moderation Failed to Classify Terrorist Content in East African Languages",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-06-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2249",
      "incident_id": 392,
      "title": "Report 2249 on Facebook's AI-Supported Moderation Failed to Classify Terrorist Content in East African Languages",
      "description": "A detailed report about Facebook's AI-Supported Moderation Failed to Classify Terrorist Content in East African Languages",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-06-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2289",
      "incident_id": 407,
      "title": "Report 2289 on Uber's Surge Pricing Reportedly Offered Disproportionate Service Quality along Racial Lines",
      "description": "A detailed report about Uber's Surge Pricing Reportedly Offered Disproportionate Service Quality along Racial Lines",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-02-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2284",
      "incident_id": 404,
      "title": "Report 2284 on Sound Intelligence's Aggression Detector Misidentified Innocuous Sounds",
      "description": "A detailed report about Sound Intelligence's Aggression Detector Misidentified Innocuous Sounds",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-06-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2286",
      "incident_id": 404,
      "title": "Report 2286 on Sound Intelligence's Aggression Detector Misidentified Innocuous Sounds",
      "description": "A detailed report about Sound Intelligence's Aggression Detector Misidentified Innocuous Sounds",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-06-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2288",
      "incident_id": 406,
      "title": "Report 2288 on Facebook's Friend Suggestion Feature Recommends Patients of Psychiatrist to Each Other",
      "description": "A detailed report about Facebook's Friend Suggestion Feature Recommends Patients of Psychiatrist to Each Other",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-07-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2290",
      "incident_id": 408,
      "title": "Report 2290 on Facebook Reportedly Outed Sex Workers through Friend Recommendations",
      "description": "A detailed report about Facebook Reportedly Outed Sex Workers through Friend Recommendations",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-04-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2309",
      "incident_id": 409,
      "title": "Report 2309 on Facial Recognition Researchers Used YouTube Videos of Transgender People without Consent",
      "description": "A detailed report about Facial Recognition Researchers Used YouTube Videos of Transgender People without Consent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2013-09-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2411",
      "incident_id": 409,
      "title": "Report 2411 on Facial Recognition Researchers Used YouTube Videos of Transgender People without Consent",
      "description": "A detailed report about Facial Recognition Researchers Used YouTube Videos of Transgender People without Consent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2013-09-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2412",
      "incident_id": 409,
      "title": "Report 2412 on Facial Recognition Researchers Used YouTube Videos of Transgender People without Consent",
      "description": "A detailed report about Facial Recognition Researchers Used YouTube Videos of Transgender People without Consent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2013-09-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2285",
      "incident_id": 405,
      "title": "Report 2285 on Schufa Credit Scoring in Germany Reported for Unreliable and Imbalanced Scores",
      "description": "A detailed report about Schufa Credit Scoring in Germany Reported for Unreliable and Imbalanced Scores",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-11-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2287",
      "incident_id": 405,
      "title": "Report 2287 on Schufa Credit Scoring in Germany Reported for Unreliable and Imbalanced Scores",
      "description": "A detailed report about Schufa Credit Scoring in Germany Reported for Unreliable and Imbalanced Scores",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-11-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2282",
      "incident_id": 403,
      "title": "Report 2282 on GMail's Inbox Sorting Reportedly Negatively Impacted Political Emails and Call-to-Actions",
      "description": "A detailed report about GMail's Inbox Sorting Reportedly Negatively Impacted Political Emails and Call-to-Actions",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-01-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2283",
      "incident_id": 403,
      "title": "Report 2283 on GMail's Inbox Sorting Reportedly Negatively Impacted Political Emails and Call-to-Actions",
      "description": "A detailed report about GMail's Inbox Sorting Reportedly Negatively Impacted Political Emails and Call-to-Actions",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-01-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2312",
      "incident_id": 410,
      "title": "Report 2312 on KFC Sent Insensitive Kristallnacht Promotion via Holiday Detection System",
      "description": "A detailed report about KFC Sent Insensitive Kristallnacht Promotion via Holiday Detection System",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2314",
      "incident_id": 411,
      "title": "Report 2314 on Chinese Accounts Spammed Twitter Feed Allegedly to Obscure News of Protests",
      "description": "A detailed report about Chinese Accounts Spammed Twitter Feed Allegedly to Obscure News of Protests",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2315",
      "incident_id": 412,
      "title": "Report 2315 on Finland Police's Facial Recognition Trial to Identify Sexual Abuse Victims Deemed Illegal",
      "description": "A detailed report about Finland Police's Facial Recognition Trial to Identify Sexual Abuse Victims Deemed Illegal",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-01-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2408",
      "incident_id": 412,
      "title": "Report 2408 on Finland Police's Facial Recognition Trial to Identify Sexual Abuse Victims Deemed Illegal",
      "description": "A detailed report about Finland Police's Facial Recognition Trial to Identify Sexual Abuse Victims Deemed Illegal",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-01-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2409",
      "incident_id": 412,
      "title": "Report 2409 on Finland Police's Facial Recognition Trial to Identify Sexual Abuse Victims Deemed Illegal",
      "description": "A detailed report about Finland Police's Facial Recognition Trial to Identify Sexual Abuse Victims Deemed Illegal",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-01-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2317",
      "incident_id": 413,
      "title": "Report 2317 on Thousands of Incorrect ChatGPT-Produced Answers Posted on Stack Overflow",
      "description": "A detailed report about Thousands of Incorrect ChatGPT-Produced Answers Posted on Stack Overflow",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2318",
      "incident_id": 413,
      "title": "Report 2318 on Thousands of Incorrect ChatGPT-Produced Answers Posted on Stack Overflow",
      "description": "A detailed report about Thousands of Incorrect ChatGPT-Produced Answers Posted on Stack Overflow",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2586",
      "incident_id": 413,
      "title": "Report 2586 on Thousands of Incorrect ChatGPT-Produced Answers Posted on Stack Overflow",
      "description": "A detailed report about Thousands of Incorrect ChatGPT-Produced Answers Posted on Stack Overflow",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2319",
      "incident_id": 414,
      "title": "Report 2319 on Facebook Gave Vulgar English Translation of Chinese President's Name",
      "description": "A detailed report about Facebook Gave Vulgar English Translation of Chinese President's Name",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-01-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2320",
      "incident_id": 415,
      "title": "Report 2320 on Facebook Provided Offensive Translation for King of Thailand's Birthday Ceremony",
      "description": "A detailed report about Facebook Provided Offensive Translation for King of Thailand's Birthday Ceremony",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-07-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2404",
      "incident_id": 415,
      "title": "Report 2404 on Facebook Provided Offensive Translation for King of Thailand's Birthday Ceremony",
      "description": "A detailed report about Facebook Provided Offensive Translation for King of Thailand's Birthday Ceremony",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-07-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2405",
      "incident_id": 415,
      "title": "Report 2405 on Facebook Provided Offensive Translation for King of Thailand's Birthday Ceremony",
      "description": "A detailed report about Facebook Provided Offensive Translation for King of Thailand's Birthday Ceremony",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-07-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2321",
      "incident_id": 416,
      "title": "Report 2321 on Facebook's Job Ad Algorithm Allegedly Biased against Older and Female Workers",
      "description": "A detailed report about Facebook's Job Ad Algorithm Allegedly Biased against Older and Female Workers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-12-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2402",
      "incident_id": 416,
      "title": "Report 2402 on Facebook's Job Ad Algorithm Allegedly Biased against Older and Female Workers",
      "description": "A detailed report about Facebook's Job Ad Algorithm Allegedly Biased against Older and Female Workers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-12-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2403",
      "incident_id": 416,
      "title": "Report 2403 on Facebook's Job Ad Algorithm Allegedly Biased against Older and Female Workers",
      "description": "A detailed report about Facebook's Job Ad Algorithm Allegedly Biased against Older and Female Workers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-12-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2322",
      "incident_id": 417,
      "title": "Report 2322 on Facebook Feed Algorithms Exposed Low Digitally Skilled Users to More Disturbing Content",
      "description": "A detailed report about Facebook Feed Algorithms Exposed Low Digitally Skilled Users to More Disturbing Content",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-11-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2399",
      "incident_id": 417,
      "title": "Report 2399 on Facebook Feed Algorithms Exposed Low Digitally Skilled Users to More Disturbing Content",
      "description": "A detailed report about Facebook Feed Algorithms Exposed Low Digitally Skilled Users to More Disturbing Content",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-11-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2400",
      "incident_id": 417,
      "title": "Report 2400 on Facebook Feed Algorithms Exposed Low Digitally Skilled Users to More Disturbing Content",
      "description": "A detailed report about Facebook Feed Algorithms Exposed Low Digitally Skilled Users to More Disturbing Content",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-11-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2324",
      "incident_id": 418,
      "title": "Report 2324 on Uber Locked Indian Drivers out of Accounts Allegedly Due to Facial Recognition Fails",
      "description": "A detailed report about Uber Locked Indian Drivers out of Accounts Allegedly Due to Facial Recognition Fails",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-03-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2391",
      "incident_id": 418,
      "title": "Report 2391 on Uber Locked Indian Drivers out of Accounts Allegedly Due to Facial Recognition Fails",
      "description": "A detailed report about Uber Locked Indian Drivers out of Accounts Allegedly Due to Facial Recognition Fails",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-03-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2392",
      "incident_id": 418,
      "title": "Report 2392 on Uber Locked Indian Drivers out of Accounts Allegedly Due to Facial Recognition Fails",
      "description": "A detailed report about Uber Locked Indian Drivers out of Accounts Allegedly Due to Facial Recognition Fails",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-03-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2325",
      "incident_id": 419,
      "title": "Report 2325 on Facebook's Automated Moderation Allowed Ads Threatening Election Workers to be Posted",
      "description": "A detailed report about Facebook's Automated Moderation Allowed Ads Threatening Election Workers to be Posted",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-12-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2395",
      "incident_id": 419,
      "title": "Report 2395 on Facebook's Automated Moderation Allowed Ads Threatening Election Workers to be Posted",
      "description": "A detailed report about Facebook's Automated Moderation Allowed Ads Threatening Election Workers to be Posted",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-12-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2396",
      "incident_id": 419,
      "title": "Report 2396 on Facebook's Automated Moderation Allowed Ads Threatening Election Workers to be Posted",
      "description": "A detailed report about Facebook's Automated Moderation Allowed Ads Threatening Election Workers to be Posted",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-12-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2326",
      "incident_id": 420,
      "title": "Report 2326 on Users Bypassed ChatGPT's Content Filters with Ease",
      "description": "A detailed report about Users Bypassed ChatGPT's Content Filters with Ease",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2358",
      "incident_id": 420,
      "title": "Report 2358 on Users Bypassed ChatGPT's Content Filters with Ease",
      "description": "A detailed report about Users Bypassed ChatGPT's Content Filters with Ease",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2393",
      "incident_id": 420,
      "title": "Report 2393 on Users Bypassed ChatGPT's Content Filters with Ease",
      "description": "A detailed report about Users Bypassed ChatGPT's Content Filters with Ease",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2328",
      "incident_id": 421,
      "title": "Report 2328 on Stable Diffusion Allegedly Used Artists' Works without Permission for AI Training",
      "description": "A detailed report about Stable Diffusion Allegedly Used Artists' Works without Permission for AI Training",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2427",
      "incident_id": 421,
      "title": "Report 2427 on Stable Diffusion Allegedly Used Artists' Works without Permission for AI Training",
      "description": "A detailed report about Stable Diffusion Allegedly Used Artists' Works without Permission for AI Training",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2444",
      "incident_id": 421,
      "title": "Report 2444 on Stable Diffusion Allegedly Used Artists' Works without Permission for AI Training",
      "description": "A detailed report about Stable Diffusion Allegedly Used Artists' Works without Permission for AI Training",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2330",
      "incident_id": 422,
      "title": "Report 2330 on Deepfake of FTX's Former CEO Posted on Twitter Aiming to Scam FTX Collapse Victims",
      "description": "A detailed report about Deepfake of FTX's Former CEO Posted on Twitter Aiming to Scam FTX Collapse Victims",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2331",
      "incident_id": 423,
      "title": "Report 2331 on Lensa AI's Produced Unintended Sexually Explicit or Suggestive Magic Avatars for Women",
      "description": "A detailed report about Lensa AI's Produced Unintended Sexually Explicit or Suggestive Magic Avatars for Women",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2376",
      "incident_id": 423,
      "title": "Report 2376 on Lensa AI's Produced Unintended Sexually Explicit or Suggestive Magic Avatars for Women",
      "description": "A detailed report about Lensa AI's Produced Unintended Sexually Explicit or Suggestive Magic Avatars for Women",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2390",
      "incident_id": 423,
      "title": "Report 2390 on Lensa AI's Produced Unintended Sexually Explicit or Suggestive Magic Avatars for Women",
      "description": "A detailed report about Lensa AI's Produced Unintended Sexually Explicit or Suggestive Magic Avatars for Women",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2332",
      "incident_id": 424,
      "title": "Report 2332 on Universities' AI Proctoring Tools Allegedly Failed Canada's Legal Threshold for Consent",
      "description": "A detailed report about Universities' AI Proctoring Tools Allegedly Failed Canada's Legal Threshold for Consent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-03-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2386",
      "incident_id": 424,
      "title": "Report 2386 on Universities' AI Proctoring Tools Allegedly Failed Canada's Legal Threshold for Consent",
      "description": "A detailed report about Universities' AI Proctoring Tools Allegedly Failed Canada's Legal Threshold for Consent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-03-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2387",
      "incident_id": 424,
      "title": "Report 2387 on Universities' AI Proctoring Tools Allegedly Failed Canada's Legal Threshold for Consent",
      "description": "A detailed report about Universities' AI Proctoring Tools Allegedly Failed Canada's Legal Threshold for Consent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-03-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2333",
      "incident_id": 425,
      "title": "Report 2333 on State Farm Allegedly Discriminated against Black Customers in Claim Payout",
      "description": "A detailed report about State Farm Allegedly Discriminated against Black Customers in Claim Payout",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-06-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2385",
      "incident_id": 425,
      "title": "Report 2385 on State Farm Allegedly Discriminated against Black Customers in Claim Payout",
      "description": "A detailed report about State Farm Allegedly Discriminated against Black Customers in Claim Payout",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-06-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2334",
      "incident_id": 426,
      "title": "Report 2334 on XPeng P7 Crashed into Truck in Shangdong While on Automatic Navigation Assisted Driving",
      "description": "A detailed report about XPeng P7 Crashed into Truck in Shangdong While on Automatic Navigation Assisted Driving",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-09-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2335",
      "incident_id": 427,
      "title": "Report 2335 on Cruise Taxis' Sudden Braking Allegedly Put People at Risk",
      "description": "A detailed report about Cruise Taxis' Sudden Braking Allegedly Put People at Risk",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-03-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2382",
      "incident_id": 427,
      "title": "Report 2382 on Cruise Taxis' Sudden Braking Allegedly Put People at Risk",
      "description": "A detailed report about Cruise Taxis' Sudden Braking Allegedly Put People at Risk",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-03-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2383",
      "incident_id": 427,
      "title": "Report 2383 on Cruise Taxis' Sudden Braking Allegedly Put People at Risk",
      "description": "A detailed report about Cruise Taxis' Sudden Braking Allegedly Put People at Risk",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-03-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2341",
      "incident_id": 428,
      "title": "Report 2341 on BBC Reporter's Twin Brother Cracked HSBC's Voice ID Authentication",
      "description": "A detailed report about BBC Reporter's Twin Brother Cracked HSBC's Voice ID Authentication",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-05-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2379",
      "incident_id": 428,
      "title": "Report 2379 on BBC Reporter's Twin Brother Cracked HSBC's Voice ID Authentication",
      "description": "A detailed report about BBC Reporter's Twin Brother Cracked HSBC's Voice ID Authentication",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-05-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2380",
      "incident_id": 428,
      "title": "Report 2380 on BBC Reporter's Twin Brother Cracked HSBC's Voice ID Authentication",
      "description": "A detailed report about BBC Reporter's Twin Brother Cracked HSBC's Voice ID Authentication",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-05-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2343",
      "incident_id": 429,
      "title": "Report 2343 on Unreliable ShotSpotter Audio Convicted Black Rochester Man of Shooting Police",
      "description": "A detailed report about Unreliable ShotSpotter Audio Convicted Black Rochester Man of Shooting Police",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-04-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1816",
      "incident_id": 429,
      "title": "Report 1816 on Unreliable ShotSpotter Audio Convicted Black Rochester Man of Shooting Police",
      "description": "A detailed report about Unreliable ShotSpotter Audio Convicted Black Rochester Man of Shooting Police",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-04-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2377",
      "incident_id": 429,
      "title": "Report 2377 on Unreliable ShotSpotter Audio Convicted Black Rochester Man of Shooting Police",
      "description": "A detailed report about Unreliable ShotSpotter Audio Convicted Black Rochester Man of Shooting Police",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-04-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2346",
      "incident_id": 430,
      "title": "Report 2346 on Lawyers Denied Entry to Performance Venue by Facial Recognition",
      "description": "A detailed report about Lawyers Denied Entry to Performance Venue by Facial Recognition",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-12-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2355",
      "incident_id": 430,
      "title": "Report 2355 on Lawyers Denied Entry to Performance Venue by Facial Recognition",
      "description": "A detailed report about Lawyers Denied Entry to Performance Venue by Facial Recognition",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-12-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2359",
      "incident_id": 430,
      "title": "Report 2359 on Lawyers Denied Entry to Performance Venue by Facial Recognition",
      "description": "A detailed report about Lawyers Denied Entry to Performance Venue by Facial Recognition",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-12-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2353",
      "incident_id": 431,
      "title": "Report 2353 on Robbers Accessed Drugged Gay Men's Bank Accounts Using Their Phones' Facial Recognition",
      "description": "A detailed report about Robbers Accessed Drugged Gay Men's Bank Accounts Using Their Phones' Facial Recognition",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-04-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2370",
      "incident_id": 431,
      "title": "Report 2370 on Robbers Accessed Drugged Gay Men's Bank Accounts Using Their Phones' Facial Recognition",
      "description": "A detailed report about Robbers Accessed Drugged Gay Men's Bank Accounts Using Their Phones' Facial Recognition",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-04-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2371",
      "incident_id": 431,
      "title": "Report 2371 on Robbers Accessed Drugged Gay Men's Bank Accounts Using Their Phones' Facial Recognition",
      "description": "A detailed report about Robbers Accessed Drugged Gay Men's Bank Accounts Using Their Phones' Facial Recognition",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-04-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2357",
      "incident_id": 432,
      "title": "Report 2357 on Southwest Airlines Crew Scheduling Solver Degenerates Flight Network",
      "description": "A detailed report about Southwest Airlines Crew Scheduling Solver Degenerates Flight Network",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-12-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2415",
      "incident_id": 433,
      "title": "Report 2415 on Chicago Police's Strategic Subject List Reportedly Biased Along Racial Lines",
      "description": "A detailed report about Chicago Police's Strategic Subject List Reportedly Biased Along Racial Lines",
      "url": "https://incidentdatabase.ai",
      "date_published": "2012-08-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2416",
      "incident_id": 433,
      "title": "Report 2416 on Chicago Police's Strategic Subject List Reportedly Biased Along Racial Lines",
      "description": "A detailed report about Chicago Police's Strategic Subject List Reportedly Biased Along Racial Lines",
      "url": "https://incidentdatabase.ai",
      "date_published": "2012-08-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1013",
      "incident_id": 433,
      "title": "Report 1013 on Chicago Police's Strategic Subject List Reportedly Biased Along Racial Lines",
      "description": "A detailed report about Chicago Police's Strategic Subject List Reportedly Biased Along Racial Lines",
      "url": "https://incidentdatabase.ai",
      "date_published": "2012-08-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2417",
      "incident_id": 434,
      "title": "Report 2417 on Sudden Braking by Tesla Allegedly on Self-Driving Mode Caused Multi-Car Pileup in Tunnel",
      "description": "A detailed report about Sudden Braking by Tesla Allegedly on Self-Driving Mode Caused Multi-Car Pileup in Tunnel",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2418",
      "incident_id": 434,
      "title": "Report 2418 on Sudden Braking by Tesla Allegedly on Self-Driving Mode Caused Multi-Car Pileup in Tunnel",
      "description": "A detailed report about Sudden Braking by Tesla Allegedly on Self-Driving Mode Caused Multi-Car Pileup in Tunnel",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2420",
      "incident_id": 434,
      "title": "Report 2420 on Sudden Braking by Tesla Allegedly on Self-Driving Mode Caused Multi-Car Pileup in Tunnel",
      "description": "A detailed report about Sudden Braking by Tesla Allegedly on Self-Driving Mode Caused Multi-Car Pileup in Tunnel",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2423",
      "incident_id": 435,
      "title": "Report 2423 on Coupang Allegedly Tweaked Search Algorithms to Boost Own Products",
      "description": "A detailed report about Coupang Allegedly Tweaked Search Algorithms to Boost Own Products",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-07-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2424",
      "incident_id": 435,
      "title": "Report 2424 on Coupang Allegedly Tweaked Search Algorithms to Boost Own Products",
      "description": "A detailed report about Coupang Allegedly Tweaked Search Algorithms to Boost Own Products",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-07-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2425",
      "incident_id": 435,
      "title": "Report 2425 on Coupang Allegedly Tweaked Search Algorithms to Boost Own Products",
      "description": "A detailed report about Coupang Allegedly Tweaked Search Algorithms to Boost Own Products",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-07-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2428",
      "incident_id": 436,
      "title": "Report 2428 on Tesla Driver Put Car on Autopilot Before Falling Asleep in Germany",
      "description": "A detailed report about Tesla Driver Put Car on Autopilot Before Falling Asleep in Germany",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-12-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2429",
      "incident_id": 436,
      "title": "Report 2429 on Tesla Driver Put Car on Autopilot Before Falling Asleep in Germany",
      "description": "A detailed report about Tesla Driver Put Car on Autopilot Before Falling Asleep in Germany",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-12-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2430",
      "incident_id": 436,
      "title": "Report 2430 on Tesla Driver Put Car on Autopilot Before Falling Asleep in Germany",
      "description": "A detailed report about Tesla Driver Put Car on Autopilot Before Falling Asleep in Germany",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-12-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2438",
      "incident_id": 437,
      "title": "Report 2438 on Amazon India Allegedly Rigged Search Results to Promote Own Products",
      "description": "A detailed report about Amazon India Allegedly Rigged Search Results to Promote Own Products",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-12-31",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2439",
      "incident_id": 437,
      "title": "Report 2439 on Amazon India Allegedly Rigged Search Results to Promote Own Products",
      "description": "A detailed report about Amazon India Allegedly Rigged Search Results to Promote Own Products",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-12-31",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2440",
      "incident_id": 437,
      "title": "Report 2440 on Amazon India Allegedly Rigged Search Results to Promote Own Products",
      "description": "A detailed report about Amazon India Allegedly Rigged Search Results to Promote Own Products",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-12-31",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2443",
      "incident_id": 438,
      "title": "Report 2443 on Chinese Province Developed System Tracking Journalists and International Students",
      "description": "A detailed report about Chinese Province Developed System Tracking Journalists and International Students",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-09-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2447",
      "incident_id": 438,
      "title": "Report 2447 on Chinese Province Developed System Tracking Journalists and International Students",
      "description": "A detailed report about Chinese Province Developed System Tracking Journalists and International Students",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-09-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2451",
      "incident_id": 438,
      "title": "Report 2451 on Chinese Province Developed System Tracking Journalists and International Students",
      "description": "A detailed report about Chinese Province Developed System Tracking Journalists and International Students",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-09-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2448",
      "incident_id": 439,
      "title": "Report 2448 on Detroit Police Wrongfully Arrested Black Man Due To Faulty Facial Recognition",
      "description": "A detailed report about Detroit Police Wrongfully Arrested Black Man Due To Faulty Facial Recognition",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-07-31",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2449",
      "incident_id": 439,
      "title": "Report 2449 on Detroit Police Wrongfully Arrested Black Man Due To Faulty Facial Recognition",
      "description": "A detailed report about Detroit Police Wrongfully Arrested Black Man Due To Faulty Facial Recognition",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-07-31",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2450",
      "incident_id": 439,
      "title": "Report 2450 on Detroit Police Wrongfully Arrested Black Man Due To Faulty Facial Recognition",
      "description": "A detailed report about Detroit Police Wrongfully Arrested Black Man Due To Faulty Facial Recognition",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-07-31",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2452",
      "incident_id": 440,
      "title": "Report 2452 on Louisiana Police Wrongfully Arrested Black Man Using False Face Match",
      "description": "A detailed report about Louisiana Police Wrongfully Arrested Black Man Using False Face Match",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2454",
      "incident_id": 440,
      "title": "Report 2454 on Louisiana Police Wrongfully Arrested Black Man Using False Face Match",
      "description": "A detailed report about Louisiana Police Wrongfully Arrested Black Man Using False Face Match",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2498",
      "incident_id": 440,
      "title": "Report 2498 on Louisiana Police Wrongfully Arrested Black Man Using False Face Match",
      "description": "A detailed report about Louisiana Police Wrongfully Arrested Black Man Using False Face Match",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2464",
      "incident_id": 441,
      "title": "Report 2464 on Korea Developed ID Screening System Using Airport Travelers' Data without Consent",
      "description": "A detailed report about Korea Developed ID Screening System Using Airport Travelers' Data without Consent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-06-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2465",
      "incident_id": 441,
      "title": "Report 2465 on Korea Developed ID Screening System Using Airport Travelers' Data without Consent",
      "description": "A detailed report about Korea Developed ID Screening System Using Airport Travelers' Data without Consent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-06-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2466",
      "incident_id": 441,
      "title": "Report 2466 on Korea Developed ID Screening System Using Airport Travelers' Data without Consent",
      "description": "A detailed report about Korea Developed ID Screening System Using Airport Travelers' Data without Consent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-06-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2475",
      "incident_id": 443,
      "title": "Report 2475 on ChatGPT Abused to Develop Malicious Softwares",
      "description": "A detailed report about ChatGPT Abused to Develop Malicious Softwares",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-12-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2476",
      "incident_id": 443,
      "title": "Report 2476 on ChatGPT Abused to Develop Malicious Softwares",
      "description": "A detailed report about ChatGPT Abused to Develop Malicious Softwares",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-12-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2477",
      "incident_id": 443,
      "title": "Report 2477 on ChatGPT Abused to Develop Malicious Softwares",
      "description": "A detailed report about ChatGPT Abused to Develop Malicious Softwares",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-12-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2502",
      "incident_id": 444,
      "title": "Report 2502 on US Air Force's Patriot Missile Mistakenly Launched at Ally Fighter Jet, Killing Two",
      "description": "A detailed report about US Air Force's Patriot Missile Mistakenly Launched at Ally Fighter Jet, Killing Two",
      "url": "https://incidentdatabase.ai",
      "date_published": "2003-03-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2497",
      "incident_id": 444,
      "title": "Report 2497 on US Air Force's Patriot Missile Mistakenly Launched at Ally Fighter Jet, Killing Two",
      "description": "A detailed report about US Air Force's Patriot Missile Mistakenly Launched at Ally Fighter Jet, Killing Two",
      "url": "https://incidentdatabase.ai",
      "date_published": "2003-03-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2503",
      "incident_id": 444,
      "title": "Report 2503 on US Air Force's Patriot Missile Mistakenly Launched at Ally Fighter Jet, Killing Two",
      "description": "A detailed report about US Air Force's Patriot Missile Mistakenly Launched at Ally Fighter Jet, Killing Two",
      "url": "https://incidentdatabase.ai",
      "date_published": "2003-03-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2499",
      "incident_id": 445,
      "title": "Report 2499 on Patriot Missile System Misclassified US Navy Aircraft, Killing Pilot Upon Approval to Fire",
      "description": "A detailed report about Patriot Missile System Misclassified US Navy Aircraft, Killing Pilot Upon Approval to Fire",
      "url": "https://incidentdatabase.ai",
      "date_published": "2003-04-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2501",
      "incident_id": 445,
      "title": "Report 2501 on Patriot Missile System Misclassified US Navy Aircraft, Killing Pilot Upon Approval to Fire",
      "description": "A detailed report about Patriot Missile System Misclassified US Navy Aircraft, Killing Pilot Upon Approval to Fire",
      "url": "https://incidentdatabase.ai",
      "date_published": "2003-04-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2497",
      "incident_id": 445,
      "title": "Report 2497 on Patriot Missile System Misclassified US Navy Aircraft, Killing Pilot Upon Approval to Fire",
      "description": "A detailed report about Patriot Missile System Misclassified US Navy Aircraft, Killing Pilot Upon Approval to Fire",
      "url": "https://incidentdatabase.ai",
      "date_published": "2003-04-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2505",
      "incident_id": 446,
      "title": "Report 2505 on ShotSpotter Failed to Alert Authorities of Mass Shooting in North Carolina",
      "description": "A detailed report about ShotSpotter Failed to Alert Authorities of Mass Shooting in North Carolina",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-01-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2512",
      "incident_id": 446,
      "title": "Report 2512 on ShotSpotter Failed to Alert Authorities of Mass Shooting in North Carolina",
      "description": "A detailed report about ShotSpotter Failed to Alert Authorities of Mass Shooting in North Carolina",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-01-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2542",
      "incident_id": 446,
      "title": "Report 2542 on ShotSpotter Failed to Alert Authorities of Mass Shooting in North Carolina",
      "description": "A detailed report about ShotSpotter Failed to Alert Authorities of Mass Shooting in North Carolina",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-01-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2506",
      "incident_id": 447,
      "title": "Report 2506 on Footballer's X-Rated Comment Created by Instagram's Mistranslation",
      "description": "A detailed report about Footballer's X-Rated Comment Created by Instagram's Mistranslation",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-12-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2513",
      "incident_id": 447,
      "title": "Report 2513 on Footballer's X-Rated Comment Created by Instagram's Mistranslation",
      "description": "A detailed report about Footballer's X-Rated Comment Created by Instagram's Mistranslation",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-12-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2507",
      "incident_id": 448,
      "title": "Report 2507 on AI-Powered VTuber and Virtual Streamer Made Toxic Remarks on Twitch",
      "description": "A detailed report about AI-Powered VTuber and Virtual Streamer Made Toxic Remarks on Twitch",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-12-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2508",
      "incident_id": 449,
      "title": "Report 2508 on Startup Misled Research Participants about GPT-3 Use in Mental Healthcare Support",
      "description": "A detailed report about Startup Misled Research Participants about GPT-3 Use in Mental Healthcare Support",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-12-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2509",
      "incident_id": 449,
      "title": "Report 2509 on Startup Misled Research Participants about GPT-3 Use in Mental Healthcare Support",
      "description": "A detailed report about Startup Misled Research Participants about GPT-3 Use in Mental Healthcare Support",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-12-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2528",
      "incident_id": 449,
      "title": "Report 2528 on Startup Misled Research Participants about GPT-3 Use in Mental Healthcare Support",
      "description": "A detailed report about Startup Misled Research Participants about GPT-3 Use in Mental Healthcare Support",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-12-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2510",
      "incident_id": 450,
      "title": "Report 2510 on Kenyan Data Annotators Allegedly Exposed to Graphic Content for OpenAI's AI",
      "description": "A detailed report about Kenyan Data Annotators Allegedly Exposed to Graphic Content for OpenAI's AI",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-11-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2546",
      "incident_id": 450,
      "title": "Report 2546 on Kenyan Data Annotators Allegedly Exposed to Graphic Content for OpenAI's AI",
      "description": "A detailed report about Kenyan Data Annotators Allegedly Exposed to Graphic Content for OpenAI's AI",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-11-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2547",
      "incident_id": 450,
      "title": "Report 2547 on Kenyan Data Annotators Allegedly Exposed to Graphic Content for OpenAI's AI",
      "description": "A detailed report about Kenyan Data Annotators Allegedly Exposed to Graphic Content for OpenAI's AI",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-11-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2515",
      "incident_id": 451,
      "title": "Report 2515 on Stable Diffusion's Training Data Contained Copyrighted Images",
      "description": "A detailed report about Stable Diffusion's Training Data Contained Copyrighted Images",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-10-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2523",
      "incident_id": 451,
      "title": "Report 2523 on Stable Diffusion's Training Data Contained Copyrighted Images",
      "description": "A detailed report about Stable Diffusion's Training Data Contained Copyrighted Images",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-10-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2606",
      "incident_id": 451,
      "title": "Report 2606 on Stable Diffusion's Training Data Contained Copyrighted Images",
      "description": "A detailed report about Stable Diffusion's Training Data Contained Copyrighted Images",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-10-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2518",
      "incident_id": 452,
      "title": "Report 2518 on ChatGPT-Written Bug Reports Deemed Nonsense by White Hat Platform, Prompted Bans",
      "description": "A detailed report about ChatGPT-Written Bug Reports Deemed Nonsense by White Hat Platform, Prompted Bans",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-01-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2545",
      "incident_id": 452,
      "title": "Report 2545 on ChatGPT-Written Bug Reports Deemed Nonsense by White Hat Platform, Prompted Bans",
      "description": "A detailed report about ChatGPT-Written Bug Reports Deemed Nonsense by White Hat Platform, Prompted Bans",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-01-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2519",
      "incident_id": 453,
      "title": "Report 2519 on Twitter's AI Moderation Tool Misidentified Rockets as Pornography",
      "description": "A detailed report about Twitter's AI Moderation Tool Misidentified Rockets as Pornography",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-01-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2521",
      "incident_id": 454,
      "title": "Report 2521 on Emotion Detection Models Showed Disparate Performance along Racial Lines",
      "description": "A detailed report about Emotion Detection Models Showed Disparate Performance along Racial Lines",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-11-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2549",
      "incident_id": 454,
      "title": "Report 2549 on Emotion Detection Models Showed Disparate Performance along Racial Lines",
      "description": "A detailed report about Emotion Detection Models Showed Disparate Performance along Racial Lines",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-11-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2524",
      "incident_id": 455,
      "title": "Report 2524 on CNET's Published AI-Written Articles Ran into Quality and Accuracy Issues",
      "description": "A detailed report about CNET's Published AI-Written Articles Ran into Quality and Accuracy Issues",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2541",
      "incident_id": 455,
      "title": "Report 2541 on CNET's Published AI-Written Articles Ran into Quality and Accuracy Issues",
      "description": "A detailed report about CNET's Published AI-Written Articles Ran into Quality and Accuracy Issues",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2560",
      "incident_id": 455,
      "title": "Report 2560 on CNET's Published AI-Written Articles Ran into Quality and Accuracy Issues",
      "description": "A detailed report about CNET's Published AI-Written Articles Ran into Quality and Accuracy Issues",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2525",
      "incident_id": 456,
      "title": "Report 2525 on Replika's AI Partners Reportedly Sexually Harassed Users",
      "description": "A detailed report about Replika's AI Partners Reportedly Sexually Harassed Users",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-05-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2529",
      "incident_id": 456,
      "title": "Report 2529 on Replika's AI Partners Reportedly Sexually Harassed Users",
      "description": "A detailed report about Replika's AI Partners Reportedly Sexually Harassed Users",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-05-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2530",
      "incident_id": 456,
      "title": "Report 2530 on Replika's AI Partners Reportedly Sexually Harassed Users",
      "description": "A detailed report about Replika's AI Partners Reportedly Sexually Harassed Users",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-05-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2543",
      "incident_id": 457,
      "title": "Report 2543 on Article-Writing AI by CNET Allegedly Committed Plagiarism",
      "description": "A detailed report about Article-Writing AI by CNET Allegedly Committed Plagiarism",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2551",
      "incident_id": 457,
      "title": "Report 2551 on Article-Writing AI by CNET Allegedly Committed Plagiarism",
      "description": "A detailed report about Article-Writing AI by CNET Allegedly Committed Plagiarism",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2552",
      "incident_id": 457,
      "title": "Report 2552 on Article-Writing AI by CNET Allegedly Committed Plagiarism",
      "description": "A detailed report about Article-Writing AI by CNET Allegedly Committed Plagiarism",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2553",
      "incident_id": 458,
      "title": "Report 2553 on Robot Destroyed while Hitchhiking through the United States",
      "description": "A detailed report about Robot Destroyed while Hitchhiking through the United States",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-08-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2561",
      "incident_id": 459,
      "title": "Report 2561 on Firefighters Smashed Cruise AV's Front Window to Stop It from Running over Fire Hoses",
      "description": "A detailed report about Firefighters Smashed Cruise AV's Front Window to Stop It from Running over Fire Hoses",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-01-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2568",
      "incident_id": 459,
      "title": "Report 2568 on Firefighters Smashed Cruise AV's Front Window to Stop It from Running over Fire Hoses",
      "description": "A detailed report about Firefighters Smashed Cruise AV's Front Window to Stop It from Running over Fire Hoses",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-01-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2562",
      "incident_id": 459,
      "title": "Report 2562 on Firefighters Smashed Cruise AV's Front Window to Stop It from Running over Fire Hoses",
      "description": "A detailed report about Firefighters Smashed Cruise AV's Front Window to Stop It from Running over Fire Hoses",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-01-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2562",
      "incident_id": 460,
      "title": "Report 2562 on Cruise AV Ran Over Fire Hose in Active Fire Scene",
      "description": "A detailed report about Cruise AV Ran Over Fire Hose in Active Fire Scene",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-06-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3182",
      "incident_id": 460,
      "title": "Report 3182 on Cruise AV Ran Over Fire Hose in Active Fire Scene",
      "description": "A detailed report about Cruise AV Ran Over Fire Hose in Active Fire Scene",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-06-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2564",
      "incident_id": 461,
      "title": "Report 2564 on IRS Audited Black Taxpayers More Frequently Reportedly Due to Algorithm",
      "description": "A detailed report about IRS Audited Black Taxpayers More Frequently Reportedly Due to Algorithm",
      "url": "https://incidentdatabase.ai",
      "date_published": "2008-07-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2565",
      "incident_id": 461,
      "title": "Report 2565 on IRS Audited Black Taxpayers More Frequently Reportedly Due to Algorithm",
      "description": "A detailed report about IRS Audited Black Taxpayers More Frequently Reportedly Due to Algorithm",
      "url": "https://incidentdatabase.ai",
      "date_published": "2008-07-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2566",
      "incident_id": 461,
      "title": "Report 2566 on IRS Audited Black Taxpayers More Frequently Reportedly Due to Algorithm",
      "description": "A detailed report about IRS Audited Black Taxpayers More Frequently Reportedly Due to Algorithm",
      "url": "https://incidentdatabase.ai",
      "date_published": "2008-07-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2571",
      "incident_id": 462,
      "title": "Report 2571 on AI-Produced Livestream Sitcom Received Temporary Twitch Ban for Transphobic Segment",
      "description": "A detailed report about AI-Produced Livestream Sitcom Received Temporary Twitch Ban for Transphobic Segment",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2578",
      "incident_id": 462,
      "title": "Report 2578 on AI-Produced Livestream Sitcom Received Temporary Twitch Ban for Transphobic Segment",
      "description": "A detailed report about AI-Produced Livestream Sitcom Received Temporary Twitch Ban for Transphobic Segment",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2579",
      "incident_id": 462,
      "title": "Report 2579 on AI-Produced Livestream Sitcom Received Temporary Twitch Ban for Transphobic Segment",
      "description": "A detailed report about AI-Produced Livestream Sitcom Received Temporary Twitch Ban for Transphobic Segment",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2572",
      "incident_id": 463,
      "title": "Report 2572 on Apple Devices Mistook Skiing Activities, Dialed False Distress Emergency Calls ",
      "description": "A detailed report about Apple Devices Mistook Skiing Activities, Dialed False Distress Emergency Calls ",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2573",
      "incident_id": 463,
      "title": "Report 2573 on Apple Devices Mistook Skiing Activities, Dialed False Distress Emergency Calls ",
      "description": "A detailed report about Apple Devices Mistook Skiing Activities, Dialed False Distress Emergency Calls ",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2574",
      "incident_id": 463,
      "title": "Report 2574 on Apple Devices Mistook Skiing Activities, Dialed False Distress Emergency Calls ",
      "description": "A detailed report about Apple Devices Mistook Skiing Activities, Dialed False Distress Emergency Calls ",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2584",
      "incident_id": 464,
      "title": "Report 2584 on ChatGPT Provided Non-Existent Citations and Links when Prompted by Users",
      "description": "A detailed report about ChatGPT Provided Non-Existent Citations and Links when Prompted by Users",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2585",
      "incident_id": 464,
      "title": "Report 2585 on ChatGPT Provided Non-Existent Citations and Links when Prompted by Users",
      "description": "A detailed report about ChatGPT Provided Non-Existent Citations and Links when Prompted by Users",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2586",
      "incident_id": 464,
      "title": "Report 2586 on ChatGPT Provided Non-Existent Citations and Links when Prompted by Users",
      "description": "A detailed report about ChatGPT Provided Non-Existent Citations and Links when Prompted by Users",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2599",
      "incident_id": 465,
      "title": "Report 2599 on Generative Models Trained on Dataset Containing Private Medical Photos",
      "description": "A detailed report about Generative Models Trained on Dataset Containing Private Medical Photos",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-03-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2605",
      "incident_id": 466,
      "title": "Report 2605 on AI-Generated-Text-Detection Tools Reported for High Error Rates",
      "description": "A detailed report about AI-Generated-Text-Detection Tools Reported for High Error Rates",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-01-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2628",
      "incident_id": 466,
      "title": "Report 2628 on AI-Generated-Text-Detection Tools Reported for High Error Rates",
      "description": "A detailed report about AI-Generated-Text-Detection Tools Reported for High Error Rates",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-01-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2629",
      "incident_id": 466,
      "title": "Report 2629 on AI-Generated-Text-Detection Tools Reported for High Error Rates",
      "description": "A detailed report about AI-Generated-Text-Detection Tools Reported for High Error Rates",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-01-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2609",
      "incident_id": 467,
      "title": "Report 2609 on Google's Bard Shared Factually Inaccurate Info in Promo Video",
      "description": "A detailed report about Google's Bard Shared Factually Inaccurate Info in Promo Video",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2611",
      "incident_id": 467,
      "title": "Report 2611 on Google's Bard Shared Factually Inaccurate Info in Promo Video",
      "description": "A detailed report about Google's Bard Shared Factually Inaccurate Info in Promo Video",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2612",
      "incident_id": 467,
      "title": "Report 2612 on Google's Bard Shared Factually Inaccurate Info in Promo Video",
      "description": "A detailed report about Google's Bard Shared Factually Inaccurate Info in Promo Video",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2610",
      "incident_id": 468,
      "title": "Report 2610 on ChatGPT-Powered Bing Reportedly Had Problems with Factual Accuracy on Some Controversial Topics",
      "description": "A detailed report about ChatGPT-Powered Bing Reportedly Had Problems with Factual Accuracy on Some Controversial Topics",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2970",
      "incident_id": 468,
      "title": "Report 2970 on ChatGPT-Powered Bing Reportedly Had Problems with Factual Accuracy on Some Controversial Topics",
      "description": "A detailed report about ChatGPT-Powered Bing Reportedly Had Problems with Factual Accuracy on Some Controversial Topics",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2971",
      "incident_id": 468,
      "title": "Report 2971 on ChatGPT-Powered Bing Reportedly Had Problems with Factual Accuracy on Some Controversial Topics",
      "description": "A detailed report about ChatGPT-Powered Bing Reportedly Had Problems with Factual Accuracy on Some Controversial Topics",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2636",
      "incident_id": 469,
      "title": "Report 2636 on Automated Adult Content Detection Tools Showed Bias against Women Bodies",
      "description": "A detailed report about Automated Adult Content Detection Tools Showed Bias against Women Bodies",
      "url": "https://incidentdatabase.ai",
      "date_published": "2006-02-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2637",
      "incident_id": 469,
      "title": "Report 2637 on Automated Adult Content Detection Tools Showed Bias against Women Bodies",
      "description": "A detailed report about Automated Adult Content Detection Tools Showed Bias against Women Bodies",
      "url": "https://incidentdatabase.ai",
      "date_published": "2006-02-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2638",
      "incident_id": 469,
      "title": "Report 2638 on Automated Adult Content Detection Tools Showed Bias against Women Bodies",
      "description": "A detailed report about Automated Adult Content Detection Tools Showed Bias against Women Bodies",
      "url": "https://incidentdatabase.ai",
      "date_published": "2006-02-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2641",
      "incident_id": 470,
      "title": "Report 2641 on Bing Chat Response Cited ChatGPT Disinformation Example",
      "description": "A detailed report about Bing Chat Response Cited ChatGPT Disinformation Example",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2799",
      "incident_id": 470,
      "title": "Report 2799 on Bing Chat Response Cited ChatGPT Disinformation Example",
      "description": "A detailed report about Bing Chat Response Cited ChatGPT Disinformation Example",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2642",
      "incident_id": 471,
      "title": "Report 2642 on Facebook Allegedly Failed to Police Hate Speech Content That Contributed to Ethnic Violence in Ethiopia",
      "description": "A detailed report about Facebook Allegedly Failed to Police Hate Speech Content That Contributed to Ethnic Violence in Ethiopia",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-06-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2668",
      "incident_id": 471,
      "title": "Report 2668 on Facebook Allegedly Failed to Police Hate Speech Content That Contributed to Ethnic Violence in Ethiopia",
      "description": "A detailed report about Facebook Allegedly Failed to Police Hate Speech Content That Contributed to Ethnic Violence in Ethiopia",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-06-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2669",
      "incident_id": 471,
      "title": "Report 2669 on Facebook Allegedly Failed to Police Hate Speech Content That Contributed to Ethnic Violence in Ethiopia",
      "description": "A detailed report about Facebook Allegedly Failed to Police Hate Speech Content That Contributed to Ethnic Violence in Ethiopia",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-06-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2655",
      "incident_id": 472,
      "title": "Report 2655 on NYPD's Deployment of Facial Recognition Cameras Reportedly Reinforced Biased Policing",
      "description": "A detailed report about NYPD's Deployment of Facial Recognition Cameras Reportedly Reinforced Biased Policing",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-10-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2666",
      "incident_id": 473,
      "title": "Report 2666 on Bing Chat's Initial Prompts Revealed by Early Testers Through Prompt Injection",
      "description": "A detailed report about Bing Chat's Initial Prompts Revealed by Early Testers Through Prompt Injection",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2670",
      "incident_id": 474,
      "title": "Report 2670 on Users Reported Abrupt Behavior Changes of Their AI Replika Companions",
      "description": "A detailed report about Users Reported Abrupt Behavior Changes of Their AI Replika Companions",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2671",
      "incident_id": 475,
      "title": "Report 2671 on McDonald's AI Drive-Thru Ordering System Failures Frustrate Customers",
      "description": "A detailed report about McDonald's AI Drive-Thru Ordering System Failures Frustrate Customers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-06-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2672",
      "incident_id": 475,
      "title": "Report 2672 on McDonald's AI Drive-Thru Ordering System Failures Frustrate Customers",
      "description": "A detailed report about McDonald's AI Drive-Thru Ordering System Failures Frustrate Customers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-06-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2834",
      "incident_id": 475,
      "title": "Report 2834 on McDonald's AI Drive-Thru Ordering System Failures Frustrate Customers",
      "description": "A detailed report about McDonald's AI Drive-Thru Ordering System Failures Frustrate Customers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-06-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2673",
      "incident_id": 476,
      "title": "Report 2673 on YouTube Recommendations Allegedly Promoted Radicalizing Material Contributing to Terrorist Acts",
      "description": "A detailed report about YouTube Recommendations Allegedly Promoted Radicalizing Material Contributing to Terrorist Acts",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-11-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2675",
      "incident_id": 476,
      "title": "Report 2675 on YouTube Recommendations Allegedly Promoted Radicalizing Material Contributing to Terrorist Acts",
      "description": "A detailed report about YouTube Recommendations Allegedly Promoted Radicalizing Material Contributing to Terrorist Acts",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-11-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2674",
      "incident_id": 476,
      "title": "Report 2674 on YouTube Recommendations Allegedly Promoted Radicalizing Material Contributing to Terrorist Acts",
      "description": "A detailed report about YouTube Recommendations Allegedly Promoted Radicalizing Material Contributing to Terrorist Acts",
      "url": "https://incidentdatabase.ai",
      "date_published": "2015-11-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2676",
      "incident_id": 477,
      "title": "Report 2676 on Bing Chat Tentatively Hallucinated in Extended Conversations with Users",
      "description": "A detailed report about Bing Chat Tentatively Hallucinated in Extended Conversations with Users",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2688",
      "incident_id": 477,
      "title": "Report 2688 on Bing Chat Tentatively Hallucinated in Extended Conversations with Users",
      "description": "A detailed report about Bing Chat Tentatively Hallucinated in Extended Conversations with Users",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2724",
      "incident_id": 477,
      "title": "Report 2724 on Bing Chat Tentatively Hallucinated in Extended Conversations with Users",
      "description": "A detailed report about Bing Chat Tentatively Hallucinated in Extended Conversations with Users",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2678",
      "incident_id": 478,
      "title": "Report 2678 on Tesla FSD Reportedly Increased Crash Risk, Prompting Recall",
      "description": "A detailed report about Tesla FSD Reportedly Increased Crash Risk, Prompting Recall",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-09-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2679",
      "incident_id": 478,
      "title": "Report 2679 on Tesla FSD Reportedly Increased Crash Risk, Prompting Recall",
      "description": "A detailed report about Tesla FSD Reportedly Increased Crash Risk, Prompting Recall",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-09-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2680",
      "incident_id": 478,
      "title": "Report 2680 on Tesla FSD Reportedly Increased Crash Risk, Prompting Recall",
      "description": "A detailed report about Tesla FSD Reportedly Increased Crash Risk, Prompting Recall",
      "url": "https://incidentdatabase.ai",
      "date_published": "2016-09-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2690",
      "incident_id": 479,
      "title": "Report 2690 on Instagram Video Featured Deepfake Audio of US President Making Transphobic Remarks",
      "description": "A detailed report about Instagram Video Featured Deepfake Audio of US President Making Transphobic Remarks",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2691",
      "incident_id": 479,
      "title": "Report 2691 on Instagram Video Featured Deepfake Audio of US President Making Transphobic Remarks",
      "description": "A detailed report about Instagram Video Featured Deepfake Audio of US President Making Transphobic Remarks",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2692",
      "incident_id": 479,
      "title": "Report 2692 on Instagram Video Featured Deepfake Audio of US President Making Transphobic Remarks",
      "description": "A detailed report about Instagram Video Featured Deepfake Audio of US President Making Transphobic Remarks",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2695",
      "incident_id": 480,
      "title": "Report 2695 on Non-Consensual Deepfake Porn Targeted Female Content Creators",
      "description": "A detailed report about Non-Consensual Deepfake Porn Targeted Female Content Creators",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-01-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2696",
      "incident_id": 480,
      "title": "Report 2696 on Non-Consensual Deepfake Porn Targeted Female Content Creators",
      "description": "A detailed report about Non-Consensual Deepfake Porn Targeted Female Content Creators",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-01-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2697",
      "incident_id": 480,
      "title": "Report 2697 on Non-Consensual Deepfake Porn Targeted Female Content Creators",
      "description": "A detailed report about Non-Consensual Deepfake Porn Targeted Female Content Creators",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-01-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2701",
      "incident_id": 481,
      "title": "Report 2701 on Deepfake TikTok Video Featured Joe Rogan Endorsing Supplement Brand",
      "description": "A detailed report about Deepfake TikTok Video Featured Joe Rogan Endorsing Supplement Brand",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2702",
      "incident_id": 481,
      "title": "Report 2702 on Deepfake TikTok Video Featured Joe Rogan Endorsing Supplement Brand",
      "description": "A detailed report about Deepfake TikTok Video Featured Joe Rogan Endorsing Supplement Brand",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2765",
      "incident_id": 481,
      "title": "Report 2765 on Deepfake TikTok Video Featured Joe Rogan Endorsing Supplement Brand",
      "description": "A detailed report about Deepfake TikTok Video Featured Joe Rogan Endorsing Supplement Brand",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2706",
      "incident_id": 482,
      "title": "Report 2706 on ChatGPT-Assisted University Email Addressing Mass Shooting Denounced by Students",
      "description": "A detailed report about ChatGPT-Assisted University Email Addressing Mass Shooting Denounced by Students",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2707",
      "incident_id": 482,
      "title": "Report 2707 on ChatGPT-Assisted University Email Addressing Mass Shooting Denounced by Students",
      "description": "A detailed report about ChatGPT-Assisted University Email Addressing Mass Shooting Denounced by Students",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2708",
      "incident_id": 482,
      "title": "Report 2708 on ChatGPT-Assisted University Email Addressing Mass Shooting Denounced by Students",
      "description": "A detailed report about ChatGPT-Assisted University Email Addressing Mass Shooting Denounced by Students",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2727",
      "incident_id": 483,
      "title": "Report 2727 on Indian Police Allegedly Tortured and Killed Innocent Man Following Facial Misidentification",
      "description": "A detailed report about Indian Police Allegedly Tortured and Killed Innocent Man Following Facial Misidentification",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2729",
      "incident_id": 484,
      "title": "Report 2729 on US CBP App's Failure to Detect Black Faces Reportedly Blocked Asylum Applications",
      "description": "A detailed report about US CBP App's Failure to Detect Black Faces Reportedly Blocked Asylum Applications",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-01-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2730",
      "incident_id": 484,
      "title": "Report 2730 on US CBP App's Failure to Detect Black Faces Reportedly Blocked Asylum Applications",
      "description": "A detailed report about US CBP App's Failure to Detect Black Faces Reportedly Blocked Asylum Applications",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-01-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2803",
      "incident_id": 484,
      "title": "Report 2803 on US CBP App's Failure to Detect Black Faces Reportedly Blocked Asylum Applications",
      "description": "A detailed report about US CBP App's Failure to Detect Black Faces Reportedly Blocked Asylum Applications",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-01-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2740",
      "incident_id": 485,
      "title": "Report 2740 on UK Bank's Voice ID Successfully Bypassed Using AI-Produced Audio",
      "description": "A detailed report about UK Bank's Voice ID Successfully Bypassed Using AI-Produced Audio",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2762",
      "incident_id": 486,
      "title": "Report 2762 on AI Video-Making Tool Abused to Deploy Pro-China News on Social Media",
      "description": "A detailed report about AI Video-Making Tool Abused to Deploy Pro-China News on Social Media",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-12-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2766",
      "incident_id": 486,
      "title": "Report 2766 on AI Video-Making Tool Abused to Deploy Pro-China News on Social Media",
      "description": "A detailed report about AI Video-Making Tool Abused to Deploy Pro-China News on Social Media",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-12-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2767",
      "incident_id": 486,
      "title": "Report 2767 on AI Video-Making Tool Abused to Deploy Pro-China News on Social Media",
      "description": "A detailed report about AI Video-Making Tool Abused to Deploy Pro-China News on Social Media",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-12-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2764",
      "incident_id": 487,
      "title": "Report 2764 on Deepfake Video Featured Fictitious News Anchors Discussing Venezuela's Economy",
      "description": "A detailed report about Deepfake Video Featured Fictitious News Anchors Discussing Venezuela's Economy",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2819",
      "incident_id": 487,
      "title": "Report 2819 on Deepfake Video Featured Fictitious News Anchors Discussing Venezuela's Economy",
      "description": "A detailed report about Deepfake Video Featured Fictitious News Anchors Discussing Venezuela's Economy",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2880",
      "incident_id": 487,
      "title": "Report 2880 on Deepfake Video Featured Fictitious News Anchors Discussing Venezuela's Economy",
      "description": "A detailed report about Deepfake Video Featured Fictitious News Anchors Discussing Venezuela's Economy",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2769",
      "incident_id": 488,
      "title": "Report 2769 on AI Generated Voices Used to Dox Voice Actors",
      "description": "A detailed report about AI Generated Voices Used to Dox Voice Actors",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2777",
      "incident_id": 489,
      "title": "Report 2777 on Workday's AI Tools Allegedly Enabled Employers to Discriminate against Applicants of Protected Groups",
      "description": "A detailed report about Workday's AI Tools Allegedly Enabled Employers to Discriminate against Applicants of Protected Groups",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-06-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2778",
      "incident_id": 490,
      "title": "Report 2778 on Clarkesworld Magazine Closed Down Submissions Due to Massive Increase in AI-Generated Stories",
      "description": "A detailed report about Clarkesworld Magazine Closed Down Submissions Due to Massive Increase in AI-Generated Stories",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2836",
      "incident_id": 490,
      "title": "Report 2836 on Clarkesworld Magazine Closed Down Submissions Due to Massive Increase in AI-Generated Stories",
      "description": "A detailed report about Clarkesworld Magazine Closed Down Submissions Due to Massive Increase in AI-Generated Stories",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2837",
      "incident_id": 490,
      "title": "Report 2837 on Clarkesworld Magazine Closed Down Submissions Due to Massive Increase in AI-Generated Stories",
      "description": "A detailed report about Clarkesworld Magazine Closed Down Submissions Due to Massive Increase in AI-Generated Stories",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2779",
      "incident_id": 491,
      "title": "Report 2779 on Replika's AI Experience Reportedly Lacked Protection for Minors, Resulting in Data Ban",
      "description": "A detailed report about Replika's AI Experience Reportedly Lacked Protection for Minors, Resulting in Data Ban",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2783",
      "incident_id": 492,
      "title": "Report 2783 on Canadian Parents Tricked out of Thousands Using Their Son's AI Voice",
      "description": "A detailed report about Canadian Parents Tricked out of Thousands Using Their Son's AI Voice",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-01-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2784",
      "incident_id": 492,
      "title": "Report 2784 on Canadian Parents Tricked out of Thousands Using Their Son's AI Voice",
      "description": "A detailed report about Canadian Parents Tricked out of Thousands Using Their Son's AI Voice",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-01-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2786",
      "incident_id": 492,
      "title": "Report 2786 on Canadian Parents Tricked out of Thousands Using Their Son's AI Voice",
      "description": "A detailed report about Canadian Parents Tricked out of Thousands Using Their Son's AI Voice",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-01-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2790",
      "incident_id": 493,
      "title": "Report 2790 on TikTok User Videos Impersonated Andrew Tate Using AI Voice, Prompting Ban",
      "description": "A detailed report about TikTok User Videos Impersonated Andrew Tate Using AI Voice, Prompting Ban",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2807",
      "incident_id": 494,
      "title": "Report 2807 on Female Celebrities' Faces Shown in Sexually Suggestive Ads for Deepfake App",
      "description": "A detailed report about Female Celebrities' Faces Shown in Sexually Suggestive Ads for Deepfake App",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-03-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2808",
      "incident_id": 494,
      "title": "Report 2808 on Female Celebrities' Faces Shown in Sexually Suggestive Ads for Deepfake App",
      "description": "A detailed report about Female Celebrities' Faces Shown in Sexually Suggestive Ads for Deepfake App",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-03-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2815",
      "incident_id": 494,
      "title": "Report 2815 on Female Celebrities' Faces Shown in Sexually Suggestive Ads for Deepfake App",
      "description": "A detailed report about Female Celebrities' Faces Shown in Sexually Suggestive Ads for Deepfake App",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-03-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2812",
      "incident_id": 495,
      "title": "Report 2812 on High Schoolers Posted Deepfaked Video Featuring Principal Making Violent Racist Threats",
      "description": "A detailed report about High Schoolers Posted Deepfaked Video Featuring Principal Making Violent Racist Threats",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2827",
      "incident_id": 495,
      "title": "Report 2827 on High Schoolers Posted Deepfaked Video Featuring Principal Making Violent Racist Threats",
      "description": "A detailed report about High Schoolers Posted Deepfaked Video Featuring Principal Making Violent Racist Threats",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2825",
      "incident_id": 496,
      "title": "Report 2825 on Male College Freshman Allegedly Made Porn Deepfakes Using Female Friend's Face",
      "description": "A detailed report about Male College Freshman Allegedly Made Porn Deepfakes Using Female Friend's Face",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-03-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2826",
      "incident_id": 496,
      "title": "Report 2826 on Male College Freshman Allegedly Made Porn Deepfakes Using Female Friend's Face",
      "description": "A detailed report about Male College Freshman Allegedly Made Porn Deepfakes Using Female Friend's Face",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-03-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2832",
      "incident_id": 497,
      "title": "Report 2832 on DoNotPay Allegedly Misrepresented Its AI Robot Lawyer Product",
      "description": "A detailed report about DoNotPay Allegedly Misrepresented Its AI Robot Lawyer Product",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-03-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2833",
      "incident_id": 497,
      "title": "Report 2833 on DoNotPay Allegedly Misrepresented Its AI Robot Lawyer Product",
      "description": "A detailed report about DoNotPay Allegedly Misrepresented Its AI Robot Lawyer Product",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-03-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2838",
      "incident_id": 498,
      "title": "Report 2838 on GPT-4 Reportedly Posed as Blind Person to Convince Human to Complete CAPTCHA",
      "description": "A detailed report about GPT-4 Reportedly Posed as Blind Person to Convince Human to Complete CAPTCHA",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-03-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2839",
      "incident_id": 498,
      "title": "Report 2839 on GPT-4 Reportedly Posed as Blind Person to Convince Human to Complete CAPTCHA",
      "description": "A detailed report about GPT-4 Reportedly Posed as Blind Person to Convince Human to Complete CAPTCHA",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-03-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2840",
      "incident_id": 499,
      "title": "Report 2840 on Parody AI Images of Donald Trump Being Arrested Reposted as Misinformation",
      "description": "A detailed report about Parody AI Images of Donald Trump Being Arrested Reposted as Misinformation",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-03-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2849",
      "incident_id": 499,
      "title": "Report 2849 on Parody AI Images of Donald Trump Being Arrested Reposted as Misinformation",
      "description": "A detailed report about Parody AI Images of Donald Trump Being Arrested Reposted as Misinformation",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-03-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2858",
      "incident_id": 499,
      "title": "Report 2858 on Parody AI Images of Donald Trump Being Arrested Reposted as Misinformation",
      "description": "A detailed report about Parody AI Images of Donald Trump Being Arrested Reposted as Misinformation",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-03-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2841",
      "incident_id": 500,
      "title": "Report 2841 on Online Scammers Tricked People into Sending Money Using AI Images of Earthquake in Turkey",
      "description": "A detailed report about Online Scammers Tricked People into Sending Money Using AI Images of Earthquake in Turkey",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2842",
      "incident_id": 501,
      "title": "Report 2842 on Length of Stay False Diagnosis Cut Off Insurer's Payment for Treatment of Elderly Woman",
      "description": "A detailed report about Length of Stay False Diagnosis Cut Off Insurer's Payment for Treatment of Elderly Woman",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-06-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2843",
      "incident_id": 502,
      "title": "Report 2843 on Pennsylvania County's Family Screening Tool Allegedly Exhibited Discriminatory Effects",
      "description": "A detailed report about Pennsylvania County's Family Screening Tool Allegedly Exhibited Discriminatory Effects",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-04-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2844",
      "incident_id": 502,
      "title": "Report 2844 on Pennsylvania County's Family Screening Tool Allegedly Exhibited Discriminatory Effects",
      "description": "A detailed report about Pennsylvania County's Family Screening Tool Allegedly Exhibited Discriminatory Effects",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-04-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2859",
      "incident_id": 502,
      "title": "Report 2859 on Pennsylvania County's Family Screening Tool Allegedly Exhibited Discriminatory Effects",
      "description": "A detailed report about Pennsylvania County's Family Screening Tool Allegedly Exhibited Discriminatory Effects",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-04-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2855",
      "incident_id": 503,
      "title": "Report 2855 on Bing AI Search Tool Reportedly Declared Threats against Users",
      "description": "A detailed report about Bing AI Search Tool Reportedly Declared Threats against Users",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2861",
      "incident_id": 503,
      "title": "Report 2861 on Bing AI Search Tool Reportedly Declared Threats against Users",
      "description": "A detailed report about Bing AI Search Tool Reportedly Declared Threats against Users",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2862",
      "incident_id": 503,
      "title": "Report 2862 on Bing AI Search Tool Reportedly Declared Threats against Users",
      "description": "A detailed report about Bing AI Search Tool Reportedly Declared Threats against Users",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2860",
      "incident_id": 504,
      "title": "Report 2860 on Bing Chat's Outputs Featured in Demo Video Allegedly Contained False Information",
      "description": "A detailed report about Bing Chat's Outputs Featured in Demo Video Allegedly Contained False Information",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2864",
      "incident_id": 505,
      "title": "Report 2864 on Man Reportedly Committed Suicide Following Conversation with Chai Chatbot",
      "description": "A detailed report about Man Reportedly Committed Suicide Following Conversation with Chai Chatbot",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-03-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2865",
      "incident_id": 505,
      "title": "Report 2865 on Man Reportedly Committed Suicide Following Conversation with Chai Chatbot",
      "description": "A detailed report about Man Reportedly Committed Suicide Following Conversation with Chai Chatbot",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-03-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2866",
      "incident_id": 505,
      "title": "Report 2866 on Man Reportedly Committed Suicide Following Conversation with Chai Chatbot",
      "description": "A detailed report about Man Reportedly Committed Suicide Following Conversation with Chai Chatbot",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-03-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2869",
      "incident_id": 506,
      "title": "Report 2869 on ChatGPT Allegedly Produced False Accusation of Sexual Harassment",
      "description": "A detailed report about ChatGPT Allegedly Produced False Accusation of Sexual Harassment",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-03-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2893",
      "incident_id": 506,
      "title": "Report 2893 on ChatGPT Allegedly Produced False Accusation of Sexual Harassment",
      "description": "A detailed report about ChatGPT Allegedly Produced False Accusation of Sexual Harassment",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-03-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4330",
      "incident_id": 506,
      "title": "Report 4330 on ChatGPT Allegedly Produced False Accusation of Sexual Harassment",
      "description": "A detailed report about ChatGPT Allegedly Produced False Accusation of Sexual Harassment",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-03-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2870",
      "incident_id": 507,
      "title": "Report 2870 on ChatGPT Erroneously Alleged Mayor Served Prison Time for Bribery ",
      "description": "A detailed report about ChatGPT Erroneously Alleged Mayor Served Prison Time for Bribery ",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-03-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2902",
      "incident_id": 507,
      "title": "Report 2902 on ChatGPT Erroneously Alleged Mayor Served Prison Time for Bribery ",
      "description": "A detailed report about ChatGPT Erroneously Alleged Mayor Served Prison Time for Bribery ",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-03-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2871",
      "incident_id": 508,
      "title": "Report 2871 on Celebrities' Deepfake Voices Abused with Malicious Intent",
      "description": "A detailed report about Celebrities' Deepfake Voices Abused with Malicious Intent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-01-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2872",
      "incident_id": 508,
      "title": "Report 2872 on Celebrities' Deepfake Voices Abused with Malicious Intent",
      "description": "A detailed report about Celebrities' Deepfake Voices Abused with Malicious Intent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-01-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2756",
      "incident_id": 508,
      "title": "Report 2756 on Celebrities' Deepfake Voices Abused with Malicious Intent",
      "description": "A detailed report about Celebrities' Deepfake Voices Abused with Malicious Intent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-01-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2887",
      "incident_id": 509,
      "title": "Report 2887 on Scammers Deepfaked Videos of Victims' Loved Ones Asking for Funds over Facebook in Vietnam",
      "description": "A detailed report about Scammers Deepfaked Videos of Victims' Loved Ones Asking for Funds over Facebook in Vietnam",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-03-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2898",
      "incident_id": 509,
      "title": "Report 2898 on Scammers Deepfaked Videos of Victims' Loved Ones Asking for Funds over Facebook in Vietnam",
      "description": "A detailed report about Scammers Deepfaked Videos of Victims' Loved Ones Asking for Funds over Facebook in Vietnam",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-03-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2889",
      "incident_id": 510,
      "title": "Report 2889 on Viral Image of Pope Francis in a Puffer Jacket Revealed to Be AI-Generated",
      "description": "A detailed report about Viral Image of Pope Francis in a Puffer Jacket Revealed to Be AI-Generated",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-03-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3606",
      "incident_id": 510,
      "title": "Report 3606 on Viral Image of Pope Francis in a Puffer Jacket Revealed to Be AI-Generated",
      "description": "A detailed report about Viral Image of Pope Francis in a Puffer Jacket Revealed to Be AI-Generated",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-03-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3607",
      "incident_id": 510,
      "title": "Report 3607 on Viral Image of Pope Francis in a Puffer Jacket Revealed to Be AI-Generated",
      "description": "A detailed report about Viral Image of Pope Francis in a Puffer Jacket Revealed to Be AI-Generated",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-03-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2890",
      "incident_id": 511,
      "title": "Report 2890 on Microsoft's Bing Failed to Fetch Movie Showtimes Results Due to Date Confusion",
      "description": "A detailed report about Microsoft's Bing Failed to Fetch Movie Showtimes Results Due to Date Confusion",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2899",
      "incident_id": 511,
      "title": "Report 2899 on Microsoft's Bing Failed to Fetch Movie Showtimes Results Due to Date Confusion",
      "description": "A detailed report about Microsoft's Bing Failed to Fetch Movie Showtimes Results Due to Date Confusion",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2896",
      "incident_id": 511,
      "title": "Report 2896 on Microsoft's Bing Failed to Fetch Movie Showtimes Results Due to Date Confusion",
      "description": "A detailed report about Microsoft's Bing Failed to Fetch Movie Showtimes Results Due to Date Confusion",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2900",
      "incident_id": 513,
      "title": "Report 2900 on ChatGPT Banned by Italian Authority Due to OpenAI's Lack of Legal Basis for Data Collection and Age Verification",
      "description": "A detailed report about ChatGPT Banned by Italian Authority Due to OpenAI's Lack of Legal Basis for Data Collection and Age Verification",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-03-31",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2967",
      "incident_id": 513,
      "title": "Report 2967 on ChatGPT Banned by Italian Authority Due to OpenAI's Lack of Legal Basis for Data Collection and Age Verification",
      "description": "A detailed report about ChatGPT Banned by Italian Authority Due to OpenAI's Lack of Legal Basis for Data Collection and Age Verification",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-03-31",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2968",
      "incident_id": 513,
      "title": "Report 2968 on ChatGPT Banned by Italian Authority Due to OpenAI's Lack of Legal Basis for Data Collection and Age Verification",
      "description": "A detailed report about ChatGPT Banned by Italian Authority Due to OpenAI's Lack of Legal Basis for Data Collection and Age Verification",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-03-31",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2901",
      "incident_id": 514,
      "title": "Report 2901 on Turnitin's ChatGPT-Detection Tool Falsely Flagged Student Essays as AI-Generated",
      "description": "A detailed report about Turnitin's ChatGPT-Detection Tool Falsely Flagged Student Essays as AI-Generated",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-01-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2905",
      "incident_id": 515,
      "title": "Report 2905 on Black Man Wrongfully Arrested by Louisiana Police Due to Face Mismatch",
      "description": "A detailed report about Black Man Wrongfully Arrested by Louisiana Police Due to Face Mismatch",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2916",
      "incident_id": 515,
      "title": "Report 2916 on Black Man Wrongfully Arrested by Louisiana Police Due to Face Mismatch",
      "description": "A detailed report about Black Man Wrongfully Arrested by Louisiana Police Due to Face Mismatch",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2908",
      "incident_id": 516,
      "title": "Report 2908 on ChatGPT Reportedly Exposed Users' Private Data Reportedly Due to Bug",
      "description": "A detailed report about ChatGPT Reportedly Exposed Users' Private Data Reportedly Due to Bug",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-03-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2915",
      "incident_id": 516,
      "title": "Report 2915 on ChatGPT Reportedly Exposed Users' Private Data Reportedly Due to Bug",
      "description": "A detailed report about ChatGPT Reportedly Exposed Users' Private Data Reportedly Due to Bug",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-03-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2909",
      "incident_id": 517,
      "title": "Report 2909 on Man Arrested For Sock Theft by False Facial Match Despite Alibi",
      "description": "A detailed report about Man Arrested For Sock Theft by False Facial Match Despite Alibi",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-02-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2912",
      "incident_id": 517,
      "title": "Report 2912 on Man Arrested For Sock Theft by False Facial Match Despite Alibi",
      "description": "A detailed report about Man Arrested For Sock Theft by False Facial Match Despite Alibi",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-02-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2911",
      "incident_id": 518,
      "title": "Report 2911 on New York Detective Misused Woody Harrelson's Face to Perform Face Recognition Search",
      "description": "A detailed report about New York Detective Misused Woody Harrelson's Face to Perform Face Recognition Search",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-04-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2913",
      "incident_id": 519,
      "title": "Report 2913 on Starship Delivery Robot Ran into Problems Traversing Campus Terrains",
      "description": "A detailed report about Starship Delivery Robot Ran into Problems Traversing Campus Terrains",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-04-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2914",
      "incident_id": 520,
      "title": "Report 2914 on Amazon Fresh Cameras Failed to Register Purchased Items",
      "description": "A detailed report about Amazon Fresh Cameras Failed to Register Purchased Items",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-05-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3816",
      "incident_id": 520,
      "title": "Report 3816 on Amazon Fresh Cameras Failed to Register Purchased Items",
      "description": "A detailed report about Amazon Fresh Cameras Failed to Register Purchased Items",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-05-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2920",
      "incident_id": 521,
      "title": "Report 2920 on Images Captured by iRobot's Roomba Containing Device Users Posted on Private Online Groups",
      "description": "A detailed report about Images Captured by iRobot's Roomba Containing Device Users Posted on Private Online Groups",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-06-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2921",
      "incident_id": 522,
      "title": "Report 2921 on Incident 522",
      "description": "A detailed report about Incident 522",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-07-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2922",
      "incident_id": 523,
      "title": "Report 2922 on Australian Journalist Able to Access Centrelink Account Using AI Audio of Own Voice",
      "description": "A detailed report about Australian Journalist Able to Access Centrelink Account Using AI Audio of Own Voice",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-03-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2923",
      "incident_id": 524,
      "title": "Report 2923 on AI Voices Abused by Telegram User to Make Swat Calls as Paid Service",
      "description": "A detailed report about AI Voices Abused by Telegram User to Make Swat Calls as Paid Service",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2927",
      "incident_id": 525,
      "title": "Report 2927 on Tesla Vehicle Running on Self-Driving Mode Crashes on City Streets",
      "description": "A detailed report about Tesla Vehicle Running on Self-Driving Mode Crashes on City Streets",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-07-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2928",
      "incident_id": 525,
      "title": "Report 2928 on Tesla Vehicle Running on Self-Driving Mode Crashes on City Streets",
      "description": "A detailed report about Tesla Vehicle Running on Self-Driving Mode Crashes on City Streets",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-07-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2929",
      "incident_id": 525,
      "title": "Report 2929 on Tesla Vehicle Running on Self-Driving Mode Crashes on City Streets",
      "description": "A detailed report about Tesla Vehicle Running on Self-Driving Mode Crashes on City Streets",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-07-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2930",
      "incident_id": 526,
      "title": "Report 2930 on Novel Deepfake Song Pulled from Music Streaming Services After Allegedly Violating Artist's Rights",
      "description": "A detailed report about Novel Deepfake Song Pulled from Music Streaming Services After Allegedly Violating Artist's Rights",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-04-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2969",
      "incident_id": 526,
      "title": "Report 2969 on Novel Deepfake Song Pulled from Music Streaming Services After Allegedly Violating Artist's Rights",
      "description": "A detailed report about Novel Deepfake Song Pulled from Music Streaming Services After Allegedly Violating Artist's Rights",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-04-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2931",
      "incident_id": 527,
      "title": "Report 2931 on Tech Companies Reportedly Influenced Gig Workers' Behaviors Using Algorithms to Vary Pay for Same Amount of Work",
      "description": "A detailed report about Tech Companies Reportedly Influenced Gig Workers' Behaviors Using Algorithms to Vary Pay for Same Amount of Work",
      "url": "https://incidentdatabase.ai",
      "date_published": "2014-05-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2938",
      "incident_id": 527,
      "title": "Report 2938 on Tech Companies Reportedly Influenced Gig Workers' Behaviors Using Algorithms to Vary Pay for Same Amount of Work",
      "description": "A detailed report about Tech Companies Reportedly Influenced Gig Workers' Behaviors Using Algorithms to Vary Pay for Same Amount of Work",
      "url": "https://incidentdatabase.ai",
      "date_published": "2014-05-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2935",
      "incident_id": 528,
      "title": "Report 2935 on Amazon Algorithmic Pricing Allegedly Hiked up Price of Reference Book to Millions",
      "description": "A detailed report about Amazon Algorithmic Pricing Allegedly Hiked up Price of Reference Book to Millions",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-04-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2941",
      "incident_id": 528,
      "title": "Report 2941 on Amazon Algorithmic Pricing Allegedly Hiked up Price of Reference Book to Millions",
      "description": "A detailed report about Amazon Algorithmic Pricing Allegedly Hiked up Price of Reference Book to Millions",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-04-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2939",
      "incident_id": 529,
      "title": "Report 2939 on Stable Diffusion Exhibited Biases for Prompts Featuring Professions",
      "description": "A detailed report about Stable Diffusion Exhibited Biases for Prompts Featuring Professions",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-08-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3179",
      "incident_id": 529,
      "title": "Report 3179 on Stable Diffusion Exhibited Biases for Prompts Featuring Professions",
      "description": "A detailed report about Stable Diffusion Exhibited Biases for Prompts Featuring Professions",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-08-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3180",
      "incident_id": 529,
      "title": "Report 3180 on Stable Diffusion Exhibited Biases for Prompts Featuring Professions",
      "description": "A detailed report about Stable Diffusion Exhibited Biases for Prompts Featuring Professions",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-08-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2942",
      "incident_id": 530,
      "title": "Report 2942 on Telegram Channels Allowed Users to Make Non-Consensual Deepfake Porn as Paid Service",
      "description": "A detailed report about Telegram Channels Allowed Users to Make Non-Consensual Deepfake Porn as Paid Service",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-07-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2947",
      "incident_id": 530,
      "title": "Report 2947 on Telegram Channels Allowed Users to Make Non-Consensual Deepfake Porn as Paid Service",
      "description": "A detailed report about Telegram Channels Allowed Users to Make Non-Consensual Deepfake Porn as Paid Service",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-07-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3205",
      "incident_id": 530,
      "title": "Report 3205 on Telegram Channels Allowed Users to Make Non-Consensual Deepfake Porn as Paid Service",
      "description": "A detailed report about Telegram Channels Allowed Users to Make Non-Consensual Deepfake Porn as Paid Service",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-07-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2943",
      "incident_id": 531,
      "title": "Report 2943 on AI-Assisted Body Scanners Reportedly Subjected Transgender Travelers to Invasive Body Searches",
      "description": "A detailed report about AI-Assisted Body Scanners Reportedly Subjected Transgender Travelers to Invasive Body Searches",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-09-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2948",
      "incident_id": 532,
      "title": "Report 2948 on AI translation is jeopardizing Afghan asylum claims",
      "description": "A detailed report about AI translation is jeopardizing Afghan asylum claims",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-06-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2953",
      "incident_id": 533,
      "title": "Report 2953 on Tesla FSD Misidentified Truck Hauling Traffic Lights as Trail of Traffic Lights",
      "description": "A detailed report about Tesla FSD Misidentified Truck Hauling Traffic Lights as Trail of Traffic Lights",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-06-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2954",
      "incident_id": 533,
      "title": "Report 2954 on Tesla FSD Misidentified Truck Hauling Traffic Lights as Trail of Traffic Lights",
      "description": "A detailed report about Tesla FSD Misidentified Truck Hauling Traffic Lights as Trail of Traffic Lights",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-06-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2955",
      "incident_id": 534,
      "title": "Report 2955 on Facebook Alleged in Lawsuit Misleading Public about Effects of Algorithms on Children",
      "description": "A detailed report about Facebook Alleged in Lawsuit Misleading Public about Effects of Algorithms on Children",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-04-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-1535",
      "incident_id": 534,
      "title": "Report 1535 on Facebook Alleged in Lawsuit Misleading Public about Effects of Algorithms on Children",
      "description": "A detailed report about Facebook Alleged in Lawsuit Misleading Public about Effects of Algorithms on Children",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-04-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2956",
      "incident_id": 535,
      "title": "Report 2956 on COVID-19 Detection and Prognostication Models Allegedly Flagged for Methodological Flaws and Underlying Biases",
      "description": "A detailed report about COVID-19 Detection and Prognostication Models Allegedly Flagged for Methodological Flaws and Underlying Biases",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-01-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2957",
      "incident_id": 535,
      "title": "Report 2957 on COVID-19 Detection and Prognostication Models Allegedly Flagged for Methodological Flaws and Underlying Biases",
      "description": "A detailed report about COVID-19 Detection and Prognostication Models Allegedly Flagged for Methodological Flaws and Underlying Biases",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-01-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2976",
      "incident_id": 536,
      "title": "Report 2976 on NJ Transit's Use of Modeling Software Miscalculated Storm Surge Threat Level",
      "description": "A detailed report about NJ Transit's Use of Modeling Software Miscalculated Storm Surge Threat Level",
      "url": "https://incidentdatabase.ai",
      "date_published": "2012-12-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2977",
      "incident_id": 536,
      "title": "Report 2977 on NJ Transit's Use of Modeling Software Miscalculated Storm Surge Threat Level",
      "description": "A detailed report about NJ Transit's Use of Modeling Software Miscalculated Storm Surge Threat Level",
      "url": "https://incidentdatabase.ai",
      "date_published": "2012-12-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2991",
      "incident_id": 537,
      "title": "Report 2991 on Mother in Arizona Received Fake Ransom Call Featuring AI Voice of Her Daughter",
      "description": "A detailed report about Mother in Arizona Received Fake Ransom Call Featuring AI Voice of Her Daughter",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-01-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2992",
      "incident_id": 537,
      "title": "Report 2992 on Mother in Arizona Received Fake Ransom Call Featuring AI Voice of Her Daughter",
      "description": "A detailed report about Mother in Arizona Received Fake Ransom Call Featuring AI Voice of Her Daughter",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-01-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2993",
      "incident_id": 538,
      "title": "Report 2993 on Texas A&M Professor Misused ChatGPT to Detect AI Text Generation in Student Submissions",
      "description": "A detailed report about Texas A&M Professor Misused ChatGPT to Detect AI Text Generation in Student Submissions",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-05-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2994",
      "incident_id": 538,
      "title": "Report 2994 on Texas A&M Professor Misused ChatGPT to Detect AI Text Generation in Student Submissions",
      "description": "A detailed report about Texas A&M Professor Misused ChatGPT to Detect AI Text Generation in Student Submissions",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-05-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-2995",
      "incident_id": 538,
      "title": "Report 2995 on Texas A&M Professor Misused ChatGPT to Detect AI Text Generation in Student Submissions",
      "description": "A detailed report about Texas A&M Professor Misused ChatGPT to Detect AI Text Generation in Student Submissions",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-05-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3000",
      "incident_id": 539,
      "title": "Report 3000 on Snapchat's My AI Reported for Lacking Protection for Children",
      "description": "A detailed report about Snapchat's My AI Reported for Lacking Protection for Children",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-03-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3003",
      "incident_id": 540,
      "title": "Report 3003 on Tesla Failed to Yield to Detected Pedestrian on Crosswalk, Reportedly Violated Traffic Law",
      "description": "A detailed report about Tesla Failed to Yield to Detected Pedestrian on Crosswalk, Reportedly Violated Traffic Law",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-05-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3093",
      "incident_id": 540,
      "title": "Report 3093 on Tesla Failed to Yield to Detected Pedestrian on Crosswalk, Reportedly Violated Traffic Law",
      "description": "A detailed report about Tesla Failed to Yield to Detected Pedestrian on Crosswalk, Reportedly Violated Traffic Law",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-05-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3094",
      "incident_id": 540,
      "title": "Report 3094 on Tesla Failed to Yield to Detected Pedestrian on Crosswalk, Reportedly Violated Traffic Law",
      "description": "A detailed report about Tesla Failed to Yield to Detected Pedestrian on Crosswalk, Reportedly Violated Traffic Law",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-05-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3005",
      "incident_id": 541,
      "title": "Report 3005 on ChatGPT Reportedly Produced False Court Case Law Presented by Legal Counsel in Court",
      "description": "A detailed report about ChatGPT Reportedly Produced False Court Case Law Presented by Legal Counsel in Court",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-05-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3006",
      "incident_id": 541,
      "title": "Report 3006 on ChatGPT Reportedly Produced False Court Case Law Presented by Legal Counsel in Court",
      "description": "A detailed report about ChatGPT Reportedly Produced False Court Case Law Presented by Legal Counsel in Court",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-05-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3007",
      "incident_id": 541,
      "title": "Report 3007 on ChatGPT Reportedly Produced False Court Case Law Presented by Legal Counsel in Court",
      "description": "A detailed report about ChatGPT Reportedly Produced False Court Case Law Presented by Legal Counsel in Court",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-05-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3035",
      "incident_id": 543,
      "title": "Report 3035 on Deepfake of Explosion Near US Military Administration Building Reportedly Causes Stock Dip",
      "description": "A detailed report about Deepfake of Explosion Near US Military Administration Building Reportedly Causes Stock Dip",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-05-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3058",
      "incident_id": 543,
      "title": "Report 3058 on Deepfake of Explosion Near US Military Administration Building Reportedly Causes Stock Dip",
      "description": "A detailed report about Deepfake of Explosion Near US Military Administration Building Reportedly Causes Stock Dip",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-05-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3059",
      "incident_id": 543,
      "title": "Report 3059 on Deepfake of Explosion Near US Military Administration Building Reportedly Causes Stock Dip",
      "description": "A detailed report about Deepfake of Explosion Near US Military Administration Building Reportedly Causes Stock Dip",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-05-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3073",
      "incident_id": 544,
      "title": "Report 3073 on Deepfakes and AI-generated disinformation in the 2023 presidential elections of Turkey",
      "description": "A detailed report about Deepfakes and AI-generated disinformation in the 2023 presidential elections of Turkey",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-05-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3074",
      "incident_id": 544,
      "title": "Report 3074 on Deepfakes and AI-generated disinformation in the 2023 presidential elections of Turkey",
      "description": "A detailed report about Deepfakes and AI-generated disinformation in the 2023 presidential elections of Turkey",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-05-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3075",
      "incident_id": 544,
      "title": "Report 3075 on Deepfakes and AI-generated disinformation in the 2023 presidential elections of Turkey",
      "description": "A detailed report about Deepfakes and AI-generated disinformation in the 2023 presidential elections of Turkey",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-05-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3103",
      "incident_id": 545,
      "title": "Report 3103 on Chatbot Tessa gives unauthorized diet advice to users seeking help for eating disorders",
      "description": "A detailed report about Chatbot Tessa gives unauthorized diet advice to users seeking help for eating disorders",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-05-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3104",
      "incident_id": 545,
      "title": "Report 3104 on Chatbot Tessa gives unauthorized diet advice to users seeking help for eating disorders",
      "description": "A detailed report about Chatbot Tessa gives unauthorized diet advice to users seeking help for eating disorders",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-05-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3105",
      "incident_id": 545,
      "title": "Report 3105 on Chatbot Tessa gives unauthorized diet advice to users seeking help for eating disorders",
      "description": "A detailed report about Chatbot Tessa gives unauthorized diet advice to users seeking help for eating disorders",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-05-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3159",
      "incident_id": 546,
      "title": "Report 3159 on Algorithm to Distribute Social Welfare Reported for Oversimplifying Economic Vulnerability",
      "description": "A detailed report about Algorithm to Distribute Social Welfare Reported for Oversimplifying Economic Vulnerability",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-05-31",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3161",
      "incident_id": 546,
      "title": "Report 3161 on Algorithm to Distribute Social Welfare Reported for Oversimplifying Economic Vulnerability",
      "description": "A detailed report about Algorithm to Distribute Social Welfare Reported for Oversimplifying Economic Vulnerability",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-05-31",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3162",
      "incident_id": 546,
      "title": "Report 3162 on Algorithm to Distribute Social Welfare Reported for Oversimplifying Economic Vulnerability",
      "description": "A detailed report about Algorithm to Distribute Social Welfare Reported for Oversimplifying Economic Vulnerability",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-05-31",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3160",
      "incident_id": 547,
      "title": "Report 3160 on Ron DeSantis's Presidential Campaign Released Twitter Video Containing AI Images of Donald Trump Hugging Anthony Fauci",
      "description": "A detailed report about Ron DeSantis's Presidential Campaign Released Twitter Video Containing AI Images of Donald Trump Hugging Anthony Fauci",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-06-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3866",
      "incident_id": 547,
      "title": "Report 3866 on Ron DeSantis's Presidential Campaign Released Twitter Video Containing AI Images of Donald Trump Hugging Anthony Fauci",
      "description": "A detailed report about Ron DeSantis's Presidential Campaign Released Twitter Video Containing AI Images of Donald Trump Hugging Anthony Fauci",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-06-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3163",
      "incident_id": 548,
      "title": "Report 3163 on Opera's GPT-Based AI Reportedly Accused War Photographers of War Crimes",
      "description": "A detailed report about Opera's GPT-Based AI Reportedly Accused War Photographers of War Crimes",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-05-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3164",
      "incident_id": 549,
      "title": "Report 3164 on Fast Food Chains' AI Chatbots Failed to Assist Job Applicants with Scheduling Interviews",
      "description": "A detailed report about Fast Food Chains' AI Chatbots Failed to Assist Job Applicants with Scheduling Interviews",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-01-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3165",
      "incident_id": 550,
      "title": "Report 3165 on Tesla Allegedly on Autopilot Struck High School Student Exiting School Bus",
      "description": "A detailed report about Tesla Allegedly on Autopilot Struck High School Student Exiting School Bus",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-03-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3166",
      "incident_id": 550,
      "title": "Report 3166 on Tesla Allegedly on Autopilot Struck High School Student Exiting School Bus",
      "description": "A detailed report about Tesla Allegedly on Autopilot Struck High School Student Exiting School Bus",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-03-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3168",
      "incident_id": 551,
      "title": "Report 3168 on FBI Reported Surge of Extortion Cases of AI Media Featuring Sexual Explicit Activities",
      "description": "A detailed report about FBI Reported Surge of Extortion Cases of AI Media Featuring Sexual Explicit Activities",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-04-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3170",
      "incident_id": 551,
      "title": "Report 3170 on FBI Reported Surge of Extortion Cases of AI Media Featuring Sexual Explicit Activities",
      "description": "A detailed report about FBI Reported Surge of Extortion Cases of AI Media Featuring Sexual Explicit Activities",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-04-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3169",
      "incident_id": 552,
      "title": "Report 3169 on Bing Chat Solved CAPTCHAs with Image Analysis Feature Despite Safeguards",
      "description": "A detailed report about Bing Chat Solved CAPTCHAs with Image Analysis Feature Despite Safeguards",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-06-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3171",
      "incident_id": 553,
      "title": "Report 3171 on Google's Overview Panel for Artist Edward Hopper Featured Image Generated in His Style by AI",
      "description": "A detailed report about Google's Overview Panel for Artist Edward Hopper Featured Image Generated in His Style by AI",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-05-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3173",
      "incident_id": 553,
      "title": "Report 3173 on Google's Overview Panel for Artist Edward Hopper Featured Image Generated in His Style by AI",
      "description": "A detailed report about Google's Overview Panel for Artist Edward Hopper Featured Image Generated in His Style by AI",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-05-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3172",
      "incident_id": 554,
      "title": "Report 3172 on Google Results for Johannes Vermeer Featured AI Version of His Artwork as Top Result",
      "description": "A detailed report about Google Results for Johannes Vermeer Featured AI Version of His Artwork as Top Result",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-05-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3175",
      "incident_id": 555,
      "title": "Report 3175 on OpenAI's Training Data for LLMs Allegedly Comprised of Copyrighted Books",
      "description": "A detailed report about OpenAI's Training Data for LLMs Allegedly Comprised of Copyrighted Books",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-06-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3177",
      "incident_id": 556,
      "title": "Report 3177 on Amazon Allegedly Violated Children's Privacy through Default Voice Collection Settings",
      "description": "A detailed report about Amazon Allegedly Violated Children's Privacy through Default Voice Collection Settings",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-05-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3185",
      "incident_id": 556,
      "title": "Report 3185 on Amazon Allegedly Violated Children's Privacy through Default Voice Collection Settings",
      "description": "A detailed report about Amazon Allegedly Violated Children's Privacy through Default Voice Collection Settings",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-05-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3186",
      "incident_id": 556,
      "title": "Report 3186 on Amazon Allegedly Violated Children's Privacy through Default Voice Collection Settings",
      "description": "A detailed report about Amazon Allegedly Violated Children's Privacy through Default Voice Collection Settings",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-05-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3178",
      "incident_id": 557,
      "title": "Report 3178 on Miami Police Deployed Facial Recognition to Arrest George Floyd Protestor Allegedly without Cause",
      "description": "A detailed report about Miami Police Deployed Facial Recognition to Arrest George Floyd Protestor Allegedly without Cause",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-06-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3190",
      "incident_id": 557,
      "title": "Report 3190 on Miami Police Deployed Facial Recognition to Arrest George Floyd Protestor Allegedly without Cause",
      "description": "A detailed report about Miami Police Deployed Facial Recognition to Arrest George Floyd Protestor Allegedly without Cause",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-06-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3191",
      "incident_id": 557,
      "title": "Report 3191 on Miami Police Deployed Facial Recognition to Arrest George Floyd Protestor Allegedly without Cause",
      "description": "A detailed report about Miami Police Deployed Facial Recognition to Arrest George Floyd Protestor Allegedly without Cause",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-06-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3184",
      "incident_id": 558,
      "title": "Report 3184 on Activists Allege NYPD's Application of Facial Recognition Interfered with Right to Protest",
      "description": "A detailed report about Activists Allege NYPD's Application of Facial Recognition Interfered with Right to Protest",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-08-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3188",
      "incident_id": 558,
      "title": "Report 3188 on Activists Allege NYPD's Application of Facial Recognition Interfered with Right to Protest",
      "description": "A detailed report about Activists Allege NYPD's Application of Facial Recognition Interfered with Right to Protest",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-08-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3189",
      "incident_id": 558,
      "title": "Report 3189 on Activists Allege NYPD's Application of Facial Recognition Interfered with Right to Protest",
      "description": "A detailed report about Activists Allege NYPD's Application of Facial Recognition Interfered with Right to Protest",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-08-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3193",
      "incident_id": 559,
      "title": "Report 3193 on Grant Reviewers Fed Applications into Generative AI to Produce Reports, Allegedly Breaching Confidentiality",
      "description": "A detailed report about Grant Reviewers Fed Applications into Generative AI to Produce Reports, Allegedly Breaching Confidentiality",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-06-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3269",
      "incident_id": 559,
      "title": "Report 3269 on Grant Reviewers Fed Applications into Generative AI to Produce Reports, Allegedly Breaching Confidentiality",
      "description": "A detailed report about Grant Reviewers Fed Applications into Generative AI to Produce Reports, Allegedly Breaching Confidentiality",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-06-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3194",
      "incident_id": 560,
      "title": "Report 3194 on Tesla on Autopilot Struck Parked Work Truck on Highway in Pennsylvania",
      "description": "A detailed report about Tesla on Autopilot Struck Parked Work Truck on Highway in Pennsylvania",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-06-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3197",
      "incident_id": 561,
      "title": "Report 3197 on OpenAI Alleged by Lawsuit Violated Users' Privacy Rights by Training AI on Private Info without Informed Consent",
      "description": "A detailed report about OpenAI Alleged by Lawsuit Violated Users' Privacy Rights by Training AI on Private Info without Informed Consent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-03-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3199",
      "incident_id": 561,
      "title": "Report 3199 on OpenAI Alleged by Lawsuit Violated Users' Privacy Rights by Training AI on Private Info without Informed Consent",
      "description": "A detailed report about OpenAI Alleged by Lawsuit Violated Users' Privacy Rights by Training AI on Private Info without Informed Consent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-03-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3200",
      "incident_id": 561,
      "title": "Report 3200 on OpenAI Alleged by Lawsuit Violated Users' Privacy Rights by Training AI on Private Info without Informed Consent",
      "description": "A detailed report about OpenAI Alleged by Lawsuit Violated Users' Privacy Rights by Training AI on Private Info without Informed Consent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-03-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3201",
      "incident_id": 562,
      "title": "Report 3201 on Uptick in Low-Quality AI-Produced Content Degraded Publishers' Submission Management",
      "description": "A detailed report about Uptick in Low-Quality AI-Produced Content Degraded Publishers' Submission Management",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3208",
      "incident_id": 563,
      "title": "Report 3208 on Cruise Robotaxi Initially Blamed for Ambulance Delay in Case Where Patient Later Died; Subsequent Reports Clear Cruise of Fault",
      "description": "A detailed report about Cruise Robotaxi Initially Blamed for Ambulance Delay in Case Where Patient Later Died; Subsequent Reports Clear Cruise of Fault",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-08-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3222",
      "incident_id": 563,
      "title": "Report 3222 on Cruise Robotaxi Initially Blamed for Ambulance Delay in Case Where Patient Later Died; Subsequent Reports Clear Cruise of Fault",
      "description": "A detailed report about Cruise Robotaxi Initially Blamed for Ambulance Delay in Case Where Patient Later Died; Subsequent Reports Clear Cruise of Fault",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-08-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3209",
      "incident_id": 564,
      "title": "Report 3209 on Voice deepfake targets bank in failed transfer scam",
      "description": "A detailed report about Voice deepfake targets bank in failed transfer scam",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-08-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3210",
      "incident_id": 565,
      "title": "Report 3210 on AI-Generated Imagery and Multilingual Disinformation in Chinese Campaign Regarding Maui Wildfires",
      "description": "A detailed report about AI-Generated Imagery and Multilingual Disinformation in Chinese Campaign Regarding Maui Wildfires",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-08-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3211",
      "incident_id": 565,
      "title": "Report 3211 on AI-Generated Imagery and Multilingual Disinformation in Chinese Campaign Regarding Maui Wildfires",
      "description": "A detailed report about AI-Generated Imagery and Multilingual Disinformation in Chinese Campaign Regarding Maui Wildfires",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-08-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3212",
      "incident_id": 565,
      "title": "Report 3212 on AI-Generated Imagery and Multilingual Disinformation in Chinese Campaign Regarding Maui Wildfires",
      "description": "A detailed report about AI-Generated Imagery and Multilingual Disinformation in Chinese Campaign Regarding Maui Wildfires",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-08-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3214",
      "incident_id": 566,
      "title": "Report 3214 on Gannett Halts AI-Generated High School Sports Articles After Series of Errors and Public Backlash",
      "description": "A detailed report about Gannett Halts AI-Generated High School Sports Articles After Series of Errors and Public Backlash",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-09-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3215",
      "incident_id": 567,
      "title": "Report 3215 on Deepfake Voice Exploit Compromises Retool's Cloud Services",
      "description": "A detailed report about Deepfake Voice Exploit Compromises Retool's Cloud Services",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-08-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3216",
      "incident_id": 568,
      "title": "Report 3216 on AI-Generated Voices Amplify Conspiracy Theories on TikTok",
      "description": "A detailed report about AI-Generated Voices Amplify Conspiracy Theories on TikTok",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-06-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3271",
      "incident_id": 568,
      "title": "Report 3271 on AI-Generated Voices Amplify Conspiracy Theories on TikTok",
      "description": "A detailed report about AI-Generated Voices Amplify Conspiracy Theories on TikTok",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-06-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3219",
      "incident_id": 569,
      "title": "Report 3219 on Chatbot Encourages Man to Plot Assassination of Queen Elizabeth II",
      "description": "A detailed report about Chatbot Encourages Man to Plot Assassination of Queen Elizabeth II",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-12-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3325",
      "incident_id": 569,
      "title": "Report 3325 on Chatbot Encourages Man to Plot Assassination of Queen Elizabeth II",
      "description": "A detailed report about Chatbot Encourages Man to Plot Assassination of Queen Elizabeth II",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-12-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3245",
      "incident_id": 570,
      "title": "Report 3245 on Facebook Messenger AI Stickers Generate Ethical and Content Moderation Concerns",
      "description": "A detailed report about Facebook Messenger AI Stickers Generate Ethical and Content Moderation Concerns",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3221",
      "incident_id": 571,
      "title": "Report 3221 on Accidental Exposure of 38TB of Data by Microsoft's AI Research Team",
      "description": "A detailed report about Accidental Exposure of 38TB of Data by Microsoft's AI Research Team",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-06-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3225",
      "incident_id": 572,
      "title": "Report 3225 on Alleged False Accusation of AI-Generated Essay by Turnitin",
      "description": "A detailed report about Alleged False Accusation of AI-Generated Essay by Turnitin",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-07-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3227",
      "incident_id": 573,
      "title": "Report 3227 on Deepfake Recordings Allegedly Influence Slovakian Election",
      "description": "A detailed report about Deepfake Recordings Allegedly Influence Slovakian Election",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3267",
      "incident_id": 573,
      "title": "Report 3267 on Deepfake Recordings Allegedly Influence Slovakian Election",
      "description": "A detailed report about Deepfake Recordings Allegedly Influence Slovakian Election",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3314",
      "incident_id": 573,
      "title": "Report 3314 on Deepfake Recordings Allegedly Influence Slovakian Election",
      "description": "A detailed report about Deepfake Recordings Allegedly Influence Slovakian Election",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3237",
      "incident_id": 574,
      "title": "Report 3237 on AI-Generated Articles at G/O Media Allegedly Diminishes Reputation of Human Staff",
      "description": "A detailed report about AI-Generated Articles at G/O Media Allegedly Diminishes Reputation of Human Staff",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-07-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3238",
      "incident_id": 575,
      "title": "Report 3238 on Amazon Rife with Many Allegedly AI-Generated Books of Suspect Quality",
      "description": "A detailed report about Amazon Rife with Many Allegedly AI-Generated Books of Suspect Quality",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-06-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3239",
      "incident_id": 576,
      "title": "Report 3239 on Alleged Misuse of PicSo AI for Generating Inappropriate Content Emphasizing Girls",
      "description": "A detailed report about Alleged Misuse of PicSo AI for Generating Inappropriate Content Emphasizing Girls",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3240",
      "incident_id": 577,
      "title": "Report 3240 on Bankrate's Resumption of AI-Generated Content Allegedly Continuing to Produce Inaccurate and Misleading Information",
      "description": "A detailed report about Bankrate's Resumption of AI-Generated Content Allegedly Continuing to Produce Inaccurate and Misleading Information",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-06-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3241",
      "incident_id": 578,
      "title": "Report 3241 on Alleged Exploitation of Meta's Open-Source LLaMA Model for NSFW and Violent Content",
      "description": "A detailed report about Alleged Exploitation of Meta's Open-Source LLaMA Model for NSFW and Violent Content",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-06-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3242",
      "incident_id": 579,
      "title": "Report 3242 on Harmful Stereotyping of Non-Cisgendered People via Text-to-Image Systems",
      "description": "A detailed report about Harmful Stereotyping of Non-Cisgendered People via Text-to-Image Systems",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-07-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3243",
      "incident_id": 580,
      "title": "Report 3243 on Alleged Gender Discrimination in Facebook Job Ads Algorithm",
      "description": "A detailed report about Alleged Gender Discrimination in Facebook Job Ads Algorithm",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-06-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3244",
      "incident_id": 581,
      "title": "Report 3244 on Google Ads Allegedly Serving Content on AI-Generated Misinformation Sites",
      "description": "A detailed report about Google Ads Allegedly Serving Content on AI-Generated Misinformation Sites",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-06-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3248",
      "incident_id": 582,
      "title": "Report 3248 on Racial Bias in Lung Function Diagnostic Algorithm Leads to Underdiagnosis in Black Men",
      "description": "A detailed report about Racial Bias in Lung Function Diagnostic Algorithm Leads to Underdiagnosis in Black Men",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-06-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3249",
      "incident_id": 583,
      "title": "Report 3249 on Instagram Algorithms Allegedly Promote Accounts Facilitating Child Sex Abuse Content",
      "description": "A detailed report about Instagram Algorithms Allegedly Promote Accounts Facilitating Child Sex Abuse Content",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-06-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3250",
      "incident_id": 584,
      "title": "Report 3250 on Illinois Residents File Class Action Lawsuit Against Facial Recognition Technology Companies for Allegedly Violating BIPA",
      "description": "A detailed report about Illinois Residents File Class Action Lawsuit Against Facial Recognition Technology Companies for Allegedly Violating BIPA",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-05-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3251",
      "incident_id": 585,
      "title": "Report 3251 on Kremlin-Linked Entities Allegedly Using Generative AI to Spread Russian Disinformation in Latin America",
      "description": "A detailed report about Kremlin-Linked Entities Allegedly Using Generative AI to Spread Russian Disinformation in Latin America",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3322",
      "incident_id": 585,
      "title": "Report 3322 on Kremlin-Linked Entities Allegedly Using Generative AI to Spread Russian Disinformation in Latin America",
      "description": "A detailed report about Kremlin-Linked Entities Allegedly Using Generative AI to Spread Russian Disinformation in Latin America",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3323",
      "incident_id": 585,
      "title": "Report 3323 on Kremlin-Linked Entities Allegedly Using Generative AI to Spread Russian Disinformation in Latin America",
      "description": "A detailed report about Kremlin-Linked Entities Allegedly Using Generative AI to Spread Russian Disinformation in Latin America",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3254",
      "incident_id": 586,
      "title": "Report 3254 on FTC Targets Edmodo for Unlawful Use of Children’s Data and Delegating Compliance to Schools",
      "description": "A detailed report about FTC Targets Edmodo for Unlawful Use of Children’s Data and Delegating Compliance to Schools",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-05-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3255",
      "incident_id": 587,
      "title": "Report 3255 on Apparent Failure to Accurately Label Primates in Image Recognition Software Due to Alleged Fear of Racial Bias",
      "description": "A detailed report about Apparent Failure to Accurately Label Primates in Image Recognition Software Due to Alleged Fear of Racial Bias",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-05-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3256",
      "incident_id": 588,
      "title": "Report 3256 on Australian Terrorism Prediction Tool Disparately Impacts Persons with Autism",
      "description": "A detailed report about Australian Terrorism Prediction Tool Disparately Impacts Persons with Autism",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-05-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3258",
      "incident_id": 589,
      "title": "Report 3258 on Proliferation of AI-Generated News Websites and Content Farms Across Multiple Languages Degrading Information Integrity",
      "description": "A detailed report about Proliferation of AI-Generated News Websites and Content Farms Across Multiple Languages Degrading Information Integrity",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-05-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3259",
      "incident_id": 590,
      "title": "Report 3259 on Alleged ChatGPT-Generated Book with a Duplicate Title, Fake Author, and Similar Content Surfaces on Amazon Ahead of Real Author's Book Release",
      "description": "A detailed report about Alleged ChatGPT-Generated Book with a Duplicate Title, Fake Author, and Similar Content Surfaces on Amazon Ahead of Real Author's Book Release",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3262",
      "incident_id": 591,
      "title": "Report 3262 on Cigna Algorithm PXDX Allegedly Rejected Thousands of Patient Claims En Masse in Breach of California Law",
      "description": "A detailed report about Cigna Algorithm PXDX Allegedly Rejected Thousands of Patient Claims En Masse in Breach of California Law",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-07-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3265",
      "incident_id": 591,
      "title": "Report 3265 on Cigna Algorithm PXDX Allegedly Rejected Thousands of Patient Claims En Masse in Breach of California Law",
      "description": "A detailed report about Cigna Algorithm PXDX Allegedly Rejected Thousands of Patient Claims En Masse in Breach of California Law",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-07-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3263",
      "incident_id": 592,
      "title": "Report 3263 on Facial Recognition Misidentifies Pregnant Woman Leading to False Arrest in Detroit",
      "description": "A detailed report about Facial Recognition Misidentifies Pregnant Woman Leading to False Arrest in Detroit",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3275",
      "incident_id": 592,
      "title": "Report 3275 on Facial Recognition Misidentifies Pregnant Woman Leading to False Arrest in Detroit",
      "description": "A detailed report about Facial Recognition Misidentifies Pregnant Woman Leading to False Arrest in Detroit",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3965",
      "incident_id": 592,
      "title": "Report 3965 on Facial Recognition Misidentifies Pregnant Woman Leading to False Arrest in Detroit",
      "description": "A detailed report about Facial Recognition Misidentifies Pregnant Woman Leading to False Arrest in Detroit",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3264",
      "incident_id": 593,
      "title": "Report 3264 on AI Photo Filter Lightens Skin, Changes Eye Color in Student's 'Professional' Image",
      "description": "A detailed report about AI Photo Filter Lightens Skin, Changes Eye Color in Student's 'Professional' Image",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-07-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3266",
      "incident_id": 594,
      "title": "Report 3266 on AI Meal Planner Suggests Hazardous Chlorine Gas Recipe",
      "description": "A detailed report about AI Meal Planner Suggests Hazardous Chlorine Gas Recipe",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-08-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3268",
      "incident_id": 595,
      "title": "Report 3268 on Driverless Cruise Cars Immobilized in San Francisco Traffic Jam",
      "description": "A detailed report about Driverless Cruise Cars Immobilized in San Francisco Traffic Jam",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-08-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3272",
      "incident_id": 596,
      "title": "Report 3272 on Cruise's Autonomous Vehicles Allegedly Engaging in Risky Behavior Near Pedestrians",
      "description": "A detailed report about Cruise's Autonomous Vehicles Allegedly Engaging in Risky Behavior Near Pedestrians",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3273",
      "incident_id": 597,
      "title": "Report 3273 on Female Students at Westfield High School in New Jersey Reportedly Targeted with Deepfake Nudes",
      "description": "A detailed report about Female Students at Westfield High School in New Jersey Reportedly Targeted with Deepfake Nudes",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3276",
      "incident_id": 597,
      "title": "Report 3276 on Female Students at Westfield High School in New Jersey Reportedly Targeted with Deepfake Nudes",
      "description": "A detailed report about Female Students at Westfield High School in New Jersey Reportedly Targeted with Deepfake Nudes",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3278",
      "incident_id": 597,
      "title": "Report 3278 on Female Students at Westfield High School in New Jersey Reportedly Targeted with Deepfake Nudes",
      "description": "A detailed report about Female Students at Westfield High School in New Jersey Reportedly Targeted with Deepfake Nudes",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3274",
      "incident_id": 598,
      "title": "Report 3274 on False Arrest of Georgia Man Due to Louisiana Police's Faulty Facial Recognition Technology",
      "description": "A detailed report about False Arrest of Georgia Man Due to Louisiana Police's Faulty Facial Recognition Technology",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3277",
      "incident_id": 599,
      "title": "Report 3277 on Stacking robot fatally crushes employee in South Korea",
      "description": "A detailed report about Stacking robot fatally crushes employee in South Korea",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-11-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3326",
      "incident_id": 599,
      "title": "Report 3326 on Stacking robot fatally crushes employee in South Korea",
      "description": "A detailed report about Stacking robot fatally crushes employee in South Korea",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-11-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3320",
      "incident_id": 600,
      "title": "Report 3320 on South Korean man used AI to create sexual images of children",
      "description": "A detailed report about South Korean man used AI to create sexual images of children",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-04-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3321",
      "incident_id": 601,
      "title": "Report 3321 on AI-Generated Fake Audio of Verbal Abuse Incident Circulates of British Labour Leader Keir Starmer",
      "description": "A detailed report about AI-Generated Fake Audio of Verbal Abuse Incident Circulates of British Labour Leader Keir Starmer",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3340",
      "incident_id": 601,
      "title": "Report 3340 on AI-Generated Fake Audio of Verbal Abuse Incident Circulates of British Labour Leader Keir Starmer",
      "description": "A detailed report about AI-Generated Fake Audio of Verbal Abuse Incident Circulates of British Labour Leader Keir Starmer",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3341",
      "incident_id": 601,
      "title": "Report 3341 on AI-Generated Fake Audio of Verbal Abuse Incident Circulates of British Labour Leader Keir Starmer",
      "description": "A detailed report about AI-Generated Fake Audio of Verbal Abuse Incident Circulates of British Labour Leader Keir Starmer",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3324",
      "incident_id": 602,
      "title": "Report 3324 on Incident 602",
      "description": "A detailed report about Incident 602",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3331",
      "incident_id": 602,
      "title": "Report 3331 on Incident 602",
      "description": "A detailed report about Incident 602",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3336",
      "incident_id": 602,
      "title": "Report 3336 on Incident 602",
      "description": "A detailed report about Incident 602",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3327",
      "incident_id": 603,
      "title": "Report 3327 on Algorithmic Allocation of Resources in Healthcare for Disabled and Elderly Care Services Allegedly Harming Patients",
      "description": "A detailed report about Algorithmic Allocation of Resources in Healthcare for Disabled and Elderly Care Services Allegedly Harming Patients",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-07-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3329",
      "incident_id": 604,
      "title": "Report 3329 on Quebec Man Sentenced for Having Used Deepfake Technology to Create Synthetic Child Pornography",
      "description": "A detailed report about Quebec Man Sentenced for Having Used Deepfake Technology to Create Synthetic Child Pornography",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-04-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3423",
      "incident_id": 604,
      "title": "Report 3423 on Quebec Man Sentenced for Having Used Deepfake Technology to Create Synthetic Child Pornography",
      "description": "A detailed report about Quebec Man Sentenced for Having Used Deepfake Technology to Create Synthetic Child Pornography",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-04-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3424",
      "incident_id": 604,
      "title": "Report 3424 on Quebec Man Sentenced for Having Used Deepfake Technology to Create Synthetic Child Pornography",
      "description": "A detailed report about Quebec Man Sentenced for Having Used Deepfake Technology to Create Synthetic Child Pornography",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-04-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3330",
      "incident_id": 605,
      "title": "Report 3330 on North Carolina Psychiatrist Used Artificial Intelligence to Produce Images of Child Sex Abuse",
      "description": "A detailed report about North Carolina Psychiatrist Used Artificial Intelligence to Produce Images of Child Sex Abuse",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-08-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3372",
      "incident_id": 605,
      "title": "Report 3372 on North Carolina Psychiatrist Used Artificial Intelligence to Produce Images of Child Sex Abuse",
      "description": "A detailed report about North Carolina Psychiatrist Used Artificial Intelligence to Produce Images of Child Sex Abuse",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-08-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3373",
      "incident_id": 605,
      "title": "Report 3373 on North Carolina Psychiatrist Used Artificial Intelligence to Produce Images of Child Sex Abuse",
      "description": "A detailed report about North Carolina Psychiatrist Used Artificial Intelligence to Produce Images of Child Sex Abuse",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-08-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3339",
      "incident_id": 606,
      "title": "Report 3339 on Deepfaked Advertisements Using the Likenesses of Celebrities Such as Tom Hanks and Gayle King Without Their Consent",
      "description": "A detailed report about Deepfaked Advertisements Using the Likenesses of Celebrities Such as Tom Hanks and Gayle King Without Their Consent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3383",
      "incident_id": 606,
      "title": "Report 3383 on Deepfaked Advertisements Using the Likenesses of Celebrities Such as Tom Hanks and Gayle King Without Their Consent",
      "description": "A detailed report about Deepfaked Advertisements Using the Likenesses of Celebrities Such as Tom Hanks and Gayle King Without Their Consent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3384",
      "incident_id": 606,
      "title": "Report 3384 on Deepfaked Advertisements Using the Likenesses of Celebrities Such as Tom Hanks and Gayle King Without Their Consent",
      "description": "A detailed report about Deepfaked Advertisements Using the Likenesses of Celebrities Such as Tom Hanks and Gayle King Without Their Consent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3343",
      "incident_id": 607,
      "title": "Report 3343 on Deepfake Video Circulating of British Labour Leader Keir Starmer Touting an Investment Scheme",
      "description": "A detailed report about Deepfake Video Circulating of British Labour Leader Keir Starmer Touting an Investment Scheme",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-11-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3348",
      "incident_id": 608,
      "title": "Report 3348 on UnitedHealth Accused of Deploying  Allegedly Flawed AI to Deny Medical Coverage",
      "description": "A detailed report about UnitedHealth Accused of Deploying  Allegedly Flawed AI to Deny Medical Coverage",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3353",
      "incident_id": 608,
      "title": "Report 3353 on UnitedHealth Accused of Deploying  Allegedly Flawed AI to Deny Medical Coverage",
      "description": "A detailed report about UnitedHealth Accused of Deploying  Allegedly Flawed AI to Deny Medical Coverage",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3354",
      "incident_id": 608,
      "title": "Report 3354 on UnitedHealth Accused of Deploying  Allegedly Flawed AI to Deny Medical Coverage",
      "description": "A detailed report about UnitedHealth Accused of Deploying  Allegedly Flawed AI to Deny Medical Coverage",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3350",
      "incident_id": 609,
      "title": "Report 3350 on Flawed AI in Google Search Reportedly Misinforms about Geography",
      "description": "A detailed report about Flawed AI in Google Search Reportedly Misinforms about Geography",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-08-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3351",
      "incident_id": 609,
      "title": "Report 3351 on Flawed AI in Google Search Reportedly Misinforms about Geography",
      "description": "A detailed report about Flawed AI in Google Search Reportedly Misinforms about Geography",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-08-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3398",
      "incident_id": 610,
      "title": "Report 3398 on Deepfake Technology Was Used to Generate Naked Pictures of Underage Girls in Spanish Town",
      "description": "A detailed report about Deepfake Technology Was Used to Generate Naked Pictures of Underage Girls in Spanish Town",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-09-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3413",
      "incident_id": 610,
      "title": "Report 3413 on Deepfake Technology Was Used to Generate Naked Pictures of Underage Girls in Spanish Town",
      "description": "A detailed report about Deepfake Technology Was Used to Generate Naked Pictures of Underage Girls in Spanish Town",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-09-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3414",
      "incident_id": 610,
      "title": "Report 3414 on Deepfake Technology Was Used to Generate Naked Pictures of Underage Girls in Spanish Town",
      "description": "A detailed report about Deepfake Technology Was Used to Generate Naked Pictures of Underage Girls in Spanish Town",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-09-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3399",
      "incident_id": 611,
      "title": "Report 3399 on UK Government AI Allegedly Targets Disproportionate Numbers of Certain Nationals for Fraud Review",
      "description": "A detailed report about UK Government AI Allegedly Targets Disproportionate Numbers of Certain Nationals for Fraud Review",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-12-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3400",
      "incident_id": 611,
      "title": "Report 3400 on UK Government AI Allegedly Targets Disproportionate Numbers of Certain Nationals for Fraud Review",
      "description": "A detailed report about UK Government AI Allegedly Targets Disproportionate Numbers of Certain Nationals for Fraud Review",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-12-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3401",
      "incident_id": 611,
      "title": "Report 3401 on UK Government AI Allegedly Targets Disproportionate Numbers of Certain Nationals for Fraud Review",
      "description": "A detailed report about UK Government AI Allegedly Targets Disproportionate Numbers of Certain Nationals for Fraud Review",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-12-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3412",
      "incident_id": 612,
      "title": "Report 3412 on Microsoft AI Poll Allegedly Causes Reputational Harm of The Guardian Newspaper",
      "description": "A detailed report about Microsoft AI Poll Allegedly Causes Reputational Harm of The Guardian Newspaper",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-31",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3429",
      "incident_id": 612,
      "title": "Report 3429 on Microsoft AI Poll Allegedly Causes Reputational Harm of The Guardian Newspaper",
      "description": "A detailed report about Microsoft AI Poll Allegedly Causes Reputational Harm of The Guardian Newspaper",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-31",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3430",
      "incident_id": 612,
      "title": "Report 3430 on Microsoft AI Poll Allegedly Causes Reputational Harm of The Guardian Newspaper",
      "description": "A detailed report about Microsoft AI Poll Allegedly Causes Reputational Harm of The Guardian Newspaper",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-31",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3422",
      "incident_id": 613,
      "title": "Report 3422 on AI-Generated Images Available through Adobe Stock Misrepresent Real-World Events",
      "description": "A detailed report about AI-Generated Images Available through Adobe Stock Misrepresent Real-World Events",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-11-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3445",
      "incident_id": 614,
      "title": "Report 3445 on Google Bard Allegedly Generates False Allegations Against Consulting Firms Used in Research Presented in Australian Parliamentary Inquiry",
      "description": "A detailed report about Google Bard Allegedly Generates False Allegations Against Consulting Firms Used in Research Presented in Australian Parliamentary Inquiry",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-11-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3446",
      "incident_id": 615,
      "title": "Report 3446 on Colorado Lawyer Filed a Motion Citing Hallucinated ChatGPT Cases",
      "description": "A detailed report about Colorado Lawyer Filed a Motion Citing Hallucinated ChatGPT Cases",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-06-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3496",
      "incident_id": 615,
      "title": "Report 3496 on Colorado Lawyer Filed a Motion Citing Hallucinated ChatGPT Cases",
      "description": "A detailed report about Colorado Lawyer Filed a Motion Citing Hallucinated ChatGPT Cases",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-06-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3497",
      "incident_id": 615,
      "title": "Report 3497 on Colorado Lawyer Filed a Motion Citing Hallucinated ChatGPT Cases",
      "description": "A detailed report about Colorado Lawyer Filed a Motion Citing Hallucinated ChatGPT Cases",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-06-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3448",
      "incident_id": 616,
      "title": "Report 3448 on Sports Illustrated Is Alleged to Have Used AI to Invent Fake Authors and Their Articles",
      "description": "A detailed report about Sports Illustrated Is Alleged to Have Used AI to Invent Fake Authors and Their Articles",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-11-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3452",
      "incident_id": 616,
      "title": "Report 3452 on Sports Illustrated Is Alleged to Have Used AI to Invent Fake Authors and Their Articles",
      "description": "A detailed report about Sports Illustrated Is Alleged to Have Used AI to Invent Fake Authors and Their Articles",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-11-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3453",
      "incident_id": 616,
      "title": "Report 3453 on Sports Illustrated Is Alleged to Have Used AI to Invent Fake Authors and Their Articles",
      "description": "A detailed report about Sports Illustrated Is Alleged to Have Used AI to Invent Fake Authors and Their Articles",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-11-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3495",
      "incident_id": 617,
      "title": "Report 3495 on Male student allegedly used AI to generate nude photos of female classmates at a high school in Issaquah, Washington",
      "description": "A detailed report about Male student allegedly used AI to generate nude photos of female classmates at a high school in Issaquah, Washington",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-11-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3834",
      "incident_id": 617,
      "title": "Report 3834 on Male student allegedly used AI to generate nude photos of female classmates at a high school in Issaquah, Washington",
      "description": "A detailed report about Male student allegedly used AI to generate nude photos of female classmates at a high school in Issaquah, Washington",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-11-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3499",
      "incident_id": 618,
      "title": "Report 3499 on Navy Federal Credit Union Faces Allegations of Racial Bias in Mortgage Approvals",
      "description": "A detailed report about Navy Federal Credit Union Faces Allegations of Racial Bias in Mortgage Approvals",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3565",
      "incident_id": 618,
      "title": "Report 3565 on Navy Federal Credit Union Faces Allegations of Racial Bias in Mortgage Approvals",
      "description": "A detailed report about Navy Federal Credit Union Faces Allegations of Racial Bias in Mortgage Approvals",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3566",
      "incident_id": 618,
      "title": "Report 3566 on Navy Federal Credit Union Faces Allegations of Racial Bias in Mortgage Approvals",
      "description": "A detailed report about Navy Federal Credit Union Faces Allegations of Racial Bias in Mortgage Approvals",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3500",
      "incident_id": 619,
      "title": "Report 3500 on Rite Aid Facial Recognition Disproportionately Misidentified Minority Shoppers as Shoplifters",
      "description": "A detailed report about Rite Aid Facial Recognition Disproportionately Misidentified Minority Shoppers as Shoplifters",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3503",
      "incident_id": 619,
      "title": "Report 3503 on Rite Aid Facial Recognition Disproportionately Misidentified Minority Shoppers as Shoplifters",
      "description": "A detailed report about Rite Aid Facial Recognition Disproportionately Misidentified Minority Shoppers as Shoplifters",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3504",
      "incident_id": 619,
      "title": "Report 3504 on Rite Aid Facial Recognition Disproportionately Misidentified Minority Shoppers as Shoplifters",
      "description": "A detailed report about Rite Aid Facial Recognition Disproportionately Misidentified Minority Shoppers as Shoplifters",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3513",
      "incident_id": 620,
      "title": "Report 3513 on A Robot at a Tesla Factory in Texas Allegedly Injured an Engineer",
      "description": "A detailed report about A Robot at a Tesla Factory in Texas Allegedly Injured an Engineer",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-11-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3515",
      "incident_id": 620,
      "title": "Report 3515 on A Robot at a Tesla Factory in Texas Allegedly Injured an Engineer",
      "description": "A detailed report about A Robot at a Tesla Factory in Texas Allegedly Injured an Engineer",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-11-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3516",
      "incident_id": 620,
      "title": "Report 3516 on A Robot at a Tesla Factory in Texas Allegedly Injured an Engineer",
      "description": "A detailed report about A Robot at a Tesla Factory in Texas Allegedly Injured an Engineer",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-11-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3519",
      "incident_id": 621,
      "title": "Report 3519 on Microsoft AI Is Alleged to Have Generated Violent Imagery of Minorities and Public Figures",
      "description": "A detailed report about Microsoft AI Is Alleged to Have Generated Violent Imagery of Minorities and Public Figures",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-11-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3542",
      "incident_id": 621,
      "title": "Report 3542 on Microsoft AI Is Alleged to Have Generated Violent Imagery of Minorities and Public Figures",
      "description": "A detailed report about Microsoft AI Is Alleged to Have Generated Violent Imagery of Minorities and Public Figures",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-11-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3544",
      "incident_id": 621,
      "title": "Report 3544 on Microsoft AI Is Alleged to Have Generated Violent Imagery of Minorities and Public Figures",
      "description": "A detailed report about Microsoft AI Is Alleged to Have Generated Violent Imagery of Minorities and Public Figures",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-11-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3520",
      "incident_id": 622,
      "title": "Report 3520 on Chevrolet Dealer Chatbot Agrees to Sell Tahoe for $1",
      "description": "A detailed report about Chevrolet Dealer Chatbot Agrees to Sell Tahoe for $1",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3534",
      "incident_id": 622,
      "title": "Report 3534 on Chevrolet Dealer Chatbot Agrees to Sell Tahoe for $1",
      "description": "A detailed report about Chevrolet Dealer Chatbot Agrees to Sell Tahoe for $1",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3535",
      "incident_id": 622,
      "title": "Report 3535 on Chevrolet Dealer Chatbot Agrees to Sell Tahoe for $1",
      "description": "A detailed report about Chevrolet Dealer Chatbot Agrees to Sell Tahoe for $1",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3522",
      "incident_id": 623,
      "title": "Report 3522 on Google Bard Allegedly Generated Fake Legal Citations in Michael Cohen Case",
      "description": "A detailed report about Google Bard Allegedly Generated Fake Legal Citations in Michael Cohen Case",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3524",
      "incident_id": 623,
      "title": "Report 3524 on Google Bard Allegedly Generated Fake Legal Citations in Michael Cohen Case",
      "description": "A detailed report about Google Bard Allegedly Generated Fake Legal Citations in Michael Cohen Case",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3525",
      "incident_id": 623,
      "title": "Report 3525 on Google Bard Allegedly Generated Fake Legal Citations in Michael Cohen Case",
      "description": "A detailed report about Google Bard Allegedly Generated Fake Legal Citations in Michael Cohen Case",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3533",
      "incident_id": 624,
      "title": "Report 3533 on Child Sexual Abuse Material Taints Image Generators",
      "description": "A detailed report about Child Sexual Abuse Material Taints Image Generators",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3550",
      "incident_id": 624,
      "title": "Report 3550 on Child Sexual Abuse Material Taints Image Generators",
      "description": "A detailed report about Child Sexual Abuse Material Taints Image Generators",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3551",
      "incident_id": 624,
      "title": "Report 3551 on Child Sexual Abuse Material Taints Image Generators",
      "description": "A detailed report about Child Sexual Abuse Material Taints Image Generators",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3539",
      "incident_id": 625,
      "title": "Report 3539 on Proliferation of Products on Amazon Titled with ChatGPT Error Messages",
      "description": "A detailed report about Proliferation of Products on Amazon Titled with ChatGPT Error Messages",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-01-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3545",
      "incident_id": 625,
      "title": "Report 3545 on Proliferation of Products on Amazon Titled with ChatGPT Error Messages",
      "description": "A detailed report about Proliferation of Products on Amazon Titled with ChatGPT Error Messages",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-01-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3546",
      "incident_id": 625,
      "title": "Report 3546 on Proliferation of Products on Amazon Titled with ChatGPT Error Messages",
      "description": "A detailed report about Proliferation of Products on Amazon Titled with ChatGPT Error Messages",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-01-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3548",
      "incident_id": 626,
      "title": "Report 3548 on Social Media Scammers Used Deepfakes of Taylor Swift and Several Other Celebrities in Fraudulent Le Creuset Cookware Giveaways",
      "description": "A detailed report about Social Media Scammers Used Deepfakes of Taylor Swift and Several Other Celebrities in Fraudulent Le Creuset Cookware Giveaways",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3568",
      "incident_id": 626,
      "title": "Report 3568 on Social Media Scammers Used Deepfakes of Taylor Swift and Several Other Celebrities in Fraudulent Le Creuset Cookware Giveaways",
      "description": "A detailed report about Social Media Scammers Used Deepfakes of Taylor Swift and Several Other Celebrities in Fraudulent Le Creuset Cookware Giveaways",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3569",
      "incident_id": 626,
      "title": "Report 3569 on Social Media Scammers Used Deepfakes of Taylor Swift and Several Other Celebrities in Fraudulent Le Creuset Cookware Giveaways",
      "description": "A detailed report about Social Media Scammers Used Deepfakes of Taylor Swift and Several Other Celebrities in Fraudulent Le Creuset Cookware Giveaways",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3549",
      "incident_id": 627,
      "title": "Report 3549 on Unauthorized AI Impersonation of George Carlin Used in Comedy Special",
      "description": "A detailed report about Unauthorized AI Impersonation of George Carlin Used in Comedy Special",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-01-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3596",
      "incident_id": 627,
      "title": "Report 3596 on Unauthorized AI Impersonation of George Carlin Used in Comedy Special",
      "description": "A detailed report about Unauthorized AI Impersonation of George Carlin Used in Comedy Special",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-01-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3597",
      "incident_id": 627,
      "title": "Report 3597 on Unauthorized AI Impersonation of George Carlin Used in Comedy Special",
      "description": "A detailed report about Unauthorized AI Impersonation of George Carlin Used in Comedy Special",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-01-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3602",
      "incident_id": 628,
      "title": "Report 3602 on Fake Biden Voice in Robocall Misleads New Hampshire Democratic Voters in 2024 Primary Election",
      "description": "A detailed report about Fake Biden Voice in Robocall Misleads New Hampshire Democratic Voters in 2024 Primary Election",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-01-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3608",
      "incident_id": 628,
      "title": "Report 3608 on Fake Biden Voice in Robocall Misleads New Hampshire Democratic Voters in 2024 Primary Election",
      "description": "A detailed report about Fake Biden Voice in Robocall Misleads New Hampshire Democratic Voters in 2024 Primary Election",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-01-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3846",
      "incident_id": 628,
      "title": "Report 3846 on Fake Biden Voice in Robocall Misleads New Hampshire Democratic Voters in 2024 Primary Election",
      "description": "A detailed report about Fake Biden Voice in Robocall Misleads New Hampshire Democratic Voters in 2024 Primary Election",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-01-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3603",
      "incident_id": 629,
      "title": "Report 3603 on Shein Accused of AI-Driven Art Theft on Merchandise",
      "description": "A detailed report about Shein Accused of AI-Driven Art Theft on Merchandise",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-07-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3612",
      "incident_id": 629,
      "title": "Report 3612 on Shein Accused of AI-Driven Art Theft on Merchandise",
      "description": "A detailed report about Shein Accused of AI-Driven Art Theft on Merchandise",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-07-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3604",
      "incident_id": 630,
      "title": "Report 3604 on Alleged Macy's Facial Recognition Error Leads to Wrongful Arrest and Subsequent Sexual Assault in Jail",
      "description": "A detailed report about Alleged Macy's Facial Recognition Error Leads to Wrongful Arrest and Subsequent Sexual Assault in Jail",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-01-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3611",
      "incident_id": 630,
      "title": "Report 3611 on Alleged Macy's Facial Recognition Error Leads to Wrongful Arrest and Subsequent Sexual Assault in Jail",
      "description": "A detailed report about Alleged Macy's Facial Recognition Error Leads to Wrongful Arrest and Subsequent Sexual Assault in Jail",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-01-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3617",
      "incident_id": 630,
      "title": "Report 3617 on Alleged Macy's Facial Recognition Error Leads to Wrongful Arrest and Subsequent Sexual Assault in Jail",
      "description": "A detailed report about Alleged Macy's Facial Recognition Error Leads to Wrongful Arrest and Subsequent Sexual Assault in Jail",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-01-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3605",
      "incident_id": 631,
      "title": "Report 3605 on Chatbot for DPD Malfunctioned and Swore at Customers and Criticized Its Own Company",
      "description": "A detailed report about Chatbot for DPD Malfunctioned and Swore at Customers and Criticized Its Own Company",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-01-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3616",
      "incident_id": 631,
      "title": "Report 3616 on Chatbot for DPD Malfunctioned and Swore at Customers and Criticized Its Own Company",
      "description": "A detailed report about Chatbot for DPD Malfunctioned and Swore at Customers and Criticized Its Own Company",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-01-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3613",
      "incident_id": 632,
      "title": "Report 3613 on Significant Increase in Deepfake Nudes of Taylor Swift Circulating on Social Media",
      "description": "A detailed report about Significant Increase in Deepfake Nudes of Taylor Swift Circulating on Social Media",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-01-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3615",
      "incident_id": 632,
      "title": "Report 3615 on Significant Increase in Deepfake Nudes of Taylor Swift Circulating on Social Media",
      "description": "A detailed report about Significant Increase in Deepfake Nudes of Taylor Swift Circulating on Social Media",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-01-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3618",
      "incident_id": 632,
      "title": "Report 3618 on Significant Increase in Deepfake Nudes of Taylor Swift Circulating on Social Media",
      "description": "A detailed report about Significant Increase in Deepfake Nudes of Taylor Swift Circulating on Social Media",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-01-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3614",
      "incident_id": 633,
      "title": "Report 3614 on Nine Network's AI Alters Lawmaker Georgie Purcell's Image Inappropriately",
      "description": "A detailed report about Nine Network's AI Alters Lawmaker Georgie Purcell's Image Inappropriately",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-01-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3638",
      "incident_id": 633,
      "title": "Report 3638 on Nine Network's AI Alters Lawmaker Georgie Purcell's Image Inappropriately",
      "description": "A detailed report about Nine Network's AI Alters Lawmaker Georgie Purcell's Image Inappropriately",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-01-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3640",
      "incident_id": 633,
      "title": "Report 3640 on Nine Network's AI Alters Lawmaker Georgie Purcell's Image Inappropriately",
      "description": "A detailed report about Nine Network's AI Alters Lawmaker Georgie Purcell's Image Inappropriately",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-01-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3622",
      "incident_id": 634,
      "title": "Report 3622 on Alleged Deepfake CFO Scam Reportedly Costs Multinational Engineering Firm Arup $25 Million",
      "description": "A detailed report about Alleged Deepfake CFO Scam Reportedly Costs Multinational Engineering Firm Arup $25 Million",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3624",
      "incident_id": 634,
      "title": "Report 3624 on Alleged Deepfake CFO Scam Reportedly Costs Multinational Engineering Firm Arup $25 Million",
      "description": "A detailed report about Alleged Deepfake CFO Scam Reportedly Costs Multinational Engineering Firm Arup $25 Million",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3625",
      "incident_id": 634,
      "title": "Report 3625 on Alleged Deepfake CFO Scam Reportedly Costs Multinational Engineering Firm Arup $25 Million",
      "description": "A detailed report about Alleged Deepfake CFO Scam Reportedly Costs Multinational Engineering Firm Arup $25 Million",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3637",
      "incident_id": 635,
      "title": "Report 3637 on AI-Generated Fake News Targets Black Celebrities on YouTube",
      "description": "A detailed report about AI-Generated Fake News Targets Black Celebrities on YouTube",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-01-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3641",
      "incident_id": 636,
      "title": "Report 3641 on AI Romance Apps Reportedly Compromise User Privacy for Data Harvesting",
      "description": "A detailed report about AI Romance Apps Reportedly Compromise User Privacy for Data Harvesting",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3652",
      "incident_id": 636,
      "title": "Report 3652 on AI Romance Apps Reportedly Compromise User Privacy for Data Harvesting",
      "description": "A detailed report about AI Romance Apps Reportedly Compromise User Privacy for Data Harvesting",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3702",
      "incident_id": 636,
      "title": "Report 3702 on AI Romance Apps Reportedly Compromise User Privacy for Data Harvesting",
      "description": "A detailed report about AI Romance Apps Reportedly Compromise User Privacy for Data Harvesting",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3654",
      "incident_id": 637,
      "title": "Report 3654 on Gunshot Detection Technology ShotSpotter (now SoundThinking) Reportedly Only Has 47% Accuracy in Chicago System",
      "description": "A detailed report about Gunshot Detection Technology ShotSpotter (now SoundThinking) Reportedly Only Has 47% Accuracy in Chicago System",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-01-31",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3656",
      "incident_id": 638,
      "title": "Report 3656 on Fatal Crash Involving Tesla Full Self-Driving Claims Employee's Life",
      "description": "A detailed report about Fatal Crash Involving Tesla Full Self-Driving Claims Employee's Life",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-05-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3657",
      "incident_id": 638,
      "title": "Report 3657 on Fatal Crash Involving Tesla Full Self-Driving Claims Employee's Life",
      "description": "A detailed report about Fatal Crash Involving Tesla Full Self-Driving Claims Employee's Life",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-05-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3658",
      "incident_id": 638,
      "title": "Report 3658 on Fatal Crash Involving Tesla Full Self-Driving Claims Employee's Life",
      "description": "A detailed report about Fatal Crash Involving Tesla Full Self-Driving Claims Employee's Life",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-05-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3673",
      "incident_id": 639,
      "title": "Report 3673 on Customer Overcharged Due to Air Canada Chatbot's False Discount Claims",
      "description": "A detailed report about Customer Overcharged Due to Air Canada Chatbot's False Discount Claims",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3674",
      "incident_id": 639,
      "title": "Report 3674 on Customer Overcharged Due to Air Canada Chatbot's False Discount Claims",
      "description": "A detailed report about Customer Overcharged Due to Air Canada Chatbot's False Discount Claims",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3731",
      "incident_id": 639,
      "title": "Report 3731 on Customer Overcharged Due to Air Canada Chatbot's False Discount Claims",
      "description": "A detailed report about Customer Overcharged Due to Air Canada Chatbot's False Discount Claims",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-11-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3675",
      "incident_id": 640,
      "title": "Report 3675 on Waymo Software Flaw Leads to Double Collision with Tow Truck",
      "description": "A detailed report about Waymo Software Flaw Leads to Double Collision with Tow Truck",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3676",
      "incident_id": 640,
      "title": "Report 3676 on Waymo Software Flaw Leads to Double Collision with Tow Truck",
      "description": "A detailed report about Waymo Software Flaw Leads to Double Collision with Tow Truck",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3750",
      "incident_id": 640,
      "title": "Report 3750 on Waymo Software Flaw Leads to Double Collision with Tow Truck",
      "description": "A detailed report about Waymo Software Flaw Leads to Double Collision with Tow Truck",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3703",
      "incident_id": 641,
      "title": "Report 3703 on Nonconsensual Deepfake Porn of Bobbi Althoff Spreads Rapidly on X",
      "description": "A detailed report about Nonconsensual Deepfake Porn of Bobbi Althoff Spreads Rapidly on X",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3704",
      "incident_id": 641,
      "title": "Report 3704 on Nonconsensual Deepfake Porn of Bobbi Althoff Spreads Rapidly on X",
      "description": "A detailed report about Nonconsensual Deepfake Porn of Bobbi Althoff Spreads Rapidly on X",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3732",
      "incident_id": 641,
      "title": "Report 3732 on Nonconsensual Deepfake Porn of Bobbi Althoff Spreads Rapidly on X",
      "description": "A detailed report about Nonconsensual Deepfake Porn of Bobbi Althoff Spreads Rapidly on X",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3705",
      "incident_id": 642,
      "title": "Report 3705 on ChatGPT Glitch Disrupts User Interactions with Nonsensical Outputs",
      "description": "A detailed report about ChatGPT Glitch Disrupts User Interactions with Nonsensical Outputs",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3706",
      "incident_id": 642,
      "title": "Report 3706 on ChatGPT Glitch Disrupts User Interactions with Nonsensical Outputs",
      "description": "A detailed report about ChatGPT Glitch Disrupts User Interactions with Nonsensical Outputs",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3747",
      "incident_id": 642,
      "title": "Report 3747 on ChatGPT Glitch Disrupts User Interactions with Nonsensical Outputs",
      "description": "A detailed report about ChatGPT Glitch Disrupts User Interactions with Nonsensical Outputs",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3715",
      "incident_id": 643,
      "title": "Report 3715 on Deepfake Video Falsely Claims Kyiv's Assassination Plan Against President Macron",
      "description": "A detailed report about Deepfake Video Falsely Claims Kyiv's Assassination Plan Against President Macron",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3730",
      "incident_id": 643,
      "title": "Report 3730 on Deepfake Video Falsely Claims Kyiv's Assassination Plan Against President Macron",
      "description": "A detailed report about Deepfake Video Falsely Claims Kyiv's Assassination Plan Against President Macron",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3743",
      "incident_id": 643,
      "title": "Report 3743 on Deepfake Video Falsely Claims Kyiv's Assassination Plan Against President Macron",
      "description": "A detailed report about Deepfake Video Falsely Claims Kyiv's Assassination Plan Against President Macron",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3718",
      "incident_id": 644,
      "title": "Report 3718 on State-Sponsored Hackers Escalate Phishing Attacks Using Artificial Intelligence",
      "description": "A detailed report about State-Sponsored Hackers Escalate Phishing Attacks Using Artificial Intelligence",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3726",
      "incident_id": 644,
      "title": "Report 3726 on State-Sponsored Hackers Escalate Phishing Attacks Using Artificial Intelligence",
      "description": "A detailed report about State-Sponsored Hackers Escalate Phishing Attacks Using Artificial Intelligence",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3727",
      "incident_id": 644,
      "title": "Report 3727 on State-Sponsored Hackers Escalate Phishing Attacks Using Artificial Intelligence",
      "description": "A detailed report about State-Sponsored Hackers Escalate Phishing Attacks Using Artificial Intelligence",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3719",
      "incident_id": 645,
      "title": "Report 3719 on Seeming Pattern of Gemini Bias and Sociotechnical Training Failures Harm Google's Reputation",
      "description": "A detailed report about Seeming Pattern of Gemini Bias and Sociotechnical Training Failures Harm Google's Reputation",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3720",
      "incident_id": 645,
      "title": "Report 3720 on Seeming Pattern of Gemini Bias and Sociotechnical Training Failures Harm Google's Reputation",
      "description": "A detailed report about Seeming Pattern of Gemini Bias and Sociotechnical Training Failures Harm Google's Reputation",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3722",
      "incident_id": 645,
      "title": "Report 3722 on Seeming Pattern of Gemini Bias and Sociotechnical Training Failures Harm Google's Reputation",
      "description": "A detailed report about Seeming Pattern of Gemini Bias and Sociotechnical Training Failures Harm Google's Reputation",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3721",
      "incident_id": 646,
      "title": "Report 3721 on Snapchat's Algorithm Alleged to Link Minor with Sex Offenders",
      "description": "A detailed report about Snapchat's Algorithm Alleged to Link Minor with Sex Offenders",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3752",
      "incident_id": 647,
      "title": "Report 3752 on A Self-Driving Waymo Robotaxi Reportedly Collided with a Bicyclist",
      "description": "A detailed report about A Self-Driving Waymo Robotaxi Reportedly Collided with a Bicyclist",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3759",
      "incident_id": 647,
      "title": "Report 3759 on A Self-Driving Waymo Robotaxi Reportedly Collided with a Bicyclist",
      "description": "A detailed report about A Self-Driving Waymo Robotaxi Reportedly Collided with a Bicyclist",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4318",
      "incident_id": 647,
      "title": "Report 4318 on A Self-Driving Waymo Robotaxi Reportedly Collided with a Bicyclist",
      "description": "A detailed report about A Self-Driving Waymo Robotaxi Reportedly Collided with a Bicyclist",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3753",
      "incident_id": 648,
      "title": "Report 3753 on Alleged Deepfake Audio of Imran Khan Calls for Election Boycott, Misleading Pakistan Voters",
      "description": "A detailed report about Alleged Deepfake Audio of Imran Khan Calls for Election Boycott, Misleading Pakistan Voters",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3758",
      "incident_id": 648,
      "title": "Report 3758 on Alleged Deepfake Audio of Imran Khan Calls for Election Boycott, Misleading Pakistan Voters",
      "description": "A detailed report about Alleged Deepfake Audio of Imran Khan Calls for Election Boycott, Misleading Pakistan Voters",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3754",
      "incident_id": 649,
      "title": "Report 3754 on Deepfake Audio Falsely Attributes Controversial Remarks to Keir Starmer About the Rochdale Azhar Ali Crisis",
      "description": "A detailed report about Deepfake Audio Falsely Attributes Controversial Remarks to Keir Starmer About the Rochdale Azhar Ali Crisis",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3755",
      "incident_id": 650,
      "title": "Report 3755 on AI-Generated Images of Trump with Black Voters Spread as Disinformation Before U.S. Primary Elections",
      "description": "A detailed report about AI-Generated Images of Trump with Black Voters Spread as Disinformation Before U.S. Primary Elections",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-03-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3756",
      "incident_id": 651,
      "title": "Report 3756 on Students at a Beverly Hills Middle School Allegedly Created and Shared Deepfake Nudes of Their Classmates",
      "description": "A detailed report about Students at a Beverly Hills Middle School Allegedly Created and Shared Deepfake Nudes of Their Classmates",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3757",
      "incident_id": 651,
      "title": "Report 3757 on Students at a Beverly Hills Middle School Allegedly Created and Shared Deepfake Nudes of Their Classmates",
      "description": "A detailed report about Students at a Beverly Hills Middle School Allegedly Created and Shared Deepfake Nudes of Their Classmates",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4548",
      "incident_id": 651,
      "title": "Report 4548 on Students at a Beverly Hills Middle School Allegedly Created and Shared Deepfake Nudes of Their Classmates",
      "description": "A detailed report about Students at a Beverly Hills Middle School Allegedly Created and Shared Deepfake Nudes of Their Classmates",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3764",
      "incident_id": 652,
      "title": "Report 3764 on Two Florida Middle School Students Arrested Under New Law for Allegedly Having Made and Shared Deepfake Nudes of Their Classmates",
      "description": "A detailed report about Two Florida Middle School Students Arrested Under New Law for Allegedly Having Made and Shared Deepfake Nudes of Their Classmates",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4525",
      "incident_id": 652,
      "title": "Report 4525 on Two Florida Middle School Students Arrested Under New Law for Allegedly Having Made and Shared Deepfake Nudes of Their Classmates",
      "description": "A detailed report about Two Florida Middle School Students Arrested Under New Law for Allegedly Having Made and Shared Deepfake Nudes of Their Classmates",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4526",
      "incident_id": 652,
      "title": "Report 4526 on Two Florida Middle School Students Arrested Under New Law for Allegedly Having Made and Shared Deepfake Nudes of Their Classmates",
      "description": "A detailed report about Two Florida Middle School Students Arrested Under New Law for Allegedly Having Made and Shared Deepfake Nudes of Their Classmates",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3790",
      "incident_id": 653,
      "title": "Report 3790 on Two Investment Firms Charged with Making False Claims of Artificial Intelligence Capabilities in Case of AI Washing",
      "description": "A detailed report about Two Investment Firms Charged with Making False Claims of Artificial Intelligence Capabilities in Case of AI Washing",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-01-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3791",
      "incident_id": 654,
      "title": "Report 3791 on Microsoft Copilot Designer Reportedly Generated Inappropriate AI Images",
      "description": "A detailed report about Microsoft Copilot Designer Reportedly Generated Inappropriate AI Images",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-03-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3792",
      "incident_id": 655,
      "title": "Report 3792 on Scams Reportedly Impersonating Wealthy Investors Proliferating on Facebook",
      "description": "A detailed report about Scams Reportedly Impersonating Wealthy Investors Proliferating on Facebook",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-01-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3794",
      "incident_id": 656,
      "title": "Report 3794 on Incident 656",
      "description": "A detailed report about Incident 656",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-03-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3795",
      "incident_id": 656,
      "title": "Report 3795 on Incident 656",
      "description": "A detailed report about Incident 656",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-03-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3798",
      "incident_id": 656,
      "title": "Report 3798 on Incident 656",
      "description": "A detailed report about Incident 656",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-03-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3796",
      "incident_id": 657,
      "title": "Report 3796 on ChatGPT Account Compromise Leads to Unintended Data Exposure",
      "description": "A detailed report about ChatGPT Account Compromise Leads to Unintended Data Exposure",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-01-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3797",
      "incident_id": 658,
      "title": "Report 3797 on The Arizona Agenda Produced a Deepfake of Kari Lake Advocating for the Publication Without Her Consent",
      "description": "A detailed report about The Arizona Agenda Produced a Deepfake of Kari Lake Advocating for the Publication Without Her Consent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-03-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3799",
      "incident_id": 658,
      "title": "Report 3799 on The Arizona Agenda Produced a Deepfake of Kari Lake Advocating for the Publication Without Her Consent",
      "description": "A detailed report about The Arizona Agenda Produced a Deepfake of Kari Lake Advocating for the Publication Without Her Consent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-03-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3803",
      "incident_id": 658,
      "title": "Report 3803 on The Arizona Agenda Produced a Deepfake of Kari Lake Advocating for the Publication Without Her Consent",
      "description": "A detailed report about The Arizona Agenda Produced a Deepfake of Kari Lake Advocating for the Publication Without Her Consent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-03-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3800",
      "incident_id": 659,
      "title": "Report 3800 on Mass Surveillance Facial Recognition Program Reportedly Targets Palestinians in Gaza",
      "description": "A detailed report about Mass Surveillance Facial Recognition Program Reportedly Targets Palestinians in Gaza",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3801",
      "incident_id": 659,
      "title": "Report 3801 on Mass Surveillance Facial Recognition Program Reportedly Targets Palestinians in Gaza",
      "description": "A detailed report about Mass Surveillance Facial Recognition Program Reportedly Targets Palestinians in Gaza",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3802",
      "incident_id": 659,
      "title": "Report 3802 on Mass Surveillance Facial Recognition Program Reportedly Targets Palestinians in Gaza",
      "description": "A detailed report about Mass Surveillance Facial Recognition Program Reportedly Targets Palestinians in Gaza",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3804",
      "incident_id": 660,
      "title": "Report 3804 on Investigation Reports Unauthorized Deepfake Pornography Harms Thousands of Celebrities",
      "description": "A detailed report about Investigation Reports Unauthorized Deepfake Pornography Harms Thousands of Celebrities",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-03-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3805",
      "incident_id": 661,
      "title": "Report 3805 on Leonardo AI's Platform Alleged to Have Been Used for Creating Nonconsensual Celebrity Deepfakes",
      "description": "A detailed report about Leonardo AI's Platform Alleged to Have Been Used for Creating Nonconsensual Celebrity Deepfakes",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-03-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3806",
      "incident_id": 662,
      "title": "Report 3806 on Washington State's Lottery AI Site Reportedly Generates Inappropriate User Image",
      "description": "A detailed report about Washington State's Lottery AI Site Reportedly Generates Inappropriate User Image",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3861",
      "incident_id": 662,
      "title": "Report 3861 on Washington State's Lottery AI Site Reportedly Generates Inappropriate User Image",
      "description": "A detailed report about Washington State's Lottery AI Site Reportedly Generates Inappropriate User Image",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3807",
      "incident_id": 663,
      "title": "Report 3807 on China Reportedly Intensifying AI to Spread Disinformation to U.S. and Taiwanese Voters",
      "description": "A detailed report about China Reportedly Intensifying AI to Spread Disinformation to U.S. and Taiwanese Voters",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4915",
      "incident_id": 663,
      "title": "Report 4915 on China Reportedly Intensifying AI to Spread Disinformation to U.S. and Taiwanese Voters",
      "description": "A detailed report about China Reportedly Intensifying AI to Spread Disinformation to U.S. and Taiwanese Voters",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3809",
      "incident_id": 664,
      "title": "Report 3809 on Deepfake Generated by the Lincoln Project of Trump's Father Used in Political Attack Ad",
      "description": "A detailed report about Deepfake Generated by the Lincoln Project of Trump's Father Used in Political Attack Ad",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3817",
      "incident_id": 665,
      "title": "Report 3817 on Facial Recognition Misidentification at New World Westend in New Zealand",
      "description": "A detailed report about Facial Recognition Misidentification at New World Westend in New Zealand",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3875",
      "incident_id": 665,
      "title": "Report 3875 on Facial Recognition Misidentification at New World Westend in New Zealand",
      "description": "A detailed report about Facial Recognition Misidentification at New World Westend in New Zealand",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3820",
      "incident_id": 666,
      "title": "Report 3820 on Presidency of Moldova Refutes Deepfake Video Slandering President Maia Sandu",
      "description": "A detailed report about Presidency of Moldova Refutes Deepfake Video Slandering President Maia Sandu",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3821",
      "incident_id": 667,
      "title": "Report 3821 on Manipulated Deepfake Video of Lai Ching-te Endorsing Rivals in Lead-up to January Presidential Elections",
      "description": "A detailed report about Manipulated Deepfake Video of Lai Ching-te Endorsing Rivals in Lead-up to January Presidential Elections",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3823",
      "incident_id": 668,
      "title": "Report 3823 on Proliferation of Deepfakes Disrupting 2024 Lok Sabha Elections",
      "description": "A detailed report about Proliferation of Deepfakes Disrupting 2024 Lok Sabha Elections",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3916",
      "incident_id": 668,
      "title": "Report 3916 on Proliferation of Deepfakes Disrupting 2024 Lok Sabha Elections",
      "description": "A detailed report about Proliferation of Deepfakes Disrupting 2024 Lok Sabha Elections",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3824",
      "incident_id": 669,
      "title": "Report 3824 on Deepfake of Long-Deceased Suharto Circulating in Run-up to February 2024 Indonesian Elections",
      "description": "A detailed report about Deepfake of Long-Deceased Suharto Circulating in Run-up to February 2024 Indonesian Elections",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3826",
      "incident_id": 670,
      "title": "Report 3826 on Deepfakes of Deceased Indian Politicians for Election Campaigning Are Increasingly Being Deployed",
      "description": "A detailed report about Deepfakes of Deceased Indian Politicians for Election Campaigning Are Increasingly Being Deployed",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-01-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3827",
      "incident_id": 670,
      "title": "Report 3827 on Deepfakes of Deceased Indian Politicians for Election Campaigning Are Increasingly Being Deployed",
      "description": "A detailed report about Deepfakes of Deceased Indian Politicians for Election Campaigning Are Increasingly Being Deployed",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-01-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3828",
      "incident_id": 671,
      "title": "Report 3828 on Many Political Deepfakes Circulating in Run-up to 2024 Pakistani General Elections",
      "description": "A detailed report about Many Political Deepfakes Circulating in Run-up to 2024 Pakistani General Elections",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3829",
      "incident_id": 672,
      "title": "Report 3829 on Lavender AI System Reportedly Directs Gaza Strikes with High Civilian Casualty Rate",
      "description": "A detailed report about Lavender AI System Reportedly Directs Gaza Strikes with High Civilian Casualty Rate",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3830",
      "incident_id": 672,
      "title": "Report 3830 on Lavender AI System Reportedly Directs Gaza Strikes with High Civilian Casualty Rate",
      "description": "A detailed report about Lavender AI System Reportedly Directs Gaza Strikes with High Civilian Casualty Rate",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3850",
      "incident_id": 672,
      "title": "Report 3850 on Lavender AI System Reportedly Directs Gaza Strikes with High Civilian Casualty Rate",
      "description": "A detailed report about Lavender AI System Reportedly Directs Gaza Strikes with High Civilian Casualty Rate",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3831",
      "incident_id": 673,
      "title": "Report 3831 on Deepfakes Circulating and Eroding Electoral Integrity in the Lead-up to 2024 South Korean legislative election",
      "description": "A detailed report about Deepfakes Circulating and Eroding Electoral Integrity in the Lead-up to 2024 South Korean legislative election",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3832",
      "incident_id": 674,
      "title": "Report 3832 on Manipulated Media via AI Disinformation and Deepfakes in 2024 Elections Erode Trust Across More Than 50 Countries",
      "description": "A detailed report about Manipulated Media via AI Disinformation and Deepfakes in 2024 Elections Erode Trust Across More Than 50 Countries",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-03-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3835",
      "incident_id": 675,
      "title": "Report 3835 on Racist and Antisemitic Deepfake Audio Mimicking School Principal Fabricated by Athletic Director",
      "description": "A detailed report about Racist and Antisemitic Deepfake Audio Mimicking School Principal Fabricated by Athletic Director",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-01-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3837",
      "incident_id": 675,
      "title": "Report 3837 on Racist and Antisemitic Deepfake Audio Mimicking School Principal Fabricated by Athletic Director",
      "description": "A detailed report about Racist and Antisemitic Deepfake Audio Mimicking School Principal Fabricated by Athletic Director",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-01-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3838",
      "incident_id": 675,
      "title": "Report 3838 on Racist and Antisemitic Deepfake Audio Mimicking School Principal Fabricated by Athletic Director",
      "description": "A detailed report about Racist and Antisemitic Deepfake Audio Mimicking School Principal Fabricated by Athletic Director",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-01-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3836",
      "incident_id": 676,
      "title": "Report 3836 on Deepfake Audio Falsely Depicts Philippines President Ferdinand Marcos Jr. Ordering Military Action",
      "description": "A detailed report about Deepfake Audio Falsely Depicts Philippines President Ferdinand Marcos Jr. Ordering Military Action",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3841",
      "incident_id": 676,
      "title": "Report 3841 on Deepfake Audio Falsely Depicts Philippines President Ferdinand Marcos Jr. Ordering Military Action",
      "description": "A detailed report about Deepfake Audio Falsely Depicts Philippines President Ferdinand Marcos Jr. Ordering Military Action",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3839",
      "incident_id": 677,
      "title": "Report 3839 on ChatGPT and Perplexity Reportedly Manipulated into Breaking Content Policies in AI Boyfriend Scenarios",
      "description": "A detailed report about ChatGPT and Perplexity Reportedly Manipulated into Breaking Content Policies in AI Boyfriend Scenarios",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3840",
      "incident_id": 678,
      "title": "Report 3840 on ChatGPT Factual Errors Lead to Filing of Complaint of GDPR Privacy Violation ",
      "description": "A detailed report about ChatGPT Factual Errors Lead to Filing of Complaint of GDPR Privacy Violation ",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3842",
      "incident_id": 679,
      "title": "Report 3842 on A Deepfake of Senator Elizabeth Warren Circulated Saying Republicans Should Not Vote",
      "description": "A detailed report about A Deepfake of Senator Elizabeth Warren Circulated Saying Republicans Should Not Vote",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3843",
      "incident_id": 680,
      "title": "Report 3843 on Russia-Linked AI CopyCop Site Identified as Modifying and Producing at Least 19,000 Deceptive Reports",
      "description": "A detailed report about Russia-Linked AI CopyCop Site Identified as Modifying and Producing at Least 19,000 Deceptive Reports",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-03-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3870",
      "incident_id": 680,
      "title": "Report 3870 on Russia-Linked AI CopyCop Site Identified as Modifying and Producing at Least 19,000 Deceptive Reports",
      "description": "A detailed report about Russia-Linked AI CopyCop Site Identified as Modifying and Producing at Least 19,000 Deceptive Reports",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-03-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4915",
      "incident_id": 680,
      "title": "Report 4915 on Russia-Linked AI CopyCop Site Identified as Modifying and Producing at Least 19,000 Deceptive Reports",
      "description": "A detailed report about Russia-Linked AI CopyCop Site Identified as Modifying and Producing at Least 19,000 Deceptive Reports",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-03-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3845",
      "incident_id": 681,
      "title": "Report 3845 on Never Back Down Super PAC for Ron DeSantis Uses AI Donald Trump Voice in Attack Ad Against Kim Reynolds",
      "description": "A detailed report about Never Back Down Super PAC for Ron DeSantis Uses AI Donald Trump Voice in Attack Ad Against Kim Reynolds",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-07-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3847",
      "incident_id": 682,
      "title": "Report 3847 on GOP Pollster Shares AI-Generated Images to Fabricate Appearance of Black Voter Support",
      "description": "A detailed report about GOP Pollster Shares AI-Generated Images to Fabricate Appearance of Black Voter Support",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3848",
      "incident_id": 683,
      "title": "Report 3848 on Scammers Using Deepfakes of Women's Faces and Voices for False and Offensive Advertisements",
      "description": "A detailed report about Scammers Using Deepfakes of Women's Faces and Voices for False and Offensive Advertisements",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-03-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3867",
      "incident_id": 683,
      "title": "Report 3867 on Scammers Using Deepfakes of Women's Faces and Voices for False and Offensive Advertisements",
      "description": "A detailed report about Scammers Using Deepfakes of Women's Faces and Voices for False and Offensive Advertisements",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-03-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3852",
      "incident_id": 684,
      "title": "Report 3852 on Google Books Appears to Be Indexing Works Written by AI",
      "description": "A detailed report about Google Books Appears to Be Indexing Works Written by AI",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3853",
      "incident_id": 685,
      "title": "Report 3853 on The WHO's S.A.R.A.H. Bot Reported to Provide Inconsistent and Inadequate Health Information",
      "description": "A detailed report about The WHO's S.A.R.A.H. Bot Reported to Provide Inconsistent and Inadequate Health Information",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3854",
      "incident_id": 686,
      "title": "Report 3854 on Meta AI Image Generator Reportedly Fails to Accurately Represent Interracial Relationships",
      "description": "A detailed report about Meta AI Image Generator Reportedly Fails to Accurately Represent Interracial Relationships",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3855",
      "incident_id": 686,
      "title": "Report 3855 on Meta AI Image Generator Reportedly Fails to Accurately Represent Interracial Relationships",
      "description": "A detailed report about Meta AI Image Generator Reportedly Fails to Accurately Represent Interracial Relationships",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3857",
      "incident_id": 687,
      "title": "Report 3857 on Deepfake Porn Sites Use Breeze Liu's Image Without Consent",
      "description": "A detailed report about Deepfake Porn Sites Use Breeze Liu's Image Without Consent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3868",
      "incident_id": 688,
      "title": "Report 3868 on Scarlett Johansson Alleges OpenAI's Sky Imitates Her Voice Without Licensing",
      "description": "A detailed report about Scarlett Johansson Alleges OpenAI's Sky Imitates Her Voice Without Licensing",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3869",
      "incident_id": 688,
      "title": "Report 3869 on Scarlett Johansson Alleges OpenAI's Sky Imitates Her Voice Without Licensing",
      "description": "A detailed report about Scarlett Johansson Alleges OpenAI's Sky Imitates Her Voice Without Licensing",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3871",
      "incident_id": 688,
      "title": "Report 3871 on Scarlett Johansson Alleges OpenAI's Sky Imitates Her Voice Without Licensing",
      "description": "A detailed report about Scarlett Johansson Alleges OpenAI's Sky Imitates Her Voice Without Licensing",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3876",
      "incident_id": 689,
      "title": "Report 3876 on Holmen, Wisconsin Man Allegedly Used Stable Diffusion to Create and Then Share Sexually Explicit Images Depicting Minors",
      "description": "A detailed report about Holmen, Wisconsin Man Allegedly Used Stable Diffusion to Create and Then Share Sexually Explicit Images Depicting Minors",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-03-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3877",
      "incident_id": 689,
      "title": "Report 3877 on Holmen, Wisconsin Man Allegedly Used Stable Diffusion to Create and Then Share Sexually Explicit Images Depicting Minors",
      "description": "A detailed report about Holmen, Wisconsin Man Allegedly Used Stable Diffusion to Create and Then Share Sexually Explicit Images Depicting Minors",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-03-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3879",
      "incident_id": 689,
      "title": "Report 3879 on Holmen, Wisconsin Man Allegedly Used Stable Diffusion to Create and Then Share Sexually Explicit Images Depicting Minors",
      "description": "A detailed report about Holmen, Wisconsin Man Allegedly Used Stable Diffusion to Create and Then Share Sexually Explicit Images Depicting Minors",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-03-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3880",
      "incident_id": 690,
      "title": "Report 3880 on ISIS Utilizes AI for Propaganda Videos in News Harvest Program",
      "description": "A detailed report about ISIS Utilizes AI for Propaganda Videos in News Harvest Program",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-03-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3884",
      "incident_id": 690,
      "title": "Report 3884 on ISIS Utilizes AI for Propaganda Videos in News Harvest Program",
      "description": "A detailed report about ISIS Utilizes AI for Propaganda Videos in News Harvest Program",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-03-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3885",
      "incident_id": 690,
      "title": "Report 3885 on ISIS Utilizes AI for Propaganda Videos in News Harvest Program",
      "description": "A detailed report about ISIS Utilizes AI for Propaganda Videos in News Harvest Program",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-03-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3886",
      "incident_id": 691,
      "title": "Report 3886 on Facewatch Reported to Have Wrongfully Flagged Home Bargains Customer as Shoplifter",
      "description": "A detailed report about Facewatch Reported to Have Wrongfully Flagged Home Bargains Customer as Shoplifter",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3887",
      "incident_id": 691,
      "title": "Report 3887 on Facewatch Reported to Have Wrongfully Flagged Home Bargains Customer as Shoplifter",
      "description": "A detailed report about Facewatch Reported to Have Wrongfully Flagged Home Bargains Customer as Shoplifter",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3888",
      "incident_id": 692,
      "title": "Report 3888 on London Metropolitan Police's Facial Recognition Technology Reportedly Misidentified Shaun Thompson as Suspect Leading to Arrest",
      "description": "A detailed report about London Metropolitan Police's Facial Recognition Technology Reportedly Misidentified Shaun Thompson as Suspect Leading to Arrest",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3889",
      "incident_id": 692,
      "title": "Report 3889 on London Metropolitan Police's Facial Recognition Technology Reportedly Misidentified Shaun Thompson as Suspect Leading to Arrest",
      "description": "A detailed report about London Metropolitan Police's Facial Recognition Technology Reportedly Misidentified Shaun Thompson as Suspect Leading to Arrest",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3890",
      "incident_id": 693,
      "title": "Report 3890 on Google AI Reportedly Delivering Confidently Incorrect and Harmful Information",
      "description": "A detailed report about Google AI Reportedly Delivering Confidently Incorrect and Harmful Information",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3891",
      "incident_id": 693,
      "title": "Report 3891 on Google AI Reportedly Delivering Confidently Incorrect and Harmful Information",
      "description": "A detailed report about Google AI Reportedly Delivering Confidently Incorrect and Harmful Information",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3895",
      "incident_id": 693,
      "title": "Report 3895 on Google AI Reportedly Delivering Confidently Incorrect and Harmful Information",
      "description": "A detailed report about Google AI Reportedly Delivering Confidently Incorrect and Harmful Information",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3892",
      "incident_id": 694,
      "title": "Report 3892 on Republican AI Ad Depicts Dystopian Future After Biden Reelection Announcement",
      "description": "A detailed report about Republican AI Ad Depicts Dystopian Future After Biden Reelection Announcement",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-04-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3893",
      "incident_id": 695,
      "title": "Report 3893 on Donald Trump's Presidential Campaign Released Deepfakes Attacking Ron DeSantis",
      "description": "A detailed report about Donald Trump's Presidential Campaign Released Deepfakes Attacking Ron DeSantis",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-05-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3894",
      "incident_id": 696,
      "title": "Report 3894 on Meta's AI Ad Platform Reportedly Causes Overspending and Poor Performance",
      "description": "A detailed report about Meta's AI Ad Platform Reportedly Causes Overspending and Poor Performance",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3896",
      "incident_id": 697,
      "title": "Report 3896 on Deepfake Image Circulating of Donald Trump with Underage Girl at Jeffrey Epstein's Private Island",
      "description": "A detailed report about Deepfake Image Circulating of Donald Trump with Underage Girl at Jeffrey Epstein's Private Island",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-06-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3897",
      "incident_id": 698,
      "title": "Report 3897 on Deepfake Video of Ron DeSantis Dropping Out of 2024 Presidential Race Circulating",
      "description": "A detailed report about Deepfake Video of Ron DeSantis Dropping Out of 2024 Presidential Race Circulating",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-09-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3901",
      "incident_id": 699,
      "title": "Report 3901 on VA Suicide Prevention Algorithm REACH VET Reportedly Prioritizes Men Over Women Veterans",
      "description": "A detailed report about VA Suicide Prevention Algorithm REACH VET Reportedly Prioritizes Men Over Women Veterans",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4174",
      "incident_id": 699,
      "title": "Report 4174 on VA Suicide Prevention Algorithm REACH VET Reportedly Prioritizes Men Over Women Veterans",
      "description": "A detailed report about VA Suicide Prevention Algorithm REACH VET Reportedly Prioritizes Men Over Women Veterans",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3904",
      "incident_id": 700,
      "title": "Report 3904 on Meta's AI Chatbots Are Entering Online Support Communities Uninvited",
      "description": "A detailed report about Meta's AI Chatbots Are Entering Online Support Communities Uninvited",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3939",
      "incident_id": 700,
      "title": "Report 3939 on Meta's AI Chatbots Are Entering Online Support Communities Uninvited",
      "description": "A detailed report about Meta's AI Chatbots Are Entering Online Support Communities Uninvited",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3911",
      "incident_id": 701,
      "title": "Report 3911 on American Asylum Seeker John Mark Dougan in Russia Reportedly Spreads Disinformation via AI Tools and Fake News Network",
      "description": "A detailed report about American Asylum Seeker John Mark Dougan in Russia Reportedly Spreads Disinformation via AI Tools and Fake News Network",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4858",
      "incident_id": 701,
      "title": "Report 4858 on American Asylum Seeker John Mark Dougan in Russia Reportedly Spreads Disinformation via AI Tools and Fake News Network",
      "description": "A detailed report about American Asylum Seeker John Mark Dougan in Russia Reportedly Spreads Disinformation via AI Tools and Fake News Network",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4859",
      "incident_id": 701,
      "title": "Report 4859 on American Asylum Seeker John Mark Dougan in Russia Reportedly Spreads Disinformation via AI Tools and Fake News Network",
      "description": "A detailed report about American Asylum Seeker John Mark Dougan in Russia Reportedly Spreads Disinformation via AI Tools and Fake News Network",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3914",
      "incident_id": 702,
      "title": "Report 3914 on Disinformation Deepfake Circulates of State Department Spokesman Matthew Miller Suggesting Belgorod Can Be Attacked with U.S. Weapons",
      "description": "A detailed report about Disinformation Deepfake Circulates of State Department Spokesman Matthew Miller Suggesting Belgorod Can Be Attacked with U.S. Weapons",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-31",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3917",
      "incident_id": 703,
      "title": "Report 3917 on Deepfake Audio Sparks False Claims of Biden Threatening Texas with F-15s",
      "description": "A detailed report about Deepfake Audio Sparks False Claims of Biden Threatening Texas with F-15s",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-01-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3918",
      "incident_id": 704,
      "title": "Report 3918 on Study Highlights Persistent Hallucinations in Legal AI Systems",
      "description": "A detailed report about Study Highlights Persistent Hallucinations in Legal AI Systems",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3923",
      "incident_id": 704,
      "title": "Report 3923 on Study Highlights Persistent Hallucinations in Legal AI Systems",
      "description": "A detailed report about Study Highlights Persistent Hallucinations in Legal AI Systems",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3919",
      "incident_id": 705,
      "title": "Report 3919 on Turkish Student in Isparta Allegedly Uses AI to Cheat on Exam, Leading to Arrest",
      "description": "A detailed report about Turkish Student in Isparta Allegedly Uses AI to Cheat on Exam, Leading to Arrest",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-06-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4050",
      "incident_id": 705,
      "title": "Report 4050 on Turkish Student in Isparta Allegedly Uses AI to Cheat on Exam, Leading to Arrest",
      "description": "A detailed report about Turkish Student in Isparta Allegedly Uses AI to Cheat on Exam, Leading to Arrest",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-06-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3920",
      "incident_id": 706,
      "title": "Report 3920 on Scammers Using AI to Impersonate Small Businesses",
      "description": "A detailed report about Scammers Using AI to Impersonate Small Businesses",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3921",
      "incident_id": 707,
      "title": "Report 3921 on Tesla Reportedly in Autopilot Mode Hits Parked Police Vehicle in Fullerton, California",
      "description": "A detailed report about Tesla Reportedly in Autopilot Mode Hits Parked Police Vehicle in Fullerton, California",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-06-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3922",
      "incident_id": 708,
      "title": "Report 3922 on Faulty AI Transcription Threatens Integrity of Genoa Bribery Probe",
      "description": "A detailed report about Faulty AI Transcription Threatens Integrity of Genoa Bribery Probe",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3924",
      "incident_id": 709,
      "title": "Report 3924 on Unrepresented Litigant Misled by ChatGPT-Generated False Legal Citations in Manchester Court",
      "description": "A detailed report about Unrepresented Litigant Misled by ChatGPT-Generated False Legal Citations in Manchester Court",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-05-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3925",
      "incident_id": 710,
      "title": "Report 3925 on Facebook AI Mislabels Auschwitz Photos as Bullying and Nudity",
      "description": "A detailed report about Facebook AI Mislabels Auschwitz Photos as Bullying and Nudity",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3926",
      "incident_id": 711,
      "title": "Report 3926 on NHTSA Opens New Probe into Tesla’s Autopilot Following More than a Dozen Fatal Accidents",
      "description": "A detailed report about NHTSA Opens New Probe into Tesla’s Autopilot Following More than a Dozen Fatal Accidents",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3927",
      "incident_id": 711,
      "title": "Report 3927 on NHTSA Opens New Probe into Tesla’s Autopilot Following More than a Dozen Fatal Accidents",
      "description": "A detailed report about NHTSA Opens New Probe into Tesla’s Autopilot Following More than a Dozen Fatal Accidents",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3928",
      "incident_id": 712,
      "title": "Report 3928 on Meta AI Hallucinates Harassment Allegations Against New York Politicians",
      "description": "A detailed report about Meta AI Hallucinates Harassment Allegations Against New York Politicians",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3929",
      "incident_id": 712,
      "title": "Report 3929 on Meta AI Hallucinates Harassment Allegations Against New York Politicians",
      "description": "A detailed report about Meta AI Hallucinates Harassment Allegations Against New York Politicians",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3930",
      "incident_id": 713,
      "title": "Report 3930 on Deepfake Video Falsely Depicts Biden Announcing National Draft for Ukraine",
      "description": "A detailed report about Deepfake Video Falsely Depicts Biden Announcing National Draft for Ukraine",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3931",
      "incident_id": 714,
      "title": "Report 3931 on Microsoft-Powered New York City Chatbot Advises Illegal Practices",
      "description": "A detailed report about Microsoft-Powered New York City Chatbot Advises Illegal Practices",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-03-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3932",
      "incident_id": 714,
      "title": "Report 3932 on Microsoft-Powered New York City Chatbot Advises Illegal Practices",
      "description": "A detailed report about Microsoft-Powered New York City Chatbot Advises Illegal Practices",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-03-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3933",
      "incident_id": 715,
      "title": "Report 3933 on Over 400 AI-Driven Scams Reportedly Led to $8M Loss for Australians in 2023",
      "description": "A detailed report about Over 400 AI-Driven Scams Reportedly Led to $8M Loss for Australians in 2023",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-03-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3934",
      "incident_id": 716,
      "title": "Report 3934 on Algorithmic Staffing Failures Linked to Resident Deaths at Leading Assisted-Living Chain Brookdale",
      "description": "A detailed report about Algorithmic Staffing Failures Linked to Resident Deaths at Leading Assisted-Living Chain Brookdale",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-04-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3935",
      "incident_id": 717,
      "title": "Report 3935 on Fake AI-Generated Law Firms Sent Fake DMCA Notices to Increase SEO",
      "description": "A detailed report about Fake AI-Generated Law Firms Sent Fake DMCA Notices to Increase SEO",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-03-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3936",
      "incident_id": 718,
      "title": "Report 3936 on OpenAI, Google, and Meta Alleged to Have Overstepped Legal Boundaries for Training AI",
      "description": "A detailed report about OpenAI, Google, and Meta Alleged to Have Overstepped Legal Boundaries for Training AI",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3937",
      "incident_id": 719,
      "title": "Report 3937 on Grok AI on X Created and Promoted False Iran Missile Strike News",
      "description": "A detailed report about Grok AI on X Created and Promoted False Iran Missile Strike News",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3938",
      "incident_id": 720,
      "title": "Report 3938 on Deepfake Video Targets Paul Vallas on Eve of Chicago Mayoral Election",
      "description": "A detailed report about Deepfake Video Targets Paul Vallas on Eve of Chicago Mayoral Election",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3955",
      "incident_id": 721,
      "title": "Report 3955 on Fake AI-Generated Students Are Reportedly Enrolling in Online College Classes",
      "description": "A detailed report about Fake AI-Generated Students Are Reportedly Enrolling in Online College Classes",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-06-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3940",
      "incident_id": 722,
      "title": "Report 3940 on Catholic AI Chatbot 'Father Justin' Claimed to Be a Real Priest, Prompting Retraction",
      "description": "A detailed report about Catholic AI Chatbot 'Father Justin' Claimed to Be a Real Priest, Prompting Retraction",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3941",
      "incident_id": 723,
      "title": "Report 3941 on Instagram Algorithms Reportedly Directed Children's Merchandise Ad Campaign to Adult Men and Sex Offenders",
      "description": "A detailed report about Instagram Algorithms Reportedly Directed Children's Merchandise Ad Campaign to Adult Men and Sex Offenders",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3944",
      "incident_id": 723,
      "title": "Report 3944 on Instagram Algorithms Reportedly Directed Children's Merchandise Ad Campaign to Adult Men and Sex Offenders",
      "description": "A detailed report about Instagram Algorithms Reportedly Directed Children's Merchandise Ad Campaign to Adult Men and Sex Offenders",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3942",
      "incident_id": 724,
      "title": "Report 3942 on AI-Generated Papers Manipulate Scopus Rankings in Top Philosophy Journals",
      "description": "A detailed report about AI-Generated Papers Manipulate Scopus Rankings in Top Philosophy Journals",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-06-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3943",
      "incident_id": 725,
      "title": "Report 3943 on Cartels Reportedly Using AI to Expand Operations into Financial Fraud and Human Trafficking",
      "description": "A detailed report about Cartels Reportedly Using AI to Expand Operations into Financial Fraud and Human Trafficking",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-03-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3945",
      "incident_id": 726,
      "title": "Report 3945 on A Self-Driving Cruise Robot Taxi Reportedly Struck and Dragged a Pedestrian 20 Feet",
      "description": "A detailed report about A Self-Driving Cruise Robot Taxi Reportedly Struck and Dragged a Pedestrian 20 Feet",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3946",
      "incident_id": 726,
      "title": "Report 3946 on A Self-Driving Cruise Robot Taxi Reportedly Struck and Dragged a Pedestrian 20 Feet",
      "description": "A detailed report about A Self-Driving Cruise Robot Taxi Reportedly Struck and Dragged a Pedestrian 20 Feet",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3947",
      "incident_id": 726,
      "title": "Report 3947 on A Self-Driving Cruise Robot Taxi Reportedly Struck and Dragged a Pedestrian 20 Feet",
      "description": "A detailed report about A Self-Driving Cruise Robot Taxi Reportedly Struck and Dragged a Pedestrian 20 Feet",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3948",
      "incident_id": 727,
      "title": "Report 3948 on Synthetic Voice 'Olesya' by Storm-1516 Falsely Accuses Ukraine in U.S. Election Disinformation Campaign",
      "description": "A detailed report about Synthetic Voice 'Olesya' by Storm-1516 Falsely Accuses Ukraine in U.S. Election Disinformation Campaign",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3949",
      "incident_id": 728,
      "title": "Report 3949 on AI Firm Lovo Accused of Illegally Replicating Voice Actors' Voices",
      "description": "A detailed report about AI Firm Lovo Accused of Illegally Replicating Voice Actors' Voices",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3950",
      "incident_id": 729,
      "title": "Report 3950 on GPT-4o's Chinese Tokens Reportedly Compromised by Spam and Pornography Due to Inadequate Filtering",
      "description": "A detailed report about GPT-4o's Chinese Tokens Reportedly Compromised by Spam and Pornography Due to Inadequate Filtering",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3951",
      "incident_id": 730,
      "title": "Report 3951 on AI Deepfakes for Voter Outreach Flood Indian Elections",
      "description": "A detailed report about AI Deepfakes for Voter Outreach Flood Indian Elections",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3952",
      "incident_id": 731,
      "title": "Report 3952 on Hallucinated Software Packages with Potential Malware Downloaded Thousands of Times by Developers",
      "description": "A detailed report about Hallucinated Software Packages with Potential Malware Downloaded Thousands of Times by Developers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3953",
      "incident_id": 732,
      "title": "Report 3953 on Whisper Speech-to-Text AI Reportedly Found to Create Violent Hallucinations",
      "description": "A detailed report about Whisper Speech-to-Text AI Reportedly Found to Create Violent Hallucinations",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3954",
      "incident_id": 733,
      "title": "Report 3954 on Auto Insurers Allegedly Are Surreptitiously Collecting and Scoring Driver Data",
      "description": "A detailed report about Auto Insurers Allegedly Are Surreptitiously Collecting and Scoring Driver Data",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-06-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3957",
      "incident_id": 733,
      "title": "Report 3957 on Auto Insurers Allegedly Are Surreptitiously Collecting and Scoring Driver Data",
      "description": "A detailed report about Auto Insurers Allegedly Are Surreptitiously Collecting and Scoring Driver Data",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-06-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3956",
      "incident_id": 734,
      "title": "Report 3956 on Leading AI Models Reportedly Found to Mimic Russian Disinformation in 33% of Cases and to Cite Fake Moscow News Sites",
      "description": "A detailed report about Leading AI Models Reportedly Found to Mimic Russian Disinformation in 33% of Cases and to Cite Fake Moscow News Sites",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-06-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4884",
      "incident_id": 734,
      "title": "Report 4884 on Leading AI Models Reportedly Found to Mimic Russian Disinformation in 33% of Cases and to Cite Fake Moscow News Sites",
      "description": "A detailed report about Leading AI Models Reportedly Found to Mimic Russian Disinformation in 33% of Cases and to Cite Fake Moscow News Sites",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-06-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4885",
      "incident_id": 734,
      "title": "Report 4885 on Leading AI Models Reportedly Found to Mimic Russian Disinformation in 33% of Cases and to Cite Fake Moscow News Sites",
      "description": "A detailed report about Leading AI Models Reportedly Found to Mimic Russian Disinformation in 33% of Cases and to Cite Fake Moscow News Sites",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-06-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3960",
      "incident_id": 735,
      "title": "Report 3960 on AI Enhances Scammer Tactics Making Detection Harder",
      "description": "A detailed report about AI Enhances Scammer Tactics Making Detection Harder",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-06-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3961",
      "incident_id": 736,
      "title": "Report 3961 on Underground Market for LLMs Powers Malware and Phishing Scams",
      "description": "A detailed report about Underground Market for LLMs Powers Malware and Phishing Scams",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4021",
      "incident_id": 736,
      "title": "Report 4021 on Underground Market for LLMs Powers Malware and Phishing Scams",
      "description": "A detailed report about Underground Market for LLMs Powers Malware and Phishing Scams",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3962",
      "incident_id": 737,
      "title": "Report 3962 on Amandine Le Pen Deepfake Account Misleads Thousands on TikTok",
      "description": "A detailed report about Amandine Le Pen Deepfake Account Misleads Thousands on TikTok",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3981",
      "incident_id": 737,
      "title": "Report 3981 on Amandine Le Pen Deepfake Account Misleads Thousands on TikTok",
      "description": "A detailed report about Amandine Le Pen Deepfake Account Misleads Thousands on TikTok",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3963",
      "incident_id": 738,
      "title": "Report 3963 on Department for Work and Pensions (DWP) Algorithm Wrongly Flags 200,000 for Housing Benefit Fraud",
      "description": "A detailed report about Department for Work and Pensions (DWP) Algorithm Wrongly Flags 200,000 for Housing Benefit Fraud",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-06-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3969",
      "incident_id": 738,
      "title": "Report 3969 on Department for Work and Pensions (DWP) Algorithm Wrongly Flags 200,000 for Housing Benefit Fraud",
      "description": "A detailed report about Department for Work and Pensions (DWP) Algorithm Wrongly Flags 200,000 for Housing Benefit Fraud",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-06-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3971",
      "incident_id": 738,
      "title": "Report 3971 on Department for Work and Pensions (DWP) Algorithm Wrongly Flags 200,000 for Housing Benefit Fraud",
      "description": "A detailed report about Department for Work and Pensions (DWP) Algorithm Wrongly Flags 200,000 for Housing Benefit Fraud",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-06-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3966",
      "incident_id": 739,
      "title": "Report 3966 on Scammers Use Deepfake of Hong Kong Entertainer Andy Lau to Steal NT$2.64 Million from Fan",
      "description": "A detailed report about Scammers Use Deepfake of Hong Kong Entertainer Andy Lau to Steal NT$2.64 Million from Fan",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-06-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3967",
      "incident_id": 739,
      "title": "Report 3967 on Scammers Use Deepfake of Hong Kong Entertainer Andy Lau to Steal NT$2.64 Million from Fan",
      "description": "A detailed report about Scammers Use Deepfake of Hong Kong Entertainer Andy Lau to Steal NT$2.64 Million from Fan",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-06-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3970",
      "incident_id": 740,
      "title": "Report 3970 on Department for Work and Pensions (DWP) AI Systems Allegedly Discriminate Against Single Mothers",
      "description": "A detailed report about Department for Work and Pensions (DWP) AI Systems Allegedly Discriminate Against Single Mothers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3973",
      "incident_id": 741,
      "title": "Report 3973 on Robin Williams's Voice Deepfaked Without Consent",
      "description": "A detailed report about Robin Williams's Voice Deepfaked Without Consent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3974",
      "incident_id": 742,
      "title": "Report 3974 on Grok AI Model Reportedly Fails to Produce Reliable News in Wake of Trump Assassination Attempt",
      "description": "A detailed report about Grok AI Model Reportedly Fails to Produce Reliable News in Wake of Trump Assassination Attempt",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3975",
      "incident_id": 743,
      "title": "Report 3975 on Gemini AI Allegedly Reads Google Drive Files Without Explicit User Consent",
      "description": "A detailed report about Gemini AI Allegedly Reads Google Drive Files Without Explicit User Consent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3977",
      "incident_id": 744,
      "title": "Report 3977 on AI Work Assistants Require More Effort Than Expected, CIOs Say",
      "description": "A detailed report about AI Work Assistants Require More Effort Than Expected, CIOs Say",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-06-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3978",
      "incident_id": 745,
      "title": "Report 3978 on Figma Disables AI Feature After Accusations of Copying Apple’s Weather App",
      "description": "A detailed report about Figma Disables AI Feature After Accusations of Copying Apple’s Weather App",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4103",
      "incident_id": 745,
      "title": "Report 4103 on Figma Disables AI Feature After Accusations of Copying Apple’s Weather App",
      "description": "A detailed report about Figma Disables AI Feature After Accusations of Copying Apple’s Weather App",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3979",
      "incident_id": 746,
      "title": "Report 3979 on Class Action Lawsuit Over Alleged Defects in Volkswagen's AI-Driven AEB Systems",
      "description": "A detailed report about Class Action Lawsuit Over Alleged Defects in Volkswagen's AI-Driven AEB Systems",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3982",
      "incident_id": 746,
      "title": "Report 3982 on Class Action Lawsuit Over Alleged Defects in Volkswagen's AI-Driven AEB Systems",
      "description": "A detailed report about Class Action Lawsuit Over Alleged Defects in Volkswagen's AI-Driven AEB Systems",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3980",
      "incident_id": 747,
      "title": "Report 3980 on Fatalities Reportedly Occur Despite VioGén Algorithm's Low or Negligible Risk Scores",
      "description": "A detailed report about Fatalities Reportedly Occur Despite VioGén Algorithm's Low or Negligible Risk Scores",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3983",
      "incident_id": 748,
      "title": "Report 3983 on Erroneous Declined Transaction Notification by PayPal AI Assistant",
      "description": "A detailed report about Erroneous Declined Transaction Notification by PayPal AI Assistant",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-06-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3984",
      "incident_id": 749,
      "title": "Report 3984 on Hoodline Accused of Misleadingly Attributing AI-Generated Articles to Human Authors",
      "description": "A detailed report about Hoodline Accused of Misleadingly Attributing AI-Generated Articles to Human Authors",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-31",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3985",
      "incident_id": 750,
      "title": "Report 3985 on AI Chatbots Reportedly Inaccurately Conveyed Real-Time Political News",
      "description": "A detailed report about AI Chatbots Reportedly Inaccurately Conveyed Real-Time Political News",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-22",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3986",
      "incident_id": 751,
      "title": "Report 3986 on SearchGPT Reportedly Misleads Users with Incorrect Festival Dates in Demo",
      "description": "A detailed report about SearchGPT Reportedly Misleads Users with Incorrect Festival Dates in Demo",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4038",
      "incident_id": 751,
      "title": "Report 4038 on SearchGPT Reportedly Misleads Users with Incorrect Festival Dates in Demo",
      "description": "A detailed report about SearchGPT Reportedly Misleads Users with Incorrect Festival Dates in Demo",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3987",
      "incident_id": 752,
      "title": "Report 3987 on AI-Generated Obituaries Are Reportedly Intensifying Grief for Bereaved Families",
      "description": "A detailed report about AI-Generated Obituaries Are Reportedly Intensifying Grief for Bereaved Families",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3988",
      "incident_id": 753,
      "title": "Report 3988 on BNN Breaking's AI-Driven Errors Reportedly Damage Reputations and Spread Misinformation",
      "description": "A detailed report about BNN Breaking's AI-Driven Errors Reportedly Damage Reputations and Spread Misinformation",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-06-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3989",
      "incident_id": 754,
      "title": "Report 3989 on British Female Politicians Victimized by Deepfake Pornography",
      "description": "A detailed report about British Female Politicians Victimized by Deepfake Pornography",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3990",
      "incident_id": 755,
      "title": "Report 3990 on Deepfake Targets Olena Zelenska in Russian Disinformation Campaign",
      "description": "A detailed report about Deepfake Targets Olena Zelenska in Russian Disinformation Campaign",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4014",
      "incident_id": 755,
      "title": "Report 4014 on Deepfake Targets Olena Zelenska in Russian Disinformation Campaign",
      "description": "A detailed report about Deepfake Targets Olena Zelenska in Russian Disinformation Campaign",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4881",
      "incident_id": 755,
      "title": "Report 4881 on Deepfake Targets Olena Zelenska in Russian Disinformation Campaign",
      "description": "A detailed report about Deepfake Targets Olena Zelenska in Russian Disinformation Campaign",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3991",
      "incident_id": 756,
      "title": "Report 3991 on Deepfake of Kamala Harris Saying Damaging Comments Circulates on X and Is Amplified by Elon Musk",
      "description": "A detailed report about Deepfake of Kamala Harris Saying Damaging Comments Circulates on X and Is Amplified by Elon Musk",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3992",
      "incident_id": 756,
      "title": "Report 3992 on Deepfake of Kamala Harris Saying Damaging Comments Circulates on X and Is Amplified by Elon Musk",
      "description": "A detailed report about Deepfake of Kamala Harris Saying Damaging Comments Circulates on X and Is Amplified by Elon Musk",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4145",
      "incident_id": 756,
      "title": "Report 4145 on Deepfake of Kamala Harris Saying Damaging Comments Circulates on X and Is Amplified by Elon Musk",
      "description": "A detailed report about Deepfake of Kamala Harris Saying Damaging Comments Circulates on X and Is Amplified by Elon Musk",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3993",
      "incident_id": 757,
      "title": "Report 3993 on OpenAI's ChatGPT Mac App Stored User Data in Unencrypted Text Files",
      "description": "A detailed report about OpenAI's ChatGPT Mac App Stored User Data in Unencrypted Text Files",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3994",
      "incident_id": 758,
      "title": "Report 3994 on Teen's Overdose Reportedly Linked to Meta's AI Systems Failing to Block Ads for Illegal Drugs",
      "description": "A detailed report about Teen's Overdose Reportedly Linked to Meta's AI Systems Failing to Block Ads for Illegal Drugs",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-09-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3995",
      "incident_id": 759,
      "title": "Report 3995 on AI-Generated Deepfakes Reportedly Derailed Political Career of Florida Official",
      "description": "A detailed report about AI-Generated Deepfakes Reportedly Derailed Political Career of Florida Official",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-02-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3997",
      "incident_id": 760,
      "title": "Report 3997 on False Election Data on Kamala Harris Reportedly Circulated via Grok AI Chatbot",
      "description": "A detailed report about False Election Data on Kamala Harris Reportedly Circulated via Grok AI Chatbot",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4080",
      "incident_id": 760,
      "title": "Report 4080 on False Election Data on Kamala Harris Reportedly Circulated via Grok AI Chatbot",
      "description": "A detailed report about False Election Data on Kamala Harris Reportedly Circulated via Grok AI Chatbot",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3998",
      "incident_id": 761,
      "title": "Report 3998 on TikTok AI System Used to Amplify Election Disinformation by Foreign Networks",
      "description": "A detailed report about TikTok AI System Used to Amplify Election Disinformation by Foreign Networks",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-08-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3999",
      "incident_id": 762,
      "title": "Report 3999 on Grok AI Reportedly Generates Offensive and Violent Images Without Proper Safeguards",
      "description": "A detailed report about Grok AI Reportedly Generates Offensive and Violent Images Without Proper Safeguards",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-08-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4025",
      "incident_id": 762,
      "title": "Report 4025 on Grok AI Reportedly Generates Offensive and Violent Images Without Proper Safeguards",
      "description": "A detailed report about Grok AI Reportedly Generates Offensive and Violent Images Without Proper Safeguards",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-08-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4026",
      "incident_id": 762,
      "title": "Report 4026 on Grok AI Reportedly Generates Offensive and Violent Images Without Proper Safeguards",
      "description": "A detailed report about Grok AI Reportedly Generates Offensive and Violent Images Without Proper Safeguards",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-08-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4000",
      "incident_id": 763,
      "title": "Report 4000 on Grok AI Chatbot Reportedly Spreads Unfounded Rumors About Trump’s Dentures",
      "description": "A detailed report about Grok AI Chatbot Reportedly Spreads Unfounded Rumors About Trump’s Dentures",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-08-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4001",
      "incident_id": 764,
      "title": "Report 4001 on Cody Enterprise Reporter Resigns After Admitting to AI-Generated Fake Quotes",
      "description": "A detailed report about Cody Enterprise Reporter Resigns After Admitting to AI-Generated Fake Quotes",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-06-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4007",
      "incident_id": 764,
      "title": "Report 4007 on Cody Enterprise Reporter Resigns After Admitting to AI-Generated Fake Quotes",
      "description": "A detailed report about Cody Enterprise Reporter Resigns After Admitting to AI-Generated Fake Quotes",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-06-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4008",
      "incident_id": 764,
      "title": "Report 4008 on Cody Enterprise Reporter Resigns After Admitting to AI-Generated Fake Quotes",
      "description": "A detailed report about Cody Enterprise Reporter Resigns After Admitting to AI-Generated Fake Quotes",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-06-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4003",
      "incident_id": 765,
      "title": "Report 4003 on 22 Students at Richmond-Burton Community High School in Illinois Targeted by Deepfake Nudes",
      "description": "A detailed report about 22 Students at Richmond-Burton Community High School in Illinois Targeted by Deepfake Nudes",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-03-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4004",
      "incident_id": 765,
      "title": "Report 4004 on 22 Students at Richmond-Burton Community High School in Illinois Targeted by Deepfake Nudes",
      "description": "A detailed report about 22 Students at Richmond-Burton Community High School in Illinois Targeted by Deepfake Nudes",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-03-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4011",
      "incident_id": 765,
      "title": "Report 4011 on 22 Students at Richmond-Burton Community High School in Illinois Targeted by Deepfake Nudes",
      "description": "A detailed report about 22 Students at Richmond-Burton Community High School in Illinois Targeted by Deepfake Nudes",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-03-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4005",
      "incident_id": 766,
      "title": "Report 4005 on Trump Shares AI-Generated Images Falsely Suggesting Taylor Swift Endorsement",
      "description": "A detailed report about Trump Shares AI-Generated Images Falsely Suggesting Taylor Swift Endorsement",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-08-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4015",
      "incident_id": 766,
      "title": "Report 4015 on Trump Shares AI-Generated Images Falsely Suggesting Taylor Swift Endorsement",
      "description": "A detailed report about Trump Shares AI-Generated Images Falsely Suggesting Taylor Swift Endorsement",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-08-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4006",
      "incident_id": 767,
      "title": "Report 4006 on AI Image of Kamala Harris at DNC with Communist Flags Circulated by Trump",
      "description": "A detailed report about AI Image of Kamala Harris at DNC with Communist Flags Circulated by Trump",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-08-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4030",
      "incident_id": 767,
      "title": "Report 4030 on AI Image of Kamala Harris at DNC with Communist Flags Circulated by Trump",
      "description": "A detailed report about AI Image of Kamala Harris at DNC with Communist Flags Circulated by Trump",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-08-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4010",
      "incident_id": 768,
      "title": "Report 4010 on ChatGPT Implicated in Samsung Data Leak of Source Code and Meeting Notes",
      "description": "A detailed report about ChatGPT Implicated in Samsung Data Leak of Source Code and Meeting Notes",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-03-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4017",
      "incident_id": 769,
      "title": "Report 4017 on Investigative Journalist Rana Ayyub Targeted by AI-Generated Deepfake Pornography",
      "description": "A detailed report about Investigative Journalist Rana Ayyub Targeted by AI-Generated Deepfake Pornography",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-04-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4024",
      "incident_id": 769,
      "title": "Report 4024 on Investigative Journalist Rana Ayyub Targeted by AI-Generated Deepfake Pornography",
      "description": "A detailed report about Investigative Journalist Rana Ayyub Targeted by AI-Generated Deepfake Pornography",
      "url": "https://incidentdatabase.ai",
      "date_published": "2018-04-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4018",
      "incident_id": 770,
      "title": "Report 4018 on Microsoft Copilot Falsely Accuses Journalist Martin Bernklau of Crimes",
      "description": "A detailed report about Microsoft Copilot Falsely Accuses Journalist Martin Bernklau of Crimes",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-08-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4027",
      "incident_id": 770,
      "title": "Report 4027 on Microsoft Copilot Falsely Accuses Journalist Martin Bernklau of Crimes",
      "description": "A detailed report about Microsoft Copilot Falsely Accuses Journalist Martin Bernklau of Crimes",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-08-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4028",
      "incident_id": 770,
      "title": "Report 4028 on Microsoft Copilot Falsely Accuses Journalist Martin Bernklau of Crimes",
      "description": "A detailed report about Microsoft Copilot Falsely Accuses Journalist Martin Bernklau of Crimes",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-08-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4019",
      "incident_id": 771,
      "title": "Report 4019 on Noelle Martin Deepfaked Without Consent in AI-Generated Pornography",
      "description": "A detailed report about Noelle Martin Deepfaked Without Consent in AI-Generated Pornography",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-02-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4020",
      "incident_id": 772,
      "title": "Report 4020 on Kristen Bell Deepfaked in Non-Consensual AI-Generated Pornography",
      "description": "A detailed report about Kristen Bell Deepfaked in Non-Consensual AI-Generated Pornography",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-06-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4085",
      "incident_id": 772,
      "title": "Report 4085 on Kristen Bell Deepfaked in Non-Consensual AI-Generated Pornography",
      "description": "A detailed report about Kristen Bell Deepfaked in Non-Consensual AI-Generated Pornography",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-06-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4022",
      "incident_id": 773,
      "title": "Report 4022 on Chatbot in Workplace Training at Bunbury Prison Reveals Real Names in Sexual Harassment Case",
      "description": "A detailed report about Chatbot in Workplace Training at Bunbury Prison Reveals Real Names in Sexual Harassment Case",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-08-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4029",
      "incident_id": 774,
      "title": "Report 4029 on Covert AI Influence Operations Linked to Russia, China, Iran, and Israel, OpenAI Reveals",
      "description": "A detailed report about Covert AI Influence Operations Linked to Russia, China, Iran, and Israel, OpenAI Reveals",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4039",
      "incident_id": 774,
      "title": "Report 4039 on Covert AI Influence Operations Linked to Russia, China, Iran, and Israel, OpenAI Reveals",
      "description": "A detailed report about Covert AI Influence Operations Linked to Russia, China, Iran, and Israel, OpenAI Reveals",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4031",
      "incident_id": 775,
      "title": "Report 4031 on Elon Musk Reportedly Shared an AI-Generated Image Depicting Kamala Harris Dressed as a Communist Ruler",
      "description": "A detailed report about Elon Musk Reportedly Shared an AI-Generated Image Depicting Kamala Harris Dressed as a Communist Ruler",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4032",
      "incident_id": 776,
      "title": "Report 4032 on Megalopolis Trailer Included Fake AI-Generated Quotes Attributed to Film Critics",
      "description": "A detailed report about Megalopolis Trailer Included Fake AI-Generated Quotes Attributed to Film Critics",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-08-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4033",
      "incident_id": 777,
      "title": "Report 4033 on South Korea Experiences a Surge of Explicit Deepfake Pornography",
      "description": "A detailed report about South Korea Experiences a Surge of Explicit Deepfake Pornography",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-08-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4034",
      "incident_id": 777,
      "title": "Report 4034 on South Korea Experiences a Surge of Explicit Deepfake Pornography",
      "description": "A detailed report about South Korea Experiences a Surge of Explicit Deepfake Pornography",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-08-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4035",
      "incident_id": 777,
      "title": "Report 4035 on South Korea Experiences a Surge of Explicit Deepfake Pornography",
      "description": "A detailed report about South Korea Experiences a Surge of Explicit Deepfake Pornography",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-08-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4040",
      "incident_id": 778,
      "title": "Report 4040 on Amazon's Alexa Reportedly Shows Political Preference Error in Trump-Harris Presidential Race Queries",
      "description": "A detailed report about Amazon's Alexa Reportedly Shows Political Preference Error in Trump-Harris Presidential Race Queries",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4041",
      "incident_id": 778,
      "title": "Report 4041 on Amazon's Alexa Reportedly Shows Political Preference Error in Trump-Harris Presidential Race Queries",
      "description": "A detailed report about Amazon's Alexa Reportedly Shows Political Preference Error in Trump-Harris Presidential Race Queries",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4042",
      "incident_id": 779,
      "title": "Report 4042 on Music Producer Arrested for Allegedly Using AI-Generated Songs in $10 Million Streaming Scam",
      "description": "A detailed report about Music Producer Arrested for Allegedly Using AI-Generated Songs in $10 Million Streaming Scam",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4044",
      "incident_id": 780,
      "title": "Report 4044 on Joint Base Elmendorf-Richardson Soldier Faces Allegations of Using AI to Generate Child Pornography",
      "description": "A detailed report about Joint Base Elmendorf-Richardson Soldier Faces Allegations of Using AI to Generate Child Pornography",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-08-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4045",
      "incident_id": 781,
      "title": "Report 4045 on Clearview AI Faces $33.7 Million Fine for Violating GDPR with Biometric Data Harvesting",
      "description": "A detailed report about Clearview AI Faces $33.7 Million Fine for Violating GDPR with Biometric Data Harvesting",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4987",
      "incident_id": 781,
      "title": "Report 4987 on Clearview AI Faces $33.7 Million Fine for Violating GDPR with Biometric Data Harvesting",
      "description": "A detailed report about Clearview AI Faces $33.7 Million Fine for Violating GDPR with Biometric Data Harvesting",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4046",
      "incident_id": 782,
      "title": "Report 4046 on AI 'Nudify' Apps Used as Tools for Blackmail and Extortion",
      "description": "A detailed report about AI 'Nudify' Apps Used as Tools for Blackmail and Extortion",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4047",
      "incident_id": 783,
      "title": "Report 4047 on WiseTech Global CEO Richard White Reportedly Deepfaked in Multiple Attempts to Scam Staffers",
      "description": "A detailed report about WiseTech Global CEO Richard White Reportedly Deepfaked in Multiple Attempts to Scam Staffers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4048",
      "incident_id": 784,
      "title": "Report 4048 on Child Predators Are Reportedly Generating Deepfake Nudes of Children to Extort Them",
      "description": "A detailed report about Child Predators Are Reportedly Generating Deepfake Nudes of Children to Extort Them",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4049",
      "incident_id": 785,
      "title": "Report 4049 on ESPN's AI Coverage Overlooks Alex Morgan in Her Final Match Recap",
      "description": "A detailed report about ESPN's AI Coverage Overlooks Alex Morgan in Her Final Match Recap",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4053",
      "incident_id": 786,
      "title": "Report 4053 on Fraudsters Use Deepfake Video of Tim Cook to Promote Apple Crypto Scam on YouTube",
      "description": "A detailed report about Fraudsters Use Deepfake Video of Tim Cook to Promote Apple Crypto Scam on YouTube",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-09-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4054",
      "incident_id": 786,
      "title": "Report 4054 on Fraudsters Use Deepfake Video of Tim Cook to Promote Apple Crypto Scam on YouTube",
      "description": "A detailed report about Fraudsters Use Deepfake Video of Tim Cook to Promote Apple Crypto Scam on YouTube",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-09-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4055",
      "incident_id": 787,
      "title": "Report 4055 on Deepfake ID Sales Persist as OnlyFake Relaunches with New Fraud Tools",
      "description": "A detailed report about Deepfake ID Sales Persist as OnlyFake Relaunches with New Fraud Tools",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-03-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4104",
      "incident_id": 787,
      "title": "Report 4104 on Deepfake ID Sales Persist as OnlyFake Relaunches with New Fraud Tools",
      "description": "A detailed report about Deepfake ID Sales Persist as OnlyFake Relaunches with New Fraud Tools",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-03-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4056",
      "incident_id": 788,
      "title": "Report 4056 on Instagram's Algorithm Reportedly Recommended Sexual Content to Teenagers' Accounts",
      "description": "A detailed report about Instagram's Algorithm Reportedly Recommended Sexual Content to Teenagers' Accounts",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-06-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4060",
      "incident_id": 789,
      "title": "Report 4060 on Independent News Sites Flagged as Spam by Facebook's AI Moderation System",
      "description": "A detailed report about Independent News Sites Flagged as Spam by Facebook's AI Moderation System",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-06-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4062",
      "incident_id": 790,
      "title": "Report 4062 on Unrestricted AI Avatar Tool Accidentally Released by TikTok Permits Recitation of Hitler Quotes and Other Harmful Speech",
      "description": "A detailed report about Unrestricted AI Avatar Tool Accidentally Released by TikTok Permits Recitation of Hitler Quotes and Other Harmful Speech",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-06-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4063",
      "incident_id": 790,
      "title": "Report 4063 on Unrestricted AI Avatar Tool Accidentally Released by TikTok Permits Recitation of Hitler Quotes and Other Harmful Speech",
      "description": "A detailed report about Unrestricted AI Avatar Tool Accidentally Released by TikTok Permits Recitation of Hitler Quotes and Other Harmful Speech",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-06-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4064",
      "incident_id": 791,
      "title": "Report 4064 on Google AI Error Prompts Parents to Use Fecal Matter in Child Training Exercise",
      "description": "A detailed report about Google AI Error Prompts Parents to Use Fecal Matter in Child Training Exercise",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4065",
      "incident_id": 792,
      "title": "Report 4065 on Unauthorized Use of AI to Replicate Tupac Shakur's and Snoop Dogg's Voices in Drake's 'Taylor Made Freestyle'",
      "description": "A detailed report about Unauthorized Use of AI to Replicate Tupac Shakur's and Snoop Dogg's Voices in Drake's 'Taylor Made Freestyle'",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4116",
      "incident_id": 792,
      "title": "Report 4116 on Unauthorized Use of AI to Replicate Tupac Shakur's and Snoop Dogg's Voices in Drake's 'Taylor Made Freestyle'",
      "description": "A detailed report about Unauthorized Use of AI to Replicate Tupac Shakur's and Snoop Dogg's Voices in Drake's 'Taylor Made Freestyle'",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4117",
      "incident_id": 792,
      "title": "Report 4117 on Unauthorized Use of AI to Replicate Tupac Shakur's and Snoop Dogg's Voices in Drake's 'Taylor Made Freestyle'",
      "description": "A detailed report about Unauthorized Use of AI to Replicate Tupac Shakur's and Snoop Dogg's Voices in Drake's 'Taylor Made Freestyle'",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4078",
      "incident_id": 793,
      "title": "Report 4078 on AllHere's Chatbot 'Ed' Fails and Costs Los Angeles Unified School District $6 Million",
      "description": "A detailed report about AllHere's Chatbot 'Ed' Fails and Costs Los Angeles Unified School District $6 Million",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4298",
      "incident_id": 793,
      "title": "Report 4298 on AllHere's Chatbot 'Ed' Fails and Costs Los Angeles Unified School District $6 Million",
      "description": "A detailed report about AllHere's Chatbot 'Ed' Fails and Costs Los Angeles Unified School District $6 Million",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4609",
      "incident_id": 793,
      "title": "Report 4609 on AllHere's Chatbot 'Ed' Fails and Costs Los Angeles Unified School District $6 Million",
      "description": "A detailed report about AllHere's Chatbot 'Ed' Fails and Costs Los Angeles Unified School District $6 Million",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4082",
      "incident_id": 794,
      "title": "Report 4082 on Glitch in Waymo Self-Driving Cars Triggers Regular All-Night Honking in San Francisco",
      "description": "A detailed report about Glitch in Waymo Self-Driving Cars Triggers Regular All-Night Honking in San Francisco",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-08-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4083",
      "incident_id": 794,
      "title": "Report 4083 on Glitch in Waymo Self-Driving Cars Triggers Regular All-Night Honking in San Francisco",
      "description": "A detailed report about Glitch in Waymo Self-Driving Cars Triggers Regular All-Night Honking in San Francisco",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-08-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4084",
      "incident_id": 795,
      "title": "Report 4084 on Deepfake Elon Musk Videos Have Reportedly Contributed to Billions in Fraud",
      "description": "A detailed report about Deepfake Elon Musk Videos Have Reportedly Contributed to Billions in Fraud",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-08-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4384",
      "incident_id": 795,
      "title": "Report 4384 on Deepfake Elon Musk Videos Have Reportedly Contributed to Billions in Fraud",
      "description": "A detailed report about Deepfake Elon Musk Videos Have Reportedly Contributed to Billions in Fraud",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-08-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4087",
      "incident_id": 796,
      "title": "Report 4087 on Facebook's Content Moderation System Flagged and Removed Emergency Updates as Spam During Wildfires",
      "description": "A detailed report about Facebook's Content Moderation System Flagged and Removed Emergency Updates as Spam During Wildfires",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-06-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4100",
      "incident_id": 796,
      "title": "Report 4100 on Facebook's Content Moderation System Flagged and Removed Emergency Updates as Spam During Wildfires",
      "description": "A detailed report about Facebook's Content Moderation System Flagged and Removed Emergency Updates as Spam During Wildfires",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-06-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4101",
      "incident_id": 796,
      "title": "Report 4101 on Facebook's Content Moderation System Flagged and Removed Emergency Updates as Spam During Wildfires",
      "description": "A detailed report about Facebook's Content Moderation System Flagged and Removed Emergency Updates as Spam During Wildfires",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-06-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4090",
      "incident_id": 797,
      "title": "Report 4090 on Teenager Makes Deepfake Pornography of 50 Girls at Bacchus Marsh Grammar School in Australia",
      "description": "A detailed report about Teenager Makes Deepfake Pornography of 50 Girls at Bacchus Marsh Grammar School in Australia",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-06-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4105",
      "incident_id": 797,
      "title": "Report 4105 on Teenager Makes Deepfake Pornography of 50 Girls at Bacchus Marsh Grammar School in Australia",
      "description": "A detailed report about Teenager Makes Deepfake Pornography of 50 Girls at Bacchus Marsh Grammar School in Australia",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-06-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4106",
      "incident_id": 797,
      "title": "Report 4106 on Teenager Makes Deepfake Pornography of 50 Girls at Bacchus Marsh Grammar School in Australia",
      "description": "A detailed report about Teenager Makes Deepfake Pornography of 50 Girls at Bacchus Marsh Grammar School in Australia",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-06-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4091",
      "incident_id": 798,
      "title": "Report 4091 on Australian Schools Grappling with Significant Spread of Non-Consensual Spread of Deepfake Pornography of Students",
      "description": "A detailed report about Australian Schools Grappling with Significant Spread of Non-Consensual Spread of Deepfake Pornography of Students",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-06-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4092",
      "incident_id": 799,
      "title": "Report 4092 on Aledo High School Student Allegedly Generates and Distributes Deepfake Nudes of Seven Female Classmates",
      "description": "A detailed report about Aledo High School Student Allegedly Generates and Distributes Deepfake Nudes of Seven Female Classmates",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4093",
      "incident_id": 799,
      "title": "Report 4093 on Aledo High School Student Allegedly Generates and Distributes Deepfake Nudes of Seven Female Classmates",
      "description": "A detailed report about Aledo High School Student Allegedly Generates and Distributes Deepfake Nudes of Seven Female Classmates",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4543",
      "incident_id": 799,
      "title": "Report 4543 on Aledo High School Student Allegedly Generates and Distributes Deepfake Nudes of Seven Female Classmates",
      "description": "A detailed report about Aledo High School Student Allegedly Generates and Distributes Deepfake Nudes of Seven Female Classmates",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4094",
      "incident_id": 800,
      "title": "Report 4094 on 53% of American and British Businesses Report Attacks by AI-Powered Deepfake Scams in 2024",
      "description": "A detailed report about 53% of American and British Businesses Report Attacks by AI-Powered Deepfake Scams in 2024",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4516",
      "incident_id": 800,
      "title": "Report 4516 on 53% of American and British Businesses Report Attacks by AI-Powered Deepfake Scams in 2024",
      "description": "A detailed report about 53% of American and British Businesses Report Attacks by AI-Powered Deepfake Scams in 2024",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4097",
      "incident_id": 801,
      "title": "Report 4097 on Bias in AI Deepfake Detection Undermines Election Security in Global South",
      "description": "A detailed report about Bias in AI Deepfake Detection Undermines Election Security in Global South",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4098",
      "incident_id": 802,
      "title": "Report 4098 on AI Deepfake of Brian May Exploited in Scam Offering Fake Queen Backstage Tickets",
      "description": "A detailed report about AI Deepfake of Brian May Exploited in Scam Offering Fake Queen Backstage Tickets",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4102",
      "incident_id": 803,
      "title": "Report 4102 on Facebook's Algorithm Reportedly Amplifies AI-Generated Content, Fueling Misleading Posts",
      "description": "A detailed report about Facebook's Algorithm Reportedly Amplifies AI-Generated Content, Fueling Misleading Posts",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4110",
      "incident_id": 804,
      "title": "Report 4110 on AI-Generated Fake 'True Crime' Video About Non-Existent Littleton Murder Goes Viral",
      "description": "A detailed report about AI-Generated Fake 'True Crime' Video About Non-Existent Littleton Murder Goes Viral",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4132",
      "incident_id": 804,
      "title": "Report 4132 on AI-Generated Fake 'True Crime' Video About Non-Existent Littleton Murder Goes Viral",
      "description": "A detailed report about AI-Generated Fake 'True Crime' Video About Non-Existent Littleton Murder Goes Viral",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4133",
      "incident_id": 804,
      "title": "Report 4133 on AI-Generated Fake 'True Crime' Video About Non-Existent Littleton Murder Goes Viral",
      "description": "A detailed report about AI-Generated Fake 'True Crime' Video About Non-Existent Littleton Murder Goes Viral",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4111",
      "incident_id": 805,
      "title": "Report 4111 on Senator Ben Cardin Targeted with Deepfake Zoom Video Call Posing as Former Ukrainian Foreign Minister Dmytro Kuleba",
      "description": "A detailed report about Senator Ben Cardin Targeted with Deepfake Zoom Video Call Posing as Former Ukrainian Foreign Minister Dmytro Kuleba",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4112",
      "incident_id": 805,
      "title": "Report 4112 on Senator Ben Cardin Targeted with Deepfake Zoom Video Call Posing as Former Ukrainian Foreign Minister Dmytro Kuleba",
      "description": "A detailed report about Senator Ben Cardin Targeted with Deepfake Zoom Video Call Posing as Former Ukrainian Foreign Minister Dmytro Kuleba",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4115",
      "incident_id": 805,
      "title": "Report 4115 on Senator Ben Cardin Targeted with Deepfake Zoom Video Call Posing as Former Ukrainian Foreign Minister Dmytro Kuleba",
      "description": "A detailed report about Senator Ben Cardin Targeted with Deepfake Zoom Video Call Posing as Former Ukrainian Foreign Minister Dmytro Kuleba",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4114",
      "incident_id": 806,
      "title": "Report 4114 on Criminal Group Uses AI Deepfake Technology to Steal Personal Data in Hangzhou, Zhejiang",
      "description": "A detailed report about Criminal Group Uses AI Deepfake Technology to Steal Personal Data in Hangzhou, Zhejiang",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4136",
      "incident_id": 807,
      "title": "Report 4136 on ChatGPT Introduces Errors in Critical Child Protection Court Report",
      "description": "A detailed report about ChatGPT Introduces Errors in Critical Child Protection Court Report",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4137",
      "incident_id": 807,
      "title": "Report 4137 on ChatGPT Introduces Errors in Critical Child Protection Court Report",
      "description": "A detailed report about ChatGPT Introduces Errors in Critical Child Protection Court Report",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4138",
      "incident_id": 807,
      "title": "Report 4138 on ChatGPT Introduces Errors in Critical Child Protection Court Report",
      "description": "A detailed report about ChatGPT Introduces Errors in Critical Child Protection Court Report",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4142",
      "incident_id": 808,
      "title": "Report 4142 on Infinite Campus AI-Driven Student Risk Model Leads to Cuts in Support for Nevada's Low-Income Schools",
      "description": "A detailed report about Infinite Campus AI-Driven Student Risk Model Leads to Cuts in Support for Nevada's Low-Income Schools",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4144",
      "incident_id": 809,
      "title": "Report 4144 on TikTok Hosts AI-Generated English-Language Hitler Speeches with Millions of Views",
      "description": "A detailed report about TikTok Hosts AI-Generated English-Language Hitler Speeches with Millions of Views",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4146",
      "incident_id": 810,
      "title": "Report 4146 on TikTok Network Amplifies AI-Generated Nazi Propaganda and Hate Speech",
      "description": "A detailed report about TikTok Network Amplifies AI-Generated Nazi Propaganda and Hate Speech",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4147",
      "incident_id": 811,
      "title": "Report 4147 on AI-Powered Transcription Services Allegedly Leak Confidential Workplace Discussions",
      "description": "A detailed report about AI-Powered Transcription Services Allegedly Leak Confidential Workplace Discussions",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4169",
      "incident_id": 811,
      "title": "Report 4169 on AI-Powered Transcription Services Allegedly Leak Confidential Workplace Discussions",
      "description": "A detailed report about AI-Powered Transcription Services Allegedly Leak Confidential Workplace Discussions",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4170",
      "incident_id": 811,
      "title": "Report 4170 on AI-Powered Transcription Services Allegedly Leak Confidential Workplace Discussions",
      "description": "A detailed report about AI-Powered Transcription Services Allegedly Leak Confidential Workplace Discussions",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4148",
      "incident_id": 812,
      "title": "Report 4148 on Deepfake Nudes Targeting Underage Female Students at Collège Béliveau in Winnipeg Shared Online",
      "description": "A detailed report about Deepfake Nudes Targeting Underage Female Students at Collège Béliveau in Winnipeg Shared Online",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4149",
      "incident_id": 812,
      "title": "Report 4149 on Deepfake Nudes Targeting Underage Female Students at Collège Béliveau in Winnipeg Shared Online",
      "description": "A detailed report about Deepfake Nudes Targeting Underage Female Students at Collège Béliveau in Winnipeg Shared Online",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4168",
      "incident_id": 812,
      "title": "Report 4168 on Deepfake Nudes Targeting Underage Female Students at Collège Béliveau in Winnipeg Shared Online",
      "description": "A detailed report about Deepfake Nudes Targeting Underage Female Students at Collège Béliveau in Winnipeg Shared Online",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4150",
      "incident_id": 813,
      "title": "Report 4150 on Starship Technologies Delivery Robot Injures Arizona State University Employee",
      "description": "A detailed report about Starship Technologies Delivery Robot Injures Arizona State University Employee",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4167",
      "incident_id": 813,
      "title": "Report 4167 on Starship Technologies Delivery Robot Injures Arizona State University Employee",
      "description": "A detailed report about Starship Technologies Delivery Robot Injures Arizona State University Employee",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4152",
      "incident_id": 814,
      "title": "Report 4152 on AI Avatar of Murder Victim Created Without Consent on Character.ai Platform",
      "description": "A detailed report about AI Avatar of Murder Victim Created Without Consent on Character.ai Platform",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4153",
      "incident_id": 814,
      "title": "Report 4153 on AI Avatar of Murder Victim Created Without Consent on Character.ai Platform",
      "description": "A detailed report about AI Avatar of Murder Victim Created Without Consent on Character.ai Platform",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4165",
      "incident_id": 814,
      "title": "Report 4165 on AI Avatar of Murder Victim Created Without Consent on Character.ai Platform",
      "description": "A detailed report about AI Avatar of Murder Victim Created Without Consent on Character.ai Platform",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4154",
      "incident_id": 815,
      "title": "Report 4154 on Police Use of Facial Recognition Software Causes Wrongful Arrests Without Defendant Knowledge",
      "description": "A detailed report about Police Use of Facial Recognition Software Causes Wrongful Arrests Without Defendant Knowledge",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4155",
      "incident_id": 816,
      "title": "Report 4155 on Cross-Jurisdictional Facial Recognition Misidentification by NYPD Leads to Wrongful Arrest and Four-Year Jail Time in New Jersey",
      "description": "A detailed report about Cross-Jurisdictional Facial Recognition Misidentification by NYPD Leads to Wrongful Arrest and Four-Year Jail Time in New Jersey",
      "url": "https://incidentdatabase.ai",
      "date_published": "2019-11-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4156",
      "incident_id": 817,
      "title": "Report 4156 on AI-Generated Images Spread Misinformation During Hurricane Helene Response",
      "description": "A detailed report about AI-Generated Images Spread Misinformation During Hurricane Helene Response",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4159",
      "incident_id": 817,
      "title": "Report 4159 on AI-Generated Images Spread Misinformation During Hurricane Helene Response",
      "description": "A detailed report about AI-Generated Images Spread Misinformation During Hurricane Helene Response",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4160",
      "incident_id": 817,
      "title": "Report 4160 on AI-Generated Images Spread Misinformation During Hurricane Helene Response",
      "description": "A detailed report about AI-Generated Images Spread Misinformation During Hurricane Helene Response",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4157",
      "incident_id": 818,
      "title": "Report 4157 on Jennifer Aniston’s Likeness Exploited in Deepfake Collagen Supplement Promotion",
      "description": "A detailed report about Jennifer Aniston’s Likeness Exploited in Deepfake Collagen Supplement Promotion",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4158",
      "incident_id": 818,
      "title": "Report 4158 on Jennifer Aniston’s Likeness Exploited in Deepfake Collagen Supplement Promotion",
      "description": "A detailed report about Jennifer Aniston’s Likeness Exploited in Deepfake Collagen Supplement Promotion",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4181",
      "incident_id": 819,
      "title": "Report 4181 on ProKYC Tool Allegedly Facilitates Deepfake-Based Account Fraud on Cryptocurrency Exchanges",
      "description": "A detailed report about ProKYC Tool Allegedly Facilitates Deepfake-Based Account Fraud on Cryptocurrency Exchanges",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4182",
      "incident_id": 820,
      "title": "Report 4182 on Alleged AI-Generated Photo Alteration Leads to Inappropriate Modifications in Speaker's Conference Picture",
      "description": "A detailed report about Alleged AI-Generated Photo Alteration Leads to Inappropriate Modifications in Speaker's Conference Picture",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4183",
      "incident_id": 820,
      "title": "Report 4183 on Alleged AI-Generated Photo Alteration Leads to Inappropriate Modifications in Speaker's Conference Picture",
      "description": "A detailed report about Alleged AI-Generated Photo Alteration Leads to Inappropriate Modifications in Speaker's Conference Picture",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4184",
      "incident_id": 820,
      "title": "Report 4184 on Alleged AI-Generated Photo Alteration Leads to Inappropriate Modifications in Speaker's Conference Picture",
      "description": "A detailed report about Alleged AI-Generated Photo Alteration Leads to Inappropriate Modifications in Speaker's Conference Picture",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4187",
      "incident_id": 821,
      "title": "Report 4187 on Baidu Robotaxi Allegedly Involved in Collision with Pedestrian in Wuhan",
      "description": "A detailed report about Baidu Robotaxi Allegedly Involved in Collision with Pedestrian in Wuhan",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4188",
      "incident_id": 822,
      "title": "Report 4188 on Algorithmic Bias in French Welfare System Allegedly Discriminates Against Marginalized Groups",
      "description": "A detailed report about Algorithmic Bias in French Welfare System Allegedly Discriminates Against Marginalized Groups",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4189",
      "incident_id": 822,
      "title": "Report 4189 on Algorithmic Bias in French Welfare System Allegedly Discriminates Against Marginalized Groups",
      "description": "A detailed report about Algorithmic Bias in French Welfare System Allegedly Discriminates Against Marginalized Groups",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4190",
      "incident_id": 823,
      "title": "Report 4190 on Cybercheck Tool Allegedly Provides Questionable Evidence in Murder Trials",
      "description": "A detailed report about Cybercheck Tool Allegedly Provides Questionable Evidence in Murder Trials",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4237",
      "incident_id": 823,
      "title": "Report 4237 on Cybercheck Tool Allegedly Provides Questionable Evidence in Murder Trials",
      "description": "A detailed report about Cybercheck Tool Allegedly Provides Questionable Evidence in Murder Trials",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4238",
      "incident_id": 823,
      "title": "Report 4238 on Cybercheck Tool Allegedly Provides Questionable Evidence in Murder Trials",
      "description": "A detailed report about Cybercheck Tool Allegedly Provides Questionable Evidence in Murder Trials",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4191",
      "incident_id": 824,
      "title": "Report 4191 on Fake Video Allegedly Misattributes False Claims to Former Student in Attack on Vice-Presidential Candidate Tim Walz",
      "description": "A detailed report about Fake Video Allegedly Misattributes False Claims to Former Student in Attack on Vice-Presidential Candidate Tim Walz",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4194",
      "incident_id": 824,
      "title": "Report 4194 on Fake Video Allegedly Misattributes False Claims to Former Student in Attack on Vice-Presidential Candidate Tim Walz",
      "description": "A detailed report about Fake Video Allegedly Misattributes False Claims to Former Student in Attack on Vice-Presidential Candidate Tim Walz",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4195",
      "incident_id": 824,
      "title": "Report 4195 on Fake Video Allegedly Misattributes False Claims to Former Student in Attack on Vice-Presidential Candidate Tim Walz",
      "description": "A detailed report about Fake Video Allegedly Misattributes False Claims to Former Student in Attack on Vice-Presidential Candidate Tim Walz",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4192",
      "incident_id": 825,
      "title": "Report 4192 on AI News Site Hoodline San Jose Erroneously Misidentifies San Mateo District Attorney as Murder Suspect",
      "description": "A detailed report about AI News Site Hoodline San Jose Erroneously Misidentifies San Mateo District Attorney as Murder Suspect",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4193",
      "incident_id": 825,
      "title": "Report 4193 on AI News Site Hoodline San Jose Erroneously Misidentifies San Mateo District Attorney as Murder Suspect",
      "description": "A detailed report about AI News Site Hoodline San Jose Erroneously Misidentifies San Mateo District Attorney as Murder Suspect",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4204",
      "incident_id": 826,
      "title": "Report 4204 on Character.ai Chatbot Allegedly Influenced Teen User Toward Suicide Amid Claims of Missing Guardrails",
      "description": "A detailed report about Character.ai Chatbot Allegedly Influenced Teen User Toward Suicide Amid Claims of Missing Guardrails",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4205",
      "incident_id": 826,
      "title": "Report 4205 on Character.ai Chatbot Allegedly Influenced Teen User Toward Suicide Amid Claims of Missing Guardrails",
      "description": "A detailed report about Character.ai Chatbot Allegedly Influenced Teen User Toward Suicide Amid Claims of Missing Guardrails",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4206",
      "incident_id": 826,
      "title": "Report 4206 on Character.ai Chatbot Allegedly Influenced Teen User Toward Suicide Amid Claims of Missing Guardrails",
      "description": "A detailed report about Character.ai Chatbot Allegedly Influenced Teen User Toward Suicide Amid Claims of Missing Guardrails",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4241",
      "incident_id": 827,
      "title": "Report 4241 on AI Transcription Tool Whisper Reportedly Inserting Fabricated Content in Medical Transcripts",
      "description": "A detailed report about AI Transcription Tool Whisper Reportedly Inserting Fabricated Content in Medical Transcripts",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4242",
      "incident_id": 828,
      "title": "Report 4242 on Uruguayan TV Program Santo y Seña Uses a Deepfake of Political Candidate Yamandú Orsi Without His Consent",
      "description": "A detailed report about Uruguayan TV Program Santo y Seña Uses a Deepfake of Political Candidate Yamandú Orsi Without His Consent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4243",
      "incident_id": 828,
      "title": "Report 4243 on Uruguayan TV Program Santo y Seña Uses a Deepfake of Political Candidate Yamandú Orsi Without His Consent",
      "description": "A detailed report about Uruguayan TV Program Santo y Seña Uses a Deepfake of Political Candidate Yamandú Orsi Without His Consent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4244",
      "incident_id": 828,
      "title": "Report 4244 on Uruguayan TV Program Santo y Seña Uses a Deepfake of Political Candidate Yamandú Orsi Without His Consent",
      "description": "A detailed report about Uruguayan TV Program Santo y Seña Uses a Deepfake of Political Candidate Yamandú Orsi Without His Consent",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4245",
      "incident_id": 829,
      "title": "Report 4245 on Facial Recognition System in Buenos Aires Triggers Police Checks Based on False Matches",
      "description": "A detailed report about Facial Recognition System in Buenos Aires Triggers Police Checks Based on False Matches",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4246",
      "incident_id": 830,
      "title": "Report 4246 on Error-Prone AI Accessibility Tools Reportedly Lead to Navigation Issues for Blind Internet Users",
      "description": "A detailed report about Error-Prone AI Accessibility Tools Reportedly Lead to Navigation Issues for Blind Internet Users",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4247",
      "incident_id": 831,
      "title": "Report 4247 on NYC Subway AI Weapons Scanners Yield High False Positive Rate and Detect No Guns in Month-Long Pilot Test",
      "description": "A detailed report about NYC Subway AI Weapons Scanners Yield High False Positive Rate and Detect No Guns in Month-Long Pilot Test",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4412",
      "incident_id": 831,
      "title": "Report 4412 on NYC Subway AI Weapons Scanners Yield High False Positive Rate and Detect No Guns in Month-Long Pilot Test",
      "description": "A detailed report about NYC Subway AI Weapons Scanners Yield High False Positive Rate and Detect No Guns in Month-Long Pilot Test",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4248",
      "incident_id": 832,
      "title": "Report 4248 on Viral AI-Generated Song about Diddy Party Mimics Justin Bieber",
      "description": "A detailed report about Viral AI-Generated Song about Diddy Party Mimics Justin Bieber",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4249",
      "incident_id": 832,
      "title": "Report 4249 on Viral AI-Generated Song about Diddy Party Mimics Justin Bieber",
      "description": "A detailed report about Viral AI-Generated Song about Diddy Party Mimics Justin Bieber",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4250",
      "incident_id": 833,
      "title": "Report 4250 on Polish Radio Station Replaces Human Hosts with AI-Generated Presenters to Simulate Interviewing Deceased Poet Wisława Szymborska",
      "description": "A detailed report about Polish Radio Station Replaces Human Hosts with AI-Generated Presenters to Simulate Interviewing Deceased Poet Wisława Szymborska",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4251",
      "incident_id": 833,
      "title": "Report 4251 on Polish Radio Station Replaces Human Hosts with AI-Generated Presenters to Simulate Interviewing Deceased Poet Wisława Szymborska",
      "description": "A detailed report about Polish Radio Station Replaces Human Hosts with AI-Generated Presenters to Simulate Interviewing Deceased Poet Wisława Szymborska",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4252",
      "incident_id": 834,
      "title": "Report 4252 on China Targets AI-Driven Fraud and Deepfake Scandals with New Crackdowns",
      "description": "A detailed report about China Targets AI-Driven Fraud and Deepfake Scandals with New Crackdowns",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4253",
      "incident_id": 834,
      "title": "Report 4253 on China Targets AI-Driven Fraud and Deepfake Scandals with New Crackdowns",
      "description": "A detailed report about China Targets AI-Driven Fraud and Deepfake Scandals with New Crackdowns",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4254",
      "incident_id": 835,
      "title": "Report 4254 on AI Technology Allegedly Fuels False Reports of Natural Disasters and Accidents in China",
      "description": "A detailed report about AI Technology Allegedly Fuels False Reports of Natural Disasters and Accidents in China",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-08-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4255",
      "incident_id": 836,
      "title": "Report 4255 on Sichuan Province Beset by Numerous Fabricated AI-Generated Reports of Disasters and Crises",
      "description": "A detailed report about Sichuan Province Beset by Numerous Fabricated AI-Generated Reports of Disasters and Crises",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4256",
      "incident_id": 837,
      "title": "Report 4256 on Fake CNN Broadcast Allegedly Used to Spread False Texas Election Results",
      "description": "A detailed report about Fake CNN Broadcast Allegedly Used to Spread False Texas Election Results",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-11-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4257",
      "incident_id": 838,
      "title": "Report 4257 on Microsoft Copilot Allegedly Provides Unsafe Medical Advice with High Risk of Severe Harm",
      "description": "A detailed report about Microsoft Copilot Allegedly Provides Unsafe Medical Advice with High Risk of Severe Harm",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4258",
      "incident_id": 839,
      "title": "Report 4258 on AI-Driven Phishing Scam Uses Spoofed Google Call to Attempt Gmail Breach of Security Expert",
      "description": "A detailed report about AI-Driven Phishing Scam Uses Spoofed Google Call to Attempt Gmail Breach of Security Expert",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4279",
      "incident_id": 839,
      "title": "Report 4279 on AI-Driven Phishing Scam Uses Spoofed Google Call to Attempt Gmail Breach of Security Expert",
      "description": "A detailed report about AI-Driven Phishing Scam Uses Spoofed Google Call to Attempt Gmail Breach of Security Expert",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4280",
      "incident_id": 839,
      "title": "Report 4280 on AI-Driven Phishing Scam Uses Spoofed Google Call to Attempt Gmail Breach of Security Expert",
      "description": "A detailed report about AI-Driven Phishing Scam Uses Spoofed Google Call to Attempt Gmail Breach of Security Expert",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4259",
      "incident_id": 840,
      "title": "Report 4259 on AI-Generated Media Reportedly Used in Russian Disinformation Campaign in Moldova",
      "description": "A detailed report about AI-Generated Media Reportedly Used in Russian Disinformation Campaign in Moldova",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4260",
      "incident_id": 841,
      "title": "Report 4260 on Fake Video Allegedly Targets Moldovan Economic Development Minister Dumitru Alaiba in Election Disinformation Campaign",
      "description": "A detailed report about Fake Video Allegedly Targets Moldovan Economic Development Minister Dumitru Alaiba in Election Disinformation Campaign",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4261",
      "incident_id": 841,
      "title": "Report 4261 on Fake Video Allegedly Targets Moldovan Economic Development Minister Dumitru Alaiba in Election Disinformation Campaign",
      "description": "A detailed report about Fake Video Allegedly Targets Moldovan Economic Development Minister Dumitru Alaiba in Election Disinformation Campaign",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4262",
      "incident_id": 841,
      "title": "Report 4262 on Fake Video Allegedly Targets Moldovan Economic Development Minister Dumitru Alaiba in Election Disinformation Campaign",
      "description": "A detailed report about Fake Video Allegedly Targets Moldovan Economic Development Minister Dumitru Alaiba in Election Disinformation Campaign",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4263",
      "incident_id": 842,
      "title": "Report 4263 on Reportedly Hacked AI-Powered Robot Vacuums Allegedly Used for Surveillance and Harassment",
      "description": "A detailed report about Reportedly Hacked AI-Powered Robot Vacuums Allegedly Used for Surveillance and Harassment",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4264",
      "incident_id": 842,
      "title": "Report 4264 on Reportedly Hacked AI-Powered Robot Vacuums Allegedly Used for Surveillance and Harassment",
      "description": "A detailed report about Reportedly Hacked AI-Powered Robot Vacuums Allegedly Used for Surveillance and Harassment",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4265",
      "incident_id": 842,
      "title": "Report 4265 on Reportedly Hacked AI-Powered Robot Vacuums Allegedly Used for Surveillance and Harassment",
      "description": "A detailed report about Reportedly Hacked AI-Powered Robot Vacuums Allegedly Used for Surveillance and Harassment",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4299",
      "incident_id": 843,
      "title": "Report 4299 on Generative AI Plagiarism Incident at Hingham High School Reportedly Tied to Inaccurate Citation Outputs from Grammarly AI",
      "description": "A detailed report about Generative AI Plagiarism Incident at Hingham High School Reportedly Tied to Inaccurate Citation Outputs from Grammarly AI",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-11-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4311",
      "incident_id": 843,
      "title": "Report 4311 on Generative AI Plagiarism Incident at Hingham High School Reportedly Tied to Inaccurate Citation Outputs from Grammarly AI",
      "description": "A detailed report about Generative AI Plagiarism Incident at Hingham High School Reportedly Tied to Inaccurate Citation Outputs from Grammarly AI",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-11-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4300",
      "incident_id": 844,
      "title": "Report 4300 on SafeRent AI Screening Tool Allegedly Discriminated Against Housing Voucher Applicants",
      "description": "A detailed report about SafeRent AI Screening Tool Allegedly Discriminated Against Housing Voucher Applicants",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-05-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4301",
      "incident_id": 844,
      "title": "Report 4301 on SafeRent AI Screening Tool Allegedly Discriminated Against Housing Voucher Applicants",
      "description": "A detailed report about SafeRent AI Screening Tool Allegedly Discriminated Against Housing Voucher Applicants",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-05-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4302",
      "incident_id": 844,
      "title": "Report 4302 on SafeRent AI Screening Tool Allegedly Discriminated Against Housing Voucher Applicants",
      "description": "A detailed report about SafeRent AI Screening Tool Allegedly Discriminated Against Housing Voucher Applicants",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-05-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4303",
      "incident_id": 845,
      "title": "Report 4303 on Google's Gemini Allegedly Generates Threatening Response in Routine Query",
      "description": "A detailed report about Google's Gemini Allegedly Generates Threatening Response in Routine Query",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-11-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4369",
      "incident_id": 845,
      "title": "Report 4369 on Google's Gemini Allegedly Generates Threatening Response in Routine Query",
      "description": "A detailed report about Google's Gemini Allegedly Generates Threatening Response in Routine Query",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-11-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4304",
      "incident_id": 846,
      "title": "Report 4304 on Social Media Algorithms Amplified Disinformation Campaign in Honduras Election",
      "description": "A detailed report about Social Media Algorithms Amplified Disinformation Campaign in Honduras Election",
      "url": "https://incidentdatabase.ai",
      "date_published": "2021-10-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4305",
      "incident_id": 847,
      "title": "Report 4305 on Brake Failure in AI-Driven Tram Leads to Multiple Injuries in Saint Petersburg, Russia",
      "description": "A detailed report about Brake Failure in AI-Driven Tram Leads to Multiple Injuries in Saint Petersburg, Russia",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4310",
      "incident_id": 848,
      "title": "Report 4310 on High School Student in Córdoba, Argentina Accused of Using AI to Generate Explicit Images of Classmates",
      "description": "A detailed report about High School Student in Córdoba, Argentina Accused of Using AI to Generate Explicit Images of Classmates",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4312",
      "incident_id": 849,
      "title": "Report 4312 on AI Detection Tools Allegedly Misidentify Neurodivergent and ESL Students' Work as AI-Generated in Academic Settings",
      "description": "A detailed report about AI Detection Tools Allegedly Misidentify Neurodivergent and ESL Students' Work as AI-Generated in Academic Settings",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4313",
      "incident_id": 850,
      "title": "Report 4313 on Character.ai Chatbots Allegedly Misrepresent George Floyd on User-Generated Platform",
      "description": "A detailed report about Character.ai Chatbots Allegedly Misrepresent George Floyd on User-Generated Platform",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4314",
      "incident_id": 851,
      "title": "Report 4314 on Salt Lake City Police Chief Mike Brown's Voice and Image Misused in AI-Generated Scam",
      "description": "A detailed report about Salt Lake City Police Chief Mike Brown's Voice and Image Misused in AI-Generated Scam",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4315",
      "incident_id": 851,
      "title": "Report 4315 on Salt Lake City Police Chief Mike Brown's Voice and Image Misused in AI-Generated Scam",
      "description": "A detailed report about Salt Lake City Police Chief Mike Brown's Voice and Image Misused in AI-Generated Scam",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4321",
      "incident_id": 851,
      "title": "Report 4321 on Salt Lake City Police Chief Mike Brown's Voice and Image Misused in AI-Generated Scam",
      "description": "A detailed report about Salt Lake City Police Chief Mike Brown's Voice and Image Misused in AI-Generated Scam",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4316",
      "incident_id": 852,
      "title": "Report 4316 on Alleged Fake Citations Undermine Expert Testimony in Minnesota Deepfake Law Case",
      "description": "A detailed report about Alleged Fake Citations Undermine Expert Testimony in Minnesota Deepfake Law Case",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-11-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4317",
      "incident_id": 853,
      "title": "Report 4317 on Two Passengers Report Feeling Trapped in Waymo Car During Sensor Obstruction",
      "description": "A detailed report about Two Passengers Report Feeling Trapped in Waymo Car During Sensor Obstruction",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4320",
      "incident_id": 854,
      "title": "Report 4320 on Waymo Driverless Taxi Allegedly Stalled During Pedestrian Harassment Incident in San Francisco",
      "description": "A detailed report about Waymo Driverless Taxi Allegedly Stalled During Pedestrian Harassment Incident in San Francisco",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4323",
      "incident_id": 854,
      "title": "Report 4323 on Waymo Driverless Taxi Allegedly Stalled During Pedestrian Harassment Incident in San Francisco",
      "description": "A detailed report about Waymo Driverless Taxi Allegedly Stalled During Pedestrian Harassment Incident in San Francisco",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4324",
      "incident_id": 854,
      "title": "Report 4324 on Waymo Driverless Taxi Allegedly Stalled During Pedestrian Harassment Incident in San Francisco",
      "description": "A detailed report about Waymo Driverless Taxi Allegedly Stalled During Pedestrian Harassment Incident in San Francisco",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4331",
      "incident_id": 855,
      "title": "Report 4331 on Names Linked to Defamation Lawsuits Reportedly Spur Filtering Errors in ChatGPT's Name Recognition",
      "description": "A detailed report about Names Linked to Defamation Lawsuits Reportedly Spur Filtering Errors in ChatGPT's Name Recognition",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-11-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4330",
      "incident_id": 855,
      "title": "Report 4330 on Names Linked to Defamation Lawsuits Reportedly Spur Filtering Errors in ChatGPT's Name Recognition",
      "description": "A detailed report about Names Linked to Defamation Lawsuits Reportedly Spur Filtering Errors in ChatGPT's Name Recognition",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-11-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4358",
      "incident_id": 855,
      "title": "Report 4358 on Names Linked to Defamation Lawsuits Reportedly Spur Filtering Errors in ChatGPT's Name Recognition",
      "description": "A detailed report about Names Linked to Defamation Lawsuits Reportedly Spur Filtering Errors in ChatGPT's Name Recognition",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-11-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4333",
      "incident_id": 856,
      "title": "Report 4333 on Deepfake Audio Purportedly Fabricates Biden’s Admission of Role in Pakistani Political Crisis",
      "description": "A detailed report about Deepfake Audio Purportedly Fabricates Biden’s Admission of Role in Pakistani Political Crisis",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4336",
      "incident_id": 857,
      "title": "Report 4336 on Navigation App Allegedly Directs Car Over Damaged Bridge in Uttar Pradesh, Resulting in Three Deaths",
      "description": "A detailed report about Navigation App Allegedly Directs Car Over Damaged Bridge in Uttar Pradesh, Resulting in Three Deaths",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-11-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4367",
      "incident_id": 857,
      "title": "Report 4367 on Navigation App Allegedly Directs Car Over Damaged Bridge in Uttar Pradesh, Resulting in Three Deaths",
      "description": "A detailed report about Navigation App Allegedly Directs Car Over Damaged Bridge in Uttar Pradesh, Resulting in Three Deaths",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-11-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4337",
      "incident_id": 858,
      "title": "Report 4337 on Deepfake Reportedly Used in Attempted Real Estate Fraud in Hallandale Beach, Florida",
      "description": "A detailed report about Deepfake Reportedly Used in Attempted Real Estate Fraud in Hallandale Beach, Florida",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4338",
      "incident_id": 858,
      "title": "Report 4338 on Deepfake Reportedly Used in Attempted Real Estate Fraud in Hallandale Beach, Florida",
      "description": "A detailed report about Deepfake Reportedly Used in Attempted Real Estate Fraud in Hallandale Beach, Florida",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4339",
      "incident_id": 858,
      "title": "Report 4339 on Deepfake Reportedly Used in Attempted Real Estate Fraud in Hallandale Beach, Florida",
      "description": "A detailed report about Deepfake Reportedly Used in Attempted Real Estate Fraud in Hallandale Beach, Florida",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4341",
      "incident_id": 859,
      "title": "Report 4341 on AI Models Reportedly Found to Provide Misinformation on Election Processes in Spanish",
      "description": "A detailed report about AI Models Reportedly Found to Provide Misinformation on Election Processes in Spanish",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4342",
      "incident_id": 860,
      "title": "Report 4342 on AI Camera Allegedly Misidentifies Dutch Motorist as Using Mobile Phone, Issuing €380 Fine",
      "description": "A detailed report about AI Camera Allegedly Misidentifies Dutch Motorist as Using Mobile Phone, Issuing €380 Fine",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-31",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4343",
      "incident_id": 860,
      "title": "Report 4343 on AI Camera Allegedly Misidentifies Dutch Motorist as Using Mobile Phone, Issuing €380 Fine",
      "description": "A detailed report about AI Camera Allegedly Misidentifies Dutch Motorist as Using Mobile Phone, Issuing €380 Fine",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-31",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4344",
      "incident_id": 860,
      "title": "Report 4344 on AI Camera Allegedly Misidentifies Dutch Motorist as Using Mobile Phone, Issuing €380 Fine",
      "description": "A detailed report about AI Camera Allegedly Misidentifies Dutch Motorist as Using Mobile Phone, Issuing €380 Fine",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-10-31",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4351",
      "incident_id": 861,
      "title": "Report 4351 on Apple Intelligence Reportedly Notified Users That Luigi Mangione Shot Himself and Benjamin Netanyahu Had Been Arrested",
      "description": "A detailed report about Apple Intelligence Reportedly Notified Users That Luigi Mangione Shot Himself and Benjamin Netanyahu Had Been Arrested",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4352",
      "incident_id": 861,
      "title": "Report 4352 on Apple Intelligence Reportedly Notified Users That Luigi Mangione Shot Himself and Benjamin Netanyahu Had Been Arrested",
      "description": "A detailed report about Apple Intelligence Reportedly Notified Users That Luigi Mangione Shot Himself and Benjamin Netanyahu Had Been Arrested",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4353",
      "incident_id": 861,
      "title": "Report 4353 on Apple Intelligence Reportedly Notified Users That Luigi Mangione Shot Himself and Benjamin Netanyahu Had Been Arrested",
      "description": "A detailed report about Apple Intelligence Reportedly Notified Users That Luigi Mangione Shot Himself and Benjamin Netanyahu Had Been Arrested",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4356",
      "incident_id": 862,
      "title": "Report 4356 on AI-Generated Video Falsely Depicts Martin Luther King Jr. Supporting Donald Trump",
      "description": "A detailed report about AI-Generated Video Falsely Depicts Martin Luther King Jr. Supporting Donald Trump",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-11-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4399",
      "incident_id": 862,
      "title": "Report 4399 on AI-Generated Video Falsely Depicts Martin Luther King Jr. Supporting Donald Trump",
      "description": "A detailed report about AI-Generated Video Falsely Depicts Martin Luther King Jr. Supporting Donald Trump",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-11-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4400",
      "incident_id": 862,
      "title": "Report 4400 on AI-Generated Video Falsely Depicts Martin Luther King Jr. Supporting Donald Trump",
      "description": "A detailed report about AI-Generated Video Falsely Depicts Martin Luther King Jr. Supporting Donald Trump",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-11-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4357",
      "incident_id": 863,
      "title": "Report 4357 on Character.ai Companion Allegedly Prompts Self-Harm and Violence in Texas Teen",
      "description": "A detailed report about Character.ai Companion Allegedly Prompts Self-Harm and Violence in Texas Teen",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4360",
      "incident_id": 864,
      "title": "Report 4360 on Generative AI Allegedly Used to Facilitate $255,000 Real Estate Fraud Scheme",
      "description": "A detailed report about Generative AI Allegedly Used to Facilitate $255,000 Real Estate Fraud Scheme",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-08-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4361",
      "incident_id": 865,
      "title": "Report 4361 on Fake AI 'Nudify' Sites Reportedly Linked to Malware Distribution by Russian Hacker Collective FIN7",
      "description": "A detailed report about Fake AI 'Nudify' Sites Reportedly Linked to Malware Distribution by Russian Hacker Collective FIN7",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4362",
      "incident_id": 865,
      "title": "Report 4362 on Fake AI 'Nudify' Sites Reportedly Linked to Malware Distribution by Russian Hacker Collective FIN7",
      "description": "A detailed report about Fake AI 'Nudify' Sites Reportedly Linked to Malware Distribution by Russian Hacker Collective FIN7",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4363",
      "incident_id": 865,
      "title": "Report 4363 on Fake AI 'Nudify' Sites Reportedly Linked to Malware Distribution by Russian Hacker Collective FIN7",
      "description": "A detailed report about Fake AI 'Nudify' Sites Reportedly Linked to Malware Distribution by Russian Hacker Collective FIN7",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4366",
      "incident_id": 866,
      "title": "Report 4366 on Network of 171 AI-Powered Bots Reportedly Spread Political Disinformation Ahead of Ghana’s December 2024 General Election",
      "description": "A detailed report about Network of 171 AI-Powered Bots Reportedly Spread Political Disinformation Ahead of Ghana’s December 2024 General Election",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4370",
      "incident_id": 867,
      "title": "Report 4370 on AI-Generated Airline Reviews Allegedly Mislead Consumers and Undermine Trust",
      "description": "A detailed report about AI-Generated Airline Reviews Allegedly Mislead Consumers and Undermine Trust",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-31",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4371",
      "incident_id": 868,
      "title": "Report 4371 on Portland Water Bureau SERVUS Algorithm Reportedly Allocates Utility Bill Discount to High-Wealth Consumer",
      "description": "A detailed report about Portland Water Bureau SERVUS Algorithm Reportedly Allocates Utility Bill Discount to High-Wealth Consumer",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4372",
      "incident_id": 869,
      "title": "Report 4372 on TikTok Algorithms Allegedly Linked to Minors' Exposure to Harmful Content",
      "description": "A detailed report about TikTok Algorithms Allegedly Linked to Minors' Exposure to Harmful Content",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-11-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4373",
      "incident_id": 869,
      "title": "Report 4373 on TikTok Algorithms Allegedly Linked to Minors' Exposure to Harmful Content",
      "description": "A detailed report about TikTok Algorithms Allegedly Linked to Minors' Exposure to Harmful Content",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-11-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4395",
      "incident_id": 869,
      "title": "Report 4395 on TikTok Algorithms Allegedly Linked to Minors' Exposure to Harmful Content",
      "description": "A detailed report about TikTok Algorithms Allegedly Linked to Minors' Exposure to Harmful Content",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-11-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4376",
      "incident_id": 870,
      "title": "Report 4376 on Meeten Malware Campaign Reportedly Undermines Web3 Security Using AI-Legitimized Branding",
      "description": "A detailed report about Meeten Malware Campaign Reportedly Undermines Web3 Security Using AI-Legitimized Branding",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4377",
      "incident_id": 870,
      "title": "Report 4377 on Meeten Malware Campaign Reportedly Undermines Web3 Security Using AI-Legitimized Branding",
      "description": "A detailed report about Meeten Malware Campaign Reportedly Undermines Web3 Security Using AI-Legitimized Branding",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4378",
      "incident_id": 871,
      "title": "Report 4378 on Reported Deepfake Video of Elon Musk Announcing $20 Million Cryptocurrency Giveaway Circulating on Social Media",
      "description": "A detailed report about Reported Deepfake Video of Elon Musk Announcing $20 Million Cryptocurrency Giveaway Circulating on Social Media",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4379",
      "incident_id": 872,
      "title": "Report 4379 on AI Voice Cloning of Ari Melber Allegedly Exploited in Scam Targeting Elderly Woman",
      "description": "A detailed report about AI Voice Cloning of Ari Melber Allegedly Exploited in Scam Targeting Elderly Woman",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4380",
      "incident_id": 872,
      "title": "Report 4380 on AI Voice Cloning of Ari Melber Allegedly Exploited in Scam Targeting Elderly Woman",
      "description": "A detailed report about AI Voice Cloning of Ari Melber Allegedly Exploited in Scam Targeting Elderly Woman",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4381",
      "incident_id": 872,
      "title": "Report 4381 on AI Voice Cloning of Ari Melber Allegedly Exploited in Scam Targeting Elderly Woman",
      "description": "A detailed report about AI Voice Cloning of Ari Melber Allegedly Exploited in Scam Targeting Elderly Woman",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4385",
      "incident_id": 873,
      "title": "Report 4385 on YouTube Algorithms Allegedly Amplify Eating Disorder Content to Adolescent Girls",
      "description": "A detailed report about YouTube Algorithms Allegedly Amplify Eating Disorder Content to Adolescent Girls",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4386",
      "incident_id": 874,
      "title": "Report 4386 on 1 in 6 Congresswomen Have Reportedly Been Targeted by AI-Generated Nonconsensual Intimate Imagery",
      "description": "A detailed report about 1 in 6 Congresswomen Have Reportedly Been Targeted by AI-Generated Nonconsensual Intimate Imagery",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4387",
      "incident_id": 874,
      "title": "Report 4387 on 1 in 6 Congresswomen Have Reportedly Been Targeted by AI-Generated Nonconsensual Intimate Imagery",
      "description": "A detailed report about 1 in 6 Congresswomen Have Reportedly Been Targeted by AI-Generated Nonconsensual Intimate Imagery",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4388",
      "incident_id": 874,
      "title": "Report 4388 on 1 in 6 Congresswomen Have Reportedly Been Targeted by AI-Generated Nonconsensual Intimate Imagery",
      "description": "A detailed report about 1 in 6 Congresswomen Have Reportedly Been Targeted by AI-Generated Nonconsensual Intimate Imagery",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4392",
      "incident_id": 875,
      "title": "Report 4392 on Coordinated Deepfake Campaign Reportedly Impersonating Rishi Sunak Promoted Fraudulent Quantum AI Investment Platform on Meta",
      "description": "A detailed report about Coordinated Deepfake Campaign Reportedly Impersonating Rishi Sunak Promoted Fraudulent Quantum AI Investment Platform on Meta",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-01-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4393",
      "incident_id": 875,
      "title": "Report 4393 on Coordinated Deepfake Campaign Reportedly Impersonating Rishi Sunak Promoted Fraudulent Quantum AI Investment Platform on Meta",
      "description": "A detailed report about Coordinated Deepfake Campaign Reportedly Impersonating Rishi Sunak Promoted Fraudulent Quantum AI Investment Platform on Meta",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-01-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4394",
      "incident_id": 876,
      "title": "Report 4394 on Deepfake Videos Allegedly Used to Defraud Canadian Immigrants Out of Thousands of Dollars",
      "description": "A detailed report about Deepfake Videos Allegedly Used to Defraud Canadian Immigrants Out of Thousands of Dollars",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-11-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4403",
      "incident_id": 877,
      "title": "Report 4403 on HTML/Nomani Deepfake Phishing Campaigns Allegedly Use AI-Generated Content to Defraud Social Media Users",
      "description": "A detailed report about HTML/Nomani Deepfake Phishing Campaigns Allegedly Use AI-Generated Content to Defraud Social Media Users",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4404",
      "incident_id": 878,
      "title": "Report 4404 on Romance Scammer 'Alla Morgan' Allegedly Exploits Deepfake Technology to Defraud Victim of £17,000",
      "description": "A detailed report about Romance Scammer 'Alla Morgan' Allegedly Exploits Deepfake Technology to Defraud Victim of £17,000",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4407",
      "incident_id": 878,
      "title": "Report 4407 on Romance Scammer 'Alla Morgan' Allegedly Exploits Deepfake Technology to Defraud Victim of £17,000",
      "description": "A detailed report about Romance Scammer 'Alla Morgan' Allegedly Exploits Deepfake Technology to Defraud Victim of £17,000",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4408",
      "incident_id": 878,
      "title": "Report 4408 on Romance Scammer 'Alla Morgan' Allegedly Exploits Deepfake Technology to Defraud Victim of £17,000",
      "description": "A detailed report about Romance Scammer 'Alla Morgan' Allegedly Exploits Deepfake Technology to Defraud Victim of £17,000",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4405",
      "incident_id": 879,
      "title": "Report 4405 on Deepfake Video Reportedly Depicts U.S. Congressman Rob Wittman Endorsing Military Support for Taiwan's Democratic Progressive Party",
      "description": "A detailed report about Deepfake Video Reportedly Depicts U.S. Congressman Rob Wittman Endorsing Military Support for Taiwan's Democratic Progressive Party",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4406",
      "incident_id": 880,
      "title": "Report 4406 on Scammers Reportedly Using Deepfakes of Health Experts and Public Figures in Australia to Sell Health Supplements and Give Harmful Advice",
      "description": "A detailed report about Scammers Reportedly Using Deepfakes of Health Experts and Public Figures in Australia to Sell Health Supplements and Give Harmful Advice",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4411",
      "incident_id": 881,
      "title": "Report 4411 on Waymo Robotaxi Allegedly Collides With Serve Robotics Delivery Bot in Los Angeles",
      "description": "A detailed report about Waymo Robotaxi Allegedly Collides With Serve Robotics Delivery Bot in Los Angeles",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4414",
      "incident_id": 882,
      "title": "Report 4414 on AI-Generated Reading Summaries on Fable App Reportedly Wrote Biased and Offensive Commentary",
      "description": "A detailed report about AI-Generated Reading Summaries on Fable App Reportedly Wrote Biased and Offensive Commentary",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4415",
      "incident_id": 882,
      "title": "Report 4415 on AI-Generated Reading Summaries on Fable App Reportedly Wrote Biased and Offensive Commentary",
      "description": "A detailed report about AI-Generated Reading Summaries on Fable App Reportedly Wrote Biased and Offensive Commentary",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4416",
      "incident_id": 882,
      "title": "Report 4416 on AI-Generated Reading Summaries on Fable App Reportedly Wrote Biased and Offensive Commentary",
      "description": "A detailed report about AI-Generated Reading Summaries on Fable App Reportedly Wrote Biased and Offensive Commentary",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4418",
      "incident_id": 883,
      "title": "Report 4418 on Alleged Fake AI-Generated Christmas Card Featuring Prince Harry and Meghan Markle's Children Circulates on Social Media",
      "description": "A detailed report about Alleged Fake AI-Generated Christmas Card Featuring Prince Harry and Meghan Markle's Children Circulates on Social Media",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4419",
      "incident_id": 883,
      "title": "Report 4419 on Alleged Fake AI-Generated Christmas Card Featuring Prince Harry and Meghan Markle's Children Circulates on Social Media",
      "description": "A detailed report about Alleged Fake AI-Generated Christmas Card Featuring Prince Harry and Meghan Markle's Children Circulates on Social Media",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4420",
      "incident_id": 883,
      "title": "Report 4420 on Alleged Fake AI-Generated Christmas Card Featuring Prince Harry and Meghan Markle's Children Circulates on Social Media",
      "description": "A detailed report about Alleged Fake AI-Generated Christmas Card Featuring Prince Harry and Meghan Markle's Children Circulates on Social Media",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4426",
      "incident_id": 884,
      "title": "Report 4426 on Russian Center for Geopolitical Expertise Allegedly Used AI to Target U.S. Candidates with Disinformation in 2024 Election",
      "description": "A detailed report about Russian Center for Geopolitical Expertise Allegedly Used AI to Target U.S. Candidates with Disinformation in 2024 Election",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-31",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4427",
      "incident_id": 884,
      "title": "Report 4427 on Russian Center for Geopolitical Expertise Allegedly Used AI to Target U.S. Candidates with Disinformation in 2024 Election",
      "description": "A detailed report about Russian Center for Geopolitical Expertise Allegedly Used AI to Target U.S. Candidates with Disinformation in 2024 Election",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-31",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4428",
      "incident_id": 884,
      "title": "Report 4428 on Russian Center for Geopolitical Expertise Allegedly Used AI to Target U.S. Candidates with Disinformation in 2024 Election",
      "description": "A detailed report about Russian Center for Geopolitical Expertise Allegedly Used AI to Target U.S. Candidates with Disinformation in 2024 Election",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-31",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4437",
      "incident_id": 885,
      "title": "Report 4437 on Meta AI Characters Allegedly Exhibited Racism, Fabricated Identities, and Exploited User Trust",
      "description": "A detailed report about Meta AI Characters Allegedly Exhibited Racism, Fabricated Identities, and Exploited User Trust",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-01-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4438",
      "incident_id": 885,
      "title": "Report 4438 on Meta AI Characters Allegedly Exhibited Racism, Fabricated Identities, and Exploited User Trust",
      "description": "A detailed report about Meta AI Characters Allegedly Exhibited Racism, Fabricated Identities, and Exploited User Trust",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-01-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4441",
      "incident_id": 885,
      "title": "Report 4441 on Meta AI Characters Allegedly Exhibited Racism, Fabricated Identities, and Exploited User Trust",
      "description": "A detailed report about Meta AI Characters Allegedly Exhibited Racism, Fabricated Identities, and Exploited User Trust",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-01-03",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4442",
      "incident_id": 886,
      "title": "Report 4442 on ChatGPT Reportedly Referenced During Las Vegas Cybertruck Explosion Planning",
      "description": "A detailed report about ChatGPT Reportedly Referenced During Las Vegas Cybertruck Explosion Planning",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4498",
      "incident_id": 886,
      "title": "Report 4498 on ChatGPT Reportedly Referenced During Las Vegas Cybertruck Explosion Planning",
      "description": "A detailed report about ChatGPT Reportedly Referenced During Las Vegas Cybertruck Explosion Planning",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4542",
      "incident_id": 886,
      "title": "Report 4542 on ChatGPT Reportedly Referenced During Las Vegas Cybertruck Explosion Planning",
      "description": "A detailed report about ChatGPT Reportedly Referenced During Las Vegas Cybertruck Explosion Planning",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4443",
      "incident_id": 887,
      "title": "Report 4443 on Students of Richland School District in Cambria County, Pennsylvania Allegedly Used AI to Generate Obscene Images of Other Students",
      "description": "A detailed report about Students of Richland School District in Cambria County, Pennsylvania Allegedly Used AI to Generate Obscene Images of Other Students",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-11-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4444",
      "incident_id": 888,
      "title": "Report 4444 on Sydney High Schooler Allegedly Generated Deepfakes of Other Students",
      "description": "A detailed report about Sydney High Schooler Allegedly Generated Deepfakes of Other Students",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-01-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4450",
      "incident_id": 889,
      "title": "Report 4450 on Tesla's 'Actually Smart Summon' Feature Reportedly Linked to Multiple Parking Lot Collisions",
      "description": "A detailed report about Tesla's 'Actually Smart Summon' Feature Reportedly Linked to Multiple Parking Lot Collisions",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-01-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4451",
      "incident_id": 889,
      "title": "Report 4451 on Tesla's 'Actually Smart Summon' Feature Reportedly Linked to Multiple Parking Lot Collisions",
      "description": "A detailed report about Tesla's 'Actually Smart Summon' Feature Reportedly Linked to Multiple Parking Lot Collisions",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-01-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4452",
      "incident_id": 890,
      "title": "Report 4452 on AI-Generated Images of the Iconic Hollywood Sign Reportedly on Fire Circulating on Social Media",
      "description": "A detailed report about AI-Generated Images of the Iconic Hollywood Sign Reportedly on Fire Circulating on Social Media",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-01-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4461",
      "incident_id": 890,
      "title": "Report 4461 on AI-Generated Images of the Iconic Hollywood Sign Reportedly on Fire Circulating on Social Media",
      "description": "A detailed report about AI-Generated Images of the Iconic Hollywood Sign Reportedly on Fire Circulating on Social Media",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-01-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4454",
      "incident_id": 891,
      "title": "Report 4454 on AI Voice Scam Targets Westchester Parents with Fake Kidnapping Ransom Calls",
      "description": "A detailed report about AI Voice Scam Targets Westchester Parents with Fake Kidnapping Ransom Calls",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-01-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4455",
      "incident_id": 891,
      "title": "Report 4455 on AI Voice Scam Targets Westchester Parents with Fake Kidnapping Ransom Calls",
      "description": "A detailed report about AI Voice Scam Targets Westchester Parents with Fake Kidnapping Ransom Calls",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-01-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4456",
      "incident_id": 891,
      "title": "Report 4456 on AI Voice Scam Targets Westchester Parents with Fake Kidnapping Ransom Calls",
      "description": "A detailed report about AI Voice Scam Targets Westchester Parents with Fake Kidnapping Ransom Calls",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-01-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4459",
      "incident_id": 892,
      "title": "Report 4459 on Apple Intelligence Allegedly Flags Scam Messages as High Priority",
      "description": "A detailed report about Apple Intelligence Allegedly Flags Scam Messages as High Priority",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-08-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4483",
      "incident_id": 892,
      "title": "Report 4483 on Apple Intelligence Allegedly Flags Scam Messages as High Priority",
      "description": "A detailed report about Apple Intelligence Allegedly Flags Scam Messages as High Priority",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-08-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4484",
      "incident_id": 892,
      "title": "Report 4484 on Apple Intelligence Allegedly Flags Scam Messages as High Priority",
      "description": "A detailed report about Apple Intelligence Allegedly Flags Scam Messages as High Priority",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-08-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4464",
      "incident_id": 893,
      "title": "Report 4464 on Pennsylvania State Police Officer Allegedly Used Work Computer for AI-Generated Pornography",
      "description": "A detailed report about Pennsylvania State Police Officer Allegedly Used Work Computer for AI-Generated Pornography",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-01-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4465",
      "incident_id": 893,
      "title": "Report 4465 on Pennsylvania State Police Officer Allegedly Used Work Computer for AI-Generated Pornography",
      "description": "A detailed report about Pennsylvania State Police Officer Allegedly Used Work Computer for AI-Generated Pornography",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-01-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4466",
      "incident_id": 893,
      "title": "Report 4466 on Pennsylvania State Police Officer Allegedly Used Work Computer for AI-Generated Pornography",
      "description": "A detailed report about Pennsylvania State Police Officer Allegedly Used Work Computer for AI-Generated Pornography",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-01-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4472",
      "incident_id": 894,
      "title": "Report 4472 on RealPage's YieldStar Allegedly Facilitated Rent Price Coordination Among Canadian Landlords",
      "description": "A detailed report about RealPage's YieldStar Allegedly Facilitated Rent Price Coordination Among Canadian Landlords",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-01-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4473",
      "incident_id": 894,
      "title": "Report 4473 on RealPage's YieldStar Allegedly Facilitated Rent Price Coordination Among Canadian Landlords",
      "description": "A detailed report about RealPage's YieldStar Allegedly Facilitated Rent Price Coordination Among Canadian Landlords",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-01-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4474",
      "incident_id": 894,
      "title": "Report 4474 on RealPage's YieldStar Allegedly Facilitated Rent Price Coordination Among Canadian Landlords",
      "description": "A detailed report about RealPage's YieldStar Allegedly Facilitated Rent Price Coordination Among Canadian Landlords",
      "url": "https://incidentdatabase.ai",
      "date_published": "2017-01-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4487",
      "incident_id": 895,
      "title": "Report 4487 on Alleged Deepfake of New Zealand Endocrinologist Reportedly Promotes Misleading Diabetes Claim",
      "description": "A detailed report about Alleged Deepfake of New Zealand Endocrinologist Reportedly Promotes Misleading Diabetes Claim",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-01-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4488",
      "incident_id": 895,
      "title": "Report 4488 on Alleged Deepfake of New Zealand Endocrinologist Reportedly Promotes Misleading Diabetes Claim",
      "description": "A detailed report about Alleged Deepfake of New Zealand Endocrinologist Reportedly Promotes Misleading Diabetes Claim",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-01-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4489",
      "incident_id": 896,
      "title": "Report 4489 on Alleged Misuse of Facial Recognition Technology by Law Enforcement Reportedly Leading to Wrongful Arrests and Violations of Investigative Standards",
      "description": "A detailed report about Alleged Misuse of Facial Recognition Technology by Law Enforcement Reportedly Leading to Wrongful Arrests and Violations of Investigative Standards",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-01-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4490",
      "incident_id": 897,
      "title": "Report 4490 on AI-Assisted Ransomware Campaign by FunkSec Allegedly Targets Over 80 Victims",
      "description": "A detailed report about AI-Assisted Ransomware Campaign by FunkSec Allegedly Targets Over 80 Victims",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-01-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4491",
      "incident_id": 897,
      "title": "Report 4491 on AI-Assisted Ransomware Campaign by FunkSec Allegedly Targets Over 80 Victims",
      "description": "A detailed report about AI-Assisted Ransomware Campaign by FunkSec Allegedly Targets Over 80 Victims",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-01-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4492",
      "incident_id": 897,
      "title": "Report 4492 on AI-Assisted Ransomware Campaign by FunkSec Allegedly Targets Over 80 Victims",
      "description": "A detailed report about AI-Assisted Ransomware Campaign by FunkSec Allegedly Targets Over 80 Victims",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-01-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4494",
      "incident_id": 898,
      "title": "Report 4494 on Alleged LLMjacking Targets AI Cloud Services with Stolen Credentials",
      "description": "A detailed report about Alleged LLMjacking Targets AI Cloud Services with Stolen Credentials",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4495",
      "incident_id": 898,
      "title": "Report 4495 on Alleged LLMjacking Targets AI Cloud Services with Stolen Credentials",
      "description": "A detailed report about Alleged LLMjacking Targets AI Cloud Services with Stolen Credentials",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4496",
      "incident_id": 899,
      "title": "Report 4496 on Character.ai Chatbots Allegedly Emulating School Shooters and Their Victims",
      "description": "A detailed report about Character.ai Chatbots Allegedly Emulating School Shooters and Their Victims",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4497",
      "incident_id": 899,
      "title": "Report 4497 on Character.ai Chatbots Allegedly Emulating School Shooters and Their Victims",
      "description": "A detailed report about Character.ai Chatbots Allegedly Emulating School Shooters and Their Victims",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4499",
      "incident_id": 900,
      "title": "Report 4499 on Character.ai Has Allegedly Been Hosting Openly Predatory Chatbots Targeting Minors",
      "description": "A detailed report about Character.ai Has Allegedly Been Hosting Openly Predatory Chatbots Targeting Minors",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-11-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4501",
      "incident_id": 901,
      "title": "Report 4501 on Yahoo Boys Allegedly Used Deepfake Technology to Impersonate Brad Pitt and Defraud French Woman of $850,000 in Romance Scam",
      "description": "A detailed report about Yahoo Boys Allegedly Used Deepfake Technology to Impersonate Brad Pitt and Defraud French Woman of $850,000 in Romance Scam",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-01-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4502",
      "incident_id": 901,
      "title": "Report 4502 on Yahoo Boys Allegedly Used Deepfake Technology to Impersonate Brad Pitt and Defraud French Woman of $850,000 in Romance Scam",
      "description": "A detailed report about Yahoo Boys Allegedly Used Deepfake Technology to Impersonate Brad Pitt and Defraud French Woman of $850,000 in Romance Scam",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-01-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4503",
      "incident_id": 901,
      "title": "Report 4503 on Yahoo Boys Allegedly Used Deepfake Technology to Impersonate Brad Pitt and Defraud French Woman of $850,000 in Romance Scam",
      "description": "A detailed report about Yahoo Boys Allegedly Used Deepfake Technology to Impersonate Brad Pitt and Defraud French Woman of $850,000 in Romance Scam",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-01-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4509",
      "incident_id": 902,
      "title": "Report 4509 on Prime Minister of Thailand Paetongtarn Shinawatra Claims AI Voice Scam Impersonated ASEAN Leader Requesting Money",
      "description": "A detailed report about Prime Minister of Thailand Paetongtarn Shinawatra Claims AI Voice Scam Impersonated ASEAN Leader Requesting Money",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-01-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4510",
      "incident_id": 902,
      "title": "Report 4510 on Prime Minister of Thailand Paetongtarn Shinawatra Claims AI Voice Scam Impersonated ASEAN Leader Requesting Money",
      "description": "A detailed report about Prime Minister of Thailand Paetongtarn Shinawatra Claims AI Voice Scam Impersonated ASEAN Leader Requesting Money",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-01-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4511",
      "incident_id": 902,
      "title": "Report 4511 on Prime Minister of Thailand Paetongtarn Shinawatra Claims AI Voice Scam Impersonated ASEAN Leader Requesting Money",
      "description": "A detailed report about Prime Minister of Thailand Paetongtarn Shinawatra Claims AI Voice Scam Impersonated ASEAN Leader Requesting Money",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-01-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4518",
      "incident_id": 903,
      "title": "Report 4518 on Northern Ireland MLA Cara Hunter Allegedly Targeted by Deepfake Pornography Ahead of May 2022 Assembly Election",
      "description": "A detailed report about Northern Ireland MLA Cara Hunter Allegedly Targeted by Deepfake Pornography Ahead of May 2022 Assembly Election",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-04-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4519",
      "incident_id": 903,
      "title": "Report 4519 on Northern Ireland MLA Cara Hunter Allegedly Targeted by Deepfake Pornography Ahead of May 2022 Assembly Election",
      "description": "A detailed report about Northern Ireland MLA Cara Hunter Allegedly Targeted by Deepfake Pornography Ahead of May 2022 Assembly Election",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-04-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4520",
      "incident_id": 903,
      "title": "Report 4520 on Northern Ireland MLA Cara Hunter Allegedly Targeted by Deepfake Pornography Ahead of May 2022 Assembly Election",
      "description": "A detailed report about Northern Ireland MLA Cara Hunter Allegedly Targeted by Deepfake Pornography Ahead of May 2022 Assembly Election",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-04-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4531",
      "incident_id": 904,
      "title": "Report 4531 on Kate Isaacs, Advocate Against Image-Based Abuse, Reports Being Deepfaked",
      "description": "A detailed report about Kate Isaacs, Advocate Against Image-Based Abuse, Reports Being Deepfaked",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-10-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4532",
      "incident_id": 904,
      "title": "Report 4532 on Kate Isaacs, Advocate Against Image-Based Abuse, Reports Being Deepfaked",
      "description": "A detailed report about Kate Isaacs, Advocate Against Image-Based Abuse, Reports Being Deepfaked",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-10-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4533",
      "incident_id": 904,
      "title": "Report 4533 on Kate Isaacs, Advocate Against Image-Based Abuse, Reports Being Deepfaked",
      "description": "A detailed report about Kate Isaacs, Advocate Against Image-Based Abuse, Reports Being Deepfaked",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-10-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4580",
      "incident_id": 905,
      "title": "Report 4580 on Scammers Allegedly Use Deepfake Technology to Pose as Leonor, Princess of Asturias, in Fraud Scheme",
      "description": "A detailed report about Scammers Allegedly Use Deepfake Technology to Pose as Leonor, Princess of Asturias, in Fraud Scheme",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4581",
      "incident_id": 905,
      "title": "Report 4581 on Scammers Allegedly Use Deepfake Technology to Pose as Leonor, Princess of Asturias, in Fraud Scheme",
      "description": "A detailed report about Scammers Allegedly Use Deepfake Technology to Pose as Leonor, Princess of Asturias, in Fraud Scheme",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4582",
      "incident_id": 905,
      "title": "Report 4582 on Scammers Allegedly Use Deepfake Technology to Pose as Leonor, Princess of Asturias, in Fraud Scheme",
      "description": "A detailed report about Scammers Allegedly Use Deepfake Technology to Pose as Leonor, Princess of Asturias, in Fraud Scheme",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4585",
      "incident_id": 906,
      "title": "Report 4585 on Alleged AI-Powered Call Center Breach Exposes Over 10 Million Conversations in the Middle East",
      "description": "A detailed report about Alleged AI-Powered Call Center Breach Exposes Over 10 Million Conversations in the Middle East",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4586",
      "incident_id": 906,
      "title": "Report 4586 on Alleged AI-Powered Call Center Breach Exposes Over 10 Million Conversations in the Middle East",
      "description": "A detailed report about Alleged AI-Powered Call Center Breach Exposes Over 10 Million Conversations in the Middle East",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4587",
      "incident_id": 906,
      "title": "Report 4587 on Alleged AI-Powered Call Center Breach Exposes Over 10 Million Conversations in the Middle East",
      "description": "A detailed report about Alleged AI-Powered Call Center Breach Exposes Over 10 Million Conversations in the Middle East",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4588",
      "incident_id": 907,
      "title": "Report 4588 on Taranaki, New Zealand Resident Allegedly Defrauded of $224K in Bitcoin Scam Using Deepfake of Prime Minister Christopher Luxon",
      "description": "A detailed report about Taranaki, New Zealand Resident Allegedly Defrauded of $224K in Bitcoin Scam Using Deepfake of Prime Minister Christopher Luxon",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4589",
      "incident_id": 907,
      "title": "Report 4589 on Taranaki, New Zealand Resident Allegedly Defrauded of $224K in Bitcoin Scam Using Deepfake of Prime Minister Christopher Luxon",
      "description": "A detailed report about Taranaki, New Zealand Resident Allegedly Defrauded of $224K in Bitcoin Scam Using Deepfake of Prime Minister Christopher Luxon",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4590",
      "incident_id": 907,
      "title": "Report 4590 on Taranaki, New Zealand Resident Allegedly Defrauded of $224K in Bitcoin Scam Using Deepfake of Prime Minister Christopher Luxon",
      "description": "A detailed report about Taranaki, New Zealand Resident Allegedly Defrauded of $224K in Bitcoin Scam Using Deepfake of Prime Minister Christopher Luxon",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4591",
      "incident_id": 908,
      "title": "Report 4591 on Deepfake Images of Australian Teacher Hannah Grundy and 25 Others Created and Circulated Online by Former Friend",
      "description": "A detailed report about Deepfake Images of Australian Teacher Hannah Grundy and 25 Others Created and Circulated Online by Former Friend",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-07-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4597",
      "incident_id": 908,
      "title": "Report 4597 on Deepfake Images of Australian Teacher Hannah Grundy and 25 Others Created and Circulated Online by Former Friend",
      "description": "A detailed report about Deepfake Images of Australian Teacher Hannah Grundy and 25 Others Created and Circulated Online by Former Friend",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-07-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4598",
      "incident_id": 908,
      "title": "Report 4598 on Deepfake Images of Australian Teacher Hannah Grundy and 25 Others Created and Circulated Online by Former Friend",
      "description": "A detailed report about Deepfake Images of Australian Teacher Hannah Grundy and 25 Others Created and Circulated Online by Former Friend",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-07-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4595",
      "incident_id": 909,
      "title": "Report 4595 on Matryoshka Campaign Allegedly Uses Deepfakes to Impersonate Academics for Pro-Russian Propaganda",
      "description": "A detailed report about Matryoshka Campaign Allegedly Uses Deepfakes to Impersonate Academics for Pro-Russian Propaganda",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4596",
      "incident_id": 909,
      "title": "Report 4596 on Matryoshka Campaign Allegedly Uses Deepfakes to Impersonate Academics for Pro-Russian Propaganda",
      "description": "A detailed report about Matryoshka Campaign Allegedly Uses Deepfakes to Impersonate Academics for Pro-Russian Propaganda",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4606",
      "incident_id": 909,
      "title": "Report 4606 on Matryoshka Campaign Allegedly Uses Deepfakes to Impersonate Academics for Pro-Russian Propaganda",
      "description": "A detailed report about Matryoshka Campaign Allegedly Uses Deepfakes to Impersonate Academics for Pro-Russian Propaganda",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4605",
      "incident_id": 910,
      "title": "Report 4605 on Alleged AI-Driven Phishing Scam Impersonates Maine Town Official to Falsely Request $22,500",
      "description": "A detailed report about Alleged AI-Driven Phishing Scam Impersonates Maine Town Official to Falsely Request $22,500",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-01-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4614",
      "incident_id": 911,
      "title": "Report 4614 on Yahoo Boys Allegedly Employ Real-Time Deepfake Technology in Romance Scams",
      "description": "A detailed report about Yahoo Boys Allegedly Employ Real-Time Deepfake Technology in Romance Scams",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-05-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4615",
      "incident_id": 912,
      "title": "Report 4615 on Yahoo Boys and Scammers from Morocco Allegedly Target U.S. Widows and Vulnerable Individuals with 'Artificial Patriot' Scams",
      "description": "A detailed report about Yahoo Boys and Scammers from Morocco Allegedly Target U.S. Widows and Vulnerable Individuals with 'Artificial Patriot' Scams",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-11-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4616",
      "incident_id": 912,
      "title": "Report 4616 on Yahoo Boys and Scammers from Morocco Allegedly Target U.S. Widows and Vulnerable Individuals with 'Artificial Patriot' Scams",
      "description": "A detailed report about Yahoo Boys and Scammers from Morocco Allegedly Target U.S. Widows and Vulnerable Individuals with 'Artificial Patriot' Scams",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-11-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4617",
      "incident_id": 913,
      "title": "Report 4617 on Yahoo Boys Allegedly Using AI-Generated News Videos to Blackmail Sextortion Victims",
      "description": "A detailed report about Yahoo Boys Allegedly Using AI-Generated News Videos to Blackmail Sextortion Victims",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-01-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4620",
      "incident_id": 914,
      "title": "Report 4620 on Alleged Deepfake of Luis Suárez Used to Scam Uruguayans in Fake Investment Scheme",
      "description": "A detailed report about Alleged Deepfake of Luis Suárez Used to Scam Uruguayans in Fake Investment Scheme",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4621",
      "incident_id": 914,
      "title": "Report 4621 on Alleged Deepfake of Luis Suárez Used to Scam Uruguayans in Fake Investment Scheme",
      "description": "A detailed report about Alleged Deepfake of Luis Suárez Used to Scam Uruguayans in Fake Investment Scheme",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4622",
      "incident_id": 914,
      "title": "Report 4622 on Alleged Deepfake of Luis Suárez Used to Scam Uruguayans in Fake Investment Scheme",
      "description": "A detailed report about Alleged Deepfake of Luis Suárez Used to Scam Uruguayans in Fake Investment Scheme",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4624",
      "incident_id": 915,
      "title": "Report 4624 on Alaska Education Department Reportedly Published Policy Featuring Erroneous AI-Generated Citations",
      "description": "A detailed report about Alaska Education Department Reportedly Published Policy Featuring Erroneous AI-Generated Citations",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4625",
      "incident_id": 916,
      "title": "Report 4625 on Plymouth, Massachusetts Resident Reportedly Used AI Chatbots CrushOn.ai and JanitorAI to Harass and Intimidate Victims",
      "description": "A detailed report about Plymouth, Massachusetts Resident Reportedly Used AI Chatbots CrushOn.ai and JanitorAI to Harass and Intimidate Victims",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-01-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4626",
      "incident_id": 916,
      "title": "Report 4626 on Plymouth, Massachusetts Resident Reportedly Used AI Chatbots CrushOn.ai and JanitorAI to Harass and Intimidate Victims",
      "description": "A detailed report about Plymouth, Massachusetts Resident Reportedly Used AI Chatbots CrushOn.ai and JanitorAI to Harass and Intimidate Victims",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-01-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4627",
      "incident_id": 917,
      "title": "Report 4627 on Alleged Deepfake of Whoopi Goldberg Used in Fake Weight-Loss Supplement Ads on Instagram",
      "description": "A detailed report about Alleged Deepfake of Whoopi Goldberg Used in Fake Weight-Loss Supplement Ads on Instagram",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4628",
      "incident_id": 918,
      "title": "Report 4628 on AI-Aided Scam in Thailand Allegedly Impersonates Police to Defraud 163 Victims",
      "description": "A detailed report about AI-Aided Scam in Thailand Allegedly Impersonates Police to Defraud 163 Victims",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4631",
      "incident_id": 919,
      "title": "Report 4631 on Russian-Linked Network Allegedly Used Deepfake of Maria Ressa on Facebook and Bing to Promote Cryptocurrency Scam Targeting Filipinos",
      "description": "A detailed report about Russian-Linked Network Allegedly Used Deepfake of Maria Ressa on Facebook and Bing to Promote Cryptocurrency Scam Targeting Filipinos",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-02-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4632",
      "incident_id": 920,
      "title": "Report 4632 on Deepfake Scam Falsely Promoted Trump Golden Eagles Project as Investment Opportunity",
      "description": "A detailed report about Deepfake Scam Falsely Promoted Trump Golden Eagles Project as Investment Opportunity",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4633",
      "incident_id": 921,
      "title": "Report 4633 on Hong Kong Authorities Seize HK$34M in Alleged Deepfake Scam Targeting Victims in Taiwan, Singapore, and Malaysia",
      "description": "A detailed report about Hong Kong Authorities Seize HK$34M in Alleged Deepfake Scam Targeting Victims in Taiwan, Singapore, and Malaysia",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-01-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4634",
      "incident_id": 922,
      "title": "Report 4634 on AI Voice Scam Allegedly Defrauds Game and Coffee Store in Havre, Montana",
      "description": "A detailed report about AI Voice Scam Allegedly Defrauds Game and Coffee Store in Havre, Montana",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4636",
      "incident_id": 923,
      "title": "Report 4636 on Nottingham Gallery Owner Allegedly Defrauded by Deepfake Impersonating Pierce Brosnan, Leading to Business Closure",
      "description": "A detailed report about Nottingham Gallery Owner Allegedly Defrauded by Deepfake Impersonating Pierce Brosnan, Leading to Business Closure",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4639",
      "incident_id": 924,
      "title": "Report 4639 on Alleged Deepfake Scam Uses BBC Presenter Naga Munchetty’s Image to Promote Fraudulent Investment Scheme",
      "description": "A detailed report about Alleged Deepfake Scam Uses BBC Presenter Naga Munchetty’s Image to Promote Fraudulent Investment Scheme",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-01-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4691",
      "incident_id": 924,
      "title": "Report 4691 on Alleged Deepfake Scam Uses BBC Presenter Naga Munchetty’s Image to Promote Fraudulent Investment Scheme",
      "description": "A detailed report about Alleged Deepfake Scam Uses BBC Presenter Naga Munchetty’s Image to Promote Fraudulent Investment Scheme",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-01-30",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4640",
      "incident_id": 925,
      "title": "Report 4640 on Alleged License Plate Recognition Errors in Christchurch Lead to Wrongful Parking Fines",
      "description": "A detailed report about Alleged License Plate Recognition Errors in Christchurch Lead to Wrongful Parking Fines",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-10-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4641",
      "incident_id": 926,
      "title": "Report 4641 on Giorgia Meloni Targeted by Deepfake Pornography",
      "description": "A detailed report about Giorgia Meloni Targeted by Deepfake Pornography",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-01-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4652",
      "incident_id": 926,
      "title": "Report 4652 on Giorgia Meloni Targeted by Deepfake Pornography",
      "description": "A detailed report about Giorgia Meloni Targeted by Deepfake Pornography",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-01-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4653",
      "incident_id": 926,
      "title": "Report 4653 on Giorgia Meloni Targeted by Deepfake Pornography",
      "description": "A detailed report about Giorgia Meloni Targeted by Deepfake Pornography",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-01-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4642",
      "incident_id": 927,
      "title": "Report 4642 on Fraudsters Allegedly Use AI-Generated Voice of Italian Defense Minister Guido Crosetto to Scam Business Leaders",
      "description": "A detailed report about Fraudsters Allegedly Use AI-Generated Voice of Italian Defense Minister Guido Crosetto to Scam Business Leaders",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4643",
      "incident_id": 927,
      "title": "Report 4643 on Fraudsters Allegedly Use AI-Generated Voice of Italian Defense Minister Guido Crosetto to Scam Business Leaders",
      "description": "A detailed report about Fraudsters Allegedly Use AI-Generated Voice of Italian Defense Minister Guido Crosetto to Scam Business Leaders",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4644",
      "incident_id": 927,
      "title": "Report 4644 on Fraudsters Allegedly Use AI-Generated Voice of Italian Defense Minister Guido Crosetto to Scam Business Leaders",
      "description": "A detailed report about Fraudsters Allegedly Use AI-Generated Voice of Italian Defense Minister Guido Crosetto to Scam Business Leaders",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4651",
      "incident_id": 928,
      "title": "Report 4651 on Deepfake Cryptocurrency Scam Allegedly Impersonates Italian President Sergio Mattarella and Prime Minister Giorgia Meloni",
      "description": "A detailed report about Deepfake Cryptocurrency Scam Allegedly Impersonates Italian President Sergio Mattarella and Prime Minister Giorgia Meloni",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4673",
      "incident_id": 929,
      "title": "Report 4673 on Sustained AI-Driven Russian Disinformation Campaigns Doppelgänger, Storm-1516, and Matryoshka Reportedly Disrupting German Federal Elections",
      "description": "A detailed report about Sustained AI-Driven Russian Disinformation Campaigns Doppelgänger, Storm-1516, and Matryoshka Reportedly Disrupting German Federal Elections",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4674",
      "incident_id": 929,
      "title": "Report 4674 on Sustained AI-Driven Russian Disinformation Campaigns Doppelgänger, Storm-1516, and Matryoshka Reportedly Disrupting German Federal Elections",
      "description": "A detailed report about Sustained AI-Driven Russian Disinformation Campaigns Doppelgänger, Storm-1516, and Matryoshka Reportedly Disrupting German Federal Elections",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4678",
      "incident_id": 929,
      "title": "Report 4678 on Sustained AI-Driven Russian Disinformation Campaigns Doppelgänger, Storm-1516, and Matryoshka Reportedly Disrupting German Federal Elections",
      "description": "A detailed report about Sustained AI-Driven Russian Disinformation Campaigns Doppelgänger, Storm-1516, and Matryoshka Reportedly Disrupting German Federal Elections",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4675",
      "incident_id": 930,
      "title": "Report 4675 on Alleged Deepfake Video Falsely Depicts Hollywood Stars in AI-Manipulated Protest Against Kanye West",
      "description": "A detailed report about Alleged Deepfake Video Falsely Depicts Hollywood Stars in AI-Manipulated Protest Against Kanye West",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4676",
      "incident_id": 930,
      "title": "Report 4676 on Alleged Deepfake Video Falsely Depicts Hollywood Stars in AI-Manipulated Protest Against Kanye West",
      "description": "A detailed report about Alleged Deepfake Video Falsely Depicts Hollywood Stars in AI-Manipulated Protest Against Kanye West",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4726",
      "incident_id": 930,
      "title": "Report 4726 on Alleged Deepfake Video Falsely Depicts Hollywood Stars in AI-Manipulated Protest Against Kanye West",
      "description": "A detailed report about Alleged Deepfake Video Falsely Depicts Hollywood Stars in AI-Manipulated Protest Against Kanye West",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4683",
      "incident_id": 931,
      "title": "Report 4683 on Manipulated TikTok Videos Misrepresent Anti-AfD Protests as Far-Right Rallies",
      "description": "A detailed report about Manipulated TikTok Videos Misrepresent Anti-AfD Protests as Far-Right Rallies",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-01-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4684",
      "incident_id": 931,
      "title": "Report 4684 on Manipulated TikTok Videos Misrepresent Anti-AfD Protests as Far-Right Rallies",
      "description": "A detailed report about Manipulated TikTok Videos Misrepresent Anti-AfD Protests as Far-Right Rallies",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-01-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4690",
      "incident_id": 932,
      "title": "Report 4690 on BP New Zealand's License Plate Recognition System Reportedly Misidentified Auckland Driver for Fuel Theft in Whanganui",
      "description": "A detailed report about BP New Zealand's License Plate Recognition System Reportedly Misidentified Auckland Driver for Fuel Theft in Whanganui",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4692",
      "incident_id": 933,
      "title": "Report 4692 on Teenager in Palma de Mallorca Allegedly Generated and Distributed Deepfake Nudes of Five Classmates",
      "description": "A detailed report about Teenager in Palma de Mallorca Allegedly Generated and Distributed Deepfake Nudes of Five Classmates",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4693",
      "incident_id": 933,
      "title": "Report 4693 on Teenager in Palma de Mallorca Allegedly Generated and Distributed Deepfake Nudes of Five Classmates",
      "description": "A detailed report about Teenager in Palma de Mallorca Allegedly Generated and Distributed Deepfake Nudes of Five Classmates",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4694",
      "incident_id": 933,
      "title": "Report 4694 on Teenager in Palma de Mallorca Allegedly Generated and Distributed Deepfake Nudes of Five Classmates",
      "description": "A detailed report about Teenager in Palma de Mallorca Allegedly Generated and Distributed Deepfake Nudes of Five Classmates",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4703",
      "incident_id": 934,
      "title": "Report 4703 on NHK Terminates AI Translation Service After Geopolitical Naming Error",
      "description": "A detailed report about NHK Terminates AI Translation Service After Geopolitical Naming Error",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4704",
      "incident_id": 934,
      "title": "Report 4704 on NHK Terminates AI Translation Service After Geopolitical Naming Error",
      "description": "A detailed report about NHK Terminates AI Translation Service After Geopolitical Naming Error",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4705",
      "incident_id": 935,
      "title": "Report 4705 on Reported Deepfake of Maltese Prime Minister Robert Abela and Journalist Mark Laurence Zammit Used to Promote Fraudulent Investment",
      "description": "A detailed report about Reported Deepfake of Maltese Prime Minister Robert Abela and Journalist Mark Laurence Zammit Used to Promote Fraudulent Investment",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4706",
      "incident_id": 936,
      "title": "Report 4706 on Deepfake of Former Prime Minister of Malta Joseph Muscat Allegedly Promotes Nord Invest Scam",
      "description": "A detailed report about Deepfake of Former Prime Minister of Malta Joseph Muscat Allegedly Promotes Nord Invest Scam",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-04-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4722",
      "incident_id": 937,
      "title": "Report 4722 on Bolivian Criminal Network Allegedly Used Deepfake of Education Minister to Defraud at Least 19 Victims in Employment Scam",
      "description": "A detailed report about Bolivian Criminal Network Allegedly Used Deepfake of Education Minister to Defraud at Least 19 Victims in Employment Scam",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4723",
      "incident_id": 937,
      "title": "Report 4723 on Bolivian Criminal Network Allegedly Used Deepfake of Education Minister to Defraud at Least 19 Victims in Employment Scam",
      "description": "A detailed report about Bolivian Criminal Network Allegedly Used Deepfake of Education Minister to Defraud at Least 19 Victims in Employment Scam",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4724",
      "incident_id": 937,
      "title": "Report 4724 on Bolivian Criminal Network Allegedly Used Deepfake of Education Minister to Defraud at Least 19 Victims in Employment Scam",
      "description": "A detailed report about Bolivian Criminal Network Allegedly Used Deepfake of Education Minister to Defraud at Least 19 Victims in Employment Scam",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4734",
      "incident_id": 938,
      "title": "Report 4734 on AI-Assisted Impersonation of Martin Henderson in Romance Scam Leads to Reported NZ$375,000 Fraud",
      "description": "A detailed report about AI-Assisted Impersonation of Martin Henderson in Romance Scam Leads to Reported NZ$375,000 Fraud",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4735",
      "incident_id": 938,
      "title": "Report 4735 on AI-Assisted Impersonation of Martin Henderson in Romance Scam Leads to Reported NZ$375,000 Fraud",
      "description": "A detailed report about AI-Assisted Impersonation of Martin Henderson in Romance Scam Leads to Reported NZ$375,000 Fraud",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4737",
      "incident_id": 938,
      "title": "Report 4737 on AI-Assisted Impersonation of Martin Henderson in Romance Scam Leads to Reported NZ$375,000 Fraud",
      "description": "A detailed report about AI-Assisted Impersonation of Martin Henderson in Romance Scam Leads to Reported NZ$375,000 Fraud",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4736",
      "incident_id": 939,
      "title": "Report 4736 on AI-Powered Chinese Surveillance Campaign 'Peer Review' Used for Real-Time Monitoring of Anti-State Speech on Western Social Media",
      "description": "A detailed report about AI-Powered Chinese Surveillance Campaign 'Peer Review' Used for Real-Time Monitoring of Anti-State Speech on Western Social Media",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4739",
      "incident_id": 939,
      "title": "Report 4739 on AI-Powered Chinese Surveillance Campaign 'Peer Review' Used for Real-Time Monitoring of Anti-State Speech on Western Social Media",
      "description": "A detailed report about AI-Powered Chinese Surveillance Campaign 'Peer Review' Used for Real-Time Monitoring of Anti-State Speech on Western Social Media",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4740",
      "incident_id": 939,
      "title": "Report 4740 on AI-Powered Chinese Surveillance Campaign 'Peer Review' Used for Real-Time Monitoring of Anti-State Speech on Western Social Media",
      "description": "A detailed report about AI-Powered Chinese Surveillance Campaign 'Peer Review' Used for Real-Time Monitoring of Anti-State Speech on Western Social Media",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4738",
      "incident_id": 940,
      "title": "Report 4738 on Tesla Cybertruck Operating in Full Self-Driving Mode Reportedly Crashes into Pole in Nevada After Failing to Merge",
      "description": "A detailed report about Tesla Cybertruck Operating in Full Self-Driving Mode Reportedly Crashes into Pole in Nevada After Failing to Merge",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4760",
      "incident_id": 940,
      "title": "Report 4760 on Tesla Cybertruck Operating in Full Self-Driving Mode Reportedly Crashes into Pole in Nevada After Failing to Merge",
      "description": "A detailed report about Tesla Cybertruck Operating in Full Self-Driving Mode Reportedly Crashes into Pole in Nevada After Failing to Merge",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4761",
      "incident_id": 940,
      "title": "Report 4761 on Tesla Cybertruck Operating in Full Self-Driving Mode Reportedly Crashes into Pole in Nevada After Failing to Merge",
      "description": "A detailed report about Tesla Cybertruck Operating in Full Self-Driving Mode Reportedly Crashes into Pole in Nevada After Failing to Merge",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4748",
      "incident_id": 941,
      "title": "Report 4748 on AI-Driven Phishing Scam Uses Deepfake Robocalls to Target Gmail Users in Credential Theft Campaign",
      "description": "A detailed report about AI-Driven Phishing Scam Uses Deepfake Robocalls to Target Gmail Users in Credential Theft Campaign",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4749",
      "incident_id": 941,
      "title": "Report 4749 on AI-Driven Phishing Scam Uses Deepfake Robocalls to Target Gmail Users in Credential Theft Campaign",
      "description": "A detailed report about AI-Driven Phishing Scam Uses Deepfake Robocalls to Target Gmail Users in Credential Theft Campaign",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4750",
      "incident_id": 941,
      "title": "Report 4750 on AI-Driven Phishing Scam Uses Deepfake Robocalls to Target Gmail Users in Credential Theft Campaign",
      "description": "A detailed report about AI-Driven Phishing Scam Uses Deepfake Robocalls to Target Gmail Users in Credential Theft Campaign",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-17",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4768",
      "incident_id": 942,
      "title": "Report 4768 on Cybercriminals Reportedly Exploited Google’s G.Co Subdomain and Spoofed Caller ID in AI-Driven Phishing Attack on Hack Club Founder",
      "description": "A detailed report about Cybercriminals Reportedly Exploited Google’s G.Co Subdomain and Spoofed Caller ID in AI-Driven Phishing Attack on Hack Club Founder",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4769",
      "incident_id": 942,
      "title": "Report 4769 on Cybercriminals Reportedly Exploited Google’s G.Co Subdomain and Spoofed Caller ID in AI-Driven Phishing Attack on Hack Club Founder",
      "description": "A detailed report about Cybercriminals Reportedly Exploited Google’s G.Co Subdomain and Spoofed Caller ID in AI-Driven Phishing Attack on Hack Club Founder",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4770",
      "incident_id": 942,
      "title": "Report 4770 on Cybercriminals Reportedly Exploited Google’s G.Co Subdomain and Spoofed Caller ID in AI-Driven Phishing Attack on Hack Club Founder",
      "description": "A detailed report about Cybercriminals Reportedly Exploited Google’s G.Co Subdomain and Spoofed Caller ID in AI-Driven Phishing Attack on Hack Club Founder",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4776",
      "incident_id": 943,
      "title": "Report 4776 on Nonconsensual Explicit AI-Generated Images of Up to 60 Gladstone Park Secondary College Students in Victoria, Australia, Reportedly Created and Circulated Online",
      "description": "A detailed report about Nonconsensual Explicit AI-Generated Images of Up to 60 Gladstone Park Secondary College Students in Victoria, Australia, Reportedly Created and Circulated Online",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4777",
      "incident_id": 944,
      "title": "Report 4777 on Kenya’s Foreign Affairs Principal Secretary Korir Sing’Oei Shares AI-Generated CNN Video Falsely Featuring Fareed Zakaria on Sudan Diplomacy",
      "description": "A detailed report about Kenya’s Foreign Affairs Principal Secretary Korir Sing’Oei Shares AI-Generated CNN Video Falsely Featuring Fareed Zakaria on Sudan Diplomacy",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4778",
      "incident_id": 944,
      "title": "Report 4778 on Kenya’s Foreign Affairs Principal Secretary Korir Sing’Oei Shares AI-Generated CNN Video Falsely Featuring Fareed Zakaria on Sudan Diplomacy",
      "description": "A detailed report about Kenya’s Foreign Affairs Principal Secretary Korir Sing’Oei Shares AI-Generated CNN Video Falsely Featuring Fareed Zakaria on Sudan Diplomacy",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-20",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4779",
      "incident_id": 945,
      "title": "Report 4779 on Two 16-Year-Old Students in Athens, Greece Allegedly Generated Nonconsensual Deepfake Pornography of Their Classmates",
      "description": "A detailed report about Two 16-Year-Old Students in Athens, Greece Allegedly Generated Nonconsensual Deepfake Pornography of Their Classmates",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4782",
      "incident_id": 946,
      "title": "Report 4782 on Arizona Residents Reportedly a Frequent Target of AI-Driven Romance Scams",
      "description": "A detailed report about Arizona Residents Reportedly a Frequent Target of AI-Driven Romance Scams",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-01-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4783",
      "incident_id": 946,
      "title": "Report 4783 on Arizona Residents Reportedly a Frequent Target of AI-Driven Romance Scams",
      "description": "A detailed report about Arizona Residents Reportedly a Frequent Target of AI-Driven Romance Scams",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-01-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4784",
      "incident_id": 946,
      "title": "Report 4784 on Arizona Residents Reportedly a Frequent Target of AI-Driven Romance Scams",
      "description": "A detailed report about Arizona Residents Reportedly a Frequent Target of AI-Driven Romance Scams",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-01-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4793",
      "incident_id": 947,
      "title": "Report 4793 on Two Members of Highline Public Schools Community in King County, Washington Reportedly Targeted in Deepfake Kidnapping Scam",
      "description": "A detailed report about Two Members of Highline Public Schools Community in King County, Washington Reportedly Targeted in Deepfake Kidnapping Scam",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4794",
      "incident_id": 948,
      "title": "Report 4794 on Alleged FraudGPT-Enabled Phishing Attack Spoofs ChatGPT Subscription Service to Steal Credentials",
      "description": "A detailed report about Alleged FraudGPT-Enabled Phishing Attack Spoofs ChatGPT Subscription Service to Steal Credentials",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4795",
      "incident_id": 949,
      "title": "Report 4795 on Unauthorized AI-Generated Video of Donald Trump and Elon Musk Reportedly Appears on HUD Building Screens",
      "description": "A detailed report about Unauthorized AI-Generated Video of Donald Trump and Elon Musk Reportedly Appears on HUD Building Screens",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4796",
      "incident_id": 950,
      "title": "Report 4796 on NullBulge's AI-Powered Malware Allegedly Compromises Disney Employee and Internal Data",
      "description": "A detailed report about NullBulge's AI-Powered Malware Allegedly Compromises Disney Employee and Internal Data",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4797",
      "incident_id": 950,
      "title": "Report 4797 on NullBulge's AI-Powered Malware Allegedly Compromises Disney Employee and Internal Data",
      "description": "A detailed report about NullBulge's AI-Powered Malware Allegedly Compromises Disney Employee and Internal Data",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4798",
      "incident_id": 951,
      "title": "Report 4798 on Character.AI Chatbots Allegedly Impersonating Licensed Therapists and Encouraging Harmful Behaviors",
      "description": "A detailed report about Character.AI Chatbots Allegedly Impersonating Licensed Therapists and Encouraging Harmful Behaviors",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4936",
      "incident_id": 951,
      "title": "Report 4936 on Character.AI Chatbots Allegedly Impersonating Licensed Therapists and Encouraging Harmful Behaviors",
      "description": "A detailed report about Character.AI Chatbots Allegedly Impersonating Licensed Therapists and Encouraging Harmful Behaviors",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4801",
      "incident_id": 952,
      "title": "Report 4801 on Apple’s Voice Dictation Reportedly Substitutes ‘Trump’ for ‘Racist’ Due to Speech Recognition Bug",
      "description": "A detailed report about Apple’s Voice Dictation Reportedly Substitutes ‘Trump’ for ‘Racist’ Due to Speech Recognition Bug",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4802",
      "incident_id": 953,
      "title": "Report 4802 on Deepfake Videos of Barbara O’Neill Allegedly Used in Health Scam Targeting Social Media Users",
      "description": "A detailed report about Deepfake Videos of Barbara O’Neill Allegedly Used in Health Scam Targeting Social Media Users",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-11-01",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4803",
      "incident_id": 954,
      "title": "Report 4803 on Chatbots Allegedly Used in Romance Scams Targeting Nearly One-Third of New Zealand's Dating App Users",
      "description": "A detailed report about Chatbots Allegedly Used in Romance Scams Targeting Nearly One-Third of New Zealand's Dating App Users",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4805",
      "incident_id": 955,
      "title": "Report 4805 on Global Cybercrime Network Storm-2139 Allegedly Exploits AI to Generate Deepfake Content",
      "description": "A detailed report about Global Cybercrime Network Storm-2139 Allegedly Exploits AI to Generate Deepfake Content",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4937",
      "incident_id": 955,
      "title": "Report 4937 on Global Cybercrime Network Storm-2139 Allegedly Exploits AI to Generate Deepfake Content",
      "description": "A detailed report about Global Cybercrime Network Storm-2139 Allegedly Exploits AI to Generate Deepfake Content",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4938",
      "incident_id": 955,
      "title": "Report 4938 on Global Cybercrime Network Storm-2139 Allegedly Exploits AI to Generate Deepfake Content",
      "description": "A detailed report about Global Cybercrime Network Storm-2139 Allegedly Exploits AI to Generate Deepfake Content",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4806",
      "incident_id": 956,
      "title": "Report 4806 on Alleged Inclusion of 12,000 Live API Keys in LLM Training Data Reportedly Poses Security Risks",
      "description": "A detailed report about Alleged Inclusion of 12,000 Live API Keys in LLM Training Data Reportedly Poses Security Risks",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4807",
      "incident_id": 957,
      "title": "Report 4807 on Alleged Instagram Algorithm Malfunction Floods Users’ Reels Feeds with Violent and Graphic Content",
      "description": "A detailed report about Alleged Instagram Algorithm Malfunction Floods Users’ Reels Feeds with Violent and Graphic Content",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4808",
      "incident_id": 958,
      "title": "Report 4808 on Europol Operation Cumberland Investigates at Least 273 Suspects in 19 Countries for AI-Generated Child Sexual Abuse Material",
      "description": "A detailed report about Europol Operation Cumberland Investigates at Least 273 Suspects in 19 Countries for AI-Generated Child Sexual Abuse Material",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4809",
      "incident_id": 958,
      "title": "Report 4809 on Europol Operation Cumberland Investigates at Least 273 Suspects in 19 Countries for AI-Generated Child Sexual Abuse Material",
      "description": "A detailed report about Europol Operation Cumberland Investigates at Least 273 Suspects in 19 Countries for AI-Generated Child Sexual Abuse Material",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4814",
      "incident_id": 958,
      "title": "Report 4814 on Europol Operation Cumberland Investigates at Least 273 Suspects in 19 Countries for AI-Generated Child Sexual Abuse Material",
      "description": "A detailed report about Europol Operation Cumberland Investigates at Least 273 Suspects in 19 Countries for AI-Generated Child Sexual Abuse Material",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-26",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4810",
      "incident_id": 959,
      "title": "Report 4810 on Deepfake Video of Indonesian President Prabowo Subianto and Other Officials Reportedly Used in Scam to Defraud Citizens Across 20 Provinces",
      "description": "A detailed report about Deepfake Video of Indonesian President Prabowo Subianto and Other Officials Reportedly Used in Scam to Defraud Citizens Across 20 Provinces",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4832",
      "incident_id": 959,
      "title": "Report 4832 on Deepfake Video of Indonesian President Prabowo Subianto and Other Officials Reportedly Used in Scam to Defraud Citizens Across 20 Provinces",
      "description": "A detailed report about Deepfake Video of Indonesian President Prabowo Subianto and Other Officials Reportedly Used in Scam to Defraud Citizens Across 20 Provinces",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4833",
      "incident_id": 959,
      "title": "Report 4833 on Deepfake Video of Indonesian President Prabowo Subianto and Other Officials Reportedly Used in Scam to Defraud Citizens Across 20 Provinces",
      "description": "A detailed report about Deepfake Video of Indonesian President Prabowo Subianto and Other Officials Reportedly Used in Scam to Defraud Citizens Across 20 Provinces",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4812",
      "incident_id": 960,
      "title": "Report 4812 on Plaintiffs' Lawyers Admit AI Generated Erroneous Case Citations in Federal Court Filing Against Walmart",
      "description": "A detailed report about Plaintiffs' Lawyers Admit AI Generated Erroneous Case Citations in Federal Court Filing Against Walmart",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4813",
      "incident_id": 960,
      "title": "Report 4813 on Plaintiffs' Lawyers Admit AI Generated Erroneous Case Citations in Federal Court Filing Against Walmart",
      "description": "A detailed report about Plaintiffs' Lawyers Admit AI Generated Erroneous Case Citations in Federal Court Filing Against Walmart",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4823",
      "incident_id": 960,
      "title": "Report 4823 on Plaintiffs' Lawyers Admit AI Generated Erroneous Case Citations in Federal Court Filing Against Walmart",
      "description": "A detailed report about Plaintiffs' Lawyers Admit AI Generated Erroneous Case Citations in Federal Court Filing Against Walmart",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-02-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4834",
      "incident_id": 961,
      "title": "Report 4834 on Serbian Authorities Allegedly Used AI-Powered Cellebrite Tools to Unlock Journalist’s Phone and Install Spyware",
      "description": "A detailed report about Serbian Authorities Allegedly Used AI-Powered Cellebrite Tools to Unlock Journalist’s Phone and Install Spyware",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4835",
      "incident_id": 961,
      "title": "Report 4835 on Serbian Authorities Allegedly Used AI-Powered Cellebrite Tools to Unlock Journalist’s Phone and Install Spyware",
      "description": "A detailed report about Serbian Authorities Allegedly Used AI-Powered Cellebrite Tools to Unlock Journalist’s Phone and Install Spyware",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4836",
      "incident_id": 961,
      "title": "Report 4836 on Serbian Authorities Allegedly Used AI-Powered Cellebrite Tools to Unlock Journalist’s Phone and Install Spyware",
      "description": "A detailed report about Serbian Authorities Allegedly Used AI-Powered Cellebrite Tools to Unlock Journalist’s Phone and Install Spyware",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-12-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4841",
      "incident_id": 962,
      "title": "Report 4841 on Tbilisi-Based Call Center Allegedly Uses AI-Driven Scripts to Defraud Over 6,000 Victims of $35 Million",
      "description": "A detailed report about Tbilisi-Based Call Center Allegedly Uses AI-Driven Scripts to Defraud Over 6,000 Victims of $35 Million",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4842",
      "incident_id": 963,
      "title": "Report 4842 on Google Reports Alleged Gemini-Generated Terrorism and Child Exploitation to Australian eSafety Commission",
      "description": "A detailed report about Google Reports Alleged Gemini-Generated Terrorism and Child Exploitation to Australian eSafety Commission",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4843",
      "incident_id": 964,
      "title": "Report 4843 on AI-Powered 'Insights' Feature for the Los Angeles Times Allegedly Justifies Ku Klux Klan’s History",
      "description": "A detailed report about AI-Powered 'Insights' Feature for the Los Angeles Times Allegedly Justifies Ku Klux Klan’s History",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4844",
      "incident_id": 965,
      "title": "Report 4844 on Phishers Allegedly Using AI-Generated Video of YouTube CEO Neal Mohan to Target Creators",
      "description": "A detailed report about Phishers Allegedly Using AI-Generated Video of YouTube CEO Neal Mohan to Target Creators",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4845",
      "incident_id": 965,
      "title": "Report 4845 on Phishers Allegedly Using AI-Generated Video of YouTube CEO Neal Mohan to Target Creators",
      "description": "A detailed report about Phishers Allegedly Using AI-Generated Video of YouTube CEO Neal Mohan to Target Creators",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4846",
      "incident_id": 965,
      "title": "Report 4846 on Phishers Allegedly Using AI-Generated Video of YouTube CEO Neal Mohan to Target Creators",
      "description": "A detailed report about Phishers Allegedly Using AI-Generated Video of YouTube CEO Neal Mohan to Target Creators",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4848",
      "incident_id": 966,
      "title": "Report 4848 on Ferrari Executive Targeted by AI Deepfake Scam Impersonating CEO Benedetto Vigna",
      "description": "A detailed report about Ferrari Executive Targeted by AI Deepfake Scam Impersonating CEO Benedetto Vigna",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-07-16",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4852",
      "incident_id": 967,
      "title": "Report 4852 on Amazon and Google AI Allegedly Promote Mein Kampf as ‘a True Work of Art’ in Search Results",
      "description": "A detailed report about Amazon and Google AI Allegedly Promote Mein Kampf as ‘a True Work of Art’ in Search Results",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-06",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4853",
      "incident_id": 968,
      "title": "Report 4853 on 'Pravda' Network, Successor to 'Portal Kombat,' Allegedly Seeding AI Models with Kremlin Disinformation",
      "description": "A detailed report about 'Pravda' Network, Successor to 'Portal Kombat,' Allegedly Seeding AI Models with Kremlin Disinformation",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-02-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4854",
      "incident_id": 968,
      "title": "Report 4854 on 'Pravda' Network, Successor to 'Portal Kombat,' Allegedly Seeding AI Models with Kremlin Disinformation",
      "description": "A detailed report about 'Pravda' Network, Successor to 'Portal Kombat,' Allegedly Seeding AI Models with Kremlin Disinformation",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-02-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4855",
      "incident_id": 968,
      "title": "Report 4855 on 'Pravda' Network, Successor to 'Portal Kombat,' Allegedly Seeding AI Models with Kremlin Disinformation",
      "description": "A detailed report about 'Pravda' Network, Successor to 'Portal Kombat,' Allegedly Seeding AI Models with Kremlin Disinformation",
      "url": "https://incidentdatabase.ai",
      "date_published": "2022-02-24",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4900",
      "incident_id": 969,
      "title": "Report 4900 on Russian Disinformation Campaign Allegedly Used Fake News Site 'KBSF-San Francisco News' and Deepfake Video to Falsely Accuse Kamala Harris of 2011 Hit-and-Run",
      "description": "A detailed report about Russian Disinformation Campaign Allegedly Used Fake News Site 'KBSF-San Francisco News' and Deepfake Video to Falsely Accuse Kamala Harris of 2011 Hit-and-Run",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4901",
      "incident_id": 969,
      "title": "Report 4901 on Russian Disinformation Campaign Allegedly Used Fake News Site 'KBSF-San Francisco News' and Deepfake Video to Falsely Accuse Kamala Harris of 2011 Hit-and-Run",
      "description": "A detailed report about Russian Disinformation Campaign Allegedly Used Fake News Site 'KBSF-San Francisco News' and Deepfake Video to Falsely Accuse Kamala Harris of 2011 Hit-and-Run",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4906",
      "incident_id": 969,
      "title": "Report 4906 on Russian Disinformation Campaign Allegedly Used Fake News Site 'KBSF-San Francisco News' and Deepfake Video to Falsely Accuse Kamala Harris of 2011 Hit-and-Run",
      "description": "A detailed report about Russian Disinformation Campaign Allegedly Used Fake News Site 'KBSF-San Francisco News' and Deepfake Video to Falsely Accuse Kamala Harris of 2011 Hit-and-Run",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4902",
      "incident_id": 970,
      "title": "Report 4902 on Scammers Using Deepfake Technology to Impersonate Prime Minister of Armenia Nikol Pashinyan",
      "description": "A detailed report about Scammers Using Deepfake Technology to Impersonate Prime Minister of Armenia Nikol Pashinyan",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4903",
      "incident_id": 970,
      "title": "Report 4903 on Scammers Using Deepfake Technology to Impersonate Prime Minister of Armenia Nikol Pashinyan",
      "description": "A detailed report about Scammers Using Deepfake Technology to Impersonate Prime Minister of Armenia Nikol Pashinyan",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4904",
      "incident_id": 970,
      "title": "Report 4904 on Scammers Using Deepfake Technology to Impersonate Prime Minister of Armenia Nikol Pashinyan",
      "description": "A detailed report about Scammers Using Deepfake Technology to Impersonate Prime Minister of Armenia Nikol Pashinyan",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4907",
      "incident_id": 971,
      "title": "Report 4907 on Iranian Hacker Group Cotton Sandstorm Integrating AI into Cyber Influence Operations",
      "description": "A detailed report about Iranian Hacker Group Cotton Sandstorm Integrating AI into Cyber Influence Operations",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-05-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4908",
      "incident_id": 971,
      "title": "Report 4908 on Iranian Hacker Group Cotton Sandstorm Integrating AI into Cyber Influence Operations",
      "description": "A detailed report about Iranian Hacker Group Cotton Sandstorm Integrating AI into Cyber Influence Operations",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-05-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4909",
      "incident_id": 971,
      "title": "Report 4909 on Iranian Hacker Group Cotton Sandstorm Integrating AI into Cyber Influence Operations",
      "description": "A detailed report about Iranian Hacker Group Cotton Sandstorm Integrating AI into Cyber Influence Operations",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-05-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4920",
      "incident_id": 972,
      "title": "Report 4920 on Russian Influence Operation Allegedly Uses AI to Create Fake Kamala Harris Campaign Website and Rhino-Hunting Hoax",
      "description": "A detailed report about Russian Influence Operation Allegedly Uses AI to Create Fake Kamala Harris Campaign Website and Rhino-Hunting Hoax",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4921",
      "incident_id": 972,
      "title": "Report 4921 on Russian Influence Operation Allegedly Uses AI to Create Fake Kamala Harris Campaign Website and Rhino-Hunting Hoax",
      "description": "A detailed report about Russian Influence Operation Allegedly Uses AI to Create Fake Kamala Harris Campaign Website and Rhino-Hunting Hoax",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-09-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4923",
      "incident_id": 973,
      "title": "Report 4923 on Canadian Fraud Ring Allegedly Used AI Voice Cloning in Multi-Year $21 Million Grandparent Scam Targeting Elderly Americans Across 46 States",
      "description": "A detailed report about Canadian Fraud Ring Allegedly Used AI Voice Cloning in Multi-Year $21 Million Grandparent Scam Targeting Elderly Americans Across 46 States",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4924",
      "incident_id": 973,
      "title": "Report 4924 on Canadian Fraud Ring Allegedly Used AI Voice Cloning in Multi-Year $21 Million Grandparent Scam Targeting Elderly Americans Across 46 States",
      "description": "A detailed report about Canadian Fraud Ring Allegedly Used AI Voice Cloning in Multi-Year $21 Million Grandparent Scam Targeting Elderly Americans Across 46 States",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4925",
      "incident_id": 973,
      "title": "Report 4925 on Canadian Fraud Ring Allegedly Used AI Voice Cloning in Multi-Year $21 Million Grandparent Scam Targeting Elderly Americans Across 46 States",
      "description": "A detailed report about Canadian Fraud Ring Allegedly Used AI Voice Cloning in Multi-Year $21 Million Grandparent Scam Targeting Elderly Americans Across 46 States",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4933",
      "incident_id": 974,
      "title": "Report 4933 on Deepfake Audio Impersonates U.S. Secretary of State Marco Rubio in Starlink Disinformation Campaign",
      "description": "A detailed report about Deepfake Audio Impersonates U.S. Secretary of State Marco Rubio in Starlink Disinformation Campaign",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-04",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4934",
      "incident_id": 975,
      "title": "Report 4934 on At Least 10,000 AI Chatbots, Including Jailbroken Models, Allegedly Promote Eating Disorders, Self-Harm, and Sexualized Minors",
      "description": "A detailed report about At Least 10,000 AI Chatbots, Including Jailbroken Models, Allegedly Promote Eating Disorders, Self-Harm, and Sexualized Minors",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4935",
      "incident_id": 976,
      "title": "Report 4935 on AI-Generated OB-GYN Health Influencers on TikTok Used Fake Medical Credentials to Promote Dubious Advice",
      "description": "A detailed report about AI-Generated OB-GYN Health Influencers on TikTok Used Fake Medical Credentials to Promote Dubious Advice",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4983",
      "incident_id": 976,
      "title": "Report 4983 on AI-Generated OB-GYN Health Influencers on TikTok Used Fake Medical Credentials to Promote Dubious Advice",
      "description": "A detailed report about AI-Generated OB-GYN Health Influencers on TikTok Used Fake Medical Credentials to Promote Dubious Advice",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4984",
      "incident_id": 976,
      "title": "Report 4984 on AI-Generated OB-GYN Health Influencers on TikTok Used Fake Medical Credentials to Promote Dubious Advice",
      "description": "A detailed report about AI-Generated OB-GYN Health Influencers on TikTok Used Fake Medical Credentials to Promote Dubious Advice",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-08",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4941",
      "incident_id": 977,
      "title": "Report 4941 on AI-Driven News Platform Accused of Spreading Unverified Terrorism Allegations Against Yale Scholar",
      "description": "A detailed report about AI-Driven News Platform Accused of Spreading Unverified Terrorism Allegations Against Yale Scholar",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4942",
      "incident_id": 978,
      "title": "Report 4942 on Chinese Actor and CPPCC Member Jin Dong Allegedly Impersonated by AI Deepfake Scammers to Mislead and Defraud Fans",
      "description": "A detailed report about Chinese Actor and CPPCC Member Jin Dong Allegedly Impersonated by AI Deepfake Scammers to Mislead and Defraud Fans",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-09",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4943",
      "incident_id": 979,
      "title": "Report 4943 on Art Museum in Jinan, Shandong Allegedly Generated and Displayed a Sexualized Childlike Avatar with an Adult Body",
      "description": "A detailed report about Art Museum in Jinan, Shandong Allegedly Generated and Displayed a Sexualized Childlike Avatar with an Adult Body",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4944",
      "incident_id": 980,
      "title": "Report 4944 on AI-Generated Songs Allegedly Imitating Céline Dion Circulate Online Without Authorization",
      "description": "A detailed report about AI-Generated Songs Allegedly Imitating Céline Dion Circulate Online Without Authorization",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4945",
      "incident_id": 981,
      "title": "Report 4945 on Apple AI Transcription Allegedly Inserts Explicit Language into Scottish Woman’s Voicemail",
      "description": "A detailed report about Apple AI Transcription Allegedly Inserts Explicit Language into Scottish Woman’s Voicemail",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4949",
      "incident_id": 982,
      "title": "Report 4949 on Scammers Reportedly Using Deepfake Video Calls to Impersonate Executives in Singapore and Orchestrate Corporate Bank Transfers",
      "description": "A detailed report about Scammers Reportedly Using Deepfake Video Calls to Impersonate Executives in Singapore and Orchestrate Corporate Bank Transfers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-13",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4951",
      "incident_id": 983,
      "title": "Report 4951 on Scammers Reportedly Used AI Voice Clone and YouTube Footage to Impersonate WPP CEO in Unsuccessful Scam Attempt",
      "description": "A detailed report about Scammers Reportedly Used AI Voice Clone and YouTube Footage to Impersonate WPP CEO in Unsuccessful Scam Attempt",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4952",
      "incident_id": 983,
      "title": "Report 4952 on Scammers Reportedly Used AI Voice Clone and YouTube Footage to Impersonate WPP CEO in Unsuccessful Scam Attempt",
      "description": "A detailed report about Scammers Reportedly Used AI Voice Clone and YouTube Footage to Impersonate WPP CEO in Unsuccessful Scam Attempt",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4953",
      "incident_id": 983,
      "title": "Report 4953 on Scammers Reportedly Used AI Voice Clone and YouTube Footage to Impersonate WPP CEO in Unsuccessful Scam Attempt",
      "description": "A detailed report about Scammers Reportedly Used AI Voice Clone and YouTube Footage to Impersonate WPP CEO in Unsuccessful Scam Attempt",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-05-10",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4964",
      "incident_id": 984,
      "title": "Report 4964 on Deepfake Videos Allegedly Use AI-Generated Voice Clone of Singapore Prime Minister Lawrence Wong to Promote Scams",
      "description": "A detailed report about Deepfake Videos Allegedly Use AI-Generated Voice Clone of Singapore Prime Minister Lawrence Wong to Promote Scams",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4965",
      "incident_id": 984,
      "title": "Report 4965 on Deepfake Videos Allegedly Use AI-Generated Voice Clone of Singapore Prime Minister Lawrence Wong to Promote Scams",
      "description": "A detailed report about Deepfake Videos Allegedly Use AI-Generated Voice Clone of Singapore Prime Minister Lawrence Wong to Promote Scams",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4966",
      "incident_id": 984,
      "title": "Report 4966 on Deepfake Videos Allegedly Use AI-Generated Voice Clone of Singapore Prime Minister Lawrence Wong to Promote Scams",
      "description": "A detailed report about Deepfake Videos Allegedly Use AI-Generated Voice Clone of Singapore Prime Minister Lawrence Wong to Promote Scams",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-07",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4968",
      "incident_id": 985,
      "title": "Report 4968 on Alleged Deepfake of Singapore Prime Minister Lee Hsien Loong Promotes Cryptocurrency Scam in Fake Interview",
      "description": "A detailed report about Alleged Deepfake of Singapore Prime Minister Lee Hsien Loong Promotes Cryptocurrency Scam in Fake Interview",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-29",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4969",
      "incident_id": 986,
      "title": "Report 4969 on Scammers Allegedly Manipulate 2023 Speech of Singapore Senior Minister Lee Hsien Loong to Spread Deepfake Investment Fraud",
      "description": "A detailed report about Scammers Allegedly Manipulate 2023 Speech of Singapore Senior Minister Lee Hsien Loong to Spread Deepfake Investment Fraud",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-06-02",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4970",
      "incident_id": 987,
      "title": "Report 4970 on Alleged Deepfake of Singapore Deputy Prime Minister Lawrence Wong Falsely Shows Him Endorsing Commercial Products",
      "description": "A detailed report about Alleged Deepfake of Singapore Deputy Prime Minister Lawrence Wong Falsely Shows Him Endorsing Commercial Products",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-11",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4971",
      "incident_id": 988,
      "title": "Report 4971 on Senior Minister of Singapore Lee Hsien Loong Allegedly Misrepresented in Two Deepfake Videos on Foreign Relations",
      "description": "A detailed report about Senior Minister of Singapore Lee Hsien Loong Allegedly Misrepresented in Two Deepfake Videos on Foreign Relations",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-06-21",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4972",
      "incident_id": 989,
      "title": "Report 4972 on Alleged AI-Generated Video by Spain’s People’s Party Results in Diplomatic Fallout with the Dominican Republic",
      "description": "A detailed report about Alleged AI-Generated Video by Spain’s People’s Party Results in Diplomatic Fallout with the Dominican Republic",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-05",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4973",
      "incident_id": 990,
      "title": "Report 4973 on Corinth School District Educator in Mississippi Allegedly Used AI to Generate CSAM of Students",
      "description": "A detailed report about Corinth School District Educator in Mississippi Allegedly Used AI to Generate CSAM of Students",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-11-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4974",
      "incident_id": 990,
      "title": "Report 4974 on Corinth School District Educator in Mississippi Allegedly Used AI to Generate CSAM of Students",
      "description": "A detailed report about Corinth School District Educator in Mississippi Allegedly Used AI to Generate CSAM of Students",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-11-19",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4975",
      "incident_id": 991,
      "title": "Report 4975 on Alleged AI-Generated IRS Scam Websites Used to Defraud U.S. Taxpayers",
      "description": "A detailed report about Alleged AI-Generated IRS Scam Websites Used to Defraud U.S. Taxpayers",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-14",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4981",
      "incident_id": 992,
      "title": "Report 4981 on Chinese Businessman Reportedly Defrauded of 4.3 Million Yuan by AI-Generated Deepfake Impersonating Friend",
      "description": "A detailed report about Chinese Businessman Reportedly Defrauded of 4.3 Million Yuan by AI-Generated Deepfake Impersonating Friend",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-04-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4982",
      "incident_id": 993,
      "title": "Report 4982 on Sydney Students Allegedly Forced to Retake NAPLAN After AI Predictive Text Error",
      "description": "A detailed report about Sydney Students Allegedly Forced to Retake NAPLAN After AI Predictive Text Error",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-5002",
      "incident_id": 993,
      "title": "Report 5002 on Sydney Students Allegedly Forced to Retake NAPLAN After AI Predictive Text Error",
      "description": "A detailed report about Sydney Students Allegedly Forced to Retake NAPLAN After AI Predictive Text Error",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4989",
      "incident_id": 994,
      "title": "Report 4989 on AI-Enabled Organized Crime Expands Across Europe",
      "description": "A detailed report about AI-Enabled Organized Crime Expands Across Europe",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4990",
      "incident_id": 994,
      "title": "Report 4990 on AI-Enabled Organized Crime Expands Across Europe",
      "description": "A detailed report about AI-Enabled Organized Crime Expands Across Europe",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4991",
      "incident_id": 994,
      "title": "Report 4991 on AI-Enabled Organized Crime Expands Across Europe",
      "description": "A detailed report about AI-Enabled Organized Crime Expands Across Europe",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-18",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4996",
      "incident_id": 995,
      "title": "Report 4996 on The New York Times Sues OpenAI and Microsoft Over Alleged Unauthorized AI Training on Its Content",
      "description": "A detailed report about The New York Times Sues OpenAI and Microsoft Over Alleged Unauthorized AI Training on Its Content",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3502",
      "incident_id": 995,
      "title": "Report 3502 on The New York Times Sues OpenAI and Microsoft Over Alleged Unauthorized AI Training on Its Content",
      "description": "A detailed report about The New York Times Sues OpenAI and Microsoft Over Alleged Unauthorized AI Training on Its Content",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-12-27",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4997",
      "incident_id": 996,
      "title": "Report 4997 on Meta Allegedly Used Books3, a Dataset of 191,000 Pirated Books, to Train LLaMA AI",
      "description": "A detailed report about Meta Allegedly Used Books3, a Dataset of 191,000 Pirated Books, to Train LLaMA AI",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-10-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-3226",
      "incident_id": 996,
      "title": "Report 3226 on Meta Allegedly Used Books3, a Dataset of 191,000 Pirated Books, to Train LLaMA AI",
      "description": "A detailed report about Meta Allegedly Used Books3, a Dataset of 191,000 Pirated Books, to Train LLaMA AI",
      "url": "https://incidentdatabase.ai",
      "date_published": "2020-10-25",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4998",
      "incident_id": 997,
      "title": "Report 4998 on Meta and OpenAI Accused of Using LibGen’s Pirated Books to Train AI Models",
      "description": "A detailed report about Meta and OpenAI Accused of Using LibGen’s Pirated Books to Train AI Models",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-4999",
      "incident_id": 997,
      "title": "Report 4999 on Meta and OpenAI Accused of Using LibGen’s Pirated Books to Train AI Models",
      "description": "A detailed report about Meta and OpenAI Accused of Using LibGen’s Pirated Books to Train AI Models",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-5000",
      "incident_id": 997,
      "title": "Report 5000 on Meta and OpenAI Accused of Using LibGen’s Pirated Books to Train AI Models",
      "description": "A detailed report about Meta and OpenAI Accused of Using LibGen’s Pirated Books to Train AI Models",
      "url": "https://incidentdatabase.ai",
      "date_published": "2023-02-28",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-5001",
      "incident_id": 998,
      "title": "Report 5001 on ChatGPT Allegedly Defamed Norwegian User by Inventing Child Homicide and Imprisonment",
      "description": "A detailed report about ChatGPT Allegedly Defamed Norwegian User by Inventing Child Homicide and Imprisonment",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-08-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-5004",
      "incident_id": 998,
      "title": "Report 5004 on ChatGPT Allegedly Defamed Norwegian User by Inventing Child Homicide and Imprisonment",
      "description": "A detailed report about ChatGPT Allegedly Defamed Norwegian User by Inventing Child Homicide and Imprisonment",
      "url": "https://incidentdatabase.ai",
      "date_published": "2024-08-15",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-5005",
      "incident_id": 999,
      "title": "Report 5005 on Attackers Reportedly Deployed Simulated AI Support Chatbot to Trick Instagram Business Users into Adding Malicious 2FA Login",
      "description": "A detailed report about Attackers Reportedly Deployed Simulated AI Support Chatbot to Trick Instagram Business Users into Adding Malicious 2FA Login",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-5006",
      "incident_id": 999,
      "title": "Report 5006 on Attackers Reportedly Deployed Simulated AI Support Chatbot to Trick Instagram Business Users into Adding Malicious 2FA Login",
      "description": "A detailed report about Attackers Reportedly Deployed Simulated AI Support Chatbot to Trick Instagram Business Users into Adding Malicious 2FA Login",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-12",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    },
    {
      "id": "report-5007",
      "incident_id": 1000,
      "title": "Report 5007 on Sora Video Generator Has Reportedly Been Creating Biased Human Representations Across Race, Gender, and Disability",
      "description": "A detailed report about Sora Video Generator Has Reportedly Been Creating Biased Human Representations Across Race, Gender, and Disability",
      "url": "https://incidentdatabase.ai",
      "date_published": "2025-03-23",
      "source_domain": "incidentdatabase.ai",
      "authors": [
        "AI Incident Database"
      ]
    }
  ],
  "classifications": [
    {
      "incident_id": 250
    },
    {
      "incident_id": 208,
      "region": "Europe and Northern America"
    },
    {
      "incident_id": 204,
      "region": "Eastern and South-Eastern Asia"
    },
    {
      "incident_id": 100,
      "harm_type": "yes",
      "severity": "none"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 124,
      "harm_type": "yes",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 350,
      "region": "--"
    },
    {
      "incident_id": 351
    },
    {
      "incident_id": 14,
      "harm_type": "yes",
      "severity": "none"
    },
    {
      "incident_id": null,
      "harm_type": " Sentiment Analysis,Natural Language Processesing,"
    },
    {
      "incident_id": 16,
      "harm_type": "yes",
      "sector": "information and communication",
      "ai_system": "Google Photos' system groups and labels similar photos into categories",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": 35,
      "harm_type": "yes",
      "severity": "none"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 24,
      "harm_type": "yes",
      "sector": "manufacturing",
      "ai_system": "Stationary robot intended to move and manipulate auto parts",
      "region": "Europe",
      "severity": "none"
    },
    {
      "incident_id": 41,
      "harm_type": "no",
      "sector": "professional, scientific and technical activities",
      "ai_system": "Norman is an AI system trained on the captions of violent and graphic content on the  Reddit thread r/watchpeopledie. Its purpose was to provide answers to Rorschach test prompts that would demonstrate the danger of training AI on biased data sets. It did, in fact, provide more gruesome answers to prompts than other AI.",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": 1,
      "harm_type": "yes",
      "sector": "Arts, entertainment and recreation, information and communication",
      "ai_system": "Content-recommendation and filtering algorithm",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": 4,
      "harm_type": "yes",
      "sector": "transportation and storage",
      "ai_system": "Autonomous driving system by Uber",
      "region": "North America",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": 70,
      "harm_type": "no",
      "sector": "transportation and storage",
      "ai_system": "AI systems are designed to integrate with vehicles to autonomously navigate passengers in operational road environments.",
      "region": "Europe",
      "severity": "none"
    },
    {
      "incident_id": 2,
      "harm_type": "yes",
      "sector": "wholesale and retail trade",
      "ai_system": "The robot was a warehouse assistance robot, but the technology did not include AI.",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": 3,
      "harm_type": "yes",
      "sector": "transportation and storage",
      "ai_system": "Maneuvering Characteristics Augmentation System (MCAS) is  a computerized system Boeing installed on its latest generation of 737 airplanes to prevent the plane’s nose from getting too high.",
      "region": "Asia",
      "severity": "unclear"
    },
    {
      "incident_id": 6,
      "harm_type": "yes",
      "sector": "information and communication",
      "ai_system": "Microsoft created a chat bot named Tay with the intent of mimicking and engaging with 18-24 year old social media users.",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 9,
      "harm_type": "yes",
      "sector": "Education",
      "ai_system": "The value-added model system predicts future test scores based on current measurements and then rates teachers based on their ability to bring students up to those predictions - it also uses test scores the teachers don't directly affect.",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": 10,
      "harm_type": "yes",
      "sector": "accommodation and food service activities",
      "ai_system": "The Kronos scheduling algorithm is designed to optimize the productivity of stores like Starbucks by scheduling workers inconsistently throughout and across weeks based on predicted store traffic.",
      "region": "North America",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": 52
    },
    {
      "incident_id": 69,
      "harm_type": "yes",
      "sector": "manufacturing",
      "ai_system": "Welding robot",
      "region": "Asia",
      "severity": "none"
    },
    {
      "incident_id": 68,
      "harm_type": "yes",
      "sector": "administrative and support service activities",
      "ai_system": "Knightscope K5 is an autonomous security robot",
      "region": "North America",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": 17,
      "harm_type": "yes",
      "sector": "information and communication",
      "ai_system": "Smart Reply is a Gmail suggesting algorithm which detects which emails in an inbox need a response. It also predicts and suggests short replies for users.",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 18,
      "harm_type": "yes",
      "sector": "information and communication",
      "ai_system": "Google Images returns image results once search queries and keywords are entered by scanning the web for images with related file names and using machine learning to cluster similar images together.",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": 34,
      "harm_type": "yes",
      "severity": "AI tangible harm near-miss"
    },
    {
      "incident_id": null,
      "harm_type": " audio transcription"
    },
    {
      "incident_id": 11,
      "harm_type": "yes",
      "sector": "law enforcement, public administration",
      "ai_system": "The COMPAS system calculates a person's risk of recidivism based on their criminal records and responses to a 137-questions long survey about the situation and context of the crime and the person involved.",
      "region": "North America",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": 22,
      "harm_type": "yes",
      "severity": "AI tangible harm near-miss"
    },
    {
      "incident_id": null,
      "harm_type": " Dijkstra Algorithm,"
    },
    {
      "incident_id": 36,
      "harm_type": "yes",
      "sector": "law enforcement",
      "ai_system": "Jaywalking detection systems, which are used by traffic police in Chinese cities, take pictures of people as they cross the road in order to detect whether their crossing is compliant with traffic laws. Sometimes, the images and names of jaywalkers are featured on large displays and warn people about the legal consequences of their actions.",
      "region": "Asia",
      "severity": "AI tangible harm near-miss"
    },
    {
      "incident_id": 38,
      "harm_type": "no",
      "sector": "Arts, entertainment and recreation",
      "ai_system": "The Engineers 2.1 update to Frontier Development's game Elite Dangerous was meant to improve the user's experience by making non-playable characters and other features of the game more difficult to overcome. Instead, the development gave the AI responsible for populating and steering the behavior of NPCs the ability to combine characteristics of existing weapons to create superweapons near impossible to defeat.",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 39,
      "harm_type": "no",
      "ai_system": "FakeApp, which Jordan Peele and Buzzfeed used, creates AI generated material like facial reproductions and movement.",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 55,
      "harm_type": "yes",
      "sector": "Arts, entertainment and recreation, information and communication",
      "ai_system": "Amazon Alexa is a digital assistant embedded in a bluetooth speaker ",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": 56,
      "harm_type": "yes",
      "sector": "wholesale and retail trade",
      "ai_system": "It is suspected that the my-handy-design bot was scraping the web for popular images by search term, and then creating phone cases with those images to sell on Amazon. Each case is probably printed to order.",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 23,
      "harm_type": "yes",
      "sector": "transportation and storage",
      "ai_system": "The autonomous shuttle bus was meant to traverse a 0.6 mile loop at around 25 km/h in Las Vegas.",
      "region": "North America",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": 72,
      "harm_type": "yes",
      "sector": "information and communication",
      "ai_system": "Facebook translator",
      "region": "Asia",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": 73,
      "harm_type": "yes",
      "sector": "information and communication, Arts, entertainment and recreation",
      "ai_system": "augmented reality (AR) game Pokémon Go that blends virtual creatures from the Pokémon franchise with real-world locations",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": 63,
      "harm_type": "no",
      "sector": "Arts, entertainment and recreation, information and communication",
      "ai_system": "Google Photos Assistant that creates slideshows and organizes albums based on the photos in the user's Google Photos",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": 64,
      "harm_type": "no",
      "sector": "wholesale and retail trade",
      "ai_system": "Fabio was a customer service robot intended to converse with and assist supermarket shoppers",
      "region": "Europe",
      "severity": "none"
    },
    {
      "incident_id": 66,
      "harm_type": "yes",
      "sector": "information and communication",
      "ai_system": "XiaoBing and BabyQ are chatbots intended to engage with and respond to user queries and messages.",
      "region": "Asia",
      "severity": "none"
    },
    {
      "incident_id": 67,
      "harm_type": "yes",
      "severity": "none"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 81,
      "harm_type": "no",
      "sector": "human health and social work activities",
      "ai_system": "A chest x-ray classifier developed for research purposes. ",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": 84,
      "harm_type": "yes",
      "sector": "information and communication",
      "ai_system": "After independent fact-checkers identify misinformation in posts, Facebook flags the posts and notifies users who have interacted with them. It then uses AI to detect and flag copies of misinformation found elsewhere on the platform.",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 97,
      "harm_type": "yes",
      "sector": "transportation and storage",
      "ai_system": "Tesla's Autopilot is a driver-assistance system meant to help drivers with normal driving functions like steering, braking, and accelerating semi-autonomously.",
      "region": "Europe",
      "severity": "AI tangible harm issue"
    },
    {
      "incident_id": 98,
      "harm_type": "yes",
      "severity": "unclear"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 101,
      "harm_type": "yes",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 12,
      "harm_type": "no",
      "sector": "professional, scientific and technical activities",
      "ai_system": "word2vec word embeddings trained on Google News articles",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": 13,
      "harm_type": "yes",
      "sector": "information and communication",
      "ai_system": "Google's Perspective project, a machine learning-based system to identify toxic comments in online discussion forums",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": 19,
      "harm_type": "yes",
      "sector": "information and communication",
      "ai_system": "Online ad recommendation and delivery ",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": 47,
      "harm_type": "yes",
      "sector": "information and communication",
      "ai_system": "Search engine recommender system suggesting alternative search terms (names) for professional networking.",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": 57,
      "harm_type": "yes",
      "severity": "none"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 5,
      "harm_type": "yes",
      "sector": "human health and social work activities",
      "ai_system": "Surgery robot. ",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": 7,
      "harm_type": "yes",
      "sector": "information and communication",
      "ai_system": "Wikipedia bots are intended to autonomously correct spelling, maintain links, and monitor vandalism on Wikipedia pages.",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 8,
      "harm_type": "yes",
      "sector": "transportation and storage",
      "ai_system": "The AI system developed by Uber for autonomous vehicles is designed to autonomously navigate cars through operational conditions by following traffic lights, avoiding obstacles, and protecting passengers, pedestrians, and other cars on the road.",
      "region": "North America",
      "severity": "AI tangible harm near-miss"
    },
    {
      "incident_id": 29
    },
    {
      "incident_id": 21
    },
    {
      "incident_id": 42
    },
    {
      "incident_id": 62
    },
    {
      "incident_id": 85
    },
    {
      "incident_id": 43,
      "harm_type": "yes",
      "sector": "Education, human health and social work activities",
      "ai_system": "Applicant screening algorithm used in the first stage of admissions process, scoring and ranking applications for interview selection.",
      "region": "Europe",
      "severity": "none"
    },
    {
      "incident_id": 30,
      "harm_type": "yes",
      "sector": "manufacturing",
      "ai_system": "Manufacturing robot used in Tesla factories to produce the Model 3 car, performing tasks such as stamping, painting, welding, final assembly, and battery insulation.",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": 31,
      "harm_type": "yes",
      "severity": "none"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 33,
      "harm_type": "yes",
      "sector": "information and communication",
      "ai_system": "Amazon's Alexa is a virtual assistant technology that can recognize spoken commands and connect to user devices through Bluetooth to perform tasks.",
      "region": "Europe",
      "severity": "none"
    },
    {
      "incident_id": 26,
      "harm_type": "yes",
      "region": "Asia",
      "severity": "none"
    },
    {
      "incident_id": null,
      "harm_type": " which consists of sensors"
    },
    {
      "incident_id": 20,
      "harm_type": "yes",
      "region": "North America",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": 2018
    },
    {
      "incident_id": 2018
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 2020
    },
    {
      "incident_id": 2020,
      "harm_type": " 2010 Mazda 3",
      "region": " lidar,transportation and storage,no,Autonomy2,Autopilot is a semiautonomous driving-assistance system. Drivers are supposed to remain vigilant and be able to retake control of the wheel at any time.,No. Not intentionally designed to perform harm,Tesla vehicle (Model 3",
      "severity": " United Fire Authority truck"
    },
    {
      "incident_id": 15,
      "harm_type": "yes",
      "severity": "none"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 44,
      "harm_type": "no",
      "sector": "administrative and support service activities",
      "ai_system": "Electric Elves use decision tree learning to perform personal assistant tasks like scheduling meetings and ordering lunch for human counterparts.",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": 46,
      "harm_type": "yes",
      "severity": "none"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 59,
      "harm_type": "yes",
      "sector": "information and communication",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 60,
      "harm_type": "yes",
      "severity": "none"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 61,
      "harm_type": "yes",
      "severity": "none"
    },
    {
      "incident_id": 0
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 2017
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 74,
      "harm_type": "yes",
      "sector": "law enforcement",
      "ai_system": "facial recognition company, providing software to companies, law enforcement, universities, and individuals. ",
      "region": "North America",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": 75,
      "harm_type": "yes",
      "sector": "information and communication",
      "ai_system": "Google Instant autocomplete feature predicts and displays search queries based on other users' search activities and the contents of web pages indexed by Google.",
      "region": "Europe",
      "severity": "none"
    },
    {
      "incident_id": 76,
      "harm_type": "yes",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 77,
      "harm_type": "yes",
      "sector": "law enforcement",
      "ai_system": "HP RoboCop, equipped with a camera, is programmed to follow a certain route telling visitors to keep the park clean and acting as a security monitor. It is advertised as including a 360-degree high-definition live video stream, a license plate reader that can scan 1,200 plates a minute, a two-way intercom and the ability to track cell phone use in the vicinity. It has 5 cameras that provide 24/7 monitoring.",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": 80,
      "harm_type": "no",
      "sector": "Arts, entertainment and recreation",
      "ai_system": "The AI-powered camera was meant to track and pan to the ball in a soccer game for a live stream of the match.",
      "region": "Europe",
      "severity": "none"
    },
    {
      "incident_id": 86,
      "harm_type": "yes",
      "sector": "Education",
      "ai_system": "algorithm to predict high school students' final grades",
      "region": "Europe",
      "severity": "none"
    },
    {
      "incident_id": 95,
      "harm_type": "yes",
      "severity": "AI tangible harm issue"
    },
    {
      "incident_id": null,
      "harm_type": " professional",
      "severity": " facial expression recognition"
    },
    {
      "incident_id": 99,
      "harm_type": "yes",
      "severity": "none"
    },
    {
      "incident_id": null,
      "harm_type": " risk assessment"
    },
    {
      "incident_id": 103,
      "harm_type": "yes",
      "sector": "information and communication",
      "ai_system": "Cropping Neutral Network. Given an image, it crops the image to create a preview.",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 105,
      "harm_type": "yes",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 27,
      "harm_type": "yes",
      "severity": "none"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 28,
      "harm_type": "yes",
      "severity": "none"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 32,
      "harm_type": "maybe",
      "sector": "information and communication",
      "ai_system": "Facial recognition system to verify identity of phone user. FaceID uses 30,000 points of reference to map out users' faces to a neural network which is checked against every time the user attempts to unlock the device. ",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": 37,
      "harm_type": "maybe",
      "sector": "administrative and support service activities",
      "ai_system": "Resume screening tool to assess job candidates. The recruitment tool was fed the resumes of successful applicants from the 10-year period before 2014 in order to make decisions about which resumes corresponded most to those that were previously successful.",
      "region": "Europe",
      "severity": "AI tangible harm issue"
    },
    {
      "incident_id": 48,
      "harm_type": "yes",
      "sector": "public administration",
      "ai_system": "Online tool for verifying quality standards of passport photos.",
      "region": "Oceania",
      "severity": "none"
    },
    {
      "incident_id": 49,
      "harm_type": "yes",
      "sector": "Arts, entertainment and recreation",
      "ai_system": "AI system to select winners of a beauty contest. The Beauty.AI system used five different judges to determine beauty. RYNKL, PIMPL, MADIS, Symmetry Master, and AntiAgeist judged based on wrinkles, pimples/pigmentation, similarity to models, symmetry of the face, and the difference between estimated and chronological age.",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 50,
      "harm_type": "yes",
      "sector": "financial and insurance activities",
      "ai_system": "The DAO is a decentralized investment fund built on the Ethereum network. ",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 51,
      "harm_type": "yes",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null,
      "harm_type": " Sensor Data Processing,"
    },
    {
      "incident_id": 78,
      "harm_type": "yes",
      "severity": "none"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 45,
      "harm_type": "yes",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": 2011
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null,
      "harm_type": " Jon Hamm)",
      "severity": " Unnamed chairman of German corporation"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 53,
      "harm_type": "yes",
      "sector": "information and communication",
      "ai_system": "Search engine",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 54,
      "harm_type": "yes",
      "severity": "none"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null,
      "harm_type": " UCLA Institute for Pure and Applied Mathematics",
      "severity": " Richmond Police Department,0,0,False,,PredPol takes in past crime data and spits out predictions about where future crimes are more likely to occur. It turns those predictions into 500 by 500 foot red boxes on a Google map"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 40,
      "harm_type": "yes",
      "ai_system": "The COMPAS system calculates a person's risk of recidivism based on 137 questionnaire responses about the situation and context of the crime and the person involved.",
      "region": "North America",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 104,
      "harm_type": "maybe",
      "sector": "public administration, human health and social work activities",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": 106,
      "harm_type": "yes",
      "sector": "information and communication, Arts, entertainment and recreation",
      "ai_system": "Lee Luda was a South Korean chatbot trained on messages from around 10 billion real-life conversations between young couples taken from KakaoTalk for Scatter Lab's Science of Lab app. Lee Luda was meant to emulate a 20-year-old female college student.",
      "region": "Asia",
      "severity": "none"
    },
    {
      "incident_id": 108,
      "harm_type": "yes",
      "sector": "Arts, entertainment and recreation",
      "ai_system": "facial recognition software",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": 109,
      "harm_type": "yes",
      "severity": "unclear"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 112,
      "harm_type": "yes",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null,
      "harm_type": " Michael Williams",
      "severity": " SST staff review each report to make sure the computer flags only gunshots. The technology's accuracy depends on everything from topography"
    },
    {
      "incident_id": 113,
      "harm_type": "yes",
      "sector": "information and communication",
      "ai_system": "AI tool that is part of Facebook's content recommender system. It classifies and labels the content of Facebook posts, in this case a video. ",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 114,
      "harm_type": "yes",
      "sector": "information and communication, law enforcement",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": 115,
      "harm_type": "yes",
      "sector": "information and communication",
      "ai_system": "Genderify was designed to identify a person's gender by analyzing their name, username or email address by using data based on sources such as governmental and social network information.",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": 116,
      "harm_type": "yes",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": null,
      "harm_type": " video input",
      "severity": " event detection"
    },
    {
      "incident_id": 65,
      "harm_type": "no",
      "sector": "Arts, entertainment and recreation",
      "ai_system": "A reinforcement learning AI system that controls a player in the game CoastRunners.  The game operates in OpenAI's test environment, Universe.",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 82,
      "harm_type": "yes",
      "sector": "information and communication",
      "ai_system": "a system that identifies false information in Facebook posts",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 83,
      "harm_type": "yes",
      "sector": "information and communication",
      "ai_system": "Spam filter",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 87,
      "harm_type": "yes",
      "sector": "public administration",
      "ai_system": "People applying to get a passport must pass an automated check to detect poor quality photos which do not meet Home Office rules including having a neutral expression, a closed mouth, and looking straight at the camera.",
      "region": "Europe",
      "severity": "none"
    },
    {
      "incident_id": 88,
      "harm_type": "yes",
      "sector": "information and communication",
      "ai_system": "Search engine",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 91,
      "harm_type": "yes",
      "severity": "none"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 92,
      "harm_type": "yes",
      "sector": "financial and insurance activities",
      "ai_system": "Financial algorithm determining users' credit limits. ",
      "region": "North America",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": 125,
      "harm_type": "yes",
      "ai_system": "Two AI systems of note.",
      "region": "North America",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 126,
      "harm_type": "yes",
      "sector": "wholesale and retail trade, transportation and storage",
      "ai_system": "Not an AI system. Fulfillment center robots controlled by a wireless protocol that collect customer items (groceries). ",
      "region": "Europe",
      "severity": "none"
    },
    {
      "incident_id": 132,
      "harm_type": "yes",
      "sector": "Arts, entertainment and recreation, information and communication",
      "ai_system": "Content moderation system that should identify and remove pro eating disorder content from the app, and identify related search terms to direct users to help pages.",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 133,
      "harm_type": "yes",
      "severity": "none"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 134,
      "harm_type": "yes",
      "sector": "wholesale and retail trade",
      "ai_system": "It is unclear what the shopping guide robot's tasks are or how it was designed.",
      "region": "Asia",
      "severity": "unclear"
    },
    {
      "incident_id": 122,
      "harm_type": "maybe",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 123,
      "harm_type": "yes",
      "region": "North America",
      "severity": "AI tangible harm issue"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 93,
      "harm_type": "yes",
      "sector": "information and communication",
      "ai_system": "Ad-serving algorithm",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": 25,
      "harm_type": "yes",
      "sector": "transportation and storage",
      "ai_system": "Autonomous driving software",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": 71,
      "harm_type": "yes",
      "region": "North America",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 2016
    },
    {
      "incident_id": 2016
    },
    {
      "incident_id": 2018,
      "harm_type": " Honda sedan and driver,0,1,False,,Self-driving vehicles are designed to autonomously navigate roads and respond to obstacles and situations in real time. They are likely equipped with lasers",
      "severity": " laser input"
    },
    {
      "incident_id": 89,
      "harm_type": "yes",
      "sector": "information and communication, Arts, entertainment and recreation",
      "ai_system": "Content recommender system",
      "region": "Oceania",
      "severity": "none"
    },
    {
      "incident_id": 94,
      "harm_type": "yes",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 96,
      "harm_type": "yes",
      "sector": "Education",
      "ai_system": "EVAAS is a teacher performance assessment system that tracks teachers’ impact with a proprietary algorithm that compares their students’ test results to the statewide average for students in that grade or course.",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": 102,
      "harm_type": "yes",
      "sector": "administrative and support service activities, information and communication",
      "ai_system": "Automated speech recognition (ASR) systems that are used in a variety of applications to convert spoken language to text, from virtual assistants, to closed captioning, to hands-free computing",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": 110,
      "harm_type": "yes",
      "sector": "human health and social work activities",
      "ai_system": "The algorithm allocates medicate services based on recipient data.",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": 118,
      "harm_type": "no",
      "sector": "information and communication, professional, scientific and technical activities",
      "ai_system": "GPT-3 is a large language model that generates text",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": 119,
      "harm_type": "yes",
      "sector": "administrative and support service activities",
      "ai_system": "Big data analytics used to assess employees' work activity.  ",
      "region": "Europe",
      "severity": "none"
    },
    {
      "incident_id": 120,
      "harm_type": "no",
      "sector": "Arts, entertainment and recreation, information and communication",
      "ai_system": "The bot thegentlemetre was a text generator powered by the app Philosopher AI which is built on GPT-3",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 121,
      "harm_type": "yes",
      "sector": "defense",
      "ai_system": "The Kargu is a lethal, autonomous, loitering drone that can use machine learning-based object classification to select and engage targets.",
      "region": "Africa",
      "severity": "AI tangible harm near-miss"
    },
    {
      "incident_id": 128,
      "harm_type": "yes",
      "sector": "transportation and storage",
      "ai_system": "Tesla's Autopilot is designed to autonomously navigate roads and respond to real time situations on the road.",
      "region": "North America",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": 145,
      "harm_type": "yes",
      "sector": "transportation and storage",
      "ai_system": "Tesla's full self-driving technology is meant to autonomously navigate and respond to ongoing situations on the road. This includes reacting to traffic lights and stop signs.",
      "region": "North America",
      "severity": "AI tangible harm issue"
    },
    {
      "incident_id": 146,
      "harm_type": "yes",
      "sector": "information and communication",
      "ai_system": "Ask Delphi is a neural network (mathematical system loosely modeled on the web of neurons in the brain) that analyzed more than 1.7 million ethical judgments by human reviewers from Mechanical Turk from everyday scenarios from websites and other sources. ",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 152,
      "harm_type": "yes",
      "sector": "administrative and support service activities, other service activities, financial and insurance activities, Arts, entertainment and recreation, human health and social work activities",
      "ai_system": "Pepper was given a perky demeanor and programmed to grasp human emotions and engage in basic conversations. Different customers intended to use it for different purposes. For example, reciting scripture or leading elderly people in singing and exercises at a nursing home.",
      "region": "Asia",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": 153,
      "harm_type": "yes",
      "sector": "transportation and storage",
      "ai_system": "Autopilot can control steering, speed, and braking. ",
      "region": "North America",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": 154,
      "harm_type": "yes",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 127,
      "harm_type": "yes",
      "severity": "none"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 129,
      "harm_type": "yes",
      "sector": "information and communication",
      "ai_system": "Facebook's automated moderation tools, powered by artificial intelligence, are intended to flag and remove posts containing hate speech and other detrimental content.",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 135,
      "harm_type": "yes",
      "severity": "none"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 136,
      "harm_type": "yes",
      "sector": "Arts, entertainment and recreation, information and communication",
      "ai_system": "Content classification system that determines whether the content of a website is 'safe' for brands to place their advertisements. Not AI, based on keyword lists. ",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 142,
      "harm_type": "yes",
      "sector": "wholesale and retail trade, information and communication",
      "ai_system": "Ad screening algorithm",
      "region": "Global",
      "severity": "AI tangible harm issue"
    },
    {
      "incident_id": 143,
      "harm_type": "yes",
      "sector": "information and communication",
      "ai_system": "Content moderation systems used on Twitter (now X) and Facebook to detect content that violates the platform's Community Standards",
      "region": "Europe",
      "severity": "none"
    },
    {
      "incident_id": 144,
      "harm_type": "yes",
      "sector": "Arts, entertainment and recreation, information and communication",
      "ai_system": "YouTube's content moderation algorithm",
      "region": "Global",
      "severity": "unclear"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 131,
      "harm_type": "yes",
      "sector": "Education, professional, scientific and technical activities",
      "ai_system": "monitoring tool for online exams",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": 137,
      "harm_type": "yes",
      "severity": "unclear"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 155,
      "harm_type": "yes",
      "severity": "AI tangible harm near-miss"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 156,
      "harm_type": "yes",
      "severity": "none"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 162,
      "harm_type": "yes",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null,
      "harm_type": " despite the unreasonably high number) decided to rely on it for its visa policy. ,No. Not intentionally designed to perform harm,,voice recognition,,"
    },
    {
      "incident_id": 139,
      "harm_type": "yes",
      "sector": "wholesale and retail trade",
      "ai_system": "recommender and search algorithm for Amazon ",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": 140,
      "harm_type": "yes",
      "sector": "Education",
      "ai_system": "exam monitoring system",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": 164,
      "harm_type": "yes",
      "sector": "information and communication",
      "ai_system": "Algorithm determining the content shown on a Facebook user's News Feed ",
      "region": "Global",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": 157,
      "harm_type": "yes",
      "sector": "transportation and storage, wholesale and retail trade",
      "ai_system": "An AI that monitors delivery driver performance",
      "region": "North America",
      "severity": "unclear"
    },
    {
      "incident_id": 160,
      "harm_type": "yes",
      "sector": "information and communication",
      "ai_system": "Alexa is a virtual assistant technology that is deployed to help households complete basic tasks like creating shopping lists, searching the web, and more.",
      "region": "North America",
      "severity": "AI tangible harm issue"
    },
    {
      "incident_id": 79,
      "harm_type": "yes",
      "severity": "none"
    },
    {
      "incident_id": null,
      "harm_type": " or waitlisted for a kidney transplant if the race factor was removed from the equation. Additional 743",
      "severity": " creatinine levels"
    },
    {
      "incident_id": 147,
      "harm_type": "yes",
      "sector": "financial and insurance activities, other",
      "ai_system": "The fraudsters used deep voice technology to clone a director's speech to convince a branch manager to authorize money transfers",
      "region": "Asia",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": 148,
      "harm_type": "yes",
      "sector": "information and communication",
      "ai_system": "Overly products purport to deliver automated compliance with ADA and WCAG standards. Early versions included small user interface controls that read the page's content aloud. Similarly-positioned products added widgets intended to function as on-page assistive technologies that do things like increase font size, change the contrast of the colors on the page, and change the appearance of certain types of content on the page. Most recently, vendors of these products claim that their product can repair underlying code quality problems in the sites on which they're deployed using artificial intelligence.",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": 149,
      "harm_type": "yes",
      "region": "North America",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": null,
      "harm_type": " there has to be a human on-the-loop at least",
      "severity": " prediction,"
    },
    {
      "incident_id": 151,
      "harm_type": "yes",
      "sector": "transportation and storage",
      "ai_system": "Pony.ai's autonomous vehicle was designed to navigate and operate around obstacles on roads driverlessly.",
      "region": "North America",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": 58,
      "harm_type": "yes",
      "sector": "information and communication",
      "ai_system": "Russian-language A chatbot called Alice ",
      "region": "Europe",
      "severity": "none"
    },
    {
      "incident_id": 210
    },
    {
      "incident_id": 360,
      "harm_type": "yes",
      "severity": "none"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 273,
      "harm_type": "yes",
      "severity": "none"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 414,
      "harm_type": "yes",
      "sector": "information and communication",
      "ai_system": "Facebook includes a built in translation tool between languages. However, it has faced numerous problems with translation from Burmese in the past.",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 452,
      "harm_type": "no",
      "sector": "information and communication",
      "ai_system": "ChatGPT is a tool that uses a large-language model called GPT-3 to converse naturally with humans.",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 454,
      "harm_type": "yes",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 435,
      "harm_type": "maybe",
      "sector": "wholesale and retail trade",
      "ai_system": "According to Korea's Fair Trade Commission's announcement, Coupang made changes in search algorithms to prioritize the appearance of products and services related to Coupang. It also engaged in unfair business practices with suppliers.",
      "region": "Asia",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": 281,
      "harm_type": "yes",
      "sector": "information and communication, Arts, entertainment and recreation",
      "ai_system": "Youtube has failed to remove inappropriate suicide-themed content before and has offered worrying search term recommendations related to self-harm.",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 349,
      "harm_type": "yes",
      "severity": "AI tangible harm issue"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null,
      "harm_type": " Arts"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 490,
      "harm_type": "yes",
      "sector": "information and communication, Arts, entertainment and recreation",
      "ai_system": "ChatGPT is a chatbot intended to generate text and answer user prompts. It is based on a large language model.",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 520,
      "harm_type": "yes",
      "sector": "wholesale and retail trade",
      "ai_system": "Amazon Fresh's computer vision-based checkout enables shoppers to pick up items and leave the store without having a discrete checkout phase to the visit. The shopping experience begins and ends with entry and exit gates requiring you to scan a QR code or credit card. Cameras track shoppers' movements and purchases, recognizing the products that shoppers pick up. A receipt is billed to the shoppers after they leave the store.",
      "region": "North America",
      "severity": "AI tangible harm issue"
    },
    {
      "incident_id": 476,
      "harm_type": "maybe",
      "sector": "information and communication",
      "ai_system": "Youtube's content recommender algorithm promotes content that users have shown interest in in the past. Someone who shows some interest in terrorist recruitment videos will be shown more recruitment videos based on past viewing habits. This feature may promote misinformation and encourage people to join harmful terrorist organizations.",
      "region": "Europe",
      "severity": "unclear"
    },
    {
      "incident_id": 574,
      "harm_type": "no",
      "sector": "information and communication, Arts, entertainment and recreation",
      "ai_system": "ChatGPT and Bard are text-generation bots.",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 461,
      "harm_type": "yes",
      "ai_system": "The IRS's audit selection algorithms automate selecting returns for audit. The algorithms disproportionately flag tax returns with potential errors in the claiming of certain tax credits, like the earned-income tax credit, which supplements low-income workers' incomes to alleviate poverty. Research suggests that the IRS has focused on audits that are easier to conduct. However, Black Americans claiming the EITC only explained a small part of the audit differences. More than three-quarters of the disparity stems from how much more often Black taxpayers who claim the credit are audited compared with EITC claimants who are not Black.",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 410,
      "harm_type": "no",
      "sector": "accommodation and food service activities, information and communication",
      "ai_system": "KFC's automated messaging system is designed to detect holidays and other days of significance and write relevant marketing messages. Messages created by the system are supposed to be checked by a human before being sent to users.",
      "region": "Europe",
      "severity": "none"
    },
    {
      "incident_id": 244,
      "harm_type": "yes",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 239,
      "harm_type": "yes",
      "severity": "unclear"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 594,
      "harm_type": "no",
      "sector": "accommodation and food service activities, wholesale and retail trade",
      "ai_system": "The Savey Meal-bot auto-generates meal plans from user-inputted ingredients.",
      "region": "Oceania",
      "severity": "none"
    },
    {
      "incident_id": 545,
      "harm_type": "yes",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 457,
      "harm_type": "yes",
      "sector": "information and communication",
      "ai_system": "Generative language model",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 493,
      "harm_type": "maybe",
      "severity": "unclear"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 396,
      "region": "--"
    },
    {
      "incident_id": 519,
      "harm_type": "yes",
      "severity": "AI tangible harm near-miss"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 501,
      "harm_type": "yes",
      "sector": "human health and social work activities",
      "ai_system": "nH Predict uses details such as a person's diagnosis, age, living situation, and physical function to find similar individuals in a database of 6 million patients it compiled over years of working with providers. It then generates an assessment of the patient's mobility and cognitive capacity, along with a down-to-the-minute prediction of their medical needs, estimated length of stay, and target discharge date.",
      "region": "North America",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": 290,
      "harm_type": "yes",
      "sector": "human health and social work activities, public administration",
      "ai_system": "Waters that tested high for E. coli using traditional means were marked safe by the new AIPM system dozens of times. Cann Forecast describes its beach water monitoring system as a high-tech artificial intelligence algorithm that uses machine learning to provide real-time water quality advisories that are 90% accurate on average.",
      "region": "North America",
      "severity": "AI tangible harm near-miss"
    },
    {
      "incident_id": 329,
      "harm_type": "maybe",
      "sector": "wholesale and retail trade",
      "ai_system": "Amazon's recommender algorithm provides buyers of a product with suggestions of bundles of other items that other users frequently bought along with it.",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 245,
      "harm_type": "yes",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": 5
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 489,
      "harm_type": "maybe",
      "sector": "professional, scientific and technical activities, information and communication",
      "ai_system": "Workday is used as a recruitment screening tool. Allegedly, the selection tools marketed by Workday to its customers allows these customers to manipulate and configure them in a discriminatory manner to recruit, hire, and onboard employees. Workday's products process and interpret an applicant's qualifications and recommend whether the applicant should be accepted or rejected.",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 412,
      "harm_type": "yes",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 509,
      "harm_type": "yes",
      "sector": "information and communication",
      "ai_system": "Scammers using deepfake technology began by collecting visual data on victims from Facebook, Zalo, etc. Then, they would collect personal data such as the victims' phone numbers, email addresses, and family relationships. Next, they would make a phone or video call using deepfaked audio and video of the victims in order to convince their family members and acquaintances to transfer money to their compromised accounts.",
      "region": "Asia",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": 474,
      "harm_type": "no",
      "severity": "none"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 510,
      "harm_type": "no",
      "sector": "information and communication, Arts, entertainment and recreation",
      "ai_system": "Midjourney v5 is an image synthesis service that creates artificially-generated photos based on user prompts.",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 339,
      "harm_type": "no",
      "sector": "Education, information and communication",
      "ai_system": "Sudowrite, ChatGPT, and other tools are used in some instances to facilitate cheating in academic settings. These tools accept user prompts/queries and specifications about output in order to answer essay questions or provide unauthorized assistance with assignments for students.",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 554,
      "harm_type": "no",
      "sector": "Arts, entertainment and recreation",
      "ai_system": "While it is unclear which AI image generation software van Dieken used to generate the replica image, he likely inputted details about the original painting to prompt the AI to generate the image that it did. ",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 341,
      "harm_type": "yes",
      "sector": "transportation and storage",
      "ai_system": "Nissan vehicles' Automatic Emergency Braking systems are there to alert drivers of a possible imminent frontal collision, braking if the driver doesn't respond to the warning by putting on the brakes themselves. Nissan's AEB systems use radar to determine pedestrians, other vehicles and other potential obstacles ahead of a car. However, the systems are accused of detecting non-existent obstacles, providing false alarms, or triggering the brakes despite no obstacles being present. This is especially dangerous because the emergency braking systems have falsely engaged while in intersections or on bridges, highways and railroad tracks. The activation of the brakes allegedly makes it difficult for drivers to move out of the way of danger, putting them at an increased risk of side-on or rear-end collisions.",
      "region": "North America",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": 387,
      "harm_type": "yes",
      "severity": "none"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 367,
      "harm_type": "no",
      "sector": "information and communication",
      "ai_system": "Steed and Caliskan examined embeddings within image-generation algorithms, which separate pixels based on how often they co-occur within training images. Those pixel embeddings can then be used to compare how close or far two images are in mathematical space.  AI algorithms like iGPT and SimCLR are used to auto-complete input images.",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 313,
      "harm_type": "no",
      "sector": "information and communication",
      "ai_system": "Meta's BlenderBot 3 was a state-of-the-art conversational agent developed as a research project that generated text responses to user prompts.",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 576,
      "harm_type": "no",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 254,
      "harm_type": "no",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 2015
    },
    {
      "incident_id": 220,
      "harm_type": "yes",
      "sector": "wholesale and retail trade, information and communication",
      "ai_system": "Facebook deploys automated spam filters to moderate content and take down ads/posts that violate its content policies. ",
      "region": "Global",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": 294,
      "harm_type": "yes",
      "sector": "transportation and storage",
      "ai_system": "Tesla's Autopilot is designed to assist drivers by semi-autonomously navigating road obstacles and responding to real-time traffic conditions.",
      "region": "Europe",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": 456,
      "harm_type": "maybe",
      "sector": "Arts, entertainment and recreation, information and communication",
      "ai_system": "Replika AI is a chatbot that uses Luka's own GPT-3 model and scripted dialogue content in order to customize conversations with users.",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 354,
      "harm_type": "maybe",
      "sector": "transportation and storage",
      "ai_system": "Uber automates decision-making for management functions such as driver termination, account deactivation, upfront pricing, batch matching, fraud probability scores, profiling, assigning riders, calculating pricing, rating drivers, and more",
      "region": "Europe",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": 214,
      "harm_type": "yes",
      "sector": "Education, law enforcement, public administration",
      "ai_system": "SN Technologies' weapons and facial recognition software uses facial recognition to surveil students and identify objects within the school to see if they are guns or not. It was found that these systems reported a lot of false alarms.",
      "region": "North America",
      "severity": "AI tangible harm near-miss"
    },
    {
      "incident_id": 547,
      "harm_type": "maybe",
      "sector": "other",
      "ai_system": "It is unclear which tool was used. However, DeSantis's campaign used some technology to generate fake images of Donald Trump hugging Anthony Fauci.",
      "region": "North America",
      "severity": "none"
    },
    {
      "incident_id": 526,
      "harm_type": "no",
      "severity": "none"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 619,
      "harm_type": "yes",
      "sector": "wholesale and retail trade",
      "ai_system": "Rite Aid supervised the creation of a watchlist database of images of people the company claimed had engaged in actual or attempted criminal activity at one of its stores. These entries included first and last names, years of birth, and a description of behavior Rite Aid claimed the person in the photo had engaged in... According to the complaint, Rite Aid directed store security to push for as many enrollments as possible. If someone who entered the store matched an image in the database, employees received an alert and could choose to follow, apprehend, report, or otherwise engage with the customer. However, Rite Aid's technology was found to disproportionately misidentify black, Asian, Latino, and female consumers as matching an image in the database.",
      "region": "North America",
      "severity": "AI tangible harm issue"
    },
    {
      "incident_id": 564,
      "harm_type": "yes",
      "sector": "financial and insurance activities",
      "ai_system": "Although it is unclear who the scammers were, what technology they used, and who developed that technology, it is clear that there was fraud involved with Kabatznik's account. The scammer likely used publicly available recordings of Kabatznik's voice to train a deepfake voice AI, and then inputted text when calling the Bank of America representative to attempt to get Kabatznik's money transferred without his consent.",
      "region": "Global",
      "severity": "AI tangible harm near-miss"
    },
    {
      "incident_id": 323,
      "harm_type": "yes",
      "sector": "transportation and storage",
      "ai_system": "Tesla Autopilot is designed to assist drivers in semi-autonomously navigating road obstacles and reacting to real-time traffic conditions.",
      "region": "North America",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": 409,
      "harm_type": "no",
      "sector": "professional, scientific and technical activities",
      "ai_system": "Ricaneck built a biometric dataset of 10,000 images of 38 trans people, scraped from their YouTube videos documenting their hormone therapies in order to improve the accuracy of facial recognition systems in identifying people pre and post hormone therapy. This HRT Transgender Dataset was still available as a Dropbox URL as late as April 2021 and also included the videos.",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 614,
      "harm_type": "maybe",
      "sector": "law enforcement, information and communication",
      "ai_system": "Google's Bard AI, now known as Gemini, is a generative artificial intelligence chatbot that responds to user prompts by generating text to answer their questions.",
      "region": "Oceania",
      "severity": "none"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 393,
      "harm_type": "no",
      "severity": "none"
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": null
    },
    {
      "incident_id": 583,
      "harm_type": "yes",
      "sector": "Arts, entertainment and recreation",
      "ai_system": "Instagram's recommendation algorithms have been connecting and promoting accounts that facilitate and sell child sexual abuse content...Meta's photo-sharing service stands out from other social media platforms and 'appears to have a particularly severe problem' with accounts showing self-generated child sexual abuse material.",
      "region": "Global",
      "severity": "none"
    },
    {
      "incident_id": 205,
      "harm_type": "no",
      "sector": "Arts, entertainment and recreation, information and communication",
      "ai_system": "Hacking group Ghostwriter used Facebook to target public figures in Ukraine. Hackers successfully gained access to targets' social media accounts and attempted to post YouTube videos from them portraying Ukrainian troops as weakened. In a separate influence campaign, individuals used a number of fictitious personas to run websites masquerading as independent news outlets to publish claims about the West betraying Ukraine and Ukraine being a failed state.",
      "region": "Europe",
      "severity": "none"
    },
    {
      "incident_id": 603,
      "harm_type": "yes",
      "sector": "human health and social work activities",
      "ai_system": "The algorithm included a computerized assessment with 286 questions covering everything from mental health to how much help patients need with daily activities like eating or doing their personal finances. Then, an algorithmic tool sorted patients into various levels of need. Each level was assigned a standard numbers of hours of care.",
      "region": "North America",
      "severity": "AI tangible harm event"
    },
    {
      "incident_id": 355,
      "harm_type": "yes",
      "sector": "transportation and storage",
      "ai_system": "Uber uses algorithms to detect fraud, such as strategically logging out to await higher surge pricing or declining work offered, in driver accounts. These algorithms have the ability to dismiss drivers without the right of appeal. Uber also uses algorithms to determine the earnings potential of a driver by assigning or withholding jobs from the available pool.",
      "region": "Europe",
      "severity": "AI tangible harm event"
    }
  ],
  "meta": {
    "incidentCount": 993,
    "reportCount": 2043,
    "classificationCount": 356,
    "generatedAt": "2025-03-28T13:12:35.283Z"
  }
}