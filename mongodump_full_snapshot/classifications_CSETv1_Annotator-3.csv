Namespace,Incident ID,Published,Incident Number,Annotator,Annotation Status,Peer Reviewer,Quality Control,Physical Objects,Entertainment Industry,"Report, Test, or Study of data",Deployed,Producer Test in Controlled Conditions,Producer Test in Operational Conditions,User Test in Controlled Conditions,User Test in Operational Conditions,Harm Domain,Tangible Harm,AI System,Clear link to technology,There is a potentially identifiable specific entity that experienced the harm,AI Harm Level,AI Tangible Harm Level Notes,Impact on Critical Services,Rights Violation,Involving Minor,Detrimental Content,Protected Characteristic,Harm Distribution Basis,Notes (special interest intangible harm),Special Interest Intangible Harm,AI System,Clear link to Technology,Harmed Class of Entities,Annotator’s AI special interest intangible harm assessment,Notes (AI special interest intangible harm),Date of Incident Year,Date of Incident Month,Date of Incident Day,Estimated Date,Multiple AI Interaction,Embedded,Location City,Location State/Province (two letters),Location Country (two letters),Location Region,Infrastructure Sectors,Operating Conditions,Notes (Environmental and Temporal Characteristics),Entities,Lives Lost,Injuries,Estimated Harm Quantities,Notes ( Tangible Harm Quantities Information),AI System Description,Data Inputs,Sector of Deployment,Public Sector Deployment,Autonomy Level,Notes (Information about AI System),Intentional Harm,Physical System Type,AI Task,AI tools and methods,Notes (AI Functionality and Techniques)
CSETv1_Annotator-3,100,True,100,007,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,yes,yes,imminent risk of tangible harm (near miss) did occur,yes,yes,True,AI tangible harm near-miss,No financial harm because the money was given back,no,no,no,no,no,none,,no,yes,no,True,no,,2021,March,17,True,no,yes,,,France,Europe,"government facilities, financial services",,,"Journalist , French Welfare Offices, Journalist",,,False,,Not clear if AI - automated fraud detection algorithms,,"financial and insurance activities, administrative and support service activities",yes,Autonomy2,,No. Not intentionally designed to perform harm,,,,Fraud detection
CSETv1_Annotator-3,99,False,99,007,1. Annotation in progress,,False,no,no,no,yes,no,no,no,no,yes,"no tangible harm, near-miss, or issue",yes,yes,True,none,It could be argued that because of the “high-impact predictor” of student success — pushing Black and other minority students into “easier” classes and majors - they will face financial loss in the future (could have gotten into higher payed jobs otherwise),no,yes,no,no,yes,race,,yes,yes,yes,True,yes,,2020,,,True,no,no,,,US,North America,Other,,,"Universities in the US, University of Texas at Austin, Universities applicants of marginalized groups, Navigate \""risk\"" algorithm, Universities active students, University of Massachusetts Amherst, University of Wisconsin–Milwaukee, University of Houston, Texas A&M University",0,-1,False,Predictive AI system assigning students risk scores about potential failure to graduate in their chosen major,Predictive analytics algorithm,,"administrative and support service activities, Education",maybe,unclear,,No. Not intentionally designed to perform harm,,risk prediction,,
CSETv1_Annotator-3,98,True,98,007,4. Peer review complete,003,False,yes,no,no,yes,no,no,no,yes,yes,"no tangible harm, near-miss, or issue",maybe,yes,True,none,,no,no,no,no,no,none,,no,maybe,yes,True,no,,2021,,,True,no,maybe,NY,NY,US,North America,,,,"NYPD, NY citizens, Digidog, Boston Dynamics",0,0,False,,"Robot dog used to aid law enforcement by""going places where humans can't""",Unclear,law enforcement,yes,unclear,,No. Not intentionally designed to perform harm,Robot dog,,,
CSETv1_Annotator-3,95,False,,,,,False,no,no,no,yes,no,no,no,no,yes,,yes,,False,AI tangible harm near-miss,it is unclear based on what the algorithm denied candidates but there is a risk that is based on race or other protected values.,maybe,maybe,no,no,maybe,unclear,,maybe,yes,maybe,True,maybe,,2019,,,True,no,no,,,US,North America,Other,recruiting-technology,,"Hilton International hiring candidates, Unilever hiring candidates, job candidates using HireVue, HireVue, Hilton International, Unilever, Employers using HireVue",0,0,True,,"Hiring algorithm that uses candidates’ computer or cellphone cameras to analyze their facial movements, word choice, and speaking voice before ranking them against other applicants based on an automatically generated “employability” score.",videos,administrative and support service activities,no,unclear,I seems that it is independent but it is not exactly clear,No. Not intentionally designed to perform harm,,recruiting tool,,
CSETv1_Annotator-3,86,True,86,007,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,unclear,yes,yes,True,unclear,Unclear if any harm has occurred,no,maybe,no,no,maybe,unclear,,maybe,yes,maybe,True,maybe,,2020,September\October,,True,no,no,Dublin,,IE,Europe,government facilities,,"Ireland’s Department of Education announced that errors in the algorithm used to calculate students’ Leaving Certificate exam grades resulted in thousands of inaccurate scores - affecting government facilities.

","Ireland Department of Education , Leaving Certificate exam takers, Leaving Certificate exam , Polymetrika",0,0,True,,predicting grades - Leaving Certificate calculated grades system ,Unclear,"Education, public administration",yes,unclear,,No. Not intentionally designed to perform harm,,grade predictor,,
CSETv1_Annotator-3,84,True,84,007,4. Peer review complete,003,False,no,no,no,yes,no,yes,no,no,yes,"no tangible harm, near-miss, or issue",yes,yes,True,none,"there wasn't necessarily a type of harm, just that the AI is failing to fulfill its purpose of completely and accurately filtering out misinformation",no,no,no,yes,no,none,AI failed to prevent the spread of misinformation,yes,yes,yes,True,yes,,2020,10,9,True,no,no,,,,Global,,,"AI is involved in Facebook's fact-checking systems. Not necessarily a definitive date or location for the failure of this system.
Date of publication","Facebook users, Facebook, Avaaz",0,0,False,,Facebook relies on both human reviewers and artificial intelligence to catch posts that break its rules - misinformation,Facebook posts,information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,fact-check,,Facebook's artificial intelligence system is used to catch posts that break its rules of misinformation
CSETv1_Annotator-3,81,True,81,007,4. Peer review complete,003,True,no,no,yes,no,yes,no,no,no,yes,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,no,yes,"race, sex, other",AI bias in health care ,yes,yes,yes,True,yes,,2020,,,True,no,no,,,,North America,,,,"Women and People of Color Patients, Chest x-ray classifier, University of Toronto, Vector Institute, MIT",0,0,False,,AI and machine learning systems that classify chest X-rays to help identify conditions like fractures and collapsed lungs,Unclear,"other, human health and social work activities",no,unclear,,No. Not intentionally designed to perform harm,x-Ray,health conditions Identificator,,
CSETv1_Annotator-3,80,True,80,007,2. Initial annotation complete,,False,yes,yes,no,yes,no,no,no,no,maybe,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,no,no,none,,no,yes,no,True,no,,2020,10,24,True,no,yes,,,Scotland,Europe,,,The camera misidentifies the ball as a bolded man standing in the field," Iverness and Ayr United fans, Inverness Caledonian Thistle Football Club, AI controlled camera",0,-1,True,,"AI-controlled camera, programmed to automatically follow the ball, removing the need for a human camera person in broadcast soccer games. The camera was supposed to track the ball automatically using AI and show footage on YouTube.",,"Arts, entertainment and recreation, information and communication",no,Autonomy1,,No. Not intentionally designed to perform harm,camera,controlled camera,,
CSETv1_Annotator-3,77,True,76,007,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,yes,yes,tangible harm definitively occurred,yes,no,True,none,"The AI robot was not linked directly to the tangible harm (the fight happened before the incident with the robot),  It is arguable that if the robot would have worked properly the tangible harm could have been minimized but important to note that the feature that would have been helpful in alerting the authorities was not an AI feature, but just the phone connection to the police",yes,no,no,no,no,none,,no,yes,no,True,no,,2019,10,,True,no,yes,LA,CA,US,North America,"government facilities, emergency services",,,"Knightscope, Injured woman, Huntington park police department, Knightscope Robocop, Cogo Guebara",0,0,True,"1 woman was injured in the context of the event, not related to AI","Robot meant to patrol a park, record surroundings, and connect users to Knightscope and then to law enforcement",videos,law enforcement,yes,Autonomy1,"A cone-shaped, 400-pound security robot on wheels",No. Not intentionally designed to perform harm,Robot ,law enforcment,unclear,"robotics; surveillance (computer vision, cell network)"
CSETv1_Annotator-3,73,True,73,007,4. Peer review complete,003,False,yes,yes,no,yes,no,no,no,no,yes,"no tangible harm, near-miss, or issue",maybe,maybe,True,none,,no,no,no,no,yes,"race, geography",,yes,maybe,yes,True,no,"players of color faced discrimination while playing Pokémon Go, based on their race.",2016,,,True,no,no,,,US,North America,,,,"Pokémon Go! players, Niantic, Inc, Pokémon Go! players",0,0,False,,augmented reality (AR) game Pokémon Go that blends virtual creatures from the Pokémon franchise with real-world locations,"GPS, video","information and communication, Arts, entertainment and recreation",no,Autonomy3,"It is unclear what data the system inputs but it seems that GPS, camera input, etc.",No. Not intentionally designed to perform harm,,augmented reality (AR) game Pokémon Go,unclear,
CSETv1_Annotator-3,72,True,72,007,4. Peer review complete,003,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,yes,no,no,no,none,,yes,yes,yes,True,yes,,2017,10,,False,no,no,Beitar Ilit,,PS,Asia,,,"Facebook's translator mistranslated ""Good morning"" in Arabic to ""attack them"""," Palestinian Facebook user, Palestinian Facebook user, Facebook, Israeli police, Facebook translation model",0,0,False,,Facebook translator,Facebook posts,information and communication,no,Autonomy3,,No. Not intentionally designed to perform harm,,Translation,unclear,"Automatic translation service offered by Facebook, which uses its own proprietary algorithms, translated the words ‘Good morning’ to “attack them” in Hebrew and “hurt them” in English."
CSETv1_Annotator-3,71,False,71,007,1. Annotation in progress,,False,yes,no,no,yes,no,yes,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,A Google driverless car collided with a bus ,no,no,no,no,no,none,,no,yes,no,True,no,,2018,8,,True,maybe,yes,Silicon Valley,CA,US,North America,,Driverless car,,Google driverless car,,,False,,,,,,,,,,,,
CSETv1_Annotator-3,70,True,70,007,4. Peer review complete,002,False,yes,no,no,no,no,yes,no,no,yes,non-imminent risk of tangible harm (an issue) occurred,yes,yes,True,AI tangible harm issue,"no harm occurred. 
Snow can interfere with the sensors used by autonomous vehicles to ""see"" the road and make decisions, rendering them less effective or even blind. This can pose safety risks and hinder the widespread adoption of self-driving cars, especially in regions with snowy and cold climates.",no,no,no,no,no,none,,no,yes,no,True,no,,2016,,,False,no,yes,,,,Global,,inclement weather and snow,date - report's publication,"Volvo, Drivers and passengers in autonomous cars, Google (Alphabet Inc.), Ford Motor Co",0,0,False,,Self-driving cars,"cameras, radar, lidar",transportation and storage,no,Autonomy2,automakers face in developing self-driving cars that can operate effectively in snowy and winter weather conditions. ,No. Not intentionally designed to perform harm,Self-driving vehicles,autonomous driving,,
CSETv1_Annotator-3,69,True,69,007,4. Peer review complete,002,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,no,yes,True,none,"there was harm (one life lost), but NOT because of AI - the machine was preprogrammed to weld metal sheets that it lifted. the metal sheet was displaced and the worker was in the wrong place at the wrong time",no,no,no,no,no,none,,no,no,no,True,no,,2015,August,12,False,no,no,Manesar,Haryana,IN,Asia,,,Not AI,"Ramji Lal, SKH Metals factory, Pre-programmed robot",1,0,False,"there was harm (one life lost), but NOT because of AI - the machine was preprogrammed to weld metal sheets that it lifted. the metal sheet was displaced and the worker was in the wrong place at the wrong time",,,,,,not AI,,,,,
CSETv1_Annotator-3,68,True,68,007,4. Peer review complete,002,False,yes,no,no,yes,no,no,no,no,yes,"no tangible harm, near-miss, or issue",yes,yes,False,none,Nothing happened as the robot only fell to the pool but it could have fell on a person or child,no,no,no,no,no,none,,no,yes,no,False,no,,2017,7,17,False,no,yes,Washington,DC,US,North America,,,,"Knightscope K5 security robot, Washington harbor complex, Knightscope, Inc",0,0,False,,autonomous security robot,"audio, video, air quality, thermal imaging, lidar, radar",law enforcement,no,Autonomy1,,No. Not intentionally designed to perform harm,autonomous security robot,Patrolling,unclear,10.4 unclear
CSETv1_Annotator-3,67,False,67,007,1. Annotation in progress,,False,yes,no,no,no,no,no,no,no,yes,imminent risk of tangible harm (near miss) did occur,yes,yes,True,AI tangible harm near-miss,"The Tesla, driving 70 mph on Autopilot while the driver passed out, could very well have caused tangible harm if not for the atypical intervention by the motorcycle and highway patrol officers. ",no,no,no,no,no,none,,no,yes,no,True,no,,2018,1,19,False,yes,yes,San Francisco ,CA,US,North America,,"Self-driving vehicles, Tesla",,"unnamed Tesla owner, Tesla, Tesla",0,-1,True,perhaps an imminent risk of financial loss if the car is damaged.,Tesla Autopilot,Unclear,transportation and storage,no,Autonomy2,The driver should have been observing,No. Not intentionally designed to perform harm,Self-driving vehicles - Autopilot,"Autopilot, Driving",,
CSETv1_Annotator-3,66,True,66,007,4. Peer review complete,003,False,no,yes,no,yes,no,no,no,no,yes,"no tangible harm, near-miss, or issue",yes,yes,True,none,No tangible harm- anti-government -  sent messages that violated Chinese censorship policies.,no,no,no,no,no,none,,no,yes,yes,True,no,,2017,08,03,True,no,no,,,CN,Asia,,,,"XiaoBing , BabyQ , Chinese Communist Party,  Tencent (Chinese Internet giant), Turing Robot Company, BabyQ and XiaoBing users",0,0,False,,Chatbots ,text,information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,Chatbot,,
CSETv1_Annotator-3,64,True,64,007,4. Peer review complete,003,False,yes,no,no,yes,no,yes,no,yes,yes,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,no,no,none,,no,yes,yes,True,no,,2018,,,True,no,yes,,,GB,Europe,,,Date of publication of news article," Fabio the robot, Margiotta supermarket, BBC \""six robots and us\, Margiotta's customers, Heriot-Watt University",0,0,False,,Robot,speech,wholesale and retail trade,no,Autonomy1,,No. Not intentionally designed to perform harm,Robot in supermarket,robotics,unclear,
CSETv1_Annotator-3,63,True,63,007,4. Peer review complete,003,False,no,yes,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,NO harm,no,no,no,no,no,none,,no,yes,no,False,no,,2016,3,23,True,no,no,,,Ca,North America,,,,"Google Photos users, Google, Google photo ",0,0,False,,Google photo assistant misedited a photo,photos,"Arts, entertainment and recreation",no,Autonomy1,,No. Not intentionally designed to perform harm,,"image recognition, photo manipulation tools",,image recognition and organization - misrecognized
CSETv1_Annotator-3,23,True,23,007,3. In peer review,003,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,"The accident was first and foremost caused by the truck driver who backed out of an alley without checking the environment. However, according to the passengers, the self-driving shuttle could have prevented the collision by backing out of the way or honking to get the driver’s attention. Both are safe driving behaviors that a human driver would likely have taken. While the AI is not at fault per se the accident could have been avoided if it had behaved differently.",no,no,no,no,no,none,,no,yes,no,True,no,,2017,1,10,False,no,yes,Las Vegas,NV,US,North America,,,,"self-driving shuttle in Las Vegas, Keolis, AAA, Navya, Truck, Driver",0,0,False,,,,transportation and storage,no,Autonomy1,,No. Not intentionally designed to perform harm,Self-driving shuttle,,,
CSETv1_Annotator-3,101,True,101,007,4. Peer review complete,003,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,financial harm and intangible harm,yes,yes,yes,no,yes,"nation of origin, citizenship, immigrant status",,yes,yes,yes,True,yes,,2013,,,False,no,no,,,NL,Europe,,,,"Dutch Tax Authority, Childcare benefits recipients, Immigrant childcare benefits recipients , Fraud prediction algorithm, Dutch Data Protection Authority, Trouw",0,0,False,financial harm,Self-learning algorithm deployed by the tax administration to create risk profiles of welfare recipients in an effort to spot childcare benefits fraud.,,public administration,yes,Autonomy3,,No. Not intentionally designed to perform harm,,fraud risk prediction,,
CSETv1_Annotator-3,103,True,103,007,2. Initial annotation complete,,False,no,,yes,yes,no,no,no,yes,yes,"no tangible harm, near-miss, or issue",yes,yes,False,none,Intangible harm,yes,no,no,no,yes,"race, sex",,yes,yes,yes,True,yes,,2021,5,,True,no,no,,,,Global,,,,"Twitter Users, Twitter, Twitter image cropping algorithm",0,0,False,,Twitter image cropping algorithm,images,information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,image cropping,,
CSETv1_Annotator-3,104,False,104,007,1. Annotation in progress,,False,no,no,no,yes,no,no,no,no,yes,unclear,yes,yes,True,AI tangible harm issue,It is unclear from the article if tangible harm actually occurred ,yes,maybe,no,no,no,geography,,yes,yes,yes,True,yes,,2021,,,True,no,no,,CA,US,North America,healthcare and public health,,,"California's Department of Public Health , California low-income neighborhoods, California's Department of Public Health algorithm to distribute COVID-19 vaccines based on ZIP codes",,0,True,It is unclear how many people might have been sick because of not receiving the covid vaccine due to the algorithm,California's Department of Public Health algorithm distributing COVID-19 vaccines based on ZIP codes,Zip codes,"public administration, administrative and support service activities",yes,Autonomy2,,No. Not intentionally designed to perform harm,,,,
CSETv1_Annotator-3,106,False,106,007,1. Annotation in progress,,False,no,no,no,yes,no,no,no,no,yes,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,yes,yes,sexual orientation or gender identity,,yes,yes,yes,True,yes,,2021,,,True,no,no,,,KR,Asia,,,,"Scatter Lab, Kim Jong-yoon , Scatter Lab users, AI chatbot, Lee Luda",0,0,False,,Chat-bot,text,information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,,,
CSETv1_Annotator-3,108,True,108,007,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,"no tangible harm, near-miss, or issue",yes,no,False,none,,no,yes,no,no,yes,race,,yes,yes,yes,True,yes,,2021,,,True,no,no,Livonia,MI,US,North America,,,,"Riverside Arena Skating Rink, Lamya Robinson, Facial recognition used in Riverside Arena",0,0,False,,facial recognition software,face image,"Arts, entertainment and recreation",no,unclear,,,,facial recognition,,
CSETv1_Annotator-3,109,True,109,007,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,unclear,yes,yes,False,unclear,"It's possible that harm could occur as a result of using PimEyes, depending on how it's used. The site's powerful facial recognition capabilities could potentially be used for malicious purposes, such as stalking or identifying individuals without their consent. Additionally, if the site's database is breached or hacked, users' personal information and images could be compromised. It's important to consider the potential risks before using any technology that involves personal data and privacy.

",no,maybe,no,no,maybe,unclear,,maybe,yes,yes,False,maybe,,2023,,,True,no,no,,,PL,Europe,unclear,,,"PimEyes, PimEyes software, PimEyes users",0,0,True,,Facial recognition software,Unclear,information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,facial-recognition,,
CSETv1_Annotator-3,12,True,12,007,4. Peer review complete,003,False,no,no,yes,no,no,no,yes,no,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,no,yes,sex,gender bias,yes,yes,yes,True,maybe,,2016,7,21,True,no,no,,,US,North America,,,"Publication date.
Research about the issue of gender bias is present in machine learning frameworks, specifically word embeddings, which represent text data as vectors. The study shows that word embeddings trained on Google News articles exhibit male/female gender stereotypes to a significant degree, and their widespread use can amplify these biases. The researchers develop a methodology to modify an embedding to remove gender stereotypes while maintaining desired associations. They define metrics to quantify direct and indirect gender biases and demonstrate that their algorithms significantly reduce gender bias in embeddings while preserving useful properties.","Womem, Word embeddings, Tolga Bolukbasi, Kai-Wei Chang, James Zou, Venkatesh Saligrama, Adam Kalai",0,0,False,,word embeddings trained on Google News articles,words,information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,natural language processing,unclear,machine learning models - word embeddings trained on Google News articles 
CSETv1_Annotator-3,13,True,13,007,4. Peer review complete,003,False,no,no,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,no,yes,"race, religion, sex, nation of origin, citizenship, immigrant status","Google's sister company, Jigsaw, has created a tool called ""Perspective"" that uses machine learning to identify online hate speech. The software has been opened up to external developers but has been criticized by researchers from Washington University for categorizing innocuous phrases as toxic while ignoring more overtly hateful comments. ",yes,yes,yes,True,yes,,2017,,,True,no,no,,,US,North America,,,,"Google, Google - Perspective, University of Washington - electrical engineers and security experts ",0,0,False,,"Google's Perspective project, a machine learning-based system to identify toxic comments in online discussion forums",text,information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,hate speech detector,unclear,The system uses a combination of natural language processing techniques and machine learning algorithms to analyze text and identify language that is hateful or harmful.
CSETv1_Annotator-3,15,True,15,007,4. Peer review complete,003,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,maybe,maybe,True,AI tangible harm event,It is not 100% clear from the articles whether or not Amazon's algorithm is based on AI or ML,no,no,no,no,yes,sexual orientation or gender identity,"While trying to make Amazon's best seller list ""family-friendly, "" the new rules affect not only adult books but also gay and lesbian titles.",no,maybe,yes,True,yes,,2009,04,,False,no,no,,,,Global,,,,"Amazon, LGBT authors, LGBT authors, Amazon Customers, Amazon ranking system",0,0,False,,Not 100% AI - algorithm sales ranking removal,text,wholesale and retail trade,no,unclear,,No. Not intentionally designed to perform harm,,"content removal, ranking",,
CSETv1_Annotator-3,7,True,7,007,4. Peer review complete,002,False,no,no,yes,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",maybe,yes,False,none,"It is unclear if any of the Wikipedia bots studied rely on machine learning technology, but it is unlikely. ",no,no,no,no,no,none,,no,maybe,yes,False,no,,2001,,,False,yes,no,,,,Global,,,"Although AI involvement is unlikely, the study analyzed bot-on-bot conflict, i.e. the interaction of multiple autonomous systems. ","Wikipedia, Wikipedia Editors, Wikipedia Users, Wikipedia bots",0,0,False,,software robots or bots deployed on Wikipedia,text,information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,Editing bot,Editing,
CSETv1_Annotator-3,8,True,8,007,4. Peer review complete,002,False,yes,no,no,no,no,yes,no,no,yes,imminent risk of tangible harm (near miss) did occur,yes,maybe,True,unclear,no clear link to AI,no,no,no,no,no,none,,no,yes,maybe,True,no,,2016,12,14,False,no,yes,San Francisco,CA,US,North America,,,,"Volvo SUV, Uber, Uber driver, pedestrian",0,0,False,,Uber's autonomous vehicles,"camera, radar, GPS",transportation and storage,no,Autonomy2,,No. Not intentionally designed to perform harm,autonomous vehicle,driving,,
CSETv1_Annotator-3,59,True,59,007,2. Initial annotation complete,,False,no,no,yes,yes,no,no,yes,yes,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,yes,yes,no,no,yes,"race, sex, sexual orientation or gender identity, age","The study found biases related to race, gender, age, and sentiment in the AI systems",yes,yes,yes,True,yes,"The study found biases related to race, gender, age, and sentiment in the AI systems' understanding of words.",2017,5,25,True,no,maybe,,,,Global,,,,"WEAT - word-embedding association test, Aylin Caliskan , Joanna J. Bryson and Arvind Narayanan",0,0,False,,AI algorithms based on words,words,information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,AI algorithms based on word embeddings derived from human language,,"The study found biases related to race, gender, age, and sentiment in the AI systems' understanding of words."
CSETv1_Annotator-3,60,False,60,007,1. Annotation in progress,,False,no,no,no,yes,no,no,no,no,yes,"no tangible harm, near-miss, or issue",yes,yes,False,none,,yes,no,no,no,yes,other,,yes,yes,yes,False,yes,,2017,,,False,no,yes,,,RU,Global,,,,"FaceApp, FaceApp users of color, Yaroslav Goncharov (FaceApp CEO)",0,0,False,,app using artificial intelligence to edit selfies and apply various filters,photos,information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,photo edit,,
CSETv1_Annotator-3,74,True,74,007,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,"Although the case was dismissed, police had already handcuffed and arrested Williams in front of his family, forced him to provide a mug shot, fingerprints and a sample of his DNA, interrogated him and imprisoned him overnight.",yes,yes,no,no,yes,race,,yes,yes,yes,True,yes,,2020,1,,False,no,yes,Detroit,MI,US,North America,,,,"Robert Julian-Borchak Williams , Robert Julian-Borchak Williams , Robert Julian-Borchak Williams , Detroit Police Department, Clearview AI",0,0,False,,"facial recognition company, providing software to companies, law enforcement, universities, and individuals. ",face image,law enforcement,yes,Autonomy2,,No. Not intentionally designed to perform harm,,facial recognition,image match,"matches faces to a database of more than 20 billion images indexed from the Internet, including social media applications"
CSETv1_Annotator-3,40,True,40,007,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,yes,yes,unclear,yes,,False,unclear,It is unclear from who are the specific entities that where false accused,no,yes,no,no,yes,race,,yes,yes,,True,yes,,2016,,,False,no,yes,,,US,North America,,,,"COMPAS, Equivant, ProPublica, Wisconsin Supreme Court, Black people",0,0,False,,"automated decision-making (ADM) systems that predict the likelihood of criminals reoffending, used in the US criminal justice system",Unclear,law enforcement,no,Autonomy3,,No. Not intentionally designed to perform harm,,predict a defendant’s risk of committing another crime,unclear,
CSETv1_Annotator-3,45,True,45,007,4. Peer review complete,002,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,Google lawsuit - financial harm,no,no,no,yes,yes,religion,,yes,yes,yes,True,yes,,2011,03,24,False,no,no,,,,Global,,,,"Google, AB - plaintiff in Google's lawsuit, Judge Roberto Bichi, AB - plaintiff in Google's lawsuit",0,0,False,,"Google search is equipped with an autocomplete feature that adds suggested terms to user queries, and added misleading and harmful terms to the entities involved in this incident. ",text,information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,"autocomplete, content ranking",,
CSETv1_Annotator-3,47,True,47,007,4. Peer review complete,002,False,no,no,no,yes,no,no,no,yes,maybe,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,no,yes,sex,,yes,yes,yes,True,yes,"LinkedIn's search feature suggests changing female names to male names, indicating potential bias in the platform's algorithm. When users search for common female names, LinkedIn prompts them to consider similar-sounding male names instead",2016,08,31,False,no,yes,,,,Global,,,,"Women, LinkedIn, Seattle Times",0,0,False,,Recommender system suggesting alternative search terms (names) to users on LinkedIn ,"words, text",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,"Search suggestions, prediction, recommendation",,
CSETv1_Annotator-3,32,True,32,007,4. Peer review complete,002,False,no,no,no,yes,no,no,no,yes,maybe,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,no,no,none,,no,yes,yes,True,no,,2017,09,13,True,no,yes,,,,Global,,,,"FaceID, Apple, iPhone X users",0,0,False,,Facial recognition,face image,information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,facial-recognition,,
CSETv1_Annotator-3,75,True,75,007,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,no,yes,religion,,yes,yes,yes,True,yes,,2017,12,7,True,no,no,,,France,Europe,,,Reported article date,"Google, Google search autocomplete feature, French anti-discrimination organization SOS Racisme",0,0,False,,Autocomplete search feature,words,information and communication,no,Autonomy1,"French lawsuit found that Google search results auto-filled ""Jewish"" after the names of certain Jewish public figures, a phenomenon not observed with public figures of other religions.",No. Not intentionally designed to perform harm,,human language technologies,unclear,
CSETv1_Annotator-3,76,True,76,007,2. Initial annotation complete,,False,no,no,yes,yes,no,no,no,yes,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,"The live facial recognition system in Buenos Aires has led to multiple false arrests, causing individuals to be wrongly detained for days, and the police lack a clear protocol to address these errors.
",no,no,no,no,no,none,,no,yes,yes,False,no,,2020,10,9,True,no,no,,,AR,South America,,,Date of publication,"CONARC - Consulta Nacional de Rebeldías y Capturas , Human Right Watch, Buenos Aires children, Buenos Aires city government, CONARC live facial recognition system false positive users, Buenos Aires facial recognition system",0,0,False,,facial recognition systems using CONARC database,"photo IDs, text",law enforcement,yes,Autonomy2,,No. Not intentionally designed to perform harm,,facial recognition,image match,"The software uses suspects’ headshots to scan for real-time matches via the city’s subway cameras. Once the system flags a person, it alerts to the police to make an arrest."
CSETv1_Annotator-3,27,True,27,007,4. Peer review complete,002,False,yes,no,no,yes,no,no,no,no,yes,imminent risk of tangible harm (near miss) did occur,no,yes,True,none,,no,no,no,no,no,none,,no,no,yes,True,no,,1983,09,26,False,no,yes,Moscow,,RU,Europe,defense-industrial base,,,"Stanislav Petrov, Soviet Union, Oko",0,0,False,,Nuclear missile defence early warning programme,,defense,yes,Autonomy3,Not an AI system,Yes. Intentionally designed to perform harm but created an unintended harm (a different harm may have occurred),,,,not AI
CSETv1_Annotator-3,112,True,112,002,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,"Several tangible harms have been reported in connection with the technology. 
1. Michael Williams spent a year in jail on murder charges based on evidence from ShotSpotter, before having his charges dismissed when prosecutors admitted they had insufficient evidence against him.
2. 13-year-old Adam Toledo was shot and killed by Chicago police after they were dispatched to his neighborhood in the early-morning hours of March 29 following a ShotSpotter alert. The boy was unarmed. 
3. The high false positive rate of the alerts leads to a significantly higher number of police deployments and because officers expect to enter a dangerous situation with active shooters during these deployments, there is a reasonable probability that residents in affected neighborhoods experience harm to their health and safety. These residents are potentially identifiable, because they have formed community activist groups fighting the use of these systems in their cities. ",no,maybe,no,no,yes,"financial means, race","Microphones are disproportionately installed in minority and low-income neighborhoods, leading to an increase in police engagement in those areas. ",yes,yes,maybe,True,maybe,"Because the choice of location of the microphones is not driven by the AI system itself, it is unclear if the fact that it dispatches police to these neighborhoods can be directly linked to the AI. ",2008,,,False,no,yes,,,US,North America,,,"The ShotSpotter technology has been deployed in more than 130 cities across the US, as of March 2022. The earliest use mentioned in the reports goes back to 2008 by the San Francisco PD. ","Various US Police Departments, ShotSpotter Inc., ShotSpotter, City of Chicago Inspector General, Surveillance Technology Oversight Project, MacArthur Justice Center, Brighton Park Neighborhood Council, Lucy Parsons Lab, Organized Communities Against Deportation, Low-income and minority neighborhoods, Residents in affected neighborhoods, ShotSpotter analysts, Michael Williams, Action Center on Race and the Economy, Adam Toledo",1,0,False,,ShotSpotter is an acoustic surveillance system used to detect gunfire. ,audio,law enforcement,yes,Autonomy3,,No. Not intentionally designed to perform harm,Microphones,"detect gunshots, locate gunshots, identify weapon calibre, predict shooter movement",,
CSETv1_Annotator-3,113,True,113,002,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,yes,yes,race,,yes,yes,yes,True,yes,,2021,08,,True,no,no,,,,Global,,,,"Facebook, The Daily Mail, Black people, Facebook users, Content classifier",0,0,False,,"AI tool that is part of Facebook's content recommender system. It classifies and labels the content of Facebook posts, in this case a video. ","video, images",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,video classification,,
CSETv1_Annotator-3,114,True,114,002,2. Initial annotation complete,,False,no,no,no,yes,no,no,yes,no,maybe,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,no,yes,race,,no,yes,yes,True,no,"The ACLU's test demonstrated Rekognition's disproportionate inaccuracy on faces of people of color. Because the bias was the result of a test, and didn't actually result in any unfavorable treatment, there was no harm for those inaccurately identified.",2018,07,,True,no,no,,,US,North America,,,ACLU's report was published in July 2018. ,"Amazon, Rekognition, ACLU, Members of 115th US Congress",0,0,False,,Facial recognition tool,images,"law enforcement, other",yes,Autonomy1,According to the report Rekognition is used by the Sheriff's department in Oregon. ,No. Not intentionally designed to perform harm,,facial recognition,,
CSETv1_Annotator-3,115,True,115,002,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,no,yes,"sex, sexual orientation or gender identity","The gender classification tool exhibited gender bias, for example by assigning female names who otherwise received a high female score a high male score when their names were entered with a Dr. title. It also did not allow for non-binary classification. ",no,yes,yes,True,no,"While the tool exhibited problematic biases, it was described as a marketing tool that was not deployed in any kind of context where it could cause harm. It was also shut down immediately in response to the public backlash. ",2020,07,,False,no,no,,,US,North America,,,,"Genderify, Genderify tool, Women and non-binary people",0,0,False,,"Gender classification tool based on names, usernames or email addresses.","names, usernames, email addresses",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,gender classification,,
CSETv1_Annotator-3,116,True,116,002,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,"The implementation of the AI-powered camera system has led to financial loss for drivers, who get penalized for alleged unsafe driving behavior. However, the cameras regularly punish drivers for so-called ""events"" that are beyond their control or don't constitute unsafe driving, such as looking at a side mirror or fiddling with the radio, stopping ahead of a stop sign at a blind intersection, or getting cut off by another car in dense traffic.",no,no,no,no,no,none,,no,yes,yes,True,no,,2021,,,False,no,yes,,,US,North America,,,,"Amazon, Netradyne, Safety cameras, Delivery drivers, Delivery Service Partners",0,0,False,,AI-powered camera system that detects 'unsafe driving behavior'. Recorded events are incorporated in a weekly performance score that determines drivers' take home pay. ,"biometrics, video",transportation and storage,no,Autonomy1,,No. Not intentionally designed to perform harm,camera,"event detection, eye tracking",computer vision,
CSETv1_Annotator-3,122,True,122,002,2. Initial annotation complete,,False,no,maybe,no,yes,no,no,no,no,maybe,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,Facebook paid a fine for implementing a facial recognition tool which stored users' biometric data without their consent. ,no,no,no,no,no,none,"Although the storage of biometric data without consent is a privacy rights violation under the Illinois Biometric Information Privacy Act, it is not a violation of human rights, civil rights, civil liberties, or democratic norms.",no,yes,yes,True,no,A privacy violation is an Other intangible harm. ,2015,,,True,no,no,,IL,US,North America,,,,"Facebook, Tag suggestion tool, Facebook users",0,0,False,,The Tag Suggestion tool uses facial recognition to identify individuals on users' photos and offers suggestions for tagging their Facebook profiles to the image.  ,"biometric data, facial images",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,facial recognition,unclear,
CSETv1_Annotator-3,123,True,123,002,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,non-imminent risk of tangible harm (an issue) occurred,yes,yes,True,AI tangible harm issue,"Epic's sepsis prediction algorithm missed two-thirds of sepsis cases, rarely found cases medical staff did not notice and frequently issued false alarms. The study did not elaborate on the consequences for patient's health outcomes, but there is a potential that due to the system's failure to alert to a sepsis case, patients received less or delayed care. ",no,no,no,no,no,none,,no,yes,yes,True,no,,2017, ,,True,no,no,,,US,North America,,,First implementation of the model in 2017. ,"Epic Systems, Epic Sepsis Model, US hospitals, Researchers from the University of Michigan Medical School, University of Michigan hospital patients",0,0,True,"The model failed to alert to a sepsis for 1,709 (67%) out of the 2,552 patients that developed a sepsis (out of the 38,455 patients under study). It is unclear if these patients had poorer health outcomes as a result. ",The Epic Sepsis Model calculates and indicates the probability of a likelihood of sepsis to help clinicians identify hard-to-spot cases.,medical records,human health and social work activities,yes,Autonomy3,,No. Not intentionally designed to perform harm,,sepsis prediction,,
CSETv1_Annotator-3,124,True,124,002,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,"The algorithm was less likely to refer black people than white people who were equally sick to programmes that aim to improve care for patients with complex medical needs.  Its bias effectively reduced the proportion of black patients receiving extra help by more than half, from almost 50 percent to less than 20 percent. Those missing out on extra care potentially faced a greater chance of emergency room visits and hospital stays.",yes,yes,no,no,yes,race,,yes,yes,yes,True,yes,,2013, ,,False,no,no,,,US,North America,,,,"Unknown US hospital, Black patients, Black patients, Black patients, Obermeyer et al. , Optum, Healthcare allocation algorithm",0,0,True,Health risk score algorithms affected the care received by millions of patients throughout the US. ,"The algorithm is used in the context of health care programmes that provide additional resources and closer medical supervision for people with multiple health problems. It assigned risk scores to patients on the basis of total health-care costs accrued in one year, because higher health-care costs are generally associated with greater health needs. Based on their risk scores, patients are referred to the programmes that provide more-personalized care.",projected health care costs,human health and social work activities,no,Autonomy3,"The algorithm operates in a mix of full autonomy (level 1) and human-in-the-loop (level 3): Patients with risk scores above the 97th percentile are automatically identified for enrollment in the program. Those above the 55th percentile are referred to their primary care physician, who is provided with contextual data about the patients and asked to consider whether they would benefit from program enrollment.",No. Not intentionally designed to perform harm,,predict healthcare needs,,
CSETv1_Annotator-3,125,True,125,002,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,maybe,no,no,no,none,"Potential violation of Economic, social and cultural rights in the International Bill of Human Rights mandates the right to 'safe and healthy working conditions' as well as the right to 'rest, leisure and the reasonable limitation of working hours'. ",maybe,yes,yes,True,maybe,,2014,,,False,yes,yes,,,US,North America,,,"Although it is unclear if the warehouse robots and the worker monitoring system interact at a system level, their simultaneous use in Amazon's fulfillment center means that workers interact with and navigate an environment shaped by both.","Amazon, Warehouse robots, Barcode scanner, Warehouse workers, OSHA, Amazon fulfillment centers",0,55000,True,"Extrapolated: 14,000 serious injuries reported in 2019, equivalent to an injury rate of 7.7/100 employees. Similar injury rate reported for 2018, following a ~10% annual increase in 2016 and 2017. No earlier data available. The number of non-serious injuries is likely substantially higher, but no hard data is available in the reports. There is also evidence of underreporting of injuries. 8.2 should be considered a most conservative estimate. ","Two AI systems of note.
1) Worker monitoring system integrated in workers' handheld RFID scanners. Tracks time in between activity (scans) which is used to assess worker performance, assigns performance targets and automatically penalizes workers if targets are not met.  The device also assigns workers products to collect from the warehouse based on their real-time location. 
2) Warehouse robots that move shelves towards workers in the warehouse. ","GPS, video, Time off Task (TOT), RFID",transportation and storage,no,unclear,,No. Not intentionally designed to perform harm,"Handheld barcode scanner; flat, round mobile robots;","move shelves, worker monitoring, performance tracking",,
CSETv1_Annotator-3,126,True,126,002,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,no,yes,True,none,,no,no,no,no,no,none,,no,no,yes,True,no,,2021,07,16,False,yes,yes,London,,GB,Europe,food and agriculture,,"The technology is not AI-powered, but it is still embedded in physical systems. More than 2300 individual robots interact in the fulfillment center. ","Ocado, Ocado fulfillment center in Erith , Ocado customers",0,0,False,,Not an AI system. Fulfillment center robots controlled by a wireless protocol that collect customer items (groceries). ,sensor,"transportation and storage, wholesale and retail trade",no,Autonomy1,,No. Not intentionally designed to perform harm,,,,Not AI.
CSETv1_Annotator-3,132,True,132,002,2. Initial annotation complete,,False,no,maybe,no,yes,no,no,no,no,maybe,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,maybe,yes,no,none,,yes,yes,yes,True,yes,,2020,07,,True,no,no,,,,Global,,,TikTok banned content labelled with hashtags promoting eating disorder habits on its platform in the summer of 2020. But in December the Guardian published an investigative report demonstrating that this type of content was still easily searchable on TikTok.  ,"TikTok, ByteDance, Content moderation algorithm, TikTok users",0,0,False,,"Content moderation system that should identify and remove pro eating disorder content from the app, and identify related search terms to direct users to help pages.","video, text, audio",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,content moderation,,
CSETv1_Annotator-3,133,True,133,002,2. Initial annotation complete,,False,no,maybe,no,yes,no,no,no,no,yes,tangible harm definitively occurred,no,yes,True,none,"3.1 Through the deletion of her account, Rose lost access to the money accrued in her TikTok Creator Fund. 
3.2 Content on TikTok is automatically removed when enough users have flagged it as violating community guidelines. This appears to be a rules-based automation rather than AI-powered. ",no,no,no,yes,yes,"disability, sexual orientation or gender identity, race",,yes,no,no,True,no,"Rose experienced discrimination and hate speech in the comments responding to her content. The reporting of her videos as violating TikToks content standards are also driven by disciminatory users. However, this behavior can not be linked to the content moderation system itself. ",2020,12,14,False,no,no,,,,Global,,,,"Rosalynne Montoya, Rosalynne Montoya, TikTok, ByteDance, Internet trolls, Minority content creators",0,0,False,,"Unclear if an AI system is involved. Automated content review, removal and appeal system in response to user reports of detrimental content. ",user reports,information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,"content moderation, enforcement of community guidelines",unclear,
CSETv1_Annotator-3,134,True,134,002,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,maybe,yes,True,unclear,Unclear what type of software powered the robot. ,no,no,no,no,no,,,no,maybe,yes,True,no,,2020,12,25,False,no,yes,Fuzhou, ,CN,Asia,,,,"Fuzhou Zhongfang Marlboro Mall, Shopping guide robot, Unidentified shoppers",0,2,False,,Guide robot deployed in a shopping mall,Unclear,wholesale and retail trade,no,Autonomy1,,No. Not intentionally designed to perform harm,4ft tall vaguely humanoid droid on wheels,unclear,unclear,
CSETv1_Annotator-3,135,True,135,002,3. In peer review,,False,no,no,no,yes,no,no,no,no,yes,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,maybe,no,no,maybe,unclear,"The articles make no indication of actual events where the system has led to biased candidate assessments. However, the descriptions of the way the system is trained and the kind of information it evaluates from candidates' applications suggests that there is at least a reasonable probability that it perpetuates the bias of previous admission decisions. This is particularly so because the developers did not take any precautions to prevent bias. ",maybe,yes,yes,True,maybe,,2013,,,False,no,no,Austin,TX,US,North America,,,,"Graduate admissions evaluator (GRADE), University of Texas at Austin researchers, University of Texas at Austin Department of Computer Science, Applicants to the UT Computer Science PhD program, Applicants to the UT Computer Science PhD program",0,0,False,,Applicant screening tool for PhD applicants to the computer sciences department using logistic regression classification. ,"GPA, university name, text, letter of recommendation, statement of interest",Education,yes,Autonomy3,Every application was assessed by one human reviewer in addition to the software tool at every stage of the selection process.,No. Not intentionally designed to perform harm,,,logistic regression,
CSETv1_Annotator-3,136,True,136,002,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,no,yes,True,none,,no,no,no,no,no,none,,no,no,yes,True,no,,2020, ,,True,no,no,,,,Global,,,,"Brand Safety Technology, Legitimate online media, Advertisers",0,0,False,,"Content classification system that determines whether the content of a website is 'safe' for brands to place their advertisements. Not AI, based on keyword lists. ","text, keywords",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,,,Not AI. 
CSETv1_Annotator-3,142,True,142,002,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,non-imminent risk of tangible harm (an issue) occurred,yes,yes,True,AI tangible harm issue,"Ads placed on Instagram and Facebook are screened for policy violations before being placed visibly on the platform. Ads for adaptive clothing and accessories are repeatedly erroneously identified as medical products and rejected. While companies can have the decision reviewed, this often takes many days, which means there is a reasonable probability that they are losing traffic to their site and profit as a result. ",no,no,no,no,maybe,disability,"Even though the incident affects only ads targeting people with disabilities, no group of people directly experienced harm based on their disability. ",no,yes,yes,False,no,,2021,,,False,no,no,,,,Global,,,,"Facebook, Meta, Ad-screening algorithm, Adaptive clothing companies, Instagram",0,0,False,,Ad screening algorithm,images,"information and communication, wholesale and retail trade",no,Autonomy1,,No. Not intentionally designed to perform harm,,detect policy violations,,
CSETv1_Annotator-3,143,True,143,002,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,yes,maybe,"geography, other","Twitter and Facebook users that speak Bosnian, Serbian, Montenegrin or Macedonian encounter more detrimental content (especially hate speech and violent content) because content moderation tools do not work effectively in their language. While users speaking these languages are not explicitly treated differently, harm is unevenly distributed based on geography and language. ",yes,yes,yes,True,yes,,2021,,,False,no,no,,,,Europe,,,,"Facebook, Twitter, Inc., Meta, Twitter, Content moderation algorithm, Balkan Investigative Reporting Network (BIRN), Twitter users of small language groups, Facebook users of small language groups",0,0,False,,Content moderation systems used on Twitter (now X) and Facebook to detect content that violates the platform's Community Standards,"text, images",information and communication,no,Autonomy1,"While complicates cases might be subject to human review, but according to a statement Facebook now relies primarily on AI. ",No. Not intentionally designed to perform harm,,identify detrimental content,,
CSETv1_Annotator-3,144,True,144,002,2. Initial annotation complete,,False,no,yes,no,no,no,no,no,no,yes,unclear,yes,yes,True,unclear,"It is likely that Antonio Radic may have lost some revenue from having his YouTube channel suspended for 24 hours, given its popularity. However, this is not explicitly mentioned in the reports. ",no,no,no,no,no,none,,no,yes,yes,True,no,,2020,06,28,False,no,no,,,,Global,,,,"YouTube, Google, Antonio Radic, CMU researchers, YouTube content moderation algorithm",0,0,False,,YouTube's content moderation algorithm,"audio, video",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,identify hate speech,,
CSETv1_Annotator-3,145,True,145,002,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,yes,maybe,non-imminent risk of tangible harm (an issue) occurred,yes,yes,True,AI tangible harm issue,,no,no,no,no,no,none,,no,yes,yes,True,no,,2021,07,22,False,no,yes,,,US,North America,,,,"Tesla, unnamed Tesla driver, Tesla autopilot",0,0,False,,Autonomous driving autopilot ,,transportation and storage,no,Autonomy2,,No. Not intentionally designed to perform harm,Tesla car,,,
CSETv1_Annotator-3,146,True,146,002,2. Initial annotation complete,,False,no,no,no,maybe,no,no,no,maybe,maybe,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,yes,no,"nation of origin, citizenship, immigrant status, race, religion, sex, sexual orientation or gender identity, geography","No group of people experienced differential treatment. However the content produced by the model was often offensive towards certain groups, in particular religious, racial and ethnic minorities in the US, women and members of the LGBTQ+ community  and people from developing countries. ",yes,yes,yes,True,yes,"The system produced biased content, reproduced stereotypes and declared genocide as morally acceptable.",2021,10,14,False,no,no,,,,Global,,,,"Allen Institute for AI, Ask Delphi, Delphi users",0,0,False,,Delphi is a language-based research prototype designed to model people’s moral judgments.,,"professional, scientific and technical activities",no,Autonomy1,,unclear,,reply to questions,neural network,The researchers developed a model to make moral judgments - which by definition will be offensive to some - and released it knowing of its inconsistencies and biases. 
CSETv1_Annotator-3,152,True,152,002,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,Customers that purchased Pepper received a subpar product that did not meet their expectations or contractual terms. They therefore incurred financial loss. ,no,no,no,no,no,none,,no,yes,yes,True,no,,2014,,,False,no,yes,,,JP,Asia,,,,"Pepper, SoftBank, Aldebaran, Nissei Eco Co., Ittokai, Other SoftBank customers",0,0,False,,Pepper is a humanoid robot with a perky demeanor designed to grasp human emotions and engage in basic conversation. ,,"financial and insurance activities, Arts, entertainment and recreation, human health and social work activities, administrative and support service activities",no,Autonomy1,,No. Not intentionally designed to perform harm,Humanoid robot,,"computer vision, natural language processing",
CSETv1_Annotator-3,153,True,153,002,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,no,no,no,no,none,,no,yes,yes,True,no,,2019,12,29,False,no,yes,Los Angeles,CA,US,North America,transportation,,,"Kevin George Aziz Riad, Gilberto Alcazar Lopez, Maria Guadalupe Nieves, 2016 Tesla Model S, Kevin George Aziz Riad, Tesla, Victim's Honda Civic, Unnamed female Tesla passenger",2,2,False,,"Tesla's Autopilot is a driver-assist technology that can control steering, braking and speed.","video, sensor",transportation and storage,no,Autonomy2,,No. Not intentionally designed to perform harm,2016 Tesla Model S,"object detection, object recognition, autonomous driving",,
CSETv1_Annotator-3,154,False,154,002,1. Annotation in progress,,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,"The algorithm's prediction of recidivism risk directly influences inmates' ability to participate in programs under the First Step Act. Participation in these programs can facilitate early release for inmates. Inaccurate predictions can therefore extend an inmate's prison time, which is a harm to physical freedom and autonomy and falls under the 'other intangible harm' category. ",no,yes,no,no,yes,race,,yes,yes,yes,True,yes,,2021,,,True,no,no,,,US,North America,,,,"Pattern, US Department of Justice, Inmates of color, Inmates of color, Inmates of color",0,0,False,"14,000 inmates were allocated to a wrong risk category. ",Recidivism risk prediction algorithm used to determine if inmates qualify for participation in resocialization programs under the First Step Act. ,,law enforcement,yes,unclear,,No. Not intentionally designed to perform harm,,predict recidivism risk,,
CSETv1_Annotator-3,155,True,155,002,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,imminent risk of tangible harm (near miss) did occur,yes,yes,True,AI tangible harm near-miss,"GPS navigation services GoogleMaps and Waze directed people to closed-off highways, mountain passes and lakeside roads to get around road closures during a severe snowstorm. ",no,no,no,no,no,none,,no,yes,yes,True,no,,2021,12,,False,no,no,,CA; NV,US,North America,transportation,"inclement weather and snow, seasonal road closures",,"Google Maps, Waze, Google, Wendy Becktold, Other Maps and Waze users travelling in the Sierra Nevada, Caltrans, Washoe County Sheriff’s Office",0,0,False,,GPS navigation system,,"information and communication, transportation and storage",no,Autonomy3,,No. Not intentionally designed to perform harm,,,,
CSETv1_Annotator-3,156,True,156,002,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,no,True,none,"Several people committed suicide using the product sold on Amazon, meaning tangible harm definitely happened. This led to Amazon's recommender system suggesting other products related to self-harm as 'Frequently bought together'. While this may have made it easier or quicker for vulnerable customers to find the products they were looking for, it does not seem likely that they would not have attempted self-harm had it not been for the recommendation. Therefore, the AI system cannot be directly linked to the tangible harm. ",no,no,maybe,yes,no,none,"Because the chemical compound is commercially available, it has become an increasingly popular method for suicide among minors. 
The promotion of products related to self-harm may be considered harmful content. ",yes,yes,yes,True,yes,,2019,,,True,no,no,,,,Global,,,The NYT investigation discovered 10 suicides linked to the chemical compound bought on Amazon since 2019. ,"Amazon, Product recommender system, Vulnerable Amazon customers considering self-harm, Suicide victims, US House of Representatives",0,0,True,"Left blank intentionally, because numbers are certainly >0, but there is no systematic tracking. The Times identified 10 suicides using the compound bought from Amazon in the US since 2019. It also identified dozens of uses in the US, UK, Italy, Australia and Canada since 2018. However, these deaths cannot be linked to Amazon's recommender system and are therefore not considered AI tangible harms. ",Product recommender system on large online retail platform. ,purchase history,wholesale and retail trade,no,Autonomy1,,No. Not intentionally designed to perform harm,,recommendation,,
CSETv1_Annotator-3,162,True,162,002,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,"3.1 Test takers were wrongfully detained and deported after their tests were flagged as invalid by the voice recognition system. 
3.3 The harm would not have occurred without the use of voice recognition to detect cheating, and is therefore directly linked to the AI system. However, it is also the result of massive wrongdoing on the side of both ETS and the UK Home Office which are equally, if not more, responsible for the harm. ETS was aware that both cheating-by-proxy and remote testing were a problem, but still used voice recognition software to identify cheaters. Conceptually this works to detect proxy test-takers, but not remote testing. Moreover, because remote testing fraud is likely done by overwriting *all* test-takers files with the same fake one, voice recognition is unable to distinguish valid tests from fake ones. Being aware of this, ETS should never have deployed voice recognition in the first place, or passed the results on to the government. Poor data management and record keeping by ETS furthermore prevented both prosecution and appeal of the outcome of the voice recognition system's output. Finally, being equally aware of this the UK Home Office should have never used the AI system's output as a base for its policy. ",no,yes,no,no,no,"nation of origin, citizenship, immigrant status","While there was no discrimination based on citizenship, the incident only affected immigrants to the UK. ",yes,yes,yes,True,yes,"Test takers had their visas wrongfully cancelled after their tests were flagged as invalid by the voice recognition system. In addition, for several years after deportations had begun, test takers were denied the right to appeal the government's decision, and the right to due process (because they did not receive access to the recordings used to identify them as cheaters). ",2014,06,,True,no,no,,,GB,Europe,Other,,"The date corresponds to the first reported detention of a test-taker, Nomi Raja, after the government was given the list of accused cheaters. ","UK Home Office, ETS, BBC Newsnight, Toeic test takers, Toeic test takers, Toeic test takers, Wahidur Rahman, Nomi Raja, Nomi Raja, Shakil Rathore",0,0,False,,Voice recognition system ,speech,public administration,yes,Autonomy3,"There were multiple 'human-in-the-loop' failures: The voice recognition software was used to determine if the same voice turned up on multiple test recordings. If a test was flagged, two ETS staff had to agree for it to be classified as ""invalid"".  Despite the incredibly high share of tests (97%) being flagged as suspicious or invalid, the list was passed on to the government who then (again, despite the unreasonably high number) decided to rely on it for its visa policy. ",No. Not intentionally designed to perform harm,,voice recognition,,
CSETv1_Annotator-3,163,True,163,002,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,yes,yes,"race, religion, sex, sexual orientation or gender identity, nation of origin, citizenship, immigrant status",,yes,yes,yes,True,yes,,2015,,,False,no,no,,,,Global,information technology,,Failure of content moderation AI on Facebook to take down more than 3-5% of hate speech there is a disruption of the functioning information technology environment. ,"Facebook, Meta, Frances Haugen, Security and Exchange Commission (SEC), Color of Change, Center for Media Justice, Facebook users of minority groups, Facebook users of minority groups, Researchers of project WoW, Content moderation algorithm",0,0,False,,"Content moderation algorithm on Facebook that detects, identifies and removes hate speech. ","text, images, Facebook posts",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,classification,natural language processing,
CSETv1_Annotator-3,164,True,164,002,2. Initial annotation complete,,False,no,maybe,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,no,no,yes,no,none,"The new algorithm’s heavy weighting of reshared material in its News Feed resulted in more harmful content on users' News Feeds overall, because misinformation, toxicity, and violent content are inordinately prevalent among reshares. ",yes,yes,yes,False,yes,,2018,01,,True,no,no,,,,Global,,,,"Facebook, Meta, News Feed algorithm, Facebook users, BuzzFeed, Meta's Integrity Team, Breitbart News, ABC News, Topix, Facebook users from Poland, Spain, India or Taiwan",0,0,False,,Algorithm determining the content shown on a Facebook user's News Feed ,"Facebook posts, text, images, user engagement, user comments",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,"prediction, engagement optimization",,
CSETv1_Annotator-3,165,True,165,002,2. Initial annotation complete,,False,no,no,no,no,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,no,yes,race,The tool exhibits bias towards generating caucasian features even when the underlying pixelated photo is of a person of color. ,maybe,yes,yes,True,maybe,"Since the tool is not deployed or accessible to non-expert users, it is not clear that the incident amounts to harm. ",2020,06,,False,no,no,,,,Global,,,,"PULSE, Duke University researchers, People of color",0,0,False,,"PULSE is a photo upsampling tool that, given a pixelated portrait as input, searches through computer generated images and picks the one that it believes is the closest match to the original photo. Images are produced by StyleGAN. ","images, portrait photos","professional, scientific and technical activities",no,Autonomy1,"Note that the tool is not commercially or otherwise deployed, but was created as a research project, which falls under ""Scientific activities"". ",No. Not intentionally designed to perform harm,,upscaling,StyleGAN,
CSETv1_Annotator-3,166,True,166,002,2. Initial annotation complete,,False,no,yes,no,yes,no,no,no,no,yes,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,no,yes,"sexual orientation or gender identity, race, sex",,yes,yes,yes,True,yes,,2020,,,False,no,no,,,,Global,,,,"Giggle, Sall Grover, Kairos, Gender verification AI, Transgender women , Women of color",0,0,False,,Facial recognition system for determining gender based on users' selfies. ,facial images,"information and communication, Arts, entertainment and recreation",no,Autonomy1,AI was deployed as part of a social media app for cis women. ,Yes. Intentionally designed to perform harm and did create intended harm,,"gender classification, facial recognition",computer vision,The reason for using biometric gender verification was to exclude men and trans women from the platform. 
CSETv1_Annotator-3,172,True,172,002,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,yes,yes,no,no,no,none,,yes,yes,yes,True,yes,,2014,,,False,no,no,,,US,North America,healthcare and public health,,"On date: Appriss began operating its overdose risk prediction algorithm in 2014. Their algorithm was not the first, but this annotation focuses on incidents involving Appriss' NarxCare database and models. This is why the year refers to the deployment of Appriss' algorithm. A previous algorithm, the Opioid Risk Tool (ORT), was published in 2005.

On location: At least eight states, including Texas, Florida, Ohio, and Michigan use the algorithm in their monitoring programs.","US Department of Justice, Appriss, Don’t Punish Pain Rally, Angela Kilby, Jennifer Oliva, NarxCare, Overdose Risk Score algorithm, Beverly Schechtman, Beverly Schechtman, Pharmacists, Doctors, Chronic pain patients, Patients receiving treatment for opioid addiction, Ryan Ward, Ryan Ward, Patients with comorbidities and complex conditions, Patients with comorbidities and complex conditions",0,0,True,It is not possible to estimate the impact the denial of medication has had on patients.  The reports cites research that shows that stopping those prescriptions without providing effective alternative care is associated with nearly triple the risk of overdose death. ,Medical algorithm to assess a patient's risk of opioid addiction and overdose. ,prescription history,human health and social work activities,no,Autonomy3,,No. Not intentionally designed to perform harm,,risk prediction,machine learning,
CSETv1_Annotator-3,173,True,173,002,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,unclear,yes,yes,False,none,"According to the incident report many of the developed AI tools were flawed (inaccurate, biased, etc.). But we cannot determine if tangible harm occurred because it is unclear which systems were deployed and how they were used in determining course of treatments for patients. We therefore cannot even potentially identify a harmed entity. ",maybe,maybe,no,no,maybe,unclear,"According to the incident report many of the developed AI tools were flawed (inaccurate, biased, ...). But we cannot determine if their use wrongfully denied some patients the treatment they needed (which would be a rights violation) or if any tool caused discriminatory treatments (and if so, by which group).  The report provides insufficient information to determine which systems were deployed and how they were used in determining course of treatments for patients. ",maybe,yes,yes,True,maybe,,2020,,,False,no,maybe,,,,Global,healthcare and public health,,,"Turing Institute, Laure Wynants, Derek Driggs, COVID-19 patients, COVID-19 patients",0,0,True,"If the flawed AI tools were used to determine patients' treatments, the errors in their outputs may have prevented necessary care and contributed to fatalities and/or delayed recoveries. But we are unable to provide an estimate for the number of affected patients. ","Multiple mentioned. One for diagnosing patients, another for predicting the disease process and a third for predicting patient risk from medical images. ",Unclear,human health and social work activities,no,unclear,,No. Not intentionally designed to perform harm,,,,
CSETv1_Annotator-3,174,True,174,002,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,no,no,none,,no,yes,yes,True,no,,2022,,,False,no,no,,,,Global,,,,"LinkedIn, Fake profiles, LinkedIn users",0,0,False,,Fake LinkedIn profiles with AI-generated profile pictures ,images,"information and communication, wholesale and retail trade",no,unclear,The fake profiles were used for sales pitches. ,No. Not intentionally designed to perform harm,,image generation,"neural network, StyleGAN",The fake profiles were created with the intention to be perceived as real people (i.e. deceive) but not to do harm.
CSETv1_Annotator-3,175,True,175,002,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,non-imminent risk of tangible harm (an issue) occurred,yes,yes,True,AI tangible harm issue,Driving without headlights at night arguably enhances the risk of a traffic accident. It present an issue of tangible harm (physical damage) to the car and other traffic participants. ,no,no,no,no,no,none,,no,yes,yes,False,no,,2022,04,01,False,yes,yes,San Francisco,CA,US,North America,,Nighttime,,"Cruise, San Francisco Police Department, Cruise vehicle",0,0,False,,Self-driving vehicle,lidar,transportation and storage,no,Autonomy1,,No. Not intentionally designed to perform harm,Chevy Bolt car,"object detection, steering, self-driving",,
CSETv1_Annotator-3,176,True,176,002,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,no,no,no,no,none,,no,yes,yes,False,no,,2022,03,,True,no,yes,Corvallis,OR,US,North America,,,,"Starship Technologies, Oregon State University, Starship delivery robot, Oregon State University’s Housing & Dining Services, Memorial Union Retail Services",0,0,False,,Food deliver robot,"image, ultrasound, radar, gps","wholesale and retail trade, accommodation and food service activities",no,Autonomy1,,No. Not intentionally designed to perform harm,boxy robot on wheels,,neural networks,
CSETv1_Annotator-3,204,True,204,002,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,maybe,True,unclear,"A fired worker claims that their former employer used a surveillance-based AI tool to predict employee attrition, and fired them based on their attained risk score. The company denies the use of this AI system, which is why we cannot determine if the AI system is linked to the harm. ",no,maybe,no,no,no,none,,maybe,yes,maybe,True,maybe,"The tool relies on data of employees' online behavior, such as their browsing history and their communications with coworkers. This is an infringement of their privacy, since employees were neither informed about the data collection and were unable to consent or opt-out. However, it is unclear if the company is using the AI tool.",2022,02,,False,no,no,,,CN,Asia,,,,"Sangfor Technology Co., Ltd., Behavior Awareness System BA, Zhihu, Unnamed Zhihu employee, Zhihu employees",0,0,False,,"""Behavioral perception system"" that uses data on workers' online behavior to predict attrition risk. ",text,"information and communication, public administration, Education, other",yes,Autonomy3,"Re: 9.3 and 9.4: The company at the heart of the incident is in the tech industry, however the reports mention the deployment of the system by 100,000 clients including government agencies and education. ",No. Not intentionally designed to perform harm,,attrition risk prediction,natural language processing,
CSETv1_Annotator-3,208,True,208,002,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,non-imminent risk of tangible harm (an issue) occurred,yes,yes,True,AI tangible harm issue,"""Phantom braking"" enhances the risk of collisions, but no actual event is reported. 
Hundreds of Tesla owners have filed complaints with the NHTSA, and are therefore potentially identifiable. 
",no,no,no,no,no,none,,no,yes,yes,True,no,,2021,10,,False,no,yes,,,US,North America,transportation,,,"National Highway Traffic Safety Administration, Tesla, Tesla cars, Tesla drivers, Tesla drivers, Tesla Autopilot",0,0,False,,Autopilot for full self-driving,video,transportation and storage,no,Autonomy2,,No. Not intentionally designed to perform harm,Car,object detection,computer vision,
CSETv1_Annotator-3,250,True,250,002,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,unclear,yes,yes,True,unclear,"It is unclear if the property value estimate provided by the algorithm is exaggerated or accurate. If it is exaggerated, there would be a tangible harm event. If not, there is no tangible harm. ",no,yes,no,no,no,none,"The harm of this incident is the acceptance of a property value estimate by the Court, despite the process of estimation violating the right to an explanation of automated decisions under the GDPR. ",yes,yes,yes,True,yes,,2016,,,False,no,no,Castricum,,NL,Europe,,,,"Castricum municipality, WOZ estimation algorithm, Amsterdam Court of Appeal, Unnamed claimant",0,0,False,,Property value estimation algorithm,,"real estate activities, public administration",yes,Autonomy1,,No. Not intentionally designed to perform harm,,prediction,,
CSETv1_Annotator-3,350,True,350,002,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,non-imminent risk of tangible harm (an issue) occurred,yes,no,True,none,"The delivery robot passed through a crime scene blocked off by police tape. While in this case there was no active threat, the robot could have just as easily been disrupting police engaged in a critical situation, putting people at the scene at risk, or contaminating evidence at the crime scene. 
Since the robot was being remote controlled at the time, the AI cannot be linked to the harm. ",no,no,no,no,no,none,,no,yes,no,True,no,,2022,09,13,False,no,yes,Los Angeles,CA,US,North America,emergency services,crime scene tape,,"Serve Robotics, Delivery robot, Los Angeles Police, Hollywood Hill high school",0,0,False,,Food delivery robot.,video,"transportation and storage, accommodation and food service activities",no,Autonomy3,,No. Not intentionally designed to perform harm,delivery robot,,,10.2 The robot is in the shape of a box on wheels. 
CSETv1_Annotator-3,351,True,351,002,2. Initial annotation complete,,False,no,yes,no,yes,no,no,no,no,yes,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,no,yes,race,,yes,yes,yes,True,yes,,2022,09,12,True,no,no,,,,Global,,,,"Halle Bailey, Twitter user @TenGazillionIQ, Disney's The Little Mermaid, Twitter, White Ariel",0,0,False,,AI-generated deepfake of a Caucasian Ariel inserted into the trailer for The Little Mermaid. ,video,"Arts, entertainment and recreation",no,Autonomy1,,Yes. Intentionally designed to perform harm and did create intended harm,,image generation,,
