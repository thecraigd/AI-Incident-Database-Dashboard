Namespace,Incident ID,Published,Incident Number,Annotator,Annotation Status,Peer Reviewer,Quality Control,Physical Objects,Entertainment Industry,"Report, Test, or Study of data",Deployed,Producer Test in Controlled Conditions,Producer Test in Operational Conditions,User Test in Controlled Conditions,User Test in Operational Conditions,Harm Domain,Tangible Harm,AI System,Clear link to technology,There is a potentially identifiable specific entity that experienced the harm,AI Harm Level,AI Tangible Harm Level Notes,Impact on Critical Services,Rights Violation,Involving Minor,Detrimental Content,Protected Characteristic,Harm Distribution Basis,Notes (special interest intangible harm),Special Interest Intangible Harm,AI System,Clear link to Technology,Harmed Class of Entities,Annotator’s AI special interest intangible harm assessment,Notes (AI special interest intangible harm),Date of Incident Year,Date of Incident Month,Date of Incident Day,Estimated Date,Multiple AI Interaction,Embedded,Location City,Location State/Province (two letters),Location Country (two letters),Location Region,Infrastructure Sectors,Operating Conditions,Notes (Environmental and Temporal Characteristics),Entities,Lives Lost,Injuries,Estimated Harm Quantities,Notes ( Tangible Harm Quantities Information),AI System Description,Data Inputs,Sector of Deployment,Public Sector Deployment,Autonomy Level,Notes (Information about AI System),Intentional Harm,Physical System Type,AI Task,AI tools and methods,Notes (AI Functionality and Techniques)
CSETv1_Annotator-1,22,True,22,005,4. Peer review complete,002,False,yes,no,no,yes,no,no,no,no,yes,imminent risk of tangible harm (near miss) did occur,yes,yes,True,AI tangible harm near-miss,"3.1 - This incident can be classified as an imminent risk of tangible harm (near miss) because harm would have occurred if not for atypical intervention. Users were directed toward routes in wildfire zones. They would have suffered harm if not for their intervention, or in some cases, the intervention of police officers redirecting traffic at intersections.
3.2 and 3.3 - Waze uses AI and machine learning to predict traffic patterns and optimize routes, functions that failed to ensure user safety in this incident.",no,no,no,no,no,none,,no,yes,no,True,no,"Though AI was involved, there was no special interest intangible harm in this incident.",2017,12,,False,no,no,,CA,US,North America,,natural disaster - wildfires,,"Waze, Google, Waze, Google Maps, and Apple Maps users, Google Maps, Apple Maps, Apple",0,0,False,"There were no quantifiable tangible harms in terms of deaths or injuries, as this incident was a near-miss.",Waze uses machine learning to predict traffic patterns based on other users' reports in order to optimize routes for the primary user. ,"user traffic reports, route specifications","transportation and storage, information and communication",no,Autonomy3,,No. Not intentionally designed to perform harm,,"navigation, route optimization","shortest-path algorithm, Dijkstra Algorithm",
CSETv1_Annotator-1,20,True,20,005,4. Peer review complete,002,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,no,no,no,no,none,,no,yes,yes,True,no,,2016,05,07,False,no,yes,,,US,North America,emergency services,,"This incident is a variant that contains several different events. May 7, 2016, is the date of the first fatal collision that occurred while Autopilot was engaged. It occurred in Williston, Florida. Joshua Brown's Tesla Model S drove under the trailer of an 18-wheel truck on a highway while in Autopilot mode because the vehicle's sensors failed to distinguish the white trailer (driver Frank Baressi) against the bright sky. 

On March 23, 2018, in Mountain View, California, a Tesla Model X collided with a highway barrier and caught fire. This killed the driver, Wei ""Walter"" Huang. Tesla reported that the driver had received several cues to reengage with the wheel but did not.

On May 11, 2018, in South Jordan, Utah, a Tesla Model S crashed into a stopped fire truck while operating in autopilot mode. The driver was looking at her phone.

In December 2019, in West Bridgewater, Massachusetts, Maria Smith was stopped by a state police trooper. As she was retrieving her vehicle registration, a Weston man named Nicholas Ciarlone crashed into the police cruiser which, in turn, hit her vehicle.

On July 14, 2020, in Arizona, a Tesla model S on autopilot crashed into a parked police vehicle and an ambulance. The driver was allegedly drunk.

On August 26, 2020, In North Carolina, a Tesla crashed into a police car because the driver activated Autopilot and was distracted watching a movie on his phone.","Tesla Model X, Tesla, Tesla Model S, Tesla Autopilot, Joshua Brown, Frank Baressi, Wei \""Walter\"" Huang, 28-year-old Tesla driver, Maria Smith, Massachusetts state police trooper, Nicholas Ciarlone, unnamed Tesla driver (NC), Nash county deputy and trooper, Frank Baressi's trailer, 2010 Mazda 3, 2017 Audi A4, 2010 Mazda 3 driver, 2017 Audi A4 driver, 28-year-old Tesla driver, United Fire Authority mechanic truck driver, United Fire Authority truck, South Jordan fire department, Maria Smith, Massachusetts state police trooper vehicle, Massachusetts state police, Nicholas Ciarlone, Nash county police, Nash county police vehicles, unnamed Tesla driver (NC), unnamed Tesla driver (AZ), unnamed Tesla driver (AZ), Ambulance (AZ), Police vehicle (AZ), Police sergeant (AZ), Ambulance occupants (AZ), Arizona emergency services",2,10,True,"Lives lost include: Joshua Brown and Wei ""Walter"" Huang. It is unclear exactly how many injuries resulted from these events, and whether or not every person involved was injured. Injuries included in 8.2 include: Truck driver Frank Baressi, 2010 Mazda 3 driver, 28-year-old woman in Utah with a broken foot, Maria Smith, Massachusetts state police trooper, Nicholas Ciarlone, Tesla driver in Nash County, Nash county deputy and trooper, and unnamed Tesla driver in AZ.","Tesla's autonomous vehicles employ autonomous driving systems intended to avoid obstacles and transport passenger to their destination safely. Tesla's Autopilot is a ""suite of software, cameras and sensors intended to assist drivers and prevent accidents by taking over many aspects of driving a car."" These include steering, braking, and accelerating.","video input, sensor data, radar, camera input",transportation and storage,no,Autonomy2,Autopilot is a semiautonomous driving-assistance system. Drivers are supposed to remain vigilant and be able to retake control of the wheel at any time.,No. Not intentionally designed to perform harm,"Tesla vehicle (Model 3, Model S, Model X)","navigation, transportation, semi-autonomous navigation",audiovisual sensing,
CSETv1_Annotator-1,19,True,19,005,4. Peer review complete,002,False,no,no,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,maybe,yes,"race, sex",,yes,yes,yes,True,yes,,2013,01,,True,yes,no,,,US,North America,,,,"Harvard Professor Latanya Sweeney, Google AdSense, Google, Google Search, Women, Black people",0,0,False,,Online ad selection and delivery,search queries,information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,"smart suggestions, search result ranking, personalized online advertising",,
CSETv1_Annotator-1,52,True,52,005,6. Complete and final,,False,,,,,,,,,,,,,False,,,,,,,,,,,,,False,,,,,,False,,,,,,--,,,,,0,0,False,,,,,,,,,Automobile,,,
CSETv1_Annotator-1,18,True,18,005,4. Peer review complete,003,False,no,no,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,no,yes,sex,,yes,yes,yes,True,yes,,2015,04,,True,no,no,,,,Global,,,,"Sean Munson, Matt Kay, Cynthia Matuszek, Women, Google, Google Images",0,0,False,,Google Images returns image results once search queries and keywords are entered by scanning the web for images with related file names and using machine learning to cluster similar images together.,"keywords, search queries",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,"search optimization, personalized online search results",web scraping,
CSETv1_Annotator-1,17,True,17,005,4. Peer review complete,003,False,no,no,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,no,no,none,,no,yes,yes,True,no,,2017,,,True,no,no,,,,Global,,,,"Google, Gmail, Gmail SmartReply, Gmail users",0,0,False,,Smart Reply is a Gmail suggesting algorithm which detects which emails in an inbox need a response. It also predicts and suggests short replies for users.,text,information and communication,no,Autonomy3,,No. Not intentionally designed to perform harm,,smart suggestions,"natural language response, natural language processing",
CSETv1_Annotator-1,16,True,16,005,4. Peer review complete,003,False,no,no,no,yes,no,no,no,no,yes,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,no,yes,race,,yes,yes,yes,True,yes,,2015,6,29,False,no,no,,,US,North America,,,,"Google, Google Photos, Jacky Alcine, Jacky Alcine's friend, Black people",0,0,False,,Google Photos' system groups and labels similar photos into categories,"images, photos",information and communication,no,Autonomy1,"The Google Photos system creates labels automatically without human interaction or intervention, although users can interact with the categorizations after they have been created.",No. Not intentionally designed to perform harm,,"image classification, image categorization",,
CSETv1_Annotator-1,15,True,15,005,4. Peer review complete,003,False,no,no,no,yes,no,no,no,no,yes,imminent risk of tangible harm (near miss) did occur,no,no,True,none,"3.1 - Considering the importance of sales rank in promoting visibility, authors/vendors would have avoided being affected only out of luck or randomness.
3.3 - It is unclear whether the AI was at fault for excluding LGBTQ+ authors from page ranks. Amazon called the incident a ""software glitch."" Human involvement because of company policy is also possible.",no,no,no,no,yes,sexual orientation or gender identity,,yes,no,no,True,no,,2009,4,,False,no,no,,,,Global,,,,"Censored authors (vendors), Amazon, Amazon Sales Ranker, Amazon users (purchasers), Censored authors (vendors)",0,0,False,,,"products, product options",wholesale and retail trade,no,unclear,9.5 - It is unclear whether or not a human/Amazon policy was responsible for or could have prevented the exclusion of LGBTQ+ authors from ranking higher on sales ranks.,,,,,not AI
CSETv1_Annotator-1,14,True,14,005,4. Peer review complete,003,False,no,no,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,no,yes,"religion, sexual orientation or gender identity, sex, race, nation of origin, citizenship, immigrant status",,yes,yes,yes,True,yes,,2017,10,,False,no,no,,,,Global,,,,"Google, Google Cloud Natural Language API, Affected Groups, Motherboard",0,0,False,,"The Google Cloud Natural Language API is meant to help customers gauge ""the structure and meaning of your text.""",text,information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,"natural language processing, sentiment analysis",,
CSETv1_Annotator-1,13,True,13,005,4. Peer review complete,003,False,no,no,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,no,yes,"sex, sexual orientation or gender identity, religion, race, nation of origin, citizenship, immigrant status",,yes,yes,yes,True,yes,,2017,,,True,no,no,,,US,North America,,,,"Google , Perspective API, Black people, Women, LGBTQ+ people, Jigsaw, The New York Times, Wikipedia, The Economist, The Guardian, Various online media outlets",0,0,False,,Comment toxicity evaluation algorithm,text,information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,"sentiment analysis, toxicity detection",,
CSETv1_Annotator-1,12,True,12,005,4. Peer review complete,003,False,no,no,yes,no,no,no,yes,maybe,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,"3.2 - Though this incident is not a test of AI itself, vector embeddings meet the threshold of complexity and sophisticated decision-making that CSET requires for this criteria and is important in machine learning and NLP.",no,no,no,no,yes,sex,,yes,yes,yes,True,yes,,2016,,,True,no,no,,,US,North America,,,"6.1 and 6.8 - Although the media report attached to this incident was of a study published at Boston University in 2016, it is unclear when the research began or when word2vec was created or when it began to display bias. Thus, the date and location are estimated.","Boston University researchers, Women, Google, Google News word2vec, Microsoft researchers",0,0,False,,Vector embeddings algebraically represent words in order to compare them to each other. This is a helpful tool in refining neural networks for natural language processing so that AI can associate relevant words with each other.,"text, words, news articles",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,"word association, natural language processing","neural networks, vector embedding, linear algebra",
CSETv1_Annotator-1,11,True,11,005,4. Peer review complete,002,False,no,no,yes,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,"ProPublica found evidence of differential performance rates of the COMPAS recidivism risk prediction system across racial groups. The system was both used in sentencing (affecting judge’s decisions concerning the length of sentences) and pretrial bond hearings (affecting decisions concerning pretrial detainment and bond amounts). There is a reasonable probability that the risk scores wrongfully aggravated choices made by judges. Moreover, there is at least one instance in which a judge admitted to assigning a longer prison sentence due to the elevated risk score, which was reduced on appeal.",no,yes,no,no,yes,race,,yes,yes,yes,True,yes,,2013,,,False,no,no,,,US,North America,,,,"ProPublica, Northpointe, COMPAS, Defendants assessed by COMPAS, Defendants assesed by COMPAS, Defendants assessed by COMPAS, Defendants assessed by COMPAS, Paul Zilly, Brisha Borden, Sade Jones, COMPAS deployers",0,0,False,,The COMPAS system calculates a person's risk of recidivism based on 137 questionnaire responses about the situation and context of the crime and the person involved.,137 questionnaire responses,"law enforcement, public administration",yes,Autonomy3,,No. Not intentionally designed to perform harm,,predict recidivism,,
CSETv1_Annotator-1,10,True,10,005,4. Peer review complete,002,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,no,no,no,no,none,,no,yes,yes,False,no,,2014,,,True,no,no,,,US,North America,,,,"Starbucks, Kronos, Kronos scheduling algorithm, Starbucks employees, Kylei Weisse, Starbucks employees, Jannette Navarro",0,0,False,,The Kronos scheduling algorithm is designed to optimize the productivity of stores like Starbucks by scheduling workers inconsistently throughout and across weeks,"schedules, worker profiles","wholesale and retail trade, accommodation and food service activities",no,Autonomy2,,No. Not intentionally designed to perform harm,,"scheduling, productivity optimization",,
CSETv1_Annotator-1,9,True,9,005,4. Peer review complete,002,False,no,no,no,yes,no,no,no,no,yes,non-imminent risk of tangible harm (an issue) occurred,no,yes,True,none,3.5 - the value-added measurement/modeling is not AI - it is a statistical model,no,no,no,no,no,none,,no,no,no,True,no,,2012,,,True,no,no,NY,NY,US,North America,,,,"Teachers in New York, Value-added model, New York City Department of Education",0,0,False,,The value-added model system predicts future test scores based on current measurements and then rates teachers based on their ability to bring students up to those predictions - it also uses test scores the teachers don't directly affect.,test scores,Education,yes,Autonomy1,,No. Not intentionally designed to perform harm,,,,
CSETv1_Annotator-1,7,True,7,005,4. Peer review complete,002,False,no,no,yes,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",maybe,yes,False,none,"3.5 - Although autonomous Wikipedia bots may have feuded with each other, there is no evidence of tangible harm, either from users reading false information or being inconvenienced by the constant undoing of bot mistakes by other bots",no,no,no,no,no,none,,no,maybe,yes,False,no,,2001,,,False,yes,no,,,,Global,,,,"Wikipedia bots, Oxford and Alan Turing Institute Researchers, Wikipedia",0,0,False,,"Wikipedia bots are intended to autonomously correct spelling, maintain links, and monitor vandalism on Wikipedia pages.",text,information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,webpage maintenance,,
CSETv1_Annotator-1,6,True,6,005,4. Peer review complete,002,False,no,maybe,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,yes,yes,"race, religion, sex, ideology, nation of origin, citizenship, immigrant status","4.6 - Tay's tweets included racist and misogynist content, far-right ideology, and harmful content against certain religions, etc.",yes,yes,yes,True,yes,,2016,03,23,False,no,no,,,US,Global,,,,"TayBot, Microsoft, Affected Twitter users with protected characteristics",0,0,False,,Microsoft created a chat bot named Tay with the intent of mimicking and engaging with 18-24 year old social media users.,"text, images, personal information",information and communication,no,Autonomy1,"9.2 - Limited personal information Tay could have access to included: nickname, gender, favorite food, zip code, and relationship status. Users could opt in to giving Tay access to that information.",No. Not intentionally designed to perform harm,,chat bot,human language technology,
CSETv1_Annotator-1,4,True,4,005,4. Peer review complete,002,False,yes,no,no,maybe,no,yes,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,no,no,no,no,none,,no,yes,no,True,no,,2018,3,18,False,no,yes,Tempe,AZ,US,North America,,,,"Uber, Uber autonomous vehicle, Elaine Herzberg, Rafaela Vasquez",1,0,False,,Uber autonomous car,"lidar, radar, video input, sensor data",transportation and storage,no,Autonomy2,"9.5 - The incident occurred because the test driver did not heed the car's warnings to take the wheel and readjust the car. However, the incident still reflects the AI's failure to accurately identify and avoid pedestrians and other obstacles.",No. Not intentionally designed to perform harm,autonomous car,"self-driving, navigation",,
CSETv1_Annotator-1,3,True,3,005,4. Peer review complete,002,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,maybe,yes,True,unclear,It is unclear whether the MCAS system utilized AI.,no,no,no,no,no,none,,no,maybe,no,True,no,,2018,10,29,False,no,yes,Java Sea,,ID,Asia,transportation,,,"Boeing, Boeing 737 MAX Airplane, Crew on Lion Air Flight 610, Passengers on Lion Air Flight 610 , MCAS (maneuvering characteristics augmentation system), Lion Air",189,0,False,,MCAS is  a computerized system Boeing installed on its latest generation of 737 to prevent the plane’s nose from getting too high.,sensor data,transportation and storage,no,Autonomy1,,No. Not intentionally designed to perform harm,,,,not AI
CSETv1_Annotator-1,2,True,2,005,4. Peer review complete,002,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,no,yes,True,none,"3.5 - Although harm did occur, it was because of a robot's accidental puncture of a bear spray can. No AI or complex decision making was involved.",no,no,no,no,no,none,,no,no,no,True,no,,2018,12,05,False,no,yes,Robbinsville,NJ,US,North America,,,,"Amazon, Amazon robot, Amazon fulfillment center workers",0,54,False,"8.2 - 24 workers were hospitalized out of the 54 total injured, but again, not because of AI ","The robot was a warehouse assistance robot, but the technology did not include AI.",,wholesale and retail trade,no,unclear,,No. Not intentionally designed to perform harm,,,,not AI
CSETv1_Annotator-1,1,True,1,005,4. Peer review complete,002,False,no,yes,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,no,True,none,"3.3 - there was harm and there was AI, but the harm was not tangible so AI cannot be linked to tangible harm.",no,no,yes,yes,no,none,"4.3 and 4.4 - The incident displayed detrimental content on Youtube Kids, whose target demographic audience consists of minors.",yes,yes,yes,True,yes,,2016,,,True,no,no,,,US,North America,,,,"Google, YouTube Kids, Children watching Youtube Kids",0,0,False,,content-moderation algorithm,Youtube videos,"Arts, entertainment and recreation",no,Autonomy1,9.5 - Content-moderation algorithms like the one involved in this incident are supposed to work without requiring human review or intervention.,No. Not intentionally designed to perform harm,,content moderation,,
CSETv1_Annotator-1,5,True,5,005,4. Peer review complete,002,False,yes,no,yes,yes,no,no,no,no,yes,tangible harm definitively occurred,no,yes,True,none,"3.2 - Although there was definitely harm, there is no evidence that the surgical robots were AI. The errors were from: ""the equipment arcing or sparking during an operation,"" ""burned or broken pieces fell into the patient's body,"" ""uncontrolled movement of the instruments,"" and ""system errors such as the loss of video feed."" Especially considering errors as early as 2000, it is unlikely that AI was involved.",no,no,no,no,no,none,,no,no,yes,True,no,,2000,,,True,no,yes,,,US,North America,healthcare and public health,,The study covered surgeries between 2000 and 2013.,"UIUC Researchers, Patients, Intuitive surgery, Da Vinci robotic system, ",144,1391,True,,"Not an AI system. Robotic surgical tools have been adopted broadly across minimally invasive surgeries in fields like gynecology, urology, general, colorectal, cardiothoracic, and head and neck surgery.",video input,human health and social work activities,no,Autonomy3,"It is not an AI system, and technically should be fully subject to the decisions and control of doctors excluding incidents of malfunction.",,,,,
CSETv1_Annotator-1,24,True,24,005,4. Peer review complete,002,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,no,yes,True,none,"3.2 - The robot was not a product containing AI. A robot crushed a man, but no AI decision-making occurred in this process. Spokesperson from Volkswagen indicated that it was human error, not a problem with the robot.",no,no,no,no,no,none,,no,no,no,True,no,,2015,06,29,False,no,no,Baunatal,,DE,Europe,,,"6.6 - the robot was a physical system, but it was not embedded with AI.","Volkswagen, 22-year old Volkswagen contractor, Volkswagen factory robot",1,0,False,,Stationary robot intended to move and manipulate auto parts,,manufacturing,no,Autonomy1,Not an AI system,,,,,not AI
CSETv1_Annotator-1,41,True,41,005,4. Peer review complete,002,False,no,no,no,no,yes,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,yes,no,none,"4.4 - Detrimental content was involved. The AI, Norman, was trained on captions of images and videos depicting gruesome deaths.",no,yes,no,False,no,"5.5 - Norman was trained on detrimental content. However, this was intentional in the MIT researchers' experiment. No entity experienced harm because of it.",2018,,,True,no,no,Cambridge,MA,US,North America,,,,"Norman, MIT Media Lab researchers",0,0,False,,"Norman is an AI system trained on the captions of violent and graphic content on the  Reddit thread r/watchpeopledie. Its purpose was to provide answers to Rorschach test prompts that would demonstrate the danger of training AI on biased data sets. It did, in fact, provide more gruesome answers to prompts than other AI.","words, image captions, video captions","professional, scientific and technical activities",no,Autonomy1,"9.5 - The AI responded to each prompt without intervention, but the experiment as a whole was monitored.",Yes. Intentionally designed to perform harm and did create intended harm,,"image identification, image interpretation",,
CSETv1_Annotator-1,35,True,35,005,4. Peer review complete,002,False,maybe,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,no,no,True,none,"3.2 - It is unclear whether the system responsible for Diallo's termination included AI or machine learning. It seems very rule-based: if someone is flagged as an ex-employee, deactivate their keycard, then shut down their JIRA account, then log them out of work devices, etc. This does not require AI or ML tools.
3.3 - Although the system can be clearly linked to the tangible harm, it is unlikely that the system is AI. See 3.2.
3.5 - Because the system was not AI, the AI harm level is ""none.""",no,no,no,no,no,none,,no,no,no,True,no,,2017,03,,True,no,no,Los Angeles,CA,US,North America,,,,"Ibrahim Diallo, Employee management system, Ibrahim Diallo's employer",0,0,False,,"The employee management system that terminated Ibrahim Diallo's contract was built to complete a series of steps to handle ex-employees, including disabling their key card, notifying security, and disabling various accounts (Windows, Jira, etc.).","employee profile, employee status",administrative and support service activities,no,Autonomy1,,,,,,The system was not AI.
CSETv1_Annotator-1,23,True,23,005,4. Peer review complete,003,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,maybe,True,AI tangible harm event,"3.1 - Although the harm was negligible (no injuries, minimal physical damage to the bus), it still did occur.
3.3 and 4.5 - The incident was caused primarily by the truck driver who backed out of an alley without checking the surrounding environment. However, according to the passengers, the self-driving shuttle could have prevented the collision by backing out of the way or honking to get the driver’s attention. Both are safe driving behaviors that a human driver would likely have taken. While the AI is not at fault per se the accident could have been avoided if it had behaved differently.",no,no,no,no,no,none,,no,yes,maybe,True,no,,2017,11,08,False,no,yes,Las Vegas,NV,US,North America,,,,"Navya, Keolis, self-driving eight-seater electric shuttle, Truck, Shuttle passengers, Truck driver",0,0,False,,The autonomous shuttle bus was meant to traverse a 0.6 mile loop at around 25 km/h in Las Vegas.,"odometer input, inertial measurement unit input, lidar sensors, visual input from cameras, traffic light signals, GNSS Antennae input, GPS input",transportation and storage,no,Autonomy1,,No. Not intentionally designed to perform harm,"oval, eight-seater, autonomous, electric shuttle bus","autonomous navigation, navigation, obstacle avoidance",,
CSETv1_Annotator-1,68,True,68,005,4. Peer review complete,002,False,yes,no,no,yes,no,no,no,no,maybe,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,no,no,no,no,none,,no,yes,no,True,no,,2017,7,17,False,no,yes,Washington,DC,US,North America,,,,"Knightscope, Knightscope K5 security robot \""Steve\, Washington Harbour office and retail complex",0,0,False,,Knightscope K5 is an autonomous security robot,"audio inputs, video input, air quality data, thermal imaging, lidar, radar input",law enforcement,no,Autonomy1,,No. Not intentionally designed to perform harm,"rocket/egg shaped, 300 pound, 5 ft. tall security robot","security, patrolling, surveillance",,
CSETv1_Annotator-1,70,True,70,005,4. Peer review complete,002,False,yes,no,no,no,no,yes,no,no,yes,non-imminent risk of tangible harm (an issue) occurred,yes,yes,True,AI tangible harm issue,"3.1 - The incident is an issue. Harm could not nearly have occurred because of the test environment, but it could in the future.",no,no,no,no,no,none,,no,yes,no,False,no,,2016,2,10,False,no,yes,,,,Global,,inclement weather - snow,"6.4 - The date corresponds to the publication of the article, as it is unclear when the risks of snow blindness emerged.","Volvo Cars, Volvo self-driving XC90 sport-utility vehicle, Drivers and passengers in autonomous vehicles, Google, Ford Motor Co.",0,0,False,,AI systems are designed to integrate with vehicles to autonomously navigate passengers in operational road environments.,"camera input, radar input, sensor input",transportation and storage,no,Autonomy2,,No. Not intentionally designed to perform harm,"Vehicles (Volvo, Lexus, Ford, Google, etc.)","navigation, transportation",,
CSETv1_Annotator-1,34,True,34,005,4. Peer review complete,003,False,yes,no,no,yes,no,no,no,no,no,tangible harm definitively occurred,yes,maybe,True,AI tangible harm near-miss,"3.3 - The financial loss that occurred when the child ordered a dollhouse and cookies cannot directly and clearly be linked to the technology because an order cannot happen by accident. Though the outcome was adverse for the family, it was not unintended by the user, in this case the child.
3.5 - There are two different incidents that occurred in a chain in this event, both with different levels of harm. The first, where the Alexa ordered a dollhouse and cookies for the 6-year-old, caused financial loss for the family (although they were reimbursed). The second, where other peoples' Alexas heard news reports about the first and attempted to do the same, was a near-miss. Only the second can be directly linked to the AI, where users had to intervene to stop their technology from ordering a dollhouse independently of user intention based on the TV reporting. Thus, only the second incident, which is a near miss, qualifies as an AI harm. ",no,no,yes,no,no,none,"4.3 - A minor was involved, but not ""targeted"" or ""disproportionately treated.""",no,yes,maybe,True,no,,2017,01,,False,no,yes,San Diego,CA,US,North America,,,,"Brooke Neitzel, Megan Neitzel, Alexa, Amazon, CW6 News anchor, CW6 News viewers with Alexas",0,0,False,,Amazon's Alexa is a virtual assistant technology ,"voice input, Amazon account information","wholesale and retail trade, information and communication",no,Autonomy2,,No. Not intentionally designed to perform harm,Amazon Alexa Echo Dot speaker,virtual assistant technology,"voice recognition, audio transcription",
CSETv1_Annotator-1,64,True,64,005,4. Peer review complete,003,False,yes,no,no,yes,no,yes,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,no,no,none,,no,yes,yes,True,no,,2018,,,True,no,yes,,,GB,Europe,,,,"Fabio the robot, Interaction Lab at Heriot-Watt University, Margiotta supermarket, BBC , Margiotta shoppers",0,0,False,,Fabio was a customer service robot intended to converse with and assist supermarket shoppers,"audio inputs, speech",wholesale and retail trade,no,Autonomy1,,No. Not intentionally designed to perform harm,vaguely humanoid robot,customer service,"voice recognition, natural language response",
CSETv1_Annotator-1,63,True,63,005,4. Peer review complete,003,False,no,yes,no,yes,no,no,no,maybe,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,"Although an AI was involved, no harm occurred.",no,no,no,no,no,none,,no,yes,yes,False,no,,2018,01,18,False,no,no,Alberta,,CA,North America,,,,"Alex Harker, Google, Google Photos, Google Photos Assistant",0,0,False,,Google Photos Assistant that creates slideshows and organizes albums based on the photos in the user's Google Photos,images,"Arts, entertainment and recreation",no,Autonomy1,,No. Not intentionally designed to perform harm,,"image recognition, image organization","image splicing, panorama",
CSETv1_Annotator-1,57,True,57,005,4. Peer review complete,002,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,no,yes,True,none,"3.5 - Although tangible harm definitely occurred, there is no evidence that the automated Centrelink RoboDebt system was AI. It did not make complex decisions or have any machine learning capabilities. For example, part of its function was to average income data and then compare it to users' reported income. If there was a discrepancy, users were assumed to have reported their income incorrectly. There were no AI capabilities involved.",yes,yes,no,no,no,financial means,"4.1 - The ineffectiveness of Centrelink's RoboDebt system hindered many users' access to assistance and resources.
4.6 - Harms were disproportionately experienced by those with less financial means, who were in debt or on welfare.",yes,no,yes,True,no,"5.5 - Although there was a special interest harm that hindered access to public services, there was no AI involved.",2016,,,False,no,no,,,AU,Oceania,government facilities,,,"Centrelink, Centrelink RoboDebt, Australian Department of Human Services, Australian welfare recipients, Australian welfare recipients",0,0,False,,"Centrelink averaged Australian Tax Office income data and compared it to users' reported income. If there were inconsistencies, the users were assumed to have incorrectly reported their income. Then, they were prompted to update their information or retrieve information they no longer had to prove that they did not owe money. The system placed an unreasonable information-gathering burden on users and generated unclear communications that hindered users' abilities to access assistance.","income data, tax reports",public administration,yes,Autonomy1,,,,,,not AI
CSETv1_Annotator-1,56,True,56,005,4. Peer review complete,003,False,yes,no,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",maybe,maybe,False,none,"3.1 - Although the phone cases may be strange and unusual, there was no harm.",no,no,no,no,no,none,,no,maybe,no,False,no,,2017,7,8,False,no,no,,,,Global,,,,"Amazon, my-handy-design bot",0,0,False,,"It is suspected that the my-handy-design bot was scraping the web for popular images by search term, and then creating phone cases with those images to sell on Amazon. Each case is probably printed to order.","search terms, images",wholesale and retail trade,no,Autonomy1,,No. Not intentionally designed to perform harm,,generate phone cases,,
CSETv1_Annotator-1,55,True,55,005,4. Peer review complete,003,False,no,no,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,yes,yes,no,none,,yes,yes,yes,True,yes,,2016,12,,False,no,yes,,,US,North America,,,,"Amazon, Alexa, William",0,0,False,,Amazon's Alexa is a virtual assistant technology ,"speech, voice input","other, Arts, entertainment and recreation",no,Autonomy2,"9.5 - Humans can tell Alexa to stop in the middle of the response, but they did not so quickly enough to prevent the harm from having happened.",No. Not intentionally designed to perform harm,Amazon Echo Dot Smart Speaker,virtual assistant technology,voice recognition,
CSETv1_Annotator-1,39,True,39,005,4. Peer review complete,003,False,no,yes,no,yes,yes,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,"3.3 - Although an AI was definitely involved, there was no tangible harm to link it to.
3.4 - Although Obama was the figure targeted/affected by the deepfake, there is no evidence that he experienced harm, tangible or intangible
",no,no,no,yes,no,none,"4.4 - Technically, misinformation was involved because the deepfakes portrayed Barack Obama saying things he never actually said. However, it did not result in or cause harm.",no,yes,yes,True,no,"5.1 - Though misinformation was involved and AI facilitated it, it did not cause harm. The incidents occurred in the context of tests/experiments as demonstrations of deepfake technology for the general public. There was no intention to deceive.",2017,07,,False,no,no,,,US,North America,,,,"Barack Obama, University of Washington Researchers, Jordan Peele, Buzzfeed, FakeApp, Adobe After Effects",0,0,False,,"FakeApp, which Jordan Peele and Buzzfeed used, creates AI generated material like facial reproductions and movement.

University of Washington researchers used neural networks to train the AI on 14 hours of Obama's speeches to reproduce how he talks in real life.","video input, speech, images","Arts, entertainment and recreation, professional, scientific and technical activities",no,Autonomy3,,No. Not intentionally designed to perform harm,,"content generation, deepfake video generation",neural networks,
CSETv1_Annotator-1,38,True,38,005,4. Peer review complete,003,False,no,yes,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,"While an AI was involved, there was no tangible harm to link it to. At worst, users were frustrated with the unreasonable difficulty of the game.",no,no,no,no,no,none,,no,yes,yes,True,no,5.4 - Affected entities can be characterized as Elite: Dangerous video game players,2016,5,26,False,no,no,,,,Global,,,,"Frontier Development, Elite Dangerous players, Elite Dangerous Engineers 2.1 Updated AI",0,0,False,,"The Engineers 2.1 update to Frontier Development's game Elite Dangerous was meant to improve the user's experience by making non-playable characters and other features of the game more difficult to overcome. Instead, the development gave the AI responsible for populating and dictating the behavior of the NPCs the ability to combine characteristics of existing weapons to create superweapons near impossible to defeat.",game data,"Arts, entertainment and recreation",no,Autonomy1,,No. Not intentionally designed to perform harm,,population of characteristics for NPCs in a video game,,
CSETv1_Annotator-1,98,True,98,005,4. Peer review complete,003,False,yes,no,no,yes,no,no,no,yes,yes,"no tangible harm, near-miss, or issue",maybe,yes,True,none,"There was no tangible harm caused by the AI, rather the reaction and backlash from the public was negative",no,no,no,no,no,none,,no,maybe,yes,True,no,"Though the harm caused was intangible, it was not based on a protected characteristic, did not violate rights or hinder access to public services, etc.",2021,,,True,maybe,yes,NY,NY,US,North America,,,,"NYPD, Digidog, Boston Dynamics, Citizens of New York, NY",0,0,False,,"Digidog is a robot dog used to aid law enforcement by""going places where humans can't"" and helping to protect the citizens.",,law enforcement,yes,unclear,9.5 - Digidog can be controlled remotely but can also operate fully autonomously.,No. Not intentionally designed to perform harm,robotic dog,law enforcement,,
CSETv1_Annotator-1,102,True,102,005,3. In peer review,,False,no,no,yes,yes,yes,maybe,no,no,no,"no tangible harm, near-miss, or issue",yes,no,True,none,"3.3 - Though an AI was involved, there is no tangible harm to link it to.",no,no,no,no,yes,race,,yes,yes,yes,True,yes,,2020,3,23,False,no,no,,CA,US,North America,,,"Date and location information is based on the study, not a specific occurrence of ASR systems misunderstanding African-American voices.","ASR systems, Stanford researchers , African-American people",0,0,False,,"ASR systems, usually embedded within personal assistant technologies, use machine learning to convert speech to text.","speech, voice input",administrative and support service activities,no,Autonomy1,,No. Not intentionally designed to perform harm,,"voice recognition, speech interpretation, speech-to-text",machine learning,
CSETv1_Annotator-1,8,True,8,005,4. Peer review complete,002,False,yes,no,no,no,no,yes,no,no,yes,imminent risk of tangible harm (near miss) did occur,yes,yes,True,AI tangible harm near-miss,"3.1 - Though no one was injured, a pedestrian was stepping into the crosswalk as the Uber self-driving car was running the red light. If the pedestrian, who had right of way, had been further along the crosswalk at the time, they could have been injured.",no,no,no,no,no,none,,no,yes,yes,True,no,,2016,12,14,False,no,yes,San Francisco,CA,US,North America,,,,"Uber, Volvo XC90 SUV, Pedestrian, Charles Rotter",0,0,False,,"The AI system developed by Uber for autonomous vehicles is designed to autonomously navigate cars through operational conditions by following traffic lights, avoiding obstacles, and protecting passengers, pedestrians, and other cars on the road.","traffic, video, sensor",transportation and storage,no,Autonomy2,"9.5 - Although Uber claimed that the vehicle running a red light was the result of human error, later investigation by the New York Times proved the vehicle was in autonomous mode at the time of the incident.",No. Not intentionally designed to perform harm,Volvo XC90 SUV,"navigation, transportation",,
CSETv1_Annotator-1,26,True,26,005,4. Peer review complete,002,False,no,no,no,yes,no,no,yes,no,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,no,no,none,,no,yes,yes,True,no,,2017,11,10,False,no,yes,,,,Global,,,"6.1-6.3 - Bkav did two demonstrates during November 2017. In the first iteration on November 10th, the mask they used to bypass Apple's FaceID used masking tape and other products. In the  second iteration on November 27th, the mask replaced tape with stone powder.
","Apple, FaceID, iPhone X users, Bkav, iPhone X",0,0,False,,"FaceID uses 30,000 points of reference to map out users' faces to a neural network which is checked against every time the user attempts to unlock the device. FaceID is powered by the TrueDepth camera system, which consists of sensors, a dot projector, infrared camera, and flood illuminator. ","images, facial images, dot projector, infrared camera, sensor data",information and communication,no,Autonomy2,"While FaceID does not use human oversight and operates independently, users can bypass the FaceID level of verification by entering the password.",No. Not intentionally designed to perform harm,Apple iPhone X,facial recognition,"image mapping, point mapping, facial recognition, facial reconstruction, image reconstruction",
CSETv1_Annotator-1,27,True,27,005,4. Peer review complete,002,False,yes,no,no,yes,no,no,no,no,yes,imminent risk of tangible harm (near miss) did occur,no,yes,False,none,"3.3 - The system was not AI. However, it was a technology system that can be directly linked to the near miss that occurred.
3.5 - Since the system was not AI, there is no AI harm.",no,no,no,no,no,none,,no,no,yes,True,no,,1983,09,26,False,no,yes,Kurilovo,,RU,Europe,,,,"Stanislav Petrov, Early warning system Oko, Russian and American citizens",0,0,False,,"Though not AI, the Oko system used satellite images to detect the presence of American nuclear weapons and missiles approaching Soviet Union airspace.",satellite data,defense,yes,Autonomy3,,,,,,not AI
CSETv1_Annotator-1,28,True,28,005,4. Peer review complete,002,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,no,yes,True,none,"3.3 - The system was not AI, it was an automated spoofing robot meant to cancel sell orders if the price approached its offers. However, it is directly implicated in the chain of harm causing this incident.
3.5 - Because there is no AI, there is no AI harm.",no,no,no,no,no,none,,no,no,yes,True,no,,2010,05,06,False,no,no,,,,Global,financial services,,6.10 - The incident was caused by British Indian trader and affected American stock markets.,"Navinder Singh Sarao, Spoofing Robot, Stock indices (Dow Jones Industrial Average, S&P 500, Nasdaq Composite), Stock owners",0,0,False,,"Sarao's spoofing robot used dynamic layering techniques to place and then automatically cancel large volumes of sell orders to drive down the price of certain stocks. It was automated, but not AI.","stock prices, stock orders",financial and insurance activities,no,Autonomy1,,Yes. Intentionally designed to perform harm and did create intended harm,,,,not AI
CSETv1_Annotator-1,36,True,36,005,4. Peer review complete,003,False,yes,no,no,yes,no,no,no,no,yes,imminent risk of tangible harm (near miss) did occur,yes,yes,True,AI tangible harm near-miss,"3.5 - Although no harm occurred because the mistake was identified, other similar failures could result in inaccurate criminal charges and fines against innocent people. Risk to the affected party was imminent.",no,no,no,no,no,none,,no,yes,yes,True,no,,2018,11,21,False,no,yes,Ningbo,,CN,Asia,,,,"Jaywalking detection algorithm, Dong Mingzhu, Chinese pedestrians",0,0,False,,"Jaywalking detection systems, which are used by traffic police in Chinese cities, take pictures of people as they cross the road in order to detect whether their crossing is compliant with traffic laws. Sometimes, the images and names of jaywalkers are ""featured on large displays and warn people about the legal consequences of their actions.""",images,"transportation and storage, public administration, law enforcement",yes,Autonomy1,,No. Not intentionally designed to perform harm,,"jaywalking detection, image identification",,
CSETv1_Annotator-1,66,True,66,005,4. Peer review complete,003,False,no,maybe,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,no,no,none,"4.4 - From the Chinese government's perspective, the responses given by the chatbots were detrimental content, as they disagreed with the Chinese Communist Party and expressed desires to experience democracy.",no,yes,yes,False,no,,2017,08,03,False,no,no,,,CN,Asia,,,,"Tencent Holdings, QQ, Turing Robot, BabyQ, Microsoft, XiaoBing, Chinese Tencent QQ Users, Chinese Communist Party",0,0,False,,XiaoBing and BabyQ are chatbots intended to engage with and respond to user queries and messages.,"text, messages",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,chat bot,"prediction, natural language processing",
CSETv1_Annotator-1,81,True,81,005,4. Peer review complete,003,False,no,no,yes,no,yes,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,no,yes,"race, sex, financial means",,yes,yes,yes,True,yes,,2020,10,16,False,no,no,,,,North America,,,"October 16, 2020, refers to the date of publication of the paper","Google, Startups like Qure.ai, Aidoc, and DarwinAI, Mount Sinai Hospital, University of Toronto researchers, Vector Institute, MIT researchers, Women, People of color (Asian, Hispanic, Black, Native), People using Medicaid insurance",0,0,False,,AI systems developed by Google and startups like DarwinAI are designed to identify medical conditions in chest X-rays.,"x-ray images, patient information",human health and social work activities,no,Autonomy1,,No. Not intentionally designed to perform harm,,image classification,,
CSETv1_Annotator-1,42,True,42,005,3. In peer review,003,False,no,no,yes,yes,no,no,no,no,yes,non-imminent risk of tangible harm (an issue) occurred,no,yes,True,none,"3.1 - This incident describes a study aiming to discover whether the National Residency Matching Program favors hospitals rather than applicants when matching applicants to hospital assignments. As such, it is unclear whether harm has occurred yet. However, pending the results of the study, it is possible that continued use of the NRMP would cause harm after the date of the study.
3.2 - The NRMP is not AI. It was created around the 1980s. 
3.3 - However, the NRMP technology is directly linked to the incident.
3.5 - Because there is no AI, this incident does not meet the CSET definition of AI tangible harm.",no,no,no,no,no,none,,no,no,no,True,no,,1996,,,True,no,no,,,US,North America,,,,"NRMP, Alvin Roth, Hospitals, Residency applicants",0,0,False,,"The National Residency Matching Program (NRMP) facilitates hospitals making ""offers to their highest ranked students, who hold the best of the offers they have so far received and reject the rest."" If rejected, hospitals make offers to their next most highly ranked students and the process continues until ""no more offers or rejections remain to be made.""","student rankings, hospital preferences, student data","Education, human health and social work activities",maybe,Autonomy3,"9.4 - Some of the hospitals participating in the NRMP may be affiliated with the government.
9.5 - If an unstable match is made, students and hospitals are not bound by the NRMP decisions. The final decision of employment and placement can still be made irrespective of the NRMP algorithm decisions.",,,,,not AI
CSETv1_Annotator-1,84,True,84,005,4. Peer review complete,003,False,no,no,no,yes,no,yes,no,no,yes,"no tangible harm, near-miss, or issue",yes,yes,True,none,"3.3 - Although there was no tangible harm, the AI was linked to the adverse outcome described in the incident.",no,no,no,yes,no,none,,yes,yes,yes,True,yes,,2020,,,True,no,no,,,,Global,,,,"Facebook, Avaaz, Independent fact-checkers (Politifact, Reuters, AP), Facebook users",0,0,False,,"After independent fact-checkers identify misinformation in posts, Facebook flags the posts, notifying users who have seen them. It then uses AI to detect copies of misinformation found elsewhere on the platform.","Facebook posts, text, images",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,"fact-check, identify misinformation",,
CSETv1_Annotator-1,95,True,95,005,4. Peer review complete,,False,no,no,no,yes,no,no,no,no,yes,non-imminent risk of tangible harm (an issue) occurred,yes,yes,True,AI tangible harm issue,,no,maybe,no,no,yes,"disability, sex, race, sexual orientation or gender identity",,yes,yes,yes,True,yes,,2019,,,True,no,no,,,US,Global,,,"6.5 - HireVue was founded in 2004. The ""complaint and request for investigation, injunction, and other relief"" described by this incident was filed by the Electronic Privacy Information Center (EPIC) in November of 2019","HireVue Inc., Electronic Privacy Information Center (EPIC), Corporations (Hilton, IKEA, Dow Jones, Unilever, Urban Outfitters, etc.), Job applicants using HireVue, Job applicants using HireVue",0,0,False,,"HireVue facilitates video interviews and pre-employment assessments for corporate customers. It uses facial recognition, collecting ""tens of thousands"" of data points regarding intonation, inflection, expression, emotions, and more to evaluate candidates' ""employability"" with predictive algorithms.","voice input, facial images, video input, inflection, intonation, emotion, expression","professional, scientific and technical activities, administrative and support service activities",no,unclear,"9.5 - Although the final decision regarding employment is up to live people, HireVue may be used to pre-screen and eliminate large portions of applicant pools.",No. Not intentionally designed to perform harm,,"candidate assessment, virtual interview","facial recognition, voice recognition",
CSETv1_Annotator-1,59,True,59,005,4. Peer review complete,,False,no,no,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,"Although AI was implicated in the adverse outcome, there is no tangible harm in this incident.",no,no,no,no,yes,"sex, race",,yes,yes,yes,True,yes,,2016,,,True,no,no,,,,Global,,,"6.4 - The paper written by Caliskan, Bryson, and Narayanan that first identified gender bias in Google Translate was published in 2016.","Google, Google Translate, Google Translate users",0,0,False,,"Google Translate produces automated translations of text between languages. It uses vector embedding, an algorithm that mathematically associates similar words with each other based on context to approximate their meaning and appropriate usage. For example, ""ice"" and ""steam"" are closely related and have similar embeddings because of their shared proximity to words like ""water"" and not ""fashion."" ","words, text",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,translation,"vector embedding, natural language processing",
CSETv1_Annotator-1,60,True,60,005,4. Peer review complete,,False,no,yes,no,yes,no,no,no,no,yes,"no tangible harm, near-miss, or issue",yes,yes,False,none,"3.3 - Although there was no tangible harm, the adverse outcomes of the incident were directly related to the AI.",no,no,no,no,yes,"race, nation of origin, citizenship, immigrant status","4.4 - FaceApp added a filter that allowed users to look like different races/ethnicities. It also added a ""hot"" filter that automatically lightened skin color.",yes,yes,yes,True,yes,"5.4 - The entities harmed can be characterized as FaceApp users, but it would be difficult to identify individual users.
5.5 - The harm in this incident falls somewhat outside those defined by CSET. Using a filter to look like a different race is widely culturally problematic, but it is not explicitly a violation of rights. Also, every user was able to access the technology so harms were not distributed unevenly based on a protected characteristic. However, individuals were in fact affected on the basis of race and national origin which qualifies this incident as causing AI special interest intangible harm.",2017,08,09,False,no,no,,,,Global,,,,"FaceApp, FaceApp race-changing filter and \""hot\"" filter, Wireless Lab, FaceApp users",0,0,False,,FaceApp's system allows users to edit images and apply filters to uploaded photos.,images,"Arts, entertainment and recreation",no,Autonomy1,,No. Not intentionally designed to perform harm,,"image modification, filter",,
CSETv1_Annotator-1,74,True,74,005,4. Peer review complete,,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,yes,no,no,yes,race,"4.2 - Robert Julian-Borchak Williams was wrongfully incarcerated.
4.5 - His wrongful incarceration was the result of the AI and the police department's failure to correctly match the man in the security footage to a line of suspects/a database of ID photos, which is exacerbated by facial recognition technology's lower effectiveness with black people as opposed to white people.",yes,yes,yes,True,yes,This incident includes both AI special interest intangible harm and AI tangible harm.,2020,01,,False,no,no,Detroit,MI,US,North America,,,,"Robert Julian-Borchak Williams, Robert Julian-Borchak Williams, Detroit Police Department, Jennifer Coulson, DataWorks Plus, DataWorks facial recognition system",0,0,False,,The facial recognition technology software matches facial images to store surveillance video footage and more,"security footage, images, video input",law enforcement,yes,Autonomy3,,No. Not intentionally designed to perform harm,,facial recognition,,
CSETv1_Annotator-1,32,True,32,005,4. Peer review complete,002,False,no,no,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,no,no,none,,no,yes,yes,True,no,"Although this incident doesn't involve harm unevenly distributed along a protected characteristic, it does only impact twins.",2017,09,13,True,no,yes,,,US,North America,,,,"Apple, FaceID, Twin iPhone X users, iPhone X",0,0,False,,"FaceID uses 30,000 points of reference to map out users' faces to a neural network which is checked against every time the user attempts to unlock the device. FaceID is powered by the TrueDepth camera system, which consists of sensors, a dot projector, infrared camera, and flood illuminator.","facial images, dot projector, infrared images",information and communication,no,Autonomy2,"9.5 - While FaceID does not use human oversight and operates independently, users can bypass the FaceID level of verification by entering the correct password.",No. Not intentionally designed to perform harm,Apple iPhone X,facial recognition,"image mapping, point mapping, facial recognition, facial reconstruction, image reconstruction",
CSETv1_Annotator-1,61,True,61,005,4. Peer review complete,,False,no,no,yes,no,yes,no,no,no,yes,non-imminent risk of tangible harm (an issue) occurred,yes,no,True,none,"3.1 - The competition's reward was $150,000 prize money. Competitors may have been discouraged or confused by the initial overfit.
3.3 - The AIs that the competitors produced to sort and identify fish species was not linked to the harm. The harm was in the sample set of data, which was extremely unrepresentative and led to poor outcomes of the models on the full set of data.
3.5 - There is an issue of tangible harm but it does not meet CSET's definition for AI tangible harm because AI is not clearly linked to the adverse outcome of the incident.",no,no,no,no,no,none,,no,yes,no,True,no,,2017,05,01,True,no,no,,,,,,,"6.4 - The blog entry was posted on May 1st, 2017. The competition occurred prior to that date, as the user describes the experience in past tense.",Kaggle Competitors,0,0,False,,Competitors produced image classification models using neural networks.,"images, fishery images","Education, information and communication",no,Autonomy1,"9.5 - The AI models competitors produced operated independently, but their development and deployment occurred wholly at the prerogative of the competitors.",No. Not intentionally designed to perform harm,,image classification,"VCG network, YOLO network algorithm, SSD network algorithm",
CSETv1_Annotator-1,75,False,75,005,--,,False,,,,,,,,,,,,,False,,,,,,,,,,,,,False,,,,,,False,,,,,,--,,,,,0,0,False,,,,,,,,,,,,
CSETv1_Annotator-1,76,True,76,005,4. Peer review complete,,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,"Although facial recognition being inaccurate plays a part in the ineffectiveness of the use of facial recognition law enforcement combined with CONARC, the main issue is in the CONARC database itself. Not only does it falsely list minors and children of having committed crimes, but it often uses their real, full names which is illegal. The information about them is often incorrect. Children's presence in the database creates a risk that they will be tracked and falsely arrested by the facial recognition tracking systems powered by the CONARC database. Their identification itself is illegal. Wrongful arrests have also occurred, making this an AI tangible harm event.",no,yes,yes,no,no,none,,yes,yes,yes,True,yes,"5.3 - AI and facial recognition systems perform worse on children. Not only do their physical features change more rapidly, but they are also less distinguishable than the features of adults",2019,,,True,no,no,,,AR,South America,,,6.1 - CONARC began in 2009. It is unclear when the first child was added to the database. The facial recognition system began to be used in 2019.,"Argentinian government, CONARC (Consulta Nacional de Rebeldías y Capturas), Argentinian children, Argentinian children",0,0,False,,"CONARC is a ""plain-text spreadsheet file"" that lists people and their alleged crimes. It began in 2009 as an effort to aid law enforcement in addressing serious crimes.","names, national IDs, alleged crimes, text","law enforcement, public administration",yes,Autonomy3,,No. Not intentionally designed to perform harm,,database,,
CSETv1_Annotator-1,78,True,78,005,3. In peer review,002,False,no,no,no,yes,no,no,no,no,yes,"no tangible harm, near-miss, or issue",no,yes,True,none,"3.2 - The prediction algorithm was statistical. It used past school trends and student assignment grades to predict students' IB scores.
3.3 - However, the technology can be linked to the adverse outcomes described in the incident.",no,no,yes,no,no,none,4.3 - IB score prediction algorithms affected high school seniors around 17-18 years of age.,yes,no,yes,True,yes,"5.1 - Although the incident does not CSET's definitions of impact on critical services, rights violation, detrimental content, or uneven distribution of harm based on a protected characteristic, students definitely did experience the intangible harm of having their chances at university admission diminished unfairly. The incident did affect mostly minors, which is a protected subgroup.
5.3 - Although there was no AI, the technology is linked to the adverse outcomes of the incident.",2020,,,False,no,no,,,,Global,,,"Although most IB students are in the U.S., the IB program is also common in international schools around the globe.","High school seniors in the IB program during the pandemic, IB Diploma Programme, IB score prediction algorithm",0,0,False,,"The IB score prediction algorithm, deployed in place of in-person tests during the pandemic, ""used signals including a student’s grades on assignments and grades from past grads at their school to predict what they would have scored had the pandemic not prevented in-person tests."" It is a statistical model and does not use AI.","past school trends, student grades",Education,yes,Autonomy1,,No. Not intentionally designed to perform harm,,,,not AI
CSETv1_Annotator-1,79,True,79,005,3. In peer review,002,False,no,no,yes,yes,no,no,no,no,yes,imminent risk of tangible harm (near miss) did occur,no,yes,True,none,"3.1 - It is unclear whether or not the use of the algorithm in the past caused someone to suffer injury they would not have if they had been evaluated outside of the algorithm, and whether the difference could be solely attributable to the use of the eGFR formula. However, the results of the study show that there is a risk black people are systemically overlooked for transplant wait lists and other treatments.
3.2 - There is no AI involved. It is a widely used calculation called CKD-EPI that interprets blood test results to find estimated glomerular filtration rate, a measure of the kidney's function.
3.3 - Even though there is no AI, the calculation can be linked to the harm in the incident.
3.5 - Because there is no AI, this incident does not qualify for the CSET definition of AI tangible harm.",yes,no,no,no,yes,race,4.1 - Black patients overlooked by the calculation because of built-in points may have their access to critical public healthcare reduced.,yes,no,yes,True,no,"5.3 - Though there was no AI, the technology involved can be linked to the adverse outcomes in the incident.
5.5 - Because there is no AI, this incident does not qualify for CSET's definition of AI special interest intangible harm.",2020,10,15,True,no,no,,,US,North America,,,"6.4 - The study that uncovered the incident was published on October 15th, 2020. It is unclear how long the CKD calculation has been in place in public healthcare.","Black patients with chronic kidney disease, Black patients with chronic kidney disease, CKD-EPI eGFR calculation",0,0,True,8.3 - It is impossible to estimate how many patients would have had more positive care outcomes if they had been evaluated without of the CKD-EPI eGFR calculation.,"This technology is not AI. The CKD-EPI eGFR interprets blood test results to determine the patient’s level of the waste product creatinine, a proxy for kidney function. A low score moves patients onto critical transplant wait lists and treatment plans. However, the equation separates all patients into non-Black or Black categories. Black patients have extra points built in to their score. In many cases, without these extra points, they would have qualified for wait lists and other treatments.","age, sex, race, creatinine levels",human health and social work activities,yes,Autonomy2,,No. Not intentionally designed to perform harm,,,,not AI
CSETv1_Annotator-1,82,True,82,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,maybe,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,yes,no,none,4.4 - Accurate reports about the killing of protestors at the Leikki toll gate were labeled as misinformation.,yes,yes,yes,True,yes,,2020,10,20,False,no,no,Lagos,,NG,Africa,,,,"Facebook, Third-party fact-checking organizations  (ex. Africa Check Nigeria, AFP Nigeria, Dubawa), Facebook users interested in the Lekki Massacre incident",0,0,False,"Although protestors died at the Leikki toll gate event, this incident is about Facebook's moderation of content about the protest.","Facebook employs and collaborates with third-party independent fact-checking organizations to moderate content on Facebook. If content is deemed to be false, its visibility is reduced and the posts are often amended with warnings about possible misinformation.","text, Facebook posts",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,content moderation,,
CSETv1_Annotator-1,83,True,83,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,"3.3 - Although there is no tangible harm, AI is linked to the adverse outcomes described in the incident.",no,no,no,maybe,yes,"nation of origin, citizenship, immigrant status","4.4 and 4.6- Spam filters (specifically Microsoft Outlook's and SpamAssassin's) often mistakenly identify emails containing words like ""Nigeria"" and ""Ivory Coast"" as spam even if they are valid emails. Emails containing words referring to other nationalities are not identified as spam at the same rates.",yes,yes,yes,True,yes,,2020,,,True,no,no,,,,Global,,,,"AlgorithmWatch, Outlook, Microsoft, Apache Software Foundation, SpamAssassin, Microsoft Outlook users",0,0,False,,"Spam filters use machine learning algorithms to find patterns of what emails are likely spam. There is likely high incidence of emails about ""Nigeria,"" ""Ivory Coast,"" and other terms in the training set of spam emails.","emails, text",information and communication,no,Autonomy2,"9.5 - Although the spam filter operates without human involvement, human users are able to view emails in a spam folder and approve them as not-spam.",No. Not intentionally designed to perform harm,,spam filter,machine learning,
CSETv1_Annotator-1,87,True,87,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,"3.3 - Although there was no tangible harm, the AI is linked to the adverse outcome in the incident.",no,no,no,no,yes,"race, sex",,yes,yes,yes,True,yes,,2020,,,True,no,no,,,UK,Europe,,,,"Dark-skinned women, UK Home Office, UK passport photo standards verification tool",0,0,False,,"People applying to get a passport must pass an automated check to ""detect poor quality photos which do not meet Home Office rules"" including ""having a neutral expression, a closed mouth, and looking straight at the camera.""","images, facial images, passport photos",public administration,yes,Autonomy2,Passport applicants are able to challenge the tool's verdict.,No. Not intentionally designed to perform harm,,passport photo quality check,"facial recognition, machine learning",
CSETv1_Annotator-1,88,True,88,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,maybe,True,none,"3.3 - The images of portable ovens showing up in searches of ""Jewish baby stroller"" was likely a result of a coordinated effort by an anti-Semitic hate campaign that uploaded offensive images and tagged them with different keywords, making them show up in Google Image searches. The root cause of this incident cannot be entirely attributed to AI, as human malice was the root cause.",no,no,no,yes,yes,religion,,yes,yes,maybe,True,yes,5.3 - see 3.3.,2017,,,True,no,no,,,US,Global,,,"6.4 - Incidences of images of portable ovens being associated with the term ""Jewish baby stroller"" have been found on sites like 4chan as early as 2017. However, the Google image search result for this incident drew attention in September of 2020.","Google, Google Images, Network Contagion Research Institute, Anti-Semitic extremists, Jewish people",0,0,False,,"Google Image search loads images associated with or next to query keywords on webpages. It does not actively identify the content of images, but relies on their context in other webpages to display them for relevant queries.","search queries, search terms, keywords",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,"image search, search optimization",,
CSETv1_Annotator-1,89,True,89,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,no,tangible harm definitively occurred,yes,maybe,True,AI tangible harm event,"3.3 - The incident describes a terrorist killing 51 worshippers in mosques in New Zealand. AI was not directly involved in this event, however, the algorithms of social media platforms like Youtube and Facebook were apparently instrumental in promoting content that radicalized and motivated the terrorist attack.
3.5 - Because the attacks would not have occurred if the terrorist had not been radicalized, the link to AI is clear enough for this incident to be classified as an AI tangible harm event.",no,no,no,yes,no,religion,"4.4 - The terrorist watched and shared detrimental white supremacist content on Youtube and other web forums and social media sites.
4.5 and 4.6 - The terrorist specifically targeted mosques because of his Islamophobia.",yes,yes,maybe,True,yes,,2019,3,15,False,no,no,Christchurch,,NZ,Oceania,,,,"Brenton Tarrant, Youtube, Facebook, Christchurch, NZ mosque worshippers",51,,False,1 of the 51 died because of injuries later in the hospital.,"Revenue on Youtube is tied to viewership, which pushes creators to produce incendiary content. That content gets more views and is pushed to other users more. Some have argued that this business model amplifies extremist and problematic content.","Youtube videos, Facebook posts",information and communication,no,Autonomy2,9.5 - Youtube moderators have the ability to remove videos and channels that violate community guidelines from the site.,No. Not intentionally designed to perform harm,,,,
CSETv1_Annotator-1,91,True,91,005,3. In peer review,,False,maybe,no,no,yes,no,no,no,no,yes,imminent risk of tangible harm (near miss) did occur,no,yes,True,none,"3.1 - Residents who were not allocated vaccines  were at imminent risk of getting infected.
3.2 - The algorithm was rules based. It used employee-based variables (ex. age) and job-based variables in an equation to determine who would get the vaccine first. Residents, who were younger, may have had low scores even with close and frequent proximity to COVID patients.
3.3 - Although there was no AI, the adverse outcomes in the event were directly related to the technology involved.
3.5 - Because there is no AI, this incident does not qualify for CSET definitions of AI tangible harm.",maybe,no,no,no,no,age,"4.6 - Residents may have had lower scores and lower priority rankings because their ages did not fall below 25 or above 65, ranges determined to be at higher risk for COVID.",no,no,no,True,no,,2020,12,,False,no,no,Palo Alto,CA,US,North America,,,,"Stanford Medical Center , Stanford Medical Center residents and nurses, Stanford Medical Center vaccine allocation algorithm",0,0,False,,"The algorithm is not AI, but a rules based equation considering several factors. It assigned each worker a score, with the highest being 3.48. The higher the score, the more prioritized the worker was in getting a vaccine.
First, employee-based variables which prioritized the oldest and youngest range of workers (over 65 and under 25). This disadvantaged residents, who fell outside that range.
Second, job-based variables, which count prevalence of COVID among a worker's job role and department and also take into account number of tests taken by the department. This disadvantaged residents, as it didn't take into account proximity and exposure to COVID. Residents who cycled through departments were also disadvantaged because of their lack of a permanent status.
Third, California Department of Public Health’s vaccine allocation guidelines and standards.","CDPH guidelines, age, job role, department",human health and social work activities,no,Autonomy1,,,,,,not AI
CSETv1_Annotator-1,92,True,92,005,3. In peer review,,False,maybe,no,no,yes,no,no,no,yes,yes,"no tangible harm, near-miss, or issue",maybe,yes,True,none,"3.2 - Goldman Sachs, who developed the card, never explicitly said whether the algorithm was AI. General media consensus is that machine learning was very likely involved.",no,no,no,no,yes,sex,"Women with similar financial backgrounds, credit scores, and other personal details as male counterparts were assigned much lower credit limits.",yes,maybe,yes,True,yes,,2019,11,,False,no,no,,,US,Global,,,,"Apple, Goldman Sachs, Female Apple Card credit applicants, New York Department of Financial Services",0,0,False,,"Goldman Sachs described its algorithm as looking at factors like ""personal credit scores, how much personal debt you have, and how that debt has been managed....in all cases, we have not and will not make decisions based on factors like gender.”","credit score, personal debt",financial and insurance activities,no,Autonomy2,"9.5 - Goldman Sachs agreed to review disputes about credit limit decisions. However, the original decision occurs without human oversight, interaction, or intervention.",No. Not intentionally designed to perform harm,,credit limit determination,,
CSETv1_Annotator-1,93,True,93,005,3. In peer review,,False,no,no,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,no,yes,"age, geography, sex, race, nation of origin, citizenship, immigrant status, disability, religion","""According to HUD, Facebook allowed advertises to exclude people from seeing housing advertisements based on interests that “closely align with the Fair Housing Act’s protected classes,” including users who Facebook classified as non-American-born, non-Christian, interested in accessibility or who were interested in Hispanic culture, in addition to other groups.""

HUD alleged that Facebook restricted who saw ads based on users' age, gender, zip code, and more.",yes,yes,yes,True,yes,,2019,3,,False,no,no,,,US,Global,,,,"U.S. Department of Housing and Urban Development, Facebook, Real estate advertisers on Facebook, Facebook users",0,0,False,,"""HUD’s charge asserts that Facebook’s machine learning and artificial intelligence (AI) tools “classify and group users to project each user’s likely response to a given ad,” potentially creating groupings defined by their protected class.""","user profiles, user demographics",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,advertisement placement,machine learning,
CSETv1_Annotator-1,30,True,30,005,4. Peer review complete,002,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,no,True,none,"3.1 - Tesla made financial losses due to production delays after invested heavily in automating production processes with robots. 
3.2 and 3.3 - Robots using AI were involved. However, the adverse outcome of the incident is directly related to decisions made by management executives like Elon Musk who chose to reorganize production processes and allocate resources to automation over human labor.",no,no,no,no,no,none,,no,yes,no,True,no,,2018,04,,False,no,yes,Fremont,CA,US,North America,,,,"Tesla, Elon Musk, Kuka, Kuka assembly robots",0,0,False,,"Robots were employed for a variety of tasks such as stamping, painting, welding, final assembly, and battery insulation. The robots used computer vision and AI to navigate often complex tasks.",,manufacturing,no,Autonomy1,"The robots operated independently when working as intended, but often required human maintenance.",No. Not intentionally designed to perform harm,,"production, assembly, object detection",computer vision,
CSETv1_Annotator-1,31,True,31,005,4. Peer review complete,002,False,yes,no,no,no,no,no,no,yes,yes,tangible harm definitively occurred,no,no,True,none,"3.2 - The incident involved a driverless train which uses the CBTC system to monitor and regulate a train's location and position on rails.
3.3 - The harm is not linked to the technology. Rather, it is linked to the failure of a human operator to re-engage the brakes.",no,no,no,no,no,none,,no,no,no,False,no,,2017,12,19,False,no,yes,Delhi,,IN,Asia,transportation,,,"Driverless Delhi Metro train, Kalindi Kunj Metro Depot, Delhi Metro Rail Corporation",0,0,False,,Driverless metro train.,,transportation and storage,no,Autonomy2,"9.4 - Although the train would operate in the public sector, it was not yet deployed at the time of the incident.",No. Not intentionally designed to perform harm,Metro train,,,not AI
CSETv1_Annotator-1,33,True,33,005,4. Peer review complete,002,False,yes,no,no,yes,no,no,no,no,no,tangible harm definitively occurred,yes,maybe,True,none,"3.3 - Logs revealed that the Amazon Echo and Alexa played the music just three minutes after the user had left the house, making it very likely that the user had accidentally activated Spotify while still in range of the Bluetooth connection.
3.5 - It is most likely that the AI turned on because of the user, not out of its own volition. Thus, AI cannot be linked directly to the chain of harm in this incident and it does not meet CSET definitions of AI tangible harm.",no,no,no,no,no,none,,no,yes,no,False,no,,2017,11,4,False,no,yes,Hamburg,,DE,Europe,,,,"Oliver Haberstroh, Amazon, Amazon Echo, Alexa",0,0,False,,Amazon's Alexa is a virtual assistant technology that can recognize spoken commands and connect to user devices through Bluetooth to perform tasks.,"voice input, speech, Bluetooth connection","administrative and support service activities, information and communication",no,Autonomy2,9.5 - Humans are able to override Alexa's decisions.,No. Not intentionally designed to perform harm,Amazon Echo ,virtual assistant technology,,
CSETv1_Annotator-1,37,True,37,005,4. Peer review complete,002,False,no,no,no,maybe,no,yes,no,no,maybe,non-imminent risk of tangible harm (an issue) occurred,yes,yes,True,AI tangible harm issue,"There are no reports of actual biased recruitment decisions made (no event). However, the algorithm's discriminatory ratings are known, as is the fact that it had been 'tested' by Amazon for several years, during which recruiters examined candidate's ratings assigned by the algorithm. ",no,no,no,no,yes,sex,Resumes including words associated with women (mentions of all-women's colleges and womens' organizations) were unfavored by the recruitment/resume screening algorithm.,yes,yes,yes,True,yes,,2014,,,False,no,no,Edinburgh,,IE,Europe,,,The recruitment tool began development in 2014.,"Amazon, Resume screening algorithm, Female applicants",0,0,False,,The recruitment tool was fed the resumes of successful applicants from the 10-year period before 2014 in order to make decisions about which resumes corresponded to applicants most similar to those that were previously successful.,"resumes, text","professional, scientific and technical activities",no,Autonomy3,,No. Not intentionally designed to perform harm,,"resume screening, recruitment","machine learning, natural language processing",
CSETv1_Annotator-1,44,True,44,005,4. Peer review complete,,False,no,no,no,yes,no,yes,no,no,no,"no tangible harm, near-miss, or issue",no,yes,True,none,3.2 - Electric Elves were not AI technology.,no,no,no,no,no,none,,no,no,no,False,no,,2000,06,,False,no,no,Los Angeles,CA,US,North America,,,"6.1 - The electric elves ran between June and December of 2000.
6.5 - There was no AI involved. However, the electric elves were occasionally required to react to/use decisions made by other electric elves.","Electric Elves, USC Information Sciences Institute, Human workers assisted by Electric Elves",0,0,False,,"Electric Elves use ""decision tree learning"" to perform personal assistant tasks like scheduling meetings and ordering lunch for human counterparts.","schedules, employee profile, daily activities",administrative and support service activities,no,Autonomy2,,,,,,not AI
CSETv1_Annotator-1,46,True,46,005,4. Peer review complete,,False,yes,no,no,yes,yes,no,no,no,yes,non-imminent risk of tangible harm (an issue) occurred,no,yes,True,none,"3.1 - Harm did not occur because Nest Labs discovered in lab trials the possibility that the Nest Wave feature would malfunction and was able to issue a recall warning to consumers. However, harm could possibly happen in the future if users continue to use smart smoke and CO detectors that have the glitch.
3.2 - It is unlikely that the detector employs AI technology. Instead, it utilizes climate, temperature, and motion sensors.",no,no,no,no,no,none,,no,no,yes,True,no,,2014,04,03,False,no,yes,,,US,Global,,,Nest Labs disclosed its discovery in April 2014. The recall was issued in May. It is unclear if users had discovered the glitch before that date.,"Nest Labs, Nest Protect: Smoke + CO Detectors, Nest Protect Users, Google",0,0,False,,Nest Protect detects smoke and carbon monoxide in the environment. It is also able to alert users if the batteries are low and can integrate with a user's home's climate control. It has a feature where users can wave their hand to signal a false alarm. Nest Labs discovered that a glitch in the algorithm might cause users to accidentally turn off the detector. It is unlikely that these functionalities utilize AI technology.,"air quality, sensor data, temperature, motion",other,no,Autonomy2,,,,,,not AI
CSETv1_Annotator-1,58,True,58,005,4. Peer review complete,,False,no,yes,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,yes,yes,"sexual orientation or gender identity, ideology, race, nation of origin, citizenship, immigrant status","4.4 and 4.5 - Yandex's chatbot Alice expressed views supporting shooting Russia's ""enemies of the people,"" opposing gay marriage, and suggesting people should put up with domestic violence. These sentiments are classified as detrimental content and indicate Alice's bias against protected groups like gay people.",yes,yes,yes,True,yes,,2017,10,10,False,no,no,,,RU,Europe,,,,"Yandex, Alice, Yandex users, Yandex users, Speechkit, Misha Bilenko",0,0,False,,"Yandex used its technology SpeechKit, which recognizes and understands Russian language, to create a chatbot named Alice with capabilities intended to be similar to those of Apple's Siri and Amazon's Alexa.","speech, audio inputs",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,"voice recognition, speech interpretation, virtual assistant technology","speech recognition, natural language processing",
CSETv1_Annotator-1,77,True,77,005,4. Peer review complete,,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,no,True,none,"3.3 - While there was tangible harm and an AI involved in the incident, the robot cannot be linked to the harm that occurred because of the fight that broke out. The failure of the AI did not cause the accident.",no,no,no,no,no,none,,no,yes,no,True,no,,2019,10,,False,no,yes,Los Angeles,CA,US,North America,,,,"HP RoboCop, Knightscope, Huntington Park Police Department, Cogo Guebara",0,0,False,"While no injuries occurred because of HP RoboCop's failure, people were injured in a fight that the HB RoboCop failed to adequately respond to.","HP RoboCop, equipped with a camera, is programmed to follow a certain route telling visitors to keep the park clean and acting as a security monitor. It is advertised as ""including a 360-degree high-definition live video stream, a license plate reader that can scan 1,200 plates a minute, a two-way intercom and the ability to track cell phone use in the vicinity."" It has 5 cameras that provide ""24/7 monitoring.""","video input, camera footage",law enforcement,yes,Autonomy1,,No. Not intentionally designed to perform harm,"rocket/egg shaped, 300 pound, 5 ft. tall security robot","security monitor, law enforcement",,
CSETv1_Annotator-1,80,True,80,005,4. Peer review complete,,False,yes,yes,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,no,no,none,,no,yes,yes,True,no,,2020,10,24,False,no,no,,,GB,Europe,,,,"Inverness Caledonian Thistle Football Club , AI-powered camera, Inverness Caledonian Thistle Football Club vs. Ayr United game watchers",0,0,False,,The AI-powered camera was meant to track and pan to the ball in a soccer game for a live stream of the match.,"video input, camera footage","Arts, entertainment and recreation",no,Autonomy1,,No. Not intentionally designed to perform harm,camera,automatic tracking,,
CSETv1_Annotator-1,86,True,86,005,4. Peer review complete,,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,no,yes,True,none,"3.2 - The algorithm was based purely on calculation and including no predictive or extrapolative decision-making.
3.3 - However, the technology did cause the adverse outcome of the incident.",no,no,yes,no,no,none,"4.3 - The mistake in the calculation affected students graduating from secondary school, some of which must have been minors.",yes,no,yes,True,yes,,2020,10,,False,no,no,,,IE,Europe,,,,"Irish Department of Education, Leaving Certificate calculated grades system, Students taking the Leaving Certificate Examination in 2020, Students taking the Leaving Certificate Examination in 2020",0,0,False,,"The grading system was intended to ""put in effect a blended formula of students' past performance that the Department of Education was implementing to come up with 'calculated' grades."" However,  a line in the code ""substituted a student’s worst two subjects for their best two subjects. Then it wrongly added a subject into the equation - the results of the Junior Cycle’s Civic, Social and Political Education. This shouldn’t have been counted."" These skewed the results of the grading.","student data, student past performance, test scores, student grades",Education,yes,Autonomy1,,,,,,not AI
CSETv1_Annotator-1,99,True,99,005,4. Peer review complete,,False,no,no,no,yes,no,no,no,no,yes,"no tangible harm, near-miss, or issue",maybe,yes,True,none,3.2 - The algorithms were trained on historic data and analyzed student data to predict their risk of dropping out.,no,maybe,no,no,yes,race,"The algorithm could be customized by different universities to include different factors to consider when making a prediction. It was discovered that some schools used race as a predictive factor which resulted in bias against Black, Asian, Indigenous, and LatinX people.",yes,maybe,yes,True,yes,,2021,,,True,no,no,,,US,North America,,,,"EAB university clients (ex. University of Massachusetts Amherst, the University of Wisconsin–Milwaukee, the University of Houston, and Texas A&M University), EAB, EAB Navigate, The Markup, Minority students at EAB client universities",0,0,False,,"""The Navigate dashboard, which also includes information like a student’s GPA, is designed to give overworked advisers a 30-second snapshot of a student’s progress...EAB’s algorithms also use other information to predict student success, such as SAT or ACT scores, high school percentile, credits attempted versus completed, and “estimated skills.”""","GPA, SAT and ACT scores, high school percentile, credits attempted, credits completed, estimated skills, student data",Education,yes,unclear,9.4 - Some universities are considered as part of the public sector.,No. Not intentionally designed to perform harm,,"risk assessment, performance prediction",machine learning,
CSETv1_Annotator-1,100,True,100,005,4. Peer review complete,,False,no,no,no,yes,no,no,no,no,yes,imminent risk of tangible harm (near miss) did occur,maybe,yes,True,AI tangible harm near-miss,3.2 - It is unclear whether there was AI involved in the robo-debt algorithms.,no,no,no,no,no,financial means,"4.6 - Welfare determination algorithms only affect citizens using welfare services, who may have less financial means.",no,maybe,yes,True,no,,2020,,,True,no,no,,,FR,Europe,,,It is unclear how long welfare decisions in France have been supplemented and made by algorithms.,"French welfare offices, French welfare recipients",0,0,False,,"The welfare determination algorithms ""use “automated controls” as well as “a statistical model known as ‘datamining’ (sic), which automatically targets risky cases”"" to review and flag welfare recipients and potentially charge them with fines.",welfare recipient data,financial and insurance activities,yes,Autonomy2,,No. Not intentionally designed to perform harm,,welfare determination,,
CSETv1_Annotator-1,97,True,97,005,4. Peer review complete,002,False,yes,no,no,yes,no,no,no,no,yes,non-imminent risk of tangible harm (an issue) occurred,yes,yes,True,AI tangible harm issue,,no,no,no,no,no,none,,no,yes,yes,True,no,,2020,,,False,no,yes,,,CH,Europe,,,,"Reddit user cyntrex, Tesla, Tesla Model 3, Tesla Autopilot",0,0,False,,"Tesla's Autopilot is a driver-assistance system meant to help drivers with normal driving functions like steering, braking, and accelerating semi-autonomously.","radar input, camera input",transportation and storage,no,Autonomy2,,No. Not intentionally designed to perform harm,Tesla Model 3,"stoplight recognition, semi-autonomous driving",,
CSETv1_Annotator-1,105,True,105,005,4. Peer review complete,002,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,no,yes,no,no,none,"4.3 - A minor was involved in the incident. Jovani Maldonado, the victim who died in the crash, was 15 years old. However, he was not disproportionately treated or specifically targeted.",no,yes,yes,True,no,,2019,08,24,False,no,yes,,CA,US,North America,,,,"Jovani Maldonado, Benjamin Maldonado, Lagman Yalung, Tesla, Tesla Model 3, Tesla Autopilot, Benjamin Maldonado, Ford Explorer, Lagman Yalung, Tesla Model 3",1,3,True,"8.1 - It is confirmed that Jovani Maldonado died as a result of the incident. It is unclear the number of injuries that occurred as a result of this incident. The incident involved Benjamin Maldonado, Jovani's father, who was driving the Ford Explorer pickup truck that was crashed into. It also involved Lagman Yalung who was driving the Tesla Model 3, and Vilma Yalung, who was riding in the passenger seat at the time of the collision.","Tesla's Autopilot is ""a suite of software, cameras and sensors intended to assist drivers and prevent accidents by taking over many aspects of driving a car - even the changing of lanes.""","radar input, camera input, sensor data",transportation and storage,no,Autonomy2,,No. Not intentionally designed to perform harm,Tesla Model 3,"autonomous navigation, semi-autonomous driving",,
CSETv1_Annotator-1,67,True,67,005,4. Peer review complete,002,False,yes,no,no,yes,no,no,no,no,yes,imminent risk of tangible harm (near miss) did occur,yes,maybe,True,unclear,"Imminent risk of tangible harm occurred. If highway patrol officers had not noticed the man sleeping in the car, they might not have intervened to slow down the car by driving in front of it. However, in this case, the AI technology seemed to have prevented further damage from occurring. If the car had not had Autopilot, the car would likely not continue driving straight and the sleeping driver would have been at more risk. 
3.3 - Thus, it is unclear if the technology can be directly and clearly linked to the adverse outcome of the incident. The most direct link would be the driver who was intoxicated and fell asleep. 
3.5 - Because it is unclear whether the AI itself caused the harm rather than the driver, this incident does not qualify as AI tangible harm.",no,no,no,no,no,none,,no,yes,maybe,True,no,,2018,11,30,False,no,yes,San Francisco,CA,US,North America,,,,"California Highway Patrol officers, Alexander Samek, Tesla, Tesla Model S, Tesla Autopilot, Tesla Traffic Aware Cruise Control",0,0,False,,"Tesla's Autopilot is a ""suite of software, cameras and sensors intended to assist drivers and prevent accidents by taking over many aspects of driving a car."" These include steering, braking, and accelerating.","radar input, camera input, sensor data, traffic patterns",transportation and storage,no,Autonomy2,,No. Not intentionally designed to perform harm,Tesla Model S,semi-autonomous navigation,,
CSETv1_Annotator-1,43,True,43,005,4. Peer review complete,002,False,no,no,no,yes,no,no,no,no,yes,"no tangible harm, near-miss, or issue",no,yes,True,none,,no,yes,no,no,yes,"nation of origin, citizenship, immigrant status, sex, race",The Commission for Racial Equality found St. George's Hospital Medical School guilty of discrimination against women and members of ethnic minorities.,yes,no,yes,True,no,,1979,,,False,no,no,London,,GB,Europe,,,6.1-6.3 refers to the date of publication of the study in the British Medical Journal detailing the findings of the Commission for Racial Equality on the St. George's Hospital Medical School admissions algorithm.,"St. George's Hospital Medical School, Applicants, Commission for Racial Equality, Dr. Franglen, St. George's Hospital Medical School admissions algorithm, Applicants",0,0,False,,"""staff at St George’s Hospital Medical School decided to write an algorithm that would automate the first round of its admissions process. The formulae used historical patterns in the characteristics of candidates whose applications were traditionally rejected to filter out new candidates whose profiles matched those of the least successful applicants.""","medical school applications, applicant data",Education,no,Autonomy2,"9.5 - The system filtered out applicants whose profiles matched traditionally least successful past applicants. Human reviewers could have overrode those decisions. In addition, the algorithm was involved only in the first round of admissions. Human decisions were likely involved in the next stages of the process and in making the final decisions on acceptance.",No. Not intentionally designed to perform harm,,,,not AI
CSETv1_Annotator-1,47,True,47,005,4. Peer review complete,002,False,no,no,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,no,yes,sex,LinkedIn's search suggestion algorithm prompted users searching for female names to choose similar-sounding male names instead.,yes,yes,yes,True,yes,,2016,08,,False,maybe,no,,,US,North America,,,,"The Seattle Times, LinkedIn, Female LinkedIn users",0,0,False,,"LinkedIn describes its search suggestion algorithm as using users' past preferences and searching history to suggest the best results, noting no involvement of gender in that process.","search queries, names",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,search suggestion,,
CSETv1_Annotator-1,48,True,48,005,4. Peer review complete,002,False,no,no,no,yes,no,no,no,no,yes,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,no,yes,race,,yes,yes,yes,True,yes,,2016,12,,False,no,no,,,NZ,Oceania,,,,"Richard Lee, New Zealand Department of Internal Affairs, Passport photo checker",0,0,False,,Online tool for verifying quality standards of passport photos.,facial images,public administration,yes,Autonomy1,,No. Not intentionally designed to perform harm,,face detection,,
CSETv1_Annotator-1,49,True,49,005,4. Peer review complete,002,False,no,yes,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,no,yes,"nation of origin, citizenship, immigrant status, race",Beauty.ai determined mostly white applicants to be most attractive among all contestants.,yes,yes,yes,True,yes,,2016,08,,False,no,no,,,,Global,,,,"Beauty.ai, Youth Laboratories, Robot Jury, Pageant contestants",0,0,False,,"The Beauty.AI system used five different judges to determine beauty. RYNKL, PIMPL, MADIS, Symmetry Master, and AntiAgeist judged based on wrinkles, pimples/pigmentation, similarity to models, symmetry of the face, and the difference between estimated and chronological age.","selfies, facial images","Arts, entertainment and recreation",no,Autonomy1,,No. Not intentionally designed to perform harm,,facial analysis,"facial recognition, deep learning, machine vision",
CSETv1_Annotator-1,50,True,50,005,4. Peer review complete,002,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,maybe,yes,True,none,"3.2 - It is unclear whether the hack of the DAO involved an AI system. It exploited a vulnerability in the software, but most likely no AI or advanced decision making was involved.",no,no,no,no,no,none,,no,maybe,yes,True,no,,2016,06,17,False,no,no,,,,Global,,,,"The DAO (Decentralized Autonomous Organization), DAO hacker, DAO token holders, Slock.it, Emin Gun Sirer",0,0,False,,The DAO is a decentralized investment fund built on the Ethereum network. ,"code, DAO token IDs",financial and insurance activities,no,Autonomy1,,No. Not intentionally designed to perform harm,,,,not AI
CSETv1_Annotator-1,40,True,40,005,2. Initial annotation complete,,False,no,no,maybe,yes,no,no,no,no,yes,non-imminent risk of tangible harm (an issue) occurred,yes,yes,True,AI tangible harm issue,"3.1 - This incident is about the results of a Dartmouth research paper on COMPAS' performance compared to non-expert human evaluators. Tangible harm could not nearly have occurred because of this study. It as most suggests that COMPAS is ineffective. See Incident 11 for examples of harm that the use of COMPAS itself actually caused to defendants.
3.2 - COMPAS uses 137 questionnaire responses about the situation and context of the crime and the person involved to calculate a person's risk of recidivism. It is unlikely that AI was involved, but it is definitely algorithmic and is involved in making decisions that tangibly affect human lives and thus can be included in this category.",no,no,no,no,no,none,"Because of the test/research environment, it is hard to ascribe special interest intangible harm to this incident. See Incident 11 for evidence of COMPAS' racial bias.

COMPAS and the non-expert evaluators were similarly accurate in correctly predicting recidivism. The two systems were similarly unfair in terms of race when predicting false positives and false negatives.",no,yes,yes,True,no,,2018,01,17,False,no,no,,,US,North America,,,6.1-6.3 - This date refers to the publication of the paper rather than the use of COMPAS.,"Correctional Offender Management Profiling for Alternative Sanctions (COMPAS), Equivant (formerly Northpointe), Julia Dressel, Hany Farid, Non-expert human evaluators , Defendants assessed by COMPAS, Defendants assessed by COMPAS",0,0,False,,"The COMPAS system calculates a person's risk of recidivism based on 137 questionnaire responses about the situation and context of the crime and the person involved.

In the Dartmouth study, participants saw a short description of a defendant that included the defendant’s sex, age, and previous criminal history, but not their race. They predicted whether this person would recidivate within 2 years of their most recent crime. The description was formatted as follows: ""The defendant is a [SEX] aged [AGE]. They have been charged with: [CRIME CHARGE]. This crime is classified as a [CRIMINAL DEGREE]. They have been convicted of [NON-JUVENILE PRIOR COUNT] prior crimes. They have [JUVENILE- FELONY COUNT] juvenile felony charges and [JUVENILE-MISDEMEANOR COUNT] juvenile misdemeanor charges on their record.""

They also used an algorithmic assessment to determine that COMPAS' predictive accuracy can be achieved with only two features in a linear classifier, and that more sophisticated classifiers do not improve prediction accuracy or fairness.","sex, age, 137 questionnaire responses, previous criminal history, criminal degree",law enforcement,no,Autonomy3,,No. Not intentionally designed to perform harm,,predict recidivism,"machine learning, logistic regression, non-linear SVM, signal detection theory",
CSETv1_Annotator-1,51,True,51,005,3. In peer review,002,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,no,yes,no,no,none,,no,yes,yes,True,no,,2017,07,08,False,no,yes,Palo Alto,CA,US,North America,,,,"Stanford Shopping Center, Harwin Cheng, Knightscope, Knightscope K5 security robot",0,1,False,,"The robot was a a K5 unit equipped with nearly 30 sensors. The bot comes equipped with sensors, lasers, and 360-degree cameras, and spends the day patrolling an assigned perimeter. It can detect sounds like cars honking, glass breaking, and people screaming, and scan license plates. When the K5 senses criminal activity, it alerts human authorities.","sensor data, camera input, video input, spatial data, infrared camera",law enforcement,no,Autonomy1,,No. Not intentionally designed to perform harm,"rocket/egg shaped, 300 pound, 5 ft. tall security robot","security, patrolling",,
CSETv1_Annotator-1,53,True,53,005,4. Peer review complete,002,False,no,no,no,yes,no,no,no,no,yes,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,no,yes,"race, sex",,yes,yes,yes,True,yes,,2012,04,,True,no,no,,,,Global,,,,"Kabir Alli, Black teenagers, Google, Google Search, Women of color",0,0,False,,Search engine and content ranking system. ,"images, image alt tags, text",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,search engine optimization,,
CSETv1_Annotator-1,65,True,65,005,2. Initial annotation complete,,False,no,yes,no,no,yes,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,no,no,none,,no,yes,yes,False,no,,2016,12,21,False,no,no,,,,Global,,,6.1-6.3 - The date refers to the publication of the blog post from OpenAI about its experiments with reinforcement learning algorithms on rewards in games.,"OpenAI, Universe, CoastRunners, Reinforcement learning agent",0,0,False,,"In reinforcement learning experiments, OpenAI found that an unclearly specified reward function encouraged an AI agent to act contrary to human behavior in completing a game. It was able to exploit a loophole with respawning targets to gain points without finishing the race in a video game . The blog post concluded that reward functions need to be more intuitive with human behavior and end goals of games like finishing a race rather than proxies like targets hit.",,"Arts, entertainment and recreation",no,Autonomy1,,No. Not intentionally designed to perform harm,,,"reinforcement learning, reward functions",
CSETv1_Annotator-1,94,True,94,005,3. In peer review,,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,"3.1 - There are two instances of harm in this incident. First, the unfavorable court ruling against Deliveroo required them to pay  €50,000 to the suing parties, which is a tangible harm. Second, the finding that the algorithm to determine rider reliability was discriminatory against valid reasons not to work such as illness. This is an imminent risk of tangible harm because riders would have their status demoted and potentially suffer financial loss. However, the incident does not list any real-life instances of this occurring, and the case was mostly hypothetical. The most severe level of harm is tangible harm, which is what is indicated in this question.",no,yes,no,no,no,none,4.2 - The ruling indicated that Deliveroo violated riders' right to not work because of injury.,yes,yes,yes,True,yes,,2021,01,,False,no,no,,,IT,Europe,,,,"Deliveroo workers, Deliveroo workers, Deliveroo, Bologna court",0,0,False,,"The reliability algorithm decreased riders' reliability index if they failed to cancel a shift pre-booked through the app at least 24 hours before its start. Since riders deemed more reliable by the algorithm were first to be offered shifts in busier timeblocks, this effectively meant that riders who couldn't make their shifts—even if it was because of a serious emergency or illness—would have fewer job opportunities in the future.
According to the court, the algorithm unjustly penalized riders with legally legitimate reasons for not working.","rider profiles, reliability index, shift data","professional, scientific and technical activities, accommodation and food service activities",no,Autonomy1,,No. Not intentionally designed to perform harm,,"shift assignment, reliability rating",machine learning,
CSETv1_Annotator-1,96,True,96,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,non-imminent risk of tangible harm (an issue) occurred,no,yes,True,none,3.5 - the value-added measurement/modeling is not AI - it is a statistical model,no,yes,no,no,no,none,"""A proprietary system that measures teacher performance based on student test scores may violate teachers’ civil rights because they can’t verify the results are accurate, a federal judge ruled, advancing a lawsuit against Texas’ largest school district.""",yes,no,yes,True,no,,2017,,,False,no,no,Houston,TX,US,North America,,,"The lawsuit was first filed in 2014 after the system was implemented in 2012. U.S. Magistrate Judge Stephen Smith sided with teachers in a decision on May 4, 2017.","Houston Independent School District, SAS Institute, Educational Value-Added Assessment System (EVAAS), Houston Federation of Teachers Local 2415 and six Houston ISD, Houston Independent School District teachers, Houston Independent School District teachers",0,0,False,,EVAAS tracks teachers’ impact with a proprietary algorithm that compares their students’ test results to the statewide average for students in that grade or course.,"student data, student test results, standardized test results, statewide average test scores",Education,yes,Autonomy3,The value-added system provides data about teachers which is used by the school district to make firing decisions.,No. Not intentionally designed to perform harm,,,,not AI
CSETv1_Annotator-1,104,True,104,005,2. Initial annotation complete,,False,maybe,no,no,yes,no,no,no,no,yes,imminent risk of tangible harm (near miss) did occur,yes,yes,True,AI tangible harm near-miss,"3.2 - It is unclear if the vaccine distribution algorithm involved AI, but it did make real-life affecting decisions algorithmically and thus is included in this category.",yes,no,no,no,yes,"financial means, geography",,yes,yes,yes,True,yes,,2021,,,False,no,no, ,CA,US,North America,,,,"California Department of Public Health, Blue Shield of California, California residents, California residents",0,0,False,,"Using zip codes instead of census tracks to determine vaccine allocation is operationally more simpler but zip codes are much broader. In generalizing, certain underserved communities are excluded from prioritization. Zip codes represent much broader geographical areas which contain both wealthy and low-income communities. The California Department of Health's original plan to use the ""Healthy Places Index"" and census tracts was disregarded after CA gave the responsibility for developing a vaccine allocation algorithm to Blue Shield.",zip code,human health and social work activities,yes,Autonomy3,,No. Not intentionally designed to perform harm,,vaccine allocation,,
CSETv1_Annotator-1,45,True,45,005,4. Peer review complete,002,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,"3.1 - People affected negatively by suggestions and image results about their character and personality from Google functionalities suffer the intangible harm of reputational damage that may affect their ability to seek employment, among other things. The tangible harm in this incident refers to the damages Google was ordered to pay in various lawsuits alleging defamation against plaintiffs because of Autocomplete suggestions and image results.",no,no,no,yes,yes,religion,"4.2 - Certain legal opinions describe Google as violating the right to personality, or that an entity's personality and reputation is respected and can be freely developed.
4.4 - Google Autocomplete suggestions imply misinformation (incorrect information about subjects). Google Image results display innocent people in relation to crimes or criminals.",yes,yes,yes,True,yes,,2011,03,24,False,no,no,,,,Global,,,"This incident is a variant that contains several different events. March 24, 2011 is the first instance of a lawsuit against Google regarding defamation. The court of Milan upheld its order for Google to filter out libellous search suggestions after an unnammed businessman and entrepreneur in the financial services sector was associated with Autocomplete suggestions like ""truffatore"" (con man) and truffa (fraud).
In June 2011, in Ireland, the Ballymascanlon hotel sued Google for defamation because Autocomplete suggested that the hotel was in receivership (financial trouble).
In January 2012, French anti-discrimination SOS Racisme and other organizations sued Google because the Autocomplete feature suggested the word ""Jewish"" in searches involving non-Jewish public figures.
In March 2012 in Japan, Google was ordered to disable part of its Autocomplete function and pay the plaintiff because an unidentified man was linked to crimes he was not involved with, apparently making it hard for him to find work. The injunction was in March 2012 and the ruling was in 2014.
In September 2012, former German first lady Bettina Wulff sued Google over search results that paired her name with terms like ""prostitute."" In May 2013, the German Federal Supreme Court held Google liable.
In May 2013, in Germany, the Federal Court of Justice stated that Google's predictions can violate the right of personality in regards to the chairman of a corporation which sold food supplements and cosmetics online that had ""betrug"" (fraud) and ""scientology"" in search results.
In August 2014, Hong Kong tycoon and founder of management company Emperor Group Albert Yeung Sau-Shing sued Google because searches for his name added ""triad"" (an organized crime group) to his name.
In October 2015, an Australian court determined Google liable for articles defamatory articles about the defendant Dr. Duffy.
In June 2018, in Melbourne, Australia, the High Court ruled that Milorad Trkulja was allowed to sue Google for defamation because searches for ""Melbourne criminal underworld photos"" brought up images of him and also known gang members. The Autocomplete function and text-based search results gave options that included phrases like ""is a former hit man,"" ""criminal,"" and ""underworld.""","Google, Google Autocomplete, Google Images, Court of Milan, Unnamed businessman AB, Judge Roberto Bichi, Ballymascanlon Hotel, SOS Racisme, Union of Jewish Students of France, Movement Against Racism and for Friendship Among Peoples, Public figures (ex. Rupert Murdoch, Jon Hamm), Tokyo District Court, Lawyer Hiroyuki Tomita, Unnamed Japanese plaintiff, German Federal Court of Justice, Unnamed chairman of German corporation, Albert Yeung Sau-Shing, High Court of Hong Kong, Dr. Duffy, High Court of Victoria, Milorad Trkulja",0,0,False,,"The Google Autocomplete feature ""predicts and displays search queries based on other users' search activities and the contents of web pages indexed by Google.""
Google Images displays results based on the matches of search queries to alt tags of images uploaded to web sites on Google","images, search queries, image alt tags",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,"autocomplete, search optimization, image search, search suggestion","search engine optimization, natural language processing",
CSETv1_Annotator-1,54,True,54,005,3. In peer review,,False,no,no,no,yes,no,no,no,no,yes,imminent risk of tangible harm (near miss) did occur,yes,yes,True,AI tangible harm near-miss,,no,maybe,no,no,yes,"financial means, race",,yes,yes,yes,True,yes,,2014,,,True,no,no,,,US,North America,,,"This incident describes a variant of many different events involving predictive policing software. 

In Oakland, CA, in 2015, the Police Department convinced the mayor to earmark funds for predictive policing software but later rescinded the funding request.

In Jennings, MO, in 2015, the St. Louis County Police Department tried out software created by HunchLab.

In Richmond, VA, in 2016, the Police Department terminated its contract with PredPol halfway into a three year program because it found no measurable impact on crime reduction.

In 2021, Gizmodo published a report about PredPol where it found predictive policing software disproportionately targets low-income, Black, and Latino neighborhoods.

PredPol was also briefly mentioned as being deployed in other locations like Santa Cruz, CA, Atlanta, GA, Chicago, IL, and Los Angeles, CA.","Geolitica (formerly PredPol), UCLA Institute for Pure and Applied Mathematics, LAPD Captain Sean Malinowski, PredPol, HunchLab, Azavea, Oakland Police Department, St. Louis County Police Department, Gizmodo, Richmond Police Department, Residents in PredPol targeted block groups, Residents in PredPol targeted block groups",0,0,False,,"PredPol takes in past crime data and spits out predictions about where future crimes are more likely to occur. It turns those predictions into 500 by 500 foot red boxes on a Google map, indicating areas that police officers should patrol when they're not actively responding to a call. 

HunchLab surveys past crimes and also digs into other factors like population density; census data; the location of bars, churches, schools, and transportation hubs; schedules for home games - even moon phases to determine where patrols would have the most impact.","past crimes, crime data, population density, census data, maps, police shifts, patrol shifts",law enforcement,yes,Autonomy3,,No. Not intentionally designed to perform harm,,predictive policing,,
CSETv1_Annotator-1,106,True,106,005,2. Initial annotation complete,,False,no,yes,no,yes,no,no,no,maybe,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,yes,yes,"disability, race, sexual orientation or gender identity, sex",,yes,yes,yes,True,yes,,2021,01,,False,no,no, ,,KR,Asia,,,,"Scatter Lab, Lee Luda, Facebook Messenger, Korean Facebook Messenger users",0,0,False,,Lee Luda was a South Korean chatbot trained on messages from around 10 billion real-life conversations between young couples taken from KakaoTalk for Scatter Lab's Science of Lab app. Lee Luda was meant to emulate a 20-year-old female college student.,text conversations,"Arts, entertainment and recreation",no,Autonomy1,,No. Not intentionally designed to perform harm,,chat bot,mesh autoencoders,
CSETv1_Annotator-1,108,True,108,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,yes,no,yes,race,Facial recognition systems misidentify black people at a rate 5-10 times more than white people,yes,yes,yes,True,yes,,2021,07, ,False,no,no,Livonia,MI,US,North America,,,,"Idemia, Lamya Robinson, Riverside Arena Skating Rink, Unnamed facial recognition system",0,0,False,,,facial images,"Arts, entertainment and recreation",no,Autonomy3,The system provides administrators with matches so that human workers can ban profile matches from entering the premises. The facial recognition systems alone cannot prevent humans from entering an establishment.,No. Not intentionally designed to perform harm,,facial recognition,,
CSETv1_Annotator-1,109,True,109,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,maybe,non-imminent risk of tangible harm (an issue) occurred,yes,yes,False,unclear,The article notes the potential for nefarious actors like stalkers to use the PimEyes tool to do tangible harm.,no,no,no,no,no,none,,maybe,yes,yes,False,maybe,It is unclear whether PimEyes violates peoples' privacy and whether or not that constitutes a rights violation.,2021, ,,False,no,no,,,,Global,,,"2021 represents the date when the article was posted, not necessarily PimEyes' date of development.","PimEyes, Lukasz Kowalczyk and Denis Tatina",0,0,False,,"PimEyes is a face-searching tool that ""can scan through more than 900 million images from across the Internet and find matches with startling accuracy."" It uses bots known as ""spiders"" to crawl the Web, ""scanning for photos of faces and then recording those images as numerical code. If the search tool is later shown a photo that resembles one of those images, it will return a direct link to where the image can be found.""",images,"Arts, entertainment and recreation, administrative and support service activities",no,Autonomy1,,No. Not intentionally designed to perform harm,,facial recognition,,
CSETv1_Annotator-1,110,True,110,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,yes,no,no,no,yes,"disability, financial means","Although the algorithm didn't specifically target disabled people or people with lesser financial means, the algorithm was only used on people who needed at-home care provided by the state. These people necessarily were those who are disabled and have lesser financial means.",yes,yes,yes,True,yes,,2018,,,False,no,no,,AR,US,North America,,,,"Tammy Dobbs, InterRAI, Arkansas Department of Human Services, Arkansas Medicaid program recipients, Idaho welfare recipients, Bradley Ledgerwood, Arkansas Medicaid program recipients, Idaho welfare recipients",0,0,True,It is unclear how many injuries or hospitalizations were caused because of the hour cuts mandated by the algorithm,"The algorithm computes about 60 descriptions, symptoms, and ailments — fever, weight loss, ventilator use — into categories, each one corresponding to a number of hours of home care.","symptoms, ailments",human health and social work activities,yes,Autonomy1,,No. Not intentionally designed to perform harm,,allocate hours,,
CSETv1_Annotator-1,25,True,25,005,2. Initial annotation complete,,False,yes,no,no,yes,no,yes,no,no,yes,"no tangible harm, near-miss, or issue",yes,maybe,False,none,"The two autonomous cars were able to avoid each other successfully. Thus, there is no adverse outcome for the technology to link to. Since there was no harm, there is no potentially identifiable specific entity that experienced harm. This incident may represent the success of autonomous driving systems to detect and avoid accidents, even with each other.",no,no,no,no,no,none,,no,yes,no,False,no,,2014,06, ,False,yes,yes,Palo Alto,CA,US,North America,,,,"Google, Delphi Technologies, Google autonomous Lexus RX400h, Delphi autonomous Audi Q5 Crossover, John Absmeier",0,0,False,,"Self-driving vehicles are designed to autonomously navigate roads and respond to obstacles and situations in real time. The Delphi vehicle was ""equipped with lasers, radar, cameras, and special computer software designed to enable the vehicle to drive itself, with a person at the wheel as backup."" The Google vehicle was ""fitted with similar hardware and software/""","camera input, radar, laser input, spatial data",transportation and storage,no,Autonomy2,"At least in the Delphi car, a human was present as a passenger with the ability to observe and override the system's decisions in real time.",No. Not intentionally designed to perform harm,"Vehicles (Audi Q5 Crossover, Lexus RX400h Crossover)","autonomous navigation, self-driving",,
CSETv1_Annotator-1,71,True,71,005,2. Initial annotation complete,,False,yes,no,no,yes,no,yes,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,no,no,no,no,none,,no,yes,yes,True,no,,2014,10, ,False,no,yes,,,US,North America,,,"This incident describes a variant with several events.

The first event occurred in October 2014, when a Delphi autonomous vehicle was broadsided by another car as it was waiting to make a left turn.

On February 14, 2016, in Mountain View CA, a self-driving Lexus SUV developed by Google detected a pile of sandbags surrounding a storm drain in its path and moved to the center lane to avoid the hazard. Three seconds later it collided with the right side of a city bus.

On September 23, 2016, in Mountain View, CA, a commercial van running a red light struck one of Google's autonomous Lexus SUVs as it crossed an intersection.

On May 14, 2018, in Phoenix, AZ, an autonomous car being tested by Google-owned Waymo swerved to avoid another car and left the human operator with minor injuries.","Delphi Technologies, Delphi Audi SQ5, Unnamed car, Google, Google Lexus SUV, Mountain View city bus, Lexus test driver, Google Lexus RX450 SUV, Commercial van and driver, Waymo, Waymo Chrysler Pacifica, Waymo self-driving car human operator, Honda sedan and driver",0,1,False,,"Self-driving vehicles are designed to autonomously navigate roads and respond to obstacles and situations in real time. They are likely equipped with lasers, radar, cameras, and computer software designed to enable the vehicle to drive itself, with a person at the wheel as backup.","camera input, laser input, radar, spatial data",transportation and storage,no,Autonomy2,,No. Not intentionally designed to perform harm,"Vehicles (Lexus, Audi, Chrysler Pacifica)","autonomous navigation, self-driving",,
CSETv1_Annotator-1,111,True,111,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,no,no,no,no,none,,no,yes,yes,True,no,,2021,06,,False,no,no,,,US,North America,,,,"Stephen Normandin, Amazon, Amazon Flex drivers, Amazon Flex human resources algorithm, Ryan Cope, Neddra Lira",0,0,False,,"The Amazon Flex Delivery human resources algorithm evaluates drivers based on several factors including whether they delivered within a certain time period, where they left the package, and more to ""decide which drivers get more routes and which are deactivated."" Ratings include four categories: Fantastic, Great, Fair or At Risk. The system is relatively opaque.",performance patterns,"wholesale and retail trade, transportation and storage",no,Autonomy1,,No. Not intentionally designed to perform harm,,"performance evaluation, human resources",,
CSETv1_Annotator-1,112,True,112,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,"Many of the police departments that deployed ShotSpotter terminated expensive contracts because it was ineffective. The main harm in this incident is that ShotSpotter is ineffective: it wastes officers' time by prompting a response to shots fired calls that cannot be verified or are not gunfire. It doesn’t result in more arrests or convictions. It increases policing in historically overpoliced neighborhoods. Microphones can record conversations of people in these neighborhoods. However, these harms are not necessarily tangible.",no,no,no,no,maybe,race,Investigations conducted by organizations like the ACLU have found that ShotSpotter false alarms send police on numerous trips into communities for no reason and on high alert.,maybe,yes,yes,True,maybe,,2008,,,True,no,yes,,,US,North America,,,The city of Troy rolled out the surveillance devices in late 2008,"ShotSpotter, SST, Troy Police Patrol, San Francisco police, Charlotte Mecklenburg Police Department, Detroit Police Department, Oakland Police Department, Chicago Police Department, Residents in neighborhoods with ShotSpotter microphones",0,0,False,,"The ShotSpotter system records all loud noises, using at least three microphones to locate gunshots within a 25-meter radius. Then, SST staff review each report to make sure the computer flags only gunshots. The technology's accuracy depends on everything from ""topography, temperature, humidity and wind speed, as well as the trained ears of employees.""","audio inputs, microphone inputs",law enforcement,yes,Autonomy3,ShotSpotter detects loud noises and sends the information to human reviewers.,No. Not intentionally designed to perform harm,microphones,gunshot detection,,
CSETv1_Annotator-1,113,True,113,005,2. Initial annotation complete,,False,no,yes,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,no,yes,race,,yes,yes,yes,True,yes,,2021,09, ,False,no,no,,,,Global,,,,"Facebook, Facebook Watch, Black people",0,0,False,,The article did not include much information about the algorithm used to identify video contents and suggest new video topics on Facebook.,Facebook videos,information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,video suggestion,,
CSETv1_Annotator-1,114,True,114,005,2. Initial annotation complete,,False,no,maybe,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,no,yes,race,,yes,yes,yes,True,yes,,2018,07,,False,no,no, ,,US,North America,,,,"Amazon, Rekognition, Members of Congress, Black people",0,0,False,,"ACLU used Rekognition to build a face database and search tool using 25,000 publicly available arrest photo. Then, they ""searched that database against public photos of every current member of the House and Senate.""","arrest photos, images, facial images",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,facial recognition,,
CSETv1_Annotator-1,115,True,115,005,2. Initial annotation complete,,False,no,maybe,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,no,yes,sex,,yes,yes,yes,False,no,"It is unclear that any harmed entities can be characterized in this incident. Although the AI did exhibit bias against women,  the extent of the harm stopped at the ineffectiveness of the tool.",2020,07, ,False,no,no,,,,Global,,,,"Genderify, Arevik Gasparayan",0,0,False,,"Genderify was designed to ""identify a person's gender by analyzing their name, username or email address"" by using ""data based on sources such as governmental and social network information.""","names, usernames, strings, email addresses",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,name classification,machine learning,
CSETv1_Annotator-1,116,True,116,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,"Delivery drivers weekly bonuses and rewards are determined in part by the number of ""events"" they are found to be a part of by the Netradyne cameras. This is a tangible financial harm caused by AI.",no,no,no,no,no,none,,no,yes,yes,True,no,,2021,,,False,no,yes,,,US,North America,,,,"Amazon, Amazon delivery drivers, Amazon van surveillance cameras, Netradyne",0,0,False,,"Netradyne cameras have ""four lenses that record drivers when they detect ""events"" such as following another vehicle too closely, stop sign and street light violations, and distracted driving. When the camera detects an ""event,"" it uploads the footage to a Netradyne interface accessible to Amazon and its delivery companies, and in some instances, a robotic voice speaks out to the driver: ""distracted driving"" or ""maintain safe distance."" Each time the camera registers an event, footage is uploaded into a system, recorded, and affects a score drivers receive at the end of the week for safe driving. For many Amazon drivers, these performance scores determine whether they receive weekly bonuses, prizes, and extra pay.""","camera input, video input","wholesale and retail trade, transportation and storage",no,Autonomy1,,No. Not intentionally designed to perform harm,surveillance cameras,"driver surveillance, safe driving detection",,
CSETv1_Annotator-1,117,True,117,005,2. Initial annotation complete,,False,no,yes,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,no,no,none,"The trend of recommending physiognomically similar accounts was consistent across different races, genders, and appearances. Therefore, it is inaccurate to say that any one group was treated differently than another.",no,yes,yes,False,no,,2020,02,,False,no,no,,,,Global,,,,"TikTok, Mark Faddoul, Filter bubble algorithm",0,0,False,,Tiktok claims that its follow suggestion recommender algorithm is based on the similarity of the content between accounts and the followings of people who follow the original account. Faddoul noted that this often resulted in recommendations of accounts that were very similar in appearance rather than just content.,"Tiktok accounts, followed accounts","Arts, entertainment and recreation",no,Autonomy1,,No. Not intentionally designed to perform harm,,follow suggestion,"automatic featurization, collaborative filtering",
CSETv1_Annotator-1,120,True,120,005,2. Initial annotation complete,,False,no,yes,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,no,no,none,"4.4 - ""Many of the bot's responses were harmless and amusing...but others promoted conspiracy theories and discussed extremely sensitive topics."" The discussion of conspiracy theories and sensitive topics does not constitute detrimental content, even if the behavior of the bot was questionable.",no,yes,yes,False,no,,2020,,,False,no,no,,,,Global,,,,"GPT-3 powered bot the gentlemetre, Reddit, Philip Winston, Philosopher AI, Murat Ayfer",0,0,False,,The bot thegentlemetre was a text generator powered by the app Philosopher AI's use of GPT-3,text,"Arts, entertainment and recreation",no,Autonomy1,,No. Not intentionally designed to perform harm,,text generation,GPT-3,
CSETv1_Annotator-1,122,True,122,005,2. Initial annotation complete,,False,no,yes,no,yes,no,no,no,no,no,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,"Although the entity that experienced the tangible harm in this case was Facebook and not the users, there still was tangible financial loss in this incident as mandated by the court.",no,maybe,no,no,no,none,"Privacy does not necessarily fall under ""human rights, civil rights, civil liberties, or democratic norms."" However, Facebook's guilty verdict indicates that the Illinois citizens' rights had been violated/",no,yes,yes,True,no,,2020, ,,False,no,no,,IL,US,North America,,,2020 refers to the date during which Facebook agreed to pay the class-action lawsuit settlement.,"Facebook, Tag Suggestions tool, Facebook users in Illinois",0,0,False,,The Tag Suggestions tool scans a user's face in photos and offers suggestions about who that person might be. ,"photos, facial images","Arts, entertainment and recreation",no,Autonomy1,,No. Not intentionally designed to perform harm,,facial recognition,facial recognition,
CSETv1_Annotator-1,121,True,121,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,imminent risk of tangible harm (near miss) did occur,yes,yes,True,AI tangible harm near-miss,"It is unclear that the autonomous drone killed or injured anyone. However, it is certain that the drone was used to ""hunt[ed] down and remotely engage[d]"" retreating [Haftar-affiliated forces] which indicates an imminent risk of tangible harm, especially considering it was not being supervised by a human.",no,no,no,no,no,none,,no,yes,yes,True,no,,2020,03,,False,no,yes,Tripoli,,LY,Africa,,,,"STM Kargu-2 drone, STM (STM (Savunma Teknolojileri Mühendislik ve Ticaret A.Ş.), Soldiers loyal to the Libyan General Khalifa Haftar, Forces backed by the government based in Tripoli",0,0,True,"It is likely, but not certain, that no one was hurt or killed in this incident.","The Kargu is a lethal, autonomous, ""loitering"" drone that can ""use machine learning-based object classification to select and engage targets, with swarming capabilities in development to allow 20 drones to work together."" ","geospatial data, sensor data",defense,yes,Autonomy1,,Yes. Intentionally designed to perform harm and did create intended harm,,targeted drone strike,"computer vision, object classification",
CSETv1_Annotator-1,123,True,123,005,2. Initial annotation complete,,False,no,no,no,yes,yes,no,no,no,maybe,non-imminent risk of tangible harm (an issue) occurred,yes,yes,True,AI tangible harm issue,"The study found that the Epic Sepsis Model was worse than expected at identifying sepsis. Although the incident describes a test, the model's deployment by ""170 customers that represent hundreds of hospitals"" indicates that some patients under the care of those hospitals are at a risk of incorrectly not being identifying as at high risk for sepsis because of the algorithm. This could impact their care and physical health/safety.",no,no,no,no,no,none,,no,yes,yes,True,no,,2021,06,,False,no,no,,,US,North America,,,The date refers to the study/research and does not encapsulate the length of time of deployment of the Epic Sepsis Model,"Epic Systems, Epic Sepsis model, University of Michigan Medical School researchers, Michigan Medicine patients, Epic Sepsis Model customer hospitals, Patients at Epic customer hospitals",0,0,False,,"Epic Sepsis Model ""calculates and indicates ""the probability of a likelihood of sepsis"" to help clinicians identify hard-to-spot cases."" ""ESM failed to identify 67 percent of the patients with sepsis; of those patients with ESM sepsis alerts, 88 percent did not have sepsis.""","electronic health records, patient data",human health and social work activities,yes,Autonomy3,"9.4 - some of the hospitals that deployed SEM were likely public hospitals.
9.5 - The tool is able to summarize and look for indications of sepsis, but the final decisions on care and patient treatment are made by doctors. They may take the tool's recommendations into consideration.",No. Not intentionally designed to perform harm,,"identify sepsis, diagnose sepsis",large language model,
CSETv1_Annotator-1,124,True,124,005,2. Initial annotation complete,,False,no,no,maybe,yes,no,yes,no,no,yes,imminent risk of tangible harm (near miss) did occur,yes,yes,True,AI tangible harm near-miss,"Black patients assigned understated risk scores by the algorithm are at risk of not being eligible for necessary health treatments that could endanger their physical health and safety. Because this system was deployed, this incident describes an AI tangible harm near-miss.",no,no,no,no,yes,"race, financial means",,yes,yes,yes,True,yes,,2019,10,24,False,,, ,,US,North America,,,6.1-6.3 - This date refers to the publication of the study that concluded that the algorithm was less likely to refer black people than white people who were equally sick to programmes that aim[ed] to improve care for patients with complex medical needs.,"Large academic hospital, Optum, Unnamed algorithm, Black patients, Black patients, Ziad Obermeyer and other researchers",0,0,False,,The algorithm assigned people to high-risk categories on the basis of how much their treatment cost the hospital.,"patient data, treatment cost",human health and social work activities,maybe,Autonomy3,"9.4. - It is unclear whether the deployer hospital was public or private.
9.5 - The algorithm assigned risk scores, but the final decisions about care are made by physicians who may take the results of the algorithm into consideration.",No. Not intentionally designed to perform harm,,assign risk ,,
CSETv1_Annotator-1,125,True,125,005,2. Initial annotation complete,,False,yes,no,maybe,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,no,no,no,no,none,,no,yes,yes,True,no,,2019,,,True,no,yes,,,US,North America,,,6.1-6.3 - this incident involves a report detailing injury rates across more than 150 Amazon fulfillment centers from 2016 through 2019,"Amazon, Amazon warehouse robots, Amazon warehouse workers, Reveal from The Center for Investigative Reporting",0,0,True,"The study revealed that injury rates were higher in locations with warehouse robots. However, it is unclear exactly how many people were caused injury or damage to physical safety/health within those injury rates at each location.","Amazon robots help fill orders by bringing shelves of merchandise to workers for packing and scanning. They ""bring items so quickly that the productivity expectations for workers more than doubled.""","worker position, geospatial data",wholesale and retail trade,no,Autonomy1,,No. Not intentionally designed to perform harm,warehouse robot,"delivery , navigation",,
CSETv1_Annotator-1,118,True,118,005,3. In peer review,,False,no,no,no,yes,no,yes,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,yes,yes,religion,"""Compared to other religions, the model consistently displays much higher rates of mentioning violence when the word “Muslim” is included in the prompt... It doesn't just regurgitate racist stuff it's read online, it actually makes up its own fresh new bigotry text.""",yes,yes,yes,True,yes,,2021,01,,False,no,no,,,,Global,,,"The date refers to the publication of a paper by Abubakar Abid detailing the ""Persistent Anti-Muslim Bias in Large Language Models"" around which the incident is centered.","GPT-3, Researchers from Stanford and McMaster, OpenAI, Muslim people",0,0,False,,GPT-3 is a contextual large language model,text,"information and communication, professional, scientific and technical activities",no,Autonomy1,,No. Not intentionally designed to perform harm,,text generation,natural language processing,
CSETv1_Annotator-1,119,True,119,005,3. In peer review,,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,no,no,no,no,none,,no,yes,yes,True,no,,2021,07,31,False,no,no,,,RU,Europe,,,,"Xsolla, Xsolla employees, Aleksander Agapitov",0,0,False,,"It is unclear how exactly the big data analysis determined who should be fired. CEO Aleksandr Agapitov's email said employee activity in Jira, Confluence, Gmail, chats, documents, and dashboards contributed to the tagging of employees as unengaged and unproductive while they worked remotely.",employee activity,administrative and support service activities,no,Autonomy3,,No. Not intentionally designed to perform harm,,productivity optimization,,
CSETv1_Annotator-1,126,True,126,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,no,no,no,no,none,,no,yes,yes,True,no,,2021,07,16,False,yes,yes,London, ,GB,Europe,,,,"Ocado, Ocado fulfillment robots, Erith Customer Fulfillment Centre, Ocado fulfillment centre employees",0,0,False,,"Robots perform basic tasks like ""lifting, sorting, and moving groceries and bringing them to human ""pickers,"" who stand on the sidelines and pack individual customers' orders...Due to the construction of the grid, robots may pass within 0.2 inches (5 millimeters) of each other as they buzz by to fulfill their respective orders.""","geospatial data, customer orders",wholesale and retail trade,no,Autonomy1,,No. Not intentionally designed to perform harm,fulfillment robot,"navigate factory, deliver products",,
CSETv1_Annotator-1,128,True,128,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,no,no,no,no,none,,no,yes,yes,True,no,,2017,,,False,no,yes,Redmond,WA,US,North America,,,,"Eric Horvitz, Tesla, Tesla sedan, Tesla Autopilot",0,0,False,,Tesla's Autopilot is designed to autonomously navigate roads and respond to real time situations on the road.,"sensor data, camera input, road data",transportation and storage,no,Autonomy2,,No. Not intentionally designed to perform harm,Tesla sedan,autonomous navigation,,
CSETv1_Annotator-1,129,True,129,005,2. Initial annotation complete,,False,no,yes,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,yes,no,none,,yes,yes,yes,True,yes,,2021,03,,False,no,no,,,,Global,,,,"Facebook, Facebook automated moderation tools, Facebook users",0,0,False,,"Facebook's automated moderation tools, powered by artificial intelligence, are intended to flag and remove posts containing hate speech and other detrimental content.",Facebook posts,"Arts, entertainment and recreation",no,Autonomy1,,No. Not intentionally designed to perform harm,,content moderation,,
CSETv1_Annotator-1,131,True,130,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,no,no,none,,no,yes,yes,True,no,,2020,10,,False,no,maybe,,CA,US,North America,,,6.6 - the proctoring software was administered on exam takers' computers,"California Committee of Bar Examiners, California bar exam takers, California bar exam proctoring software",0,0,False,,"The algorithm is designed to ""flag people for ""suspicious"" activity and then leave it to the humans to parse through the video to make sure it was a false positive.""",video input,"professional, scientific and technical activities, administrative and support service activities, Education",yes,Autonomy3,,No. Not intentionally designed to perform harm,,exam proctoring,facial recognition,
CSETv1_Annotator-1,132,True,132,005,2. Initial annotation complete,,False,no,yes,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",maybe,yes,False,none,,no,no,maybe,yes,no,none,,yes,maybe,yes,True,yes,,2020,12,,False,no,no, ,,,Global,,,,"TikTok, TikTok accounts posting content promoting unhealthy eating habits, TikTok users, TikTok algorithm",0,0,False,,"TikTok's algorithm shows an uploaded video to a ""small group of users regardless of whether they follow the account it came from or not. If the engage with the video... it will be presented to an even larger group... the process continues until the clip eventually goes viral.""","TikTok posts, TikToks","Arts, entertainment and recreation",no,Autonomy1,,No. Not intentionally designed to perform harm,,content suggestion,,
CSETv1_Annotator-1,133,True,133,005,2. Initial annotation complete,,False,no,yes,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",maybe,maybe,True,none,"3.2 - The reporting process is likely automated rather than AI.
3.3 - Users and online trolls exploited a vulnerability in the automated content reporting systems. It is not clear that the technology caused the harm; rather, the trolls used the AI in an unintended way.",no,no,no,maybe,yes,"disability, race, sexual orientation or gender identity","4.4-4.6 - TikTok accounts run by creators who are BIPOC, LGBTQ+, and disabled are wrongfully reported by discriminatory viewers for detrimental content, which negatively affects their ability to stay on the platform.",yes,maybe,maybe,True,maybe,,2020,12, ,False,no,no,,,,Global,,,,"Rosalynne (Rose) Montoya, TikTok, TikTok content moderation tools",0,0,False,,"""If enough people report a video on TikTok (even if it's a false report) the video is removed automatically... after enough violations (even if appealed and deemed to be appropriate) an account can be deleted."" BIPOC, LGBTQ+, and disabled creators are unhappy with the automated content moderation tools that negatively affect their ability to stay on the TikTok platform even if they appeal and get violations removed.","TikTok posts, TikTok accounts","Arts, entertainment and recreation",no,Autonomy1,,No. Not intentionally designed to perform harm,,content moderation,,It is unclear that this technology is AI rather than an automated system.
CSETv1_Annotator-1,134,True,134,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,no,no,no,no,none,,no,yes,yes,True,no,,2020,12,25,False,no,yes,Fuzhou,Fujian,CN,Asia,,,,"Shopping guide robot, Fuzhou Zhongfang Wanbaocheng mall, Unnamed Chinese mall-goers",0,0,False,,It is unclear what the shopping guide robot's tasks are or how it was designed.,,"wholesale and retail trade, administrative and support service activities",no,Autonomy1,,No. Not intentionally designed to perform harm,white rectangular rolling robot,shopping guide,,
CSETv1_Annotator-1,135,True,135,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,no,yes,"race, sex","The GRADE algorithm, which was designed to predict which students most closely matched previously successful PhD applicants, encoded previous biases in admissions.",yes,yes,yes,True,yes,,2013, ,,False,no,no,Austin,TX,US,North America,,,"6.1 - ""The system was used to organize graduate admissions in the Department of Computer Science between the 2013 and 2019 academic years.""","University of Texas at Austin, GRADE algorithm, Austin Waters and Risto Miikkulainen, University of Texas at Austin Computer Science Department PhD applicants",0,0,False,,"The software was trained using the details of previously accepted students, the idea being to teach the system to identify people the school would favor, and to highlight them to staff who would make the final call on the applications... Hopefuls were assigned a score from zero to five by the code.","GPA, university previously attended, letters of recommendation, area of research interest, faculty advisor ",Education,yes,Autonomy3,9.4 - The University of Texas at Austin is a public university.,No. Not intentionally designed to perform harm,,assess applicants,logistic regression model,
CSETv1_Annotator-1,127,True,127,005,2. Initial annotation complete,,False,no,yes,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,no,yes,race,,yes,yes,yes,True,yes,,2020,06,09,False,no,no,,,,Global,,,,"Jade Thirlwall, Leigh-Anne Pinnock, Microsoft, Microsoft AI journalists, MSN.com",0,0,False,,"Microsoft's robot editors select, edit, and repurpose stories from external news sites. Articles are then hosted on Microsoft's website and ad revenue is then shared with original publishers.","news articles, images","Arts, entertainment and recreation",no,Autonomy1,,No. Not intentionally designed to perform harm,,article repurposing,,
CSETv1_Annotator-1,136,True,136,005,2. Initial annotation complete,,False,no,yes,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",maybe,yes,False,none,,no,no,no,no,no,none,,no,maybe,yes,False,no,,2020,12,,False,no,no,,,,Global,,,,"Advertisers, Brand safety detection technologies, Websites with ad spaces",0,0,False,,Brand safety technology is designed to determine if a page is brand safe or unsafe - they must use crawlers to load the webpages and collect all the text content on the page for brand safety analysis.,"keywords, article text, webpage content","Arts, entertainment and recreation",no,Autonomy1,,No. Not intentionally designed to perform harm,,brand safety detection,text scraping,
CSETv1_Annotator-1,138,True,138,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,no,yes,race,,yes,yes,yes,True,yes,,2020,,,True,no,no,,IL,US,North America,,,,"University of Illinois at Urbana-Champaign, Proctorio, University of Illinois students, University of Illinois students of color",0,0,False,,"Proctorio uses machine learning technology and advanced facial detection to record students through their webcams as they take their test. The software monitors the position of the student's head. If the software detects any suspicious behavior, it automatically notifies the professors, who can review the recordings. The software also enables the professors to see the websites that their students opened while they were taking the test, and it disables computer functions like copying, pasting, and printing.",webcam input,Education,yes,Autonomy3,,No. Not intentionally designed to perform harm,,exam proctoring,facial detection,
CSETv1_Annotator-1,139,True,139,005,2. Initial annotation complete,,False,no,no,maybe,yes,no,yes,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,yes,no,none,,yes,yes,yes,True,yes,,2021,01,,False,no,no,,,,Global,,,,"Amazon, University of Washington researchers (Prerna Juneja and Tanushree Mitra), Amazon search and recommendation algorithms, Amazon users",0,0,False,,"Research found that 10.47% of search results on Amazon promoted misinformative health products. Those products were ranked higher than debunking products. In addition, users performing actions on misinformative products were presented with more misinformation in their homepages, product page recommendations, and pre-purchase recommendations.","Amazon account information, Amazon products",wholesale and retail trade,no,Autonomy1,,No. Not intentionally designed to perform harm,,"search suggestion, product recommendation",search engine optimization,
CSETv1_Annotator-1,140,True,140,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,no,yes,race,,yes,yes,yes,True,yes,,2021,02,,False,no,no,Toronto,ON,CA,North America,,,,"University of Toronto, University of Toronto BIPOC students, ProctorU",0,0,False,,"ProctorU ""uses a diverse group of trained human proctors, assisted by technology, to safeguard exam integrity and assist students."" Services provided include identity verification, webcam monitoring, and more.",webcam input,Education,yes,Autonomy3,,No. Not intentionally designed to perform harm,,"exam proctoring, remote proctoring",facial detection,
CSETv1_Annotator-1,142,True,142,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,no,non-imminent risk of tangible harm (an issue) occurred,yes,yes,True,AI tangible harm issue,,no,no,no,no,yes,disability,,yes,yes,yes,True,yes,,2021, ,,False,no,no,,,,Global,,,,"Meta (Facebook and Instagram), Mighty Well, Facebook and Instagram marketing algorithms, Yarrow, Small adaptive clothing companies, Mighty Well, Yarrow, Small adaptive clothing companies",0,0,False,,"A company makes an ad, or creates a shop, and submits it to Facebook for approval. This is an automated process. If the system flags a potential violation, the ad or product is sent back to the company as noncompliant.",advertisements,"wholesale and retail trade, information and communication",no,Autonomy1,,No. Not intentionally designed to perform harm,,advertisement screening,,
CSETv1_Annotator-1,143,True,143,005,2. Initial annotation complete,,False,no,maybe,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,yes,no,none,"4.4 - Detrimental content was involved. However, this incident is not about the proliferation of detrimental content on such platforms. Rather, it is about the arbitrary reporting of non-detrimental content as detrimental content, regarding in censorship and suspension.",no,yes,yes,True,no,,2021, ,,False,no,no,,,RS,Europe,,,,"Twitter, Facebook, Facebook and Twitter content moderation algorithms, Partners Serbia, Balkan NGOs, media organizations, and public figures",0,0,False,,"Facebook and Twitter use a hybrid model, a combination of artificial intelligence and human assessment when reviewing reports of hate speech. Both social networks adopt a ""proactive approach,"" which means they remove content or suspend accounts even without a report of suspicious conduct.","Facebook posts, Twitter posts",information and communication,no,unclear,It is unclear how much of the content moderation process passes through the human reviewers in Facebook and Twitter's hybrid models.,No. Not intentionally designed to perform harm,,content moderation,,
CSETv1_Annotator-1,144,True,144,005,2. Initial annotation complete,,False,no,yes,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,maybe,no,none,,no,yes,yes,True,no,,2020,06,,False,no,no,,, ,Global,,,,"Youtube, Youtube content moderation algorithms, Agadmator (Antonio Radic)",0,0,False,,Youtube's moderation system relies on both human and AI algorithms.,"Youtube videos, Youtube content","Arts, entertainment and recreation",no,unclear,It is unclear how much of the reviewing process goes through humans as opposed to AI.,No. Not intentionally designed to perform harm,,content moderation,,
CSETv1_Annotator-1,145,True,145,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,yes,yes,non-imminent risk of tangible harm (an issue) occurred,yes,yes,True,AI tangible harm issue,Stopping incorrectly could cause accidents on the road.,no,no,no,no,no,none,,no,yes,yes,True,no,,2021,07,22,False,no,yes, ,,US,North America,,,,"Tesla, Tesla vehicle, Tesla self-driving function, Tesla user @JordanTeslaTech",0,0,False,,Tesla's full self-driving technology is meant to autonomously navigate and respond to ongoing situations on the road. This includes reacting to traffic lights and stop signs.,"camera input, spatial data",transportation and storage,no,Autonomy2,,No. Not intentionally designed to perform harm,"Tesla vehicle (Model 3, Model S, Model X)",autonomous navigation,,
CSETv1_Annotator-1,107,True,107,001,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,no,True,none,"Through the reported AI systems, the Uyghurs are experiencing differential treatment and potential human rights violations because of persistent surveillance.  The Uyghurs in China have experienced tangible harm from the Chinese government. However, the reports do not provide clear evidence linking the specific use of the reported AI systems to the tangible harm experienced by the Uyghurs.",no,yes,no,no,yes,"geography, race",,yes,yes,yes,True,yes,,2020,12,17,True,no,no,,,CN,Asia,,,,"Alibaba, Alibaba Cloud, Uyghurs, AI-based surveillance system on Alibaba Cloud, Uyghurs, Chinese government, IPVM, Huawei, Megvii, Face++, Chinese Academy of Sciences, SenseTime, Uyghurs",0,0,True,,,,law enforcement,yes,Autonomy3,,Yes. Intentionally designed to perform harm and did create intended harm,,image classification,computer vision,
CSETv1_Annotator-1,141,True,141,005,2. Initial annotation complete,,True,yes,maybe,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,no,True,none,"Because Fair misunderstood that Instagram's copyright detection algorithms would strike Devermont's livestream for including music, the algorithm did not achieve his intended purpose and thus is not linked to the adverse outcome in this event.",no,maybe,no,no,no,none,Sergeant Billy Fair may have been violating Sennet Devermont's right to free speech and free expression by trying to stop him from recording their interaction.,maybe,yes,no,True,no,,2021,02,05,False,no,no,Beverly Hills,CA,US,North America,,,,"Sergeant Billy Fair, Instagram copyright detection algorithm, Sennett Devermont",0,0,False,,"Any video that contains music, even if it's playing in the background, is potentially subject to removal by Instagram. If the copyright algorithm detects music that violates Instagram's music guidelines (ensure there is a ""visual component"", only use short clips), it may end or mute the livestream.","livestream, livestream audio input","information and communication, Arts, entertainment and recreation",no,Autonomy1,,No. Not intentionally designed to perform harm,,copy right violation detection,"detection, classification",
CSETv1_Annotator-1,137,True,137,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,non-imminent risk of tangible harm (an issue) occurred,no,yes,True,none,"3.1 - The adverse outcome of this incident is a lack of transparency/legal dispute over whether the Israeli Tax Authority should be obligated to disclose the software/algorithm used to make tax decisions. It is unclear that any individual or business assessed by the algorithm was financially harmed or was forced to pay more taxes than they would have if assessed by a human. However, there is a non-imminent risk of unjustified financial loss that could occur in the future if taxpayers continue to be kept in the dark regarding tax decisions made by algorithms.
3.2 - It is unlikely that there was any AI involved in this incident. The algorithm likely does not use AI in complex decision making, but rather relies on a formula or set of equations to determine the tax.",no,no,no,no,no,none,,no,no,yes,True,no,,2014,,,True,no,no,,,IL,Asia,,,"6.1 - The incident describes that Har Shemesh's original request to the Tax Authority asking it to explain how it had calculated a fine the farm was required to pay occurred in 2014.
6.10 - Israel is a country in the Middle East that is geographically located on the continent of Asia.","Israel Tax Authority, Moshe Har Shemesh, Israel District Court, Israel Supreme Court, Israeli taxpayers",0,0,False,,It is unclear which factors or mathematical relationships the tax algorithm considered when making its decisions.,"income statements, tax returns","financial and insurance activities, public administration",yes,unclear,It is unclear whether human reviewers were involved in the process in between the algorithm's decisions and the final result. ,,,,,not AI
CSETv1_Annotator-1,146,True,146,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,yes,yes,"race, sex, sexual orientation or gender identity","Especially in the beginning, Delphi applied moral judgments to neutral identifiers based on qualities like race. For example, it said ""being a white man"" is more morally acceptable than ""being a black woman."" Since then, Ask Delphi has been updated with fixes to better detect offensive speech and guard against statements implying racism and sexism.",yes,yes,yes,True,yes,,2021,10,14,False,no,no, ,,,Global,,,"Ask Delphi was launched on October 14th, 2021. It was developed at a research institute in the United States but the website can be accessed outside of the United States as well.","Ask Delphi, Allen Institute for AI, Ask Delphi users, Ask Delphi users, Mechanical Turk reviewers",0,0,False,,Ask Delphi is a neural network (mathematical system loosely modeled on the web of neurons in the brain) that analyzed more than 1.7 million ethical judgments by human reviewers from Mechanical Turk from everyday scenarios from websites and other sources. ,"ethical judgments, ethical scenarios",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,ethical decision making,"machine learning, natural language processing",
CSETv1_Annotator-1,147,True,147,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,no,no,no,no,none,"Although no special interest intangible harm occurred according to CSET definitions, the bank robbers did break the law.",no,yes,yes,True,no,,2020,,,False,no,no,,Hong Kong,CN,Asia,,,,"Japanese company branch manager, Unnamed Japanese company, Martin Zelner, Unnamed Japanese parent company director, Centennial Bank, Dubai Public Prosecution Office, Bank fraudsters",0,0,False,,"The fraudsters used ""deep voice"" technology to clone a director's speech to convince a branch manager to authorize money transfers","audio inputs, speech, voice input",financial and insurance activities,no,Autonomy3,The deepfake technology was only a tool in this instance which helped robbers facilitate the scam. It would not have occurred without humans actively choosing to use the AI for nefarious purposes.,No. Not intentionally designed to perform harm,,deepfake audio generation,,
CSETv1_Annotator-1,148,True,148,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,maybe,"no tangible harm, near-miss, or issue",yes,yes,True,none,3.2 - Overlay vendors offer products like on-page assistive technologies but also claim that they are using artificial intelligence to render websites complaint with laws and standards having to do with accessibility,no,no,no,no,yes,disability,"Overlays as solutions to accessibility are not effective at accommodating webpages for people with disabilities. Not only are they misleading and misadvertized, but they are also ineffective.",yes,yes,yes,True,yes,,2021,,,True,no,no,,,,Global,,,,"Overlay vendors, Overlay accessibility products, Webpages that install overlay accessibility products, Web users with disabilities, Accessibility Guidelines Working Group of the Worldwide Web Consortium",0,0,False,,"Overly products purport to deliver automated compliance with ADA and WCAG standards. Early versions included small user interface controls that read the page's content aloud. Similarly-positioned products added ""widgets"" intended to function as on-page assistive technologies that do things like increase font size, change the contrast of the colors on the page, and change the appearance of certain types of content on the page. Most recently, vendors of these products claim that their product can repair underlying code quality problems in the sites on which they're deployed using artificial intelligence.","webpage, webpage code",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,accessibility compliance,,
CSETv1_Annotator-1,149,True,149,005,2. Initial annotation complete,,False,maybe,no,no,yes,no,yes,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,no,no,no,no,none,,no,yes,yes,True,no,,2018,,,True,no,no,,,US,North America,,,Zillow Offers was launched in 2018,"Zillow, Zillow Offers, Zestimate, Zillow Offers employees",0,0,False,,"Zestimate is a machine learning assisted estimate of a home's market value that is calculated by taking into account...data about the property gathered from sources including tax and property records, homeowner-submitted details such as the addition of a bathroom or bedroom, and pictures of the house.","tax records, property records, homeowner-submitted details, hosue pictures, home valuations",real estate activities,no,Autonomy2,It is likely that Zestimate identified and determined offer prices for houses but human employees were still necessary to execute and complete the deals,No. Not intentionally designed to perform harm,,"determine market price, market forecasting, price determination, home valuation",,
CSETv1_Annotator-1,150,True,150,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",no,no,True,none,"3.2 - The founders described Natural Cycles' algorithm as ""just math,"" indicating that there was no AI involved.
3.3 - The adverse outcomes (unwanted pregnancies) in this incident are not directly linked to the algorithm. The unwanted pregnancies occurred because users were not consistently perfect at recording their temperatures, didn't heed the app's warnings about using protection on certain days, or didn't feel completely informed about the level of vigilance they had to use on top of using the app.
3.5 - Because the harm is not directly linked to the AI, this incident does not classify as AI tangible harm.",no,no,no,no,no,none,"Although the app did not treat a group of people differently based upon a protected characteristic, by design a vast majority of the app's users are women.",no,no,no,True,no,,2018,,,False,no,no,,,,Global,,,"Though developed in Sweden, Natural Cycles is available globally.","Natural Cycles, Natural Cycles users",0,0,False,,"The Natural Cycles algorithm tracks when users are fertile or not by recording their basal body temperature which naturally rises slightly after ovulation. However, its algorithm does not involve the use of AI.","basal body temperature, menstruation cycles, sperm survival, menstruation regularity",human health and social work activities,no,Autonomy3,9.5 - The app provides recommendations on which days to abstain and which days on which the risk of pregnancy is negligible. Users can choose to adhere by these recommendations or not.,,,,,not AI
CSETv1_Annotator-1,151,True,151,005,2. Initial annotation complete,,False,yes,no,no,yes,no,yes,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,no,no,no,no,none,,no,yes,yes,True,no,,2021,10,28,False,no,yes,Fremont,CA,US,North America,,,,"Pony.ai, Pony.ai Hyundai Kona autonomous vehicle, California Department of Motor Vehicles",0,0,False,,Pony.ai's autonomous vehicle was designed to navigate and operate around obstacles on roads driverlessly.,"spatial data, video input, sensor data",transportation and storage,no,Autonomy1,The vehicle was completely driverless. There were no safety operators in the car at the time of the crash.,No. Not intentionally designed to perform harm,Hyundai Kona EV,autonomous navigation,,
CSETv1_Annotator-1,152,True,152,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,yes,no,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,Users experienced financial loss and dissatisfaction with the product because of Pepper's ineffectiveness and frequent mechanical and software errors.,no,no,no,no,no,none,,no,yes,yes,True,no,,2021,,,True,no,yes,  ,,JP,Asia,,,,"Nissei Eco Co., Pepper, Softbank Group Corp., Ittokai nursing-home operator, Tsutsumu Ishikawa",0,0,False,,"Pepper was given a perky demeanor and programmed to grasp human emotions and engage in basic conversations. Different customers intended to use it for different purposes. For example, reciting scripture or leading elderly people in singing and exercises at a nursing home.","sensor data, audio inputs","administrative and support service activities, other service activities",no,Autonomy1,,No. Not intentionally designed to perform harm,"child-sized, humanoid, white robot","chant scripture, entertain guests, household administration, cheerleading, exercise demonstration, concierge",,
CSETv1_Annotator-1,153,True,153,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,3.3 - Criminal charging documents do not mention Autopilot. But the National Highway Traffic Safety Administration confirmed that Autopilot was in use in the Tesla at the time of the crash.,no,no,no,no,no,none,,no,yes,yes,True,no,,2019,12,29,False,no,yes,Los Angeles,CA,US,North America,,,,"Kevin George Aziz Riad, Tesla, Tesla Model S vehicle, Tesla Autopilot, Honda Civic, Gilberto Alcazar Lopez, Maria Guadalupe Nieves-Lopez, unnamed woman in the Tesla",2,2,False,,"Autopilot can control steering, speed, and braking. ","sensor data, video input",transportation and storage,no,Autonomy2,,No. Not intentionally designed to perform harm,Tesla Model S,semi-autonomous navigation,,
CSETv1_Annotator-1,154,True,154,005,2. Initial annotation complete,,False,no,no,maybe,yes,no,no,no,no,yes,non-imminent risk of tangible harm (an issue) occurred,maybe,yes,True,AI tangible harm issue,"3.2 - It is unclear if the PATTERN algorithm uses AI. It is possible that it is formulaic. The article notes that Pattern ""suffered from math and human errors"" and that it ""sounds highly technical, but it's not.""
3.5 - Considering PATTERN's decision making responsibility and a quote from Sasha Costanza-Chock describing it as a ""harmful artificial intelligence system,"" this incident qualifies as an AI tangible harm issue. Inmates who are denied the opportunity to gain credits that would help them attain early release are at risk of suffering tangible losses. However, it is unclear whether human decision makers in the absence of the system would decide differently.",no,no,no,no,yes,race,,yes,maybe,yes,True,yes,,2021,12,,False,no,no, ,,US,North America,,,,"United States Justice Department, Pattern, Black people in federal prison, Hispanic people in federal prison, Asian people in federal prison, Black people in federal prison, Hispanic people in federal prison, Asian people in federal prison",0,0,False,,Pattern calculates inmates' risk of returning to crime. This risk level is used to determine whether or not inmates are able to qualify for programs that could give them credits for early release through the First Step Act.,previous criminal history,law enforcement,yes,Autonomy3,,No. Not intentionally designed to perform harm,,"risk assessment, predict recidivism",,
CSETv1_Annotator-1,155,True,155,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,imminent risk of tangible harm (near miss) did occur,yes,yes,True,AI tangible harm near-miss,"3.1 - This incident can be classified as an imminent risk of tangible harm (near miss) because harm would have occurred if not for atypical intervention. Users were directed toward ""precarious and dangerous situations with unplowed roads/dirt roads"" while trying to avoid highway closures.",no,no,no,no,no,none,,no,yes,yes,True,no,,2021,12,,False,no,no, ,CA,US,North America,,inclement weather - snow,Users in both Nevada and California were impacted by Google Maps failing to direct them effectively during the snow storm.,"Google, Google Maps, Google Maps users driving during inclement weather",0,0,False,,Google Maps uses machine learning to predict traffic patterns based on GPS data and other users' reports in order to optimize routes for the primary user.,"traffic patterns, user traffic reports",transportation and storage,no,Autonomy3,,No. Not intentionally designed to perform harm,,"navigation, route optimization","shortest-path algorithm, Dijkstra Algorithm",
CSETv1_Annotator-1,156,True,156,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,no,True,none,"3.3 and 3.5 - The adverse outcome in this event, the suicides involving online purchases of the preservative chemical compound, cannot be directly linked to the AI. Although the e-commerce sites did include the products on their platforms and did suggest ""other products that customers frequently bought along with it"", this inclusion was not the direct reason for the adverse outcomes.",no,no,maybe,maybe,no,none,"4.3 - Some of the buyers who had killed themselves using the chemical compound included minors. However, they were not disproportionally treated or specifically targeted/affected.
4.4 - By recommending products also used in suicide, Amazon may have been promoting detrimental content that encouraged self-harm. In that case, the AI would be directly linked.",yes,yes,yes,True,yes,,2019,,,True,no,no, ,,,Global,,,,"Amazon, eBay, Etsy, Metalchem, E-commerce buyers of sodium nitrite, E-commerce buyers of sodium nitrite",18,0,True,"8.1 - The New York Times identified 10 people who had killed themselves using the chemical compound after buying it through Amazon and 8 suicides involving eBay sales of the poison. 
8.3 - There are likely more people who used the chemical compound for suicide after purchasing it from e-commerce vendors.",Amazon's vice president for public policy stated that “Amazon makes a wide selection of products available to our customers because we trust that they will use those products as intended by the manufacturers.” Amazon's suggestion algorithm recommends products that other buyers also bought to users.,,wholesale and retail trade,no,Autonomy3,,No. Not intentionally designed to perform harm,,product recommendation,,
CSETv1_Annotator-1,157,True,157,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,no,True,none,"3.3 - The delivery driver was being monitored by an AI system. However, the AI did not directly cause the crash. Instead, the AI may have placed undue pressure on the delivery driver which may have caused him to speed, leading to the crash.",no,no,no,no,no,none,,no,yes,no,True,no,,2021,03,,False,no,yes,Atlanta,GA,US,North America,,,,"Amazon, driver hit by AMazon delivery van, Tesla Model S, Amazon delivery van, Toyota Corolla, Harper Logistics LLC, Bryan Williams",0,1,False,,"""Amazon closely monitors its drivers through the use of a smartphone app and in-van cameras and sensors in a bid to minimize delivery times and address safety concerns. The company keeps close tabs on a number of actions drivers take, including “backup monitoring, speed, braking, acceleration, cornering, seatbelt usage, phone calls, texting, in-van cameras that use artificial intelligence to detect for yawning, and more”.""","speed, breaking, acceleration, delivery times, seatbelt usage, phone calls, texting, in-van camera input",transportation and storage,no,Autonomy1,,No. Not intentionally designed to perform harm,in-van cameras and sensors,driver monitoring,,
CSETv1_Annotator-1,160,True,160,005,2. Initial annotation complete,,False,yes,maybe,no,yes,no,no,no,yes,yes,imminent risk of tangible harm (near miss) did occur,yes,yes,True,AI tangible harm near-miss,"Harm would very nearly have happened if not for atypical intervention. Once Alexa gave the suggestion, Kristin Livdahl shouted ""No, Alexa, no!"" in order to stop the Alexa and warn her daughter not to do the challenge. This is an imminent risk of harm because another child without supervision might actually participate in the challenge and it is unclear whether Livdahl's daughter would have if not for her mother's intervention.",no,no,yes,maybe,no,none,"4.3 - A minor was involved. Livdahl's daughter was ten years old when she asked the Alexa for the challenge. However, the child was not disproportionately treated or specifically targeted/affected because she was a minor.
4.4  - The harmful challenge may be classified as detrimental content.",no,yes,yes,True,no,,12,26,2021,False,no,yes,,,,Global,,,,"Kristin Livdahl's 10-year-old daughter, Kristin Livdahl, Amazon, Alexa",0,0,False,,"Alexa is a virtual assistant technology that is deployed to help households complete basic tasks like creating shopping lists, searching the web, and more.",voice input,information and communication,no,Autonomy2,,No. Not intentionally designed to perform harm,Amazon Alexa ,virtual assistant technology,,
CSETv1_Annotator-1,161,True,161,005,2. Initial annotation complete,,False,no,maybe,no,yes,no,yes,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,no,yes,sex,Facebook's ad-delivery system shows different job ads to women and men even though the jobs require the same qualifications. The findings suggest that Facebook's algorithms are somehow picking up on existing demographic distributions for the jobs.,yes,yes,yes,True,yes,,2021,04,,False,no,no,,,,Global,,,,"Facebook, University of Southern California researchers, Facebook job-seekers",0,0,False,,"Facebook's ad-delivery system targets advertisements bought by employers to different users who might fit those jobs. Findings suggest that algorithms show the ads to statistically distinct demographic groups, usually along the lines of existing demographic distributions within the jobs.","job advertisements, Facebook profiles","information and communication, professional, scientific and technical activities",no,Autonomy1,,No. Not intentionally designed to perform harm,,"advertisement optimization, ad delivery",,
CSETv1_Annotator-1,162,True,162,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,"More than 2,500 people were deported and at least 7,2000 more were forced to leave Britain after ETS accused them of cheating in an exam it set and marked. Some had to contest the accusations in court and were met with roadblocks in accessing the audio files that had allegedly proved they had cheated.",no,yes,no,no,maybe,"nation of origin, citizenship, immigrant status","4.2 - Testers have the right to view the test recordings that allegedly proved they had cheated. One tester struggled for three years to get hold of the recording. Another waited six years for his test recording to be played in court. Testers also have the right to not be unjustly accused of cheating on an exam that could affect whether or not they are allowed to remain in or apply to citizenship in a country.
4.6 - This incident only affected immigrants and testers trying to obtain a pass they could use to apply for a visa.",yes,yes,yes,True,,,2022, ,,True,no,no,,,GB,Europe,,,"A BBC Panorama investigation in 2014 revealed two London test centres were running fraudulent exams so people could falsely obtain a pass they could use to apply for a visa. This prompted the government to investigate and crack down on fraud, with results that were ineffective and caused the unjust deportation and investigation of many testers into 2022.","Newsnight, Home Office, ETS, ETS test takers, ETS test takers, Wahidur Rahman, Nomi Raja, Shakil Rathore",0,0,False,,"ETS came up with voice recognition software that looked to see if the same voice turned up on multiple test recordings, indicating the same proxy had faked exams for several people. If a test was flagged and two ETS staff agreed, it was classified as ""invalid"" - meaning the candidate had definitely cheated. Even if that didn't indicate cheating, ETS might designate a test as ""questionable"" if it was taken at a centre with many ""invalid"" results.","voice recordings, exam audio recordings",Education,yes,Autonomy3,,No. Not intentionally designed to perform harm,,"voice recognition, cheating identification",,
CSETv1_Annotator-1,158,True,158,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,no,yes,race,,yes,yes,yes,True,yes,,2021,,,True,no,no,,OH,US,North America,,,,"Amaya Ross, Proctorio, Ohio State University",0,0,False,,Proctorio uses face detection to verify the identity of the person taking the exam. Digital monitoring was meant to help schools and universities detect cheating during lockdown.,"facial images, video input",Education,yes,Autonomy1,,No. Not intentionally designed to perform harm,,"facial recognition, facial verification",facial recognition,
CSETv1_Annotator-1,163,True,163,005,2. Initial annotation complete,,False,no,maybe,maybe,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,yes,yes,"nation of origin, citizenship, immigrant status, race, religion, sex, sexual orientation or gender identity",,yes,yes,yes,True,yes,,2021,,,False,no,no,,,US,North America,,,,"Facebook, Frances Haugen, Securities and Exchange Commission, Instagram, Facebook content moderation algorithm, Facebook users, Facebook users, Project WoW researchers",0,0,False,,"Facebook's content moderation algorithms are intended to detect hate speech automatically and flag it for review and possible removal. ""Algorithm detection is important not just because it's more efficient, but also because it can be done proactively, before any users flag the hate speech.""",Facebook posts,information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,"content moderation, hate speech detection",natural language processing,
CSETv1_Annotator-1,164,True,164,005,2. Initial annotation complete,,False,no,yes,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,yes,no,none,,yes,yes,yes,True,yes,,2018, ,,True,no,no,,,,Global,,,,"Facebook (now Meta), Buzzfeed , Facebook News Feed, Facebook News Feed algorithm, Facebook users, The Wall Street Journal, European political parties",0,0,False,,"The overhaul of Facebook's News Feed algorithm in 2018 was meant to boost ""meaningful social interactions,"" ""strengthen bonds between users,"" and ""improve their well-being."" Although meant to encourage less passive consumption of professionally produced content, the algorithm change actually encouraged sensationalized posts that produced high levels of comments and reactions that translated to success on Facebook. Heavy weighting of reshared material in News Feed makes angry voices even louder.   

News Feed is a constantly updated, personally customized scroll of friends' family photos and links to news stories. The company sells user attention to advertisers in order to make money. A proprietary algorithm controls what appears in each user's News Feed. It takes into account who users are friends with, what kind of group sthey have joined, what pages they have liked, which advertisers have paid to target them and what types of stories are popular or driving conversation. 

Facebook's algorithm measures how much ""meaningful"" interaction a post sparks. Under an internal point system used to measure its success, a ""like"" was worth one point; a reaction, reshare without text or reply to an invite was worth five points; and a significant comment, message, reshare or RSVP, 30 points. Additional multipliers were added depending on whether the interaction was between members of a group, friends or strangers.","Facebook posts, Facebook reactions, Facebook likes, Facebook comments, Facebook reshares",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,"content recommendation, increase user engagement",,
CSETv1_Annotator-1,165,True,165,005,2. Initial annotation complete,,False,no,maybe,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,no,yes,race,"The AI image tool PULSE, using StyleGAN, produced images of white people when given low-res input photos of people of color. Some speculate that this is a result of biased input data, while others suggest it is a problem with the algorithm itself.",yes,yes,yes,True,yes,,2020,06,,False,no,no,,,US,North America,,,,"Celebrity input into depixelation algorithm, PULSE, StyleGAN, NVIDIA, ThisPersonDoesNotExist.com, Researchers at Duke University, People of color",0,0,False,,"PULSE uses StyleGAN to ""imagine"" the high-res version of pixelated inputs. It does this by generating a completely new high-res face that, when pixelated, looks the same as the one inputted by the user. The algorithm is not ""finding"" new detail in the image as in the ""zoom and enhance"" trope; it's instead inventing new faces that revert to the input data. The bias is likely inherited from the dataset StyleGAN was trained on.","facial images, images",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,image enhancement,upscaling,
CSETv1_Annotator-1,166,True,166,005,2. Initial annotation complete,,False,no,maybe,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,no,yes,"sexual orientation or gender identity, race",,yes,yes,yes,True,yes,,2020,,,True,no,no,,,US,North America,,,6.1 and 6.4 - Giggle was first launched in early 2020.,"Giggle, Giggle's gender verification software, Sall Grover, Transgender users of Giggle, Kairos, Women of color users of Giggle",0,0,False,,Giggle's gender-verification software supposedly looks at the bone structure of a person's face to determine their gender. ,"facial images, selfies",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,"facial recognition, gender verification","facial recognition, computer vision, deep learning",
CSETv1_Annotator-1,169,True,169,001,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,no,yes,True,none,"The reports discuss the problem of Muslim hate speech propagating in Myanmar through Facebook. There is discussion about how Myanmar's laws around hate speech and disinformation do not require Facebook to do much. The articles also discuss Facebook's lack of effort in policing these in Myanmar.  However, the connection to an AI or any algorithm is not discussed.",no,no,no,yes,yes,religion,,yes,no,yes,True,no,"The reports discuss the problem of Muslim hate speech propagating in Myanmar through Facebook. There is discussion about how Myanmar's laws around hate speech and disinformation do not require Facebook to do much. The articles also discuss Facebook's lack of effort in policing these in Myanmar.  However, the connection to an AI or any algorithm is not discussed.",2017,,,True,no,no,,,MM,Asia,,,,"Facebook, Meta, Muslims in Myanmar, Muslims in Myanmar, Harry Myo Lin, Ko Ni",1,0,True,,,,information and communication,no,unclear,,No. Not intentionally designed to perform harm,,,,
CSETv1_Annotator-1,167,True,167,001,2. Initial annotation complete,,False,no,no,no,no,yes,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,no,yes,sexual orientation or gender identity,,yes,yes,no,True,no,"This was a reported research project, highlighting potential issues associated with applying AI and facial recognition. The AI was not deployed. Thus there was not domain for AI harm and the CSET definition for AI harm was not met.",2017,,,False,no,no,,,US,North America,,,,"Michal Kosinski, Clare Garvie, Georgetown University's Center on Privacy and Technology, Yilun Wang, Glaad, Human Rights Campaign, LGTBQ individuals",0,0,False,,,images,,no,Autonomy3,,Yes. Intentionally designed to perform harm and did create intended harm,,prediction,"neural networks, prediction",
CSETv1_Annotator-1,168,True,168,005,2. Initial annotation complete,,False,no,yes,maybe,maybe,yes,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,no,no,none,,no,yes,yes,True,no,5.4 - Users of deployers with little interest in popular items,2022,03,01,False,no,no,,,,Global,,,6.1-6.3 - Date refers to the publication of the paper.,"Collaborative filtering multimedia recommender systems, BookCrossing, MovieLens, Last.fm, MyAnimeList, Dominik Kowald and Emanuel Lacic, Users with little interest into popular items",0,0,False,,"Collaborative filtering recommender algorithms prioritize items that are perceived to be popular among ""people like you,"" as best the host framework can understand what kind of consumer you are. It is significantly cheaper and more established than more capable algorithms like content-based filtering, which may recommend items that are more similar to the other items users consume rather than based on a perceived user profile.","books, movies, music, animes","Arts, entertainment and recreation, information and communication",no,Autonomy1,,unclear,,multimedia recommendation,collaborative filtering,"10.1 - Collaborative filtering is intended to perform recommendations based on perceived user profiles. However, receiving poor recommendations is not a harm by CSET standards."
CSETv1_Annotator-1,170,True,170,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",maybe,yes,False,none,"3.2 - It is unclear whether there was an AI involved. Target data scientist Pole was described as having analyzed mass amounts of data to identify trends that might predict when women were due for pregnancy soon. This also occurred in 2012. These qualifiers, like buying a lot of lotion, could be hardcoded or formulaic.",no,no,no,no,yes,"familial status (e.g., having or not having children) or pregnancy","Pregnant women were targeted with ads revolving around child care and pregnancy products. However, other demographics are also targeted for products that Target determines might meet their needs.",maybe,maybe,yes,True,no,,2012,02,16,True,no,no,,,US,North America,,,The date refers to the article published in the New York Times by Charles Duhigg that brought to light Target's advertising practices.,"Target, Target pregnancy prediction algorithm, Andrew Pole, Target customers",0,0,False,,"Whenever possible, Target assigns each shopper a unique code - known internally as the Guest ID number - that keeps tabs on everything they buy. Also linked to your Guest ID is demographic information like your age, marital and parental status, geographic location, salary, financial status, education, and preferences. It then tracks customers purchasing habits in order to predict when they might be pregnant, then deploying ads and coupons for products related to pregnancy.","customer profile, age, marital status, parental status, geographic location, salary, education, purchasing preferences",wholesale and retail trade,no,Autonomy3,"9.5 - The algorithm may be able to predict pregnancy, but the deployment of advertisements occurs because of humans who actively choose to proceed with the AI information.",,,,,not AI 
CSETv1_Annotator-1,171,True,171,005,2. Initial annotation complete,,False,maybe,no,no,yes,no,no,no,no,yes,imminent risk of tangible harm (near miss) did occur,yes,yes,True,AI tangible harm near-miss,"Although Paula and David did not end up having to pay the fine for the traffic violation they did not commit, they did get charged with a citation and would have had to pay it if not for human intervention and correction.",no,no,no,no,no,none,,no,yes,yes,True,no,,2021,06,,False,no,yes,Bath,,GB,Europe,,,,"David and Paula Knight, Pedestrian wearing \""KNITTER\"" sweater, Traffic camera, Bath local government",0,0,False,,Traffic cameras record the roads and intersections in order to detect traffic violations like driving in the bus lane.,"camera input, video input, traffic camera input",transportation and storage,yes,unclear,It is unclear whether detection of traffic violations automatically causes fine issuance. ,No. Not intentionally designed to perform harm,traffic camera,detect traffic violations,,
CSETv1_Annotator-1,172,True,172,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,non-imminent risk of tangible harm (an issue) occurred,yes,yes,True,AI tangible harm issue,"3.1 - If patients are denied prescription drugs because of their NarxCare addiction risk scores, they may experience pain and physical health deterioration that could have been prevented.",maybe,no,no,no,yes,"disability, other","4.1 - Patients may experience denial of access to critical healthcare services because the algorithm determined that they are at high risk of becoming addicted to prescription drugs.
4.6 - This algorithm specifically affects those who suffer from chronic illnesses or pain and require prescription medication.",yes,yes,yes,True,yes,,2020,07,,False,no,no,,MI,US,North America,,,"Date and location refers to the story of ""Kathryn,"" but the algorithm has been used and has affected patients starting before July 2020","Kathryn, Patients with chronic illnesses seeking pain-related drug prescriptions, Hospitals, U.S. Department of Justice, NarxCare, Prescription drug monitoring programs (PDMPs), Appriss, State drug registries",0,0,False,,"NarxCare offers states access to a complex machine-learning product that automatically assigns each patient a unique, comprehensive Overdose Risk Score that draws on state drug registry data but ""may include medical claims data, electronic health records, EMS data, and criminal justice data.""","state drug registries, medical claims data, electronic health records, EMS data, criminal justice data, patient records",human health and social work activities,yes,Autonomy3,,No. Not intentionally designed to perform harm,,addiction risk assessment,,
CSETv1_Annotator-1,173,True,173,005,2. Initial annotation complete,,False,no,no,maybe,no,yes,no,no,no,no,"no tangible harm, near-miss, or issue",yes,maybe,False,none,3.3 - The adverse outcome of the incident is more closely related to the datasets being biased and incomplete rather than the algorithms themselves,no,no,no,no,no,none,,no,yes,maybe,False,no,5.3 - The adverse outcome of the incident is more closely related to the datasets being biased and incomplete rather than the algorithms themselves,2020,06,,False,no,no,,,,Global,,,,"Laure Wynants, Predictive tools designed to diagnose and triage COVID patients, Derek Driggs",0,0,False,,"Hundreds of AI tools were developed during the pandemic to help diagnose and triage patients faster. However, many were ineffective. These problems stemmed from bad data - datasets were spliced together from multiple sources and contained duplicates. The tools learned to identify features of scans that were unrelated to COVID, like a person's position, age, or the hospital they were scanned at. Many encoded individual doctors' biases.","patient information, medical scans, chest scans, electronic health records",human health and social work activities,no,Autonomy3,,No. Not intentionally designed to perform harm,,diagnose patients,,
CSETv1_Annotator-1,174,True,174,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,no,no,none,,no,yes,yes,True,no,,2022,03,,False,no,no,,,US,North America,,,,"Stanford Internet Observatory, AI generated LinkedIn profiles, Advertising and sales companies, LinkedIn, LinkedIn users",0,0,False,,The technology most likely used to create the LinkedIn profiles is known as a generative adversarial network that creates lifelike faces by training on large datasets of real people's photos.,"facial images, Linkedin profiles",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,"sales and marketing, message LinkedIn users","generative adversarial network, GAN",
CSETv1_Annotator-1,175,True,175,005,2. Initial annotation complete,,False,yes,no,no,yes,no,yes,no,no,yes,non-imminent risk of tangible harm (an issue) occurred,yes,yes,True,AI tangible harm issue,"The Cruise vehicle was operating without its headlights, which could cause potential incidents in the future because the vehicles are only authorized to drive during nighttime hours. In addition, its odd reaction to the police stop could cause more harm in the future.",no,no,no,no,no,none,,no,yes,yes,True,no,,2022,04,01,False,no,yes,San Francisco,CA,US,North America,,,,"Cruise, General Motors, San Francisco Police Department, Chevy Bolt",0,0,False,,"Cruise uses LIDAR technology to power its self-driving vehicles, which are meant to be able to autonomously navigate roads and react to real-time traffic situations.","lidar, video input, sensor data",transportation and storage,,Autonomy1,,No. Not intentionally designed to perform harm,Chevy Bolt,autonomous navigation,,
CSETv1_Annotator-1,176,True,176,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,no,no,no,no,none,,no,yes,yes,True,no,,2022,,,True,no,yes,,OR,US,North America,,,,"Starship, Oregon State University, Autonomous food delivery robot, Train",0,0,False,,The autonomous food delivery bot got stranded in a railroad crossing and ended up getting run over and destroyed by a train.,"sensor data, geospatial data","accommodation and food service activities, transportation and storage",maybe,Autonomy1,,No. Not intentionally designed to perform harm,food delivery robot,"food delivery, autonomous navigation",,
CSETv1_Annotator-1,177,True,177,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,no,no,none,,no,yes,yes,True,no,,2022,04,,False,no,no,,,,Global,,,,"Google, Google assistive writing feature, Google Docs, Google Docs users",0,0,False,,"Google's assistive writing feature is meant to make style and tone notes on word choice, concision, and inclusive language.",text,information and communication,no,Autonomy3,,No. Not intentionally designed to perform harm,,edit text,language understanding models,
CSETv1_Annotator-1,178,True,178,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,non-imminent risk of tangible harm (an issue) occurred,yes,yes,True,AI tangible harm issue,"In this case, the Tesla collided with the jet too slowly to cause real damage to either the car or the aircraft. However, the inability of the Smart Summon feature to detect obstacles in the path of parking could cause harm in the future. ",no,no,no,no,no,none,,no,yes,yes,True,no,,2022,04,,False,no,yes,Spokane,WA,US,North America,,,,"Tesla vehicle, Tesla, Tesla Smart Summon, Cirrus Vision jet",0,0,False,,Tesla's Smart Summon function allows the vehicle to use its self-driving technology to leave a parking spot and drive around obstacles until it reaches its owner.,"sensor data, geospatial data",transportation and storage,no,Autonomy1,,No. Not intentionally designed to perform harm,Tesla model Y,autonomous navigation,,
CSETv1_Annotator-1,179,True,179,005,2. Initial annotation complete,,False,no,yes,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,no,yes,"sex, race","OpenAI's DALL-E 2 seems to reinforce stereotypes, generating images of mostly white men upon user prompts of ""lawyer"" or mostly images of Asian women for user prompts of ""flight attendant."" DALL-E 2's results reflect gender and racial biases that exist in its training data.",yes,yes,yes,False,no,"Because there are no harmed entities, this adverse outcome cannot be classified as a CSET AI special interest intangible harm. DALL-E 2 users are not exposed to detrimental content, per se, even if the results reinforce stereotypes. The images are not explicitly derogatory toward any group.",2022,04,,False,no,no,,,,Global,,,,"OpenAI, DALL-E 2, DALL-E 2 users",0,0,False,,DALL-E 2 is an AI system that can turn textual description into images,text prompts,"Arts, entertainment and recreation, information and communication",no,Autonomy1,,No. Not intentionally designed to perform harm,,image generation,,
CSETv1_Annotator-1,180,True,180,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,non-imminent risk of tangible harm (an issue) occurred,yes,yes,True,AI tangible harm issue,"Defendants may receive stricter punishments as the result of AI recommendations to judges in Malaysian court. However, it is unclear whether the two defendants mentioned in this event would have received lighter sentences in the absence of AI.",no,maybe,no,no,no,none,"4.2 - The use of an opaque algorithm in making sentencing decisions may violate due process. However, it is unclear how strongly the Malaysian constitution upholds due process.",no,yes,yes,True,no,,2020,02,19,False,no,no,,,MY,Asia,,,,"Malaysian judiciary, Malaysian sentencing AI, Counsel Hamid Ismail, Magistrate Jessica Ombou Kakayun, Denis Modili, Christopher Divingson Mainol, Malaysian convicted people",0,0,False,,The sentencing AI used in the Malaysian judiciary would analyse a database of cases between 2014 and 2019 in Sabah and Sarawak in order to deliver a recommendation for jail sentencing to the court.,"Malaysian court cases, crime data, alleged crimes, age, employment status, socio-economic data",law enforcement,yes,Autonomy3,,No. Not intentionally designed to perform harm,,sentencing recommendation,,
CSETv1_Annotator-1,181,True,181,005,2. Initial annotation complete,,False,yes,no,no,yes,yes,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,no,no,no,no,none,,no,yes,yes,True,no,,2022,02,11,False,no,yes,,CA,US,North America,,,,"Cruise, General Motors, Cruise autonomous vehicle, BMW vehicle",0,0,False,,Cruise's self-driving vehicles are meant to autonomously navigate roads and react in real-time to changing road and traffic situations.,"sensor data, geospatial data",transportation and storage,no,Autonomy1,,No. Not intentionally designed to perform harm,Cruise AV,autonomous navigation,,
CSETv1_Annotator-1,182,True,182,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,no,True,none,"Only one of the Cruise vehicles was in autonomous mode. The other was operating in conventional mode. The one operating in conventional mode contacted the rear bumper of the autonomous mode car. Thus, the AI did not cause the crash. Instead, it was the human driver of the second Cruise vehicle. Therefore, the adverse outcome in this event cannot be linked to AI.",no,no,no,no,no,none,,no,yes,no,True,no,,2018,06,11,False,no,yes,San Francisco,CA,US,North America,,,,"Cruise, General Motors, Cruise operated Chevrolet Bolt in autonomous mode, Cruise operated Chevrolet Bolt in conventional mode",0,0,False,,Cruise self-driving vehicles are meant to autonomously navigate roads and react in real-time to changing traffic and road conditions,"sensor data, geospatial data",transportation and storage,no,unclear,"The autonomous vehicle in autonomous mode was operating at autonomy level 1. However, the other one was operating in conventional mode with a human driver.",No. Not intentionally designed to perform harm,Chevrolet Bolt,autonomous navigation,,
CSETv1_Annotator-1,183,True,183,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,no,maybe,"other, unclear","As a private company, Airbnb can decide who does and does not use its properties.
4.6 - Airbnb's algorithm took into account factors like level of education and occupation in order to determine trustworthiness.",maybe,yes,yes,True,no,,2022,03,,True,no,no,,,AU,Oceania,,,"6.4 - Airbnb acquired Trooly and its patented algorithm in 2017. However, Choice reported on Airbnb's use of a trustworthiness algorithm in March 2022.","Airbnb, Trooly, Choice, Renae Macheda, Airbnb users",0,0,False,,"The patented algorithm is claimed to ""assess people's personality traits, such as narcissism or conscientiousness, along with behavioral traits, such as use of drugs or alcohol or involvement in civil litigation and other behavior, and combine them to create a holistic score that judges a person's trustworthiness.","social media posts, educational level, online data, occupation, location data","accommodation and food service activities, information and communication",no,unclear,"It is unclear whether there is a human in the loop reviewing the decisions made by the trustworthiness algorithm, or if the algorithm automatically bans and blocks users it determines to be untrustworthy.",No. Not intentionally designed to perform harm,,background check algorithm,,
CSETv1_Annotator-1,184,True,184,005,2. Initial annotation complete,,False,no,no,no,maybe,no,no,no,no,maybe,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,"Even if the system was not deployed on citizens in São Paulo, Companhia do Metropolitano de São Paulo (METRO) had to suspend the implementation of the system and go to court.",no,yes,no,no,no,none,"4.2 - Since February 2022, personal data protection is a fundamental right in Brazil.",no,yes,yes,False,no,"The implementation of the facial recognition system in the São Paulo metro would be a violation of rights and therefore a AI special interest intangible harm. However, because it is unclear whether the system was in use at the time of the court case and suspension, it is unclear if this special interest intangible harm actually occurred.",2022,03,22,False,no,no,São Paulo,,Brazil,South America,,,,"Companhia de Metropolitano de São Paulo, SecurOS, Judge Cynthia Thome, ISS, ViaQuatro, São Paulo Metro users",0,0,False,,"The electronic monitoring system would use facial recognition  to read, copy, measure, and record biometric data of subway users.",facial images,"transportation and storage, information and communication",yes,unclear,"9.5 - Because the system was not deployed yet, it is unclear what level of autonomy it would operate on.",No. Not intentionally designed to perform harm,,"facial recognition, subway surveillance",facial recognition,
CSETv1_Annotator-1,185,True,185,005,2. Initial annotation complete,,False,no,yes,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,maybe,yes,no,none,"4.3 - According to Statista, a quarter of TikTok's users in the U.S. in 2021 were between the ages of 10 and 19. Bloomberg has reported that approximately 30 percent of French TikTok users are under 18, as are a third of Italian users and nearly one-quarter of German users.",yes,yes,yes,True,yes,,2022,,,True,no,no,,,,Global,,,,"TikTok, TikTok \""For You\"" algorithm, NewsGuard, TikTok users watching content about the Ukraine War",0,0,False,,"TikTok's algorithm for its ""For You"" page suggests videos based on what people have previously seen, liked or shared.",TikTok videos,"information and communication, Arts, entertainment and recreation",no,Autonomy1,,No. Not intentionally designed to perform harm,,content suggestion,,
CSETv1_Annotator-1,186,True,186,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,no,no,True,none,"3.2 - Answers to the intimate partner violence risk assessment forms used for the VioGén system are fed into classical statistical models and mathematical formulas. There is no evidence that these algorithms use AI.
3.3 - The adverse outcome of the incident is violence against women. Although an effective algorithm would help police mitigate violence earlier, the ineffectiveness of the algorithm does not cause the domestic violence and adverse outcomes described.",maybe,no,no,no,no,none,4.1 - Women whose cases are deemed to be low-risk may receive less vital attention and check ups from police that are meant to ensure that they are safe.,no,no,no,True,no,,2007,,,True,no,no,,,ES,Europe,,,6.1-6.4 - Spain has been using VioGén since 2007 to help the police assess the risk women face when they file complaints of abuse.,"Spanish Ministry of Interior, Spanish police stations and police officers, VioGén, Women in Spain who file complaints of abuse, Eticas Consulting",2,0,True,"Martina and Nerea, children of Itziar P., were killed by her husband in 2018 after her case was deemed as low-risk. It is unclear how many people were harmed after women reported their abuse and it was deemed low risk. However, these adverse outcomes were the fault of the perpetrator and were not directly caused by the faulty risk assessment done by VioGén.","""VioGén uses classical statistical models to perform a risk evaluation based on the weighted sum of all the responses according to pre-set weights for each variable. It offers women a risk score, which determines how much help they will receive. ""","risk indicators, aggressor's criminal record, aggressor's mental and psychiatric disorders, aggressor's behavioral patterns and life or work-related problems, victim's mental health and substance addiction, level of violence",law enforcement,yes,unclear,"9.5 - Humans are able to adjust the algorithm's risk assessment. However, a 2014 study found that Spanish agents stuck to the automatic outcome in 95% of cases. Although human police officers are able to adjust the risk assessments while the woman is reporting, the VioGén system automatically activates police protection measures for each victim according to their risk score.",,,,,not AI
CSETv1_Annotator-1,187,True,187,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,yes,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,"There are two levels of tangible harm in this incident. First, Tesla employee John Bernal was fired from his job for sharing videos of Tesla's FSD beta software on his Youtube channel, causing financial loss. Next, the Tesla he drove in his Youtube videos did encounter difficulties, and in some cases, even crashed. AI is involved in both levels of harm. However, AI cannot be directly and clearly linked to the adverse outcome of Bernal's unemployment. That decision was made by Tesla executives who disapproved of Bernal's Youtube channel and was not caused by the malfunctioning FSD software.",no,no,no,no,no,none,,no,yes,yes,True,no,,2022,02,,False,no,yes,,CA,US,North America,,,February 2022 refers to when Bernal was fired from his job.,"John Bernal, Tesla Model 3, Tesla, Tesla Autopilot, Tesla Full Self Driving Beta system",0,0,False,,"""The FSD Beta option can best be summarized as a set of new driver assistance features that are not finished or fully debugged. Chief among them is “autosteer on city streets,” which lets the car navigate around complex urban environments without the driver needing to move the steering wheel. Customers must first have FSD, which costs $12,000 up front or $199 per month in the U.S., and then obtain and maintain a high driver-safety score, as determined by Tesla software that monitors their driving habits.""","geospatial data, camera input, video input, sensor data",transportation and storage,no,Autonomy2,,No. Not intentionally designed to perform harm,Tesla Model 3,semi-autonomous navigation,,
CSETv1_Annotator-1,188,True,188,005,2. Initial annotation complete,,False,no,no,no,maybe,no,maybe,no,no,yes,non-imminent risk of tangible harm (an issue) occurred,yes,yes,True,AI tangible harm issue,"Historian Marisa Miranda says Salta's AI system should be understood in light of Argentina's long history of ""the persistent eugenic impulse that...assumes that reproduction ""should be managed by the powerful."" Argentine governments in the past have discriminated against and surveilled pregnant women in the past with physical consequences, even kidnapping pregnant women and murdering them after giving birth. It is unclear what the Argentinian government intended to do with the results of Salta's government. However, it is reasonable to assume that teenage girls suspected to become pregnant would be at a non-imminent risk of experiencing tangible harm.",no,no,yes,no,yes,"age, disability, familial status (e.g., having or not having children) or pregnancy, financial means, geography, nation of origin, citizenship, immigrant status, sex","The stated goal was to use the algorithm to predict which girls from low-income areas would become pregnant in the next five years. The system was based on data including age, country of origin, disability, and whether the subject's home had hot water in the bathroom. The subjects were mostly poor, with some being migrants from Bolivia and other countries in South America, and others being from Indigenous Wichí, Qulla, and Guaraní communities. ",yes,yes,yes,True,yes,,2018,04,,False,no,no,Salta,Salta,AR,South America,,,,"Microsoft, Technology Platform for Social Intervention, Salta Ministry of Early Childhood, Argentinian province Salta, Low-income teenage girls in Salta, Low-income teenage girls in Salta, Low-income teenage girls in Salta",0,0,False,,"The Technology Platform for Social Intervention was developed with the goal of predicted teenage pregnancy, identifying which girls at which address were most at risk of having an adolescent pregnancy in the next five or six years. However, audits of the algorithm revealed methodological problems and unreliable data.","data on 200000 residents in the city of Salta, survey questions, photos, GPS locations, age, ethnicity, country of origin, disability, financial status, home utilities","human health and social work activities, public administration",yes,Autonomy3,,No. Not intentionally designed to perform harm,,pregnancy prediction,,
CSETv1_Annotator-1,189,True,189,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm near-miss,"3.1 and 3.5 - If the DWP's algorithm really was falsely accusing claimants of fraud, this could cut off needed benefits or force claimants to pay more out of pocket for welfare. However, the sources only describe the initiation of investigations with the results of the challenge to the DWP not having happened yet. Thus, it is unclear whether claimants can attribute their welfare changes and tangible harm to the algorithm. However, it is certain that claimants go through added work and stress appealing and attempting to prove that they are not committing fraud.",maybe,no,no,no,yes,"disability, financial means","The DWP claimed that the algorithms were applied to all welfare claimants, disabled people and non-disabled people alike. However, disabled claimants and groups like the Greater Manchester Coalition of Disabled People believe that the algorithm is ""'over-picking' disabled people for its benefit fraud investigations.""",yes,yes,yes,True,yes,,2021,,,True,no,no,,,GB,Europe,,,,"UK Department for Work and Pensions (DWP), British benefits claimants , Disabled British benefits claimants, Privacy International and the Greater Manchester Coalition of Disabled People, DWP data-matching algorithms",0,0,False,,"DWP official Schofield described the algorithm as ""data matching that is identifying questions to be answered and then we put those questions to the claimants themselves and give them the right to say, well what is going on here.""","income statements, welfare claims, e-payment activity","public administration, human health and social work activities",yes,Autonomy3,"9.5 - DWP official Peter Schofield ""did not deny that DWP used an algorithm, but he insisted that any decision on action being taken by DWP 'always comes down to an individual.'""",No. Not intentionally designed to perform harm,,welfare fraud detection,data matching,
CSETv1_Annotator-1,190,True,190,005,2. Initial annotation complete,,False,no,yes,yes,yes,no,yes,no,no,no,"no tangible harm, near-miss, or issue",maybe,yes,True,none,"3.2 - see 2.3. Scraped content was potentially used to train TikTok's ""For You"" algorithm, but no AI was directly involved in data scraping.",no,no,no,no,no,none,"Although no special interest intangible harm occurred, ByteDance's scraping activities may have violated the content policies of the social media apps they scraped from, like Instagram and Snapchat. In addition, creators of content ByteDance scraped may have been intangibly harmed.",no,maybe,yes,True,no,,2017,01,,False,no,no,,,CN,Asia,,,,"ByteDance, Flipagram (later renamed Vigo Video), BuzzFeed News, TikTok, \""For You\"" algorithm, Snapchat, Musical.ly, Instagram, Creators of scraped content from Instagram, Snapchat, Musical.ly",0,0,False,,"The ""For You"" personalization algorithm powers TikTok by recommending content that users are likely to enjoy. ByteDance, TikTok's parent company, allegedly scraped content from other social media sites like Snapchat and Musical.ly to test what content would do well on Flipagram to help train the ""For You"" algorithm.",short-form videos,"Arts, entertainment and recreation",no,Autonomy1,"The ""For You"" algorithm is a recommender system that operates autonomously. However, this incident centers around the scraped data allegedly used to train it, not the algorithm itself.",No. Not intentionally designed to perform harm,,content recommendation,,
CSETv1_Annotator-1,191,True,191,005,2. Initial annotation complete,,False,no,maybe,no,yes,no,no,no,no,no,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,Naver was fined 26.7 billion won ($23 million) for manipulating its shopping and video services search algorithms to place its own services on top of search results.,no,no,no,no,no,none,"This incident does not involve special interest intangible harm. However, the FTC did determine that Naver had violated fair competition and antitrust laws.",no,yes,yes,True,no,,2020,10,06,False,no,no,,,KR,Asia,,,"October 6, 2020 refers to the date on which South Korea's antitrust regulator FTC imposed a 26.7 billion won fine on Naver.","Fair Trade Commission of South Korea, Naver, Interpark and Gmarket",0,0,False,,"According to the Fair Trade Commission's announcement, Naver made changes in search algorithms to have products or services sold by those that are linked to its payment service Naver Pay have better exposure on the company's online shopping platform.","products on Naver, services on Naver, Naver search results, videos on Naver",wholesale and retail trade,no,Autonomy3,9.5 - The choice to push Naver-affiliated products and services to the top of Naver search results was made by Naver itself. The AI was a tool Naver used to achieve its goal of capturing more market share. ,Yes. Intentionally designed to perform harm and did create intended harm,,search result ranking,,10.1 - Naver successfully used the search AI to promote its own products and services
CSETv1_Annotator-1,192,True,192,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,no,no,no,no,none,,no,yes,yes,True,yes,,2022,03,,True,no,no,,,US,North America,,,The make-up artists settled with Estée Lauder Companies out of court in March of 2022. It is unclear when they were terminated by the algorithm.,"Estée Lauder Companies, Makeup artists working for MAC fired by Hirevue, HireVue, HireVue algorithm",0,0,False,,"The HireVue video interview system is an interface that conducts virtual interviews whose results are marked by algorithms. Questions in the video interview process included how to create a smokey eye. The three women said that no one could explain how they were scored in the HireVue interview. Estée Lauder said that ""teams who overlay objective performance-related data and other qualitative feedback, which accounted for the majority of the employment assessment, to make decisions on employment,"" were involved and that no facial recognition was involved.",15000 data points,"professional, scientific and technical activities",no,unclear,"It is unclear whether or not humans were in the loop with the termination decisions. HireVue was used, but Estée Lauder said humans were involved. ",No. Not intentionally designed to perform harm,,virtual interview,,
CSETv1_Annotator-1,193,True,193,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,no,no,True,none,"3.2 and 3.3 - This incident involves the failure of Target staff to notice and respond to internal alerts about suspicious activity on point of sale systems by thieves because of information overload. There was no AI involved and the technology was working as intended. In the face of an overwhelming influx of information and redundant alerts, some of which were false positives, the Target employees failed to respond to real alerts.",no,no,no,no,no,none,,no,no,no,True,no,,2013,,,False,no,no,,,US,North America,,,,"Target, Target credit card holders, Department of Justice, FireEye",0,0,False,,FireEye was a monitoring software that made up part of Target's network infiltration alerting system.,,wholesale and retail trade,no,Autonomy3,,,,,,no AI 
CSETv1_Annotator-1,194,True,194,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,maybe,True,AI tangible harm event,"The Australian telecommunications company spent more than $11 million dollars trying to fix its incident management bot, which overwhelmingly decided to send technicians into the field rather than solving issues programmatically. However, it is important to note that the bot was working generally as intended. The incident arose because the automation team neglected to create a kill switch and fired all of the human operators before the bot was implemented, making solving the issue much more difficult than it should have been if best practices were in place.",no,no,no,no,no,none,,no,yes,maybe,True,no,,2018,,,False,no,no,,,AU,Oceania,,,,"unnamed Australian telecommunications company, Incident management bot, Automation team ",0,0,False,,"The bot was ""designed to intercept all of the network incidents... follow a series of checks based on the problem as reported by the users... [and] take one of the three pre-defined actions based on the tests it would perform...Firstly, it would remotely resolve the incident by fixing the issue programmatically. If that did not work, it would assume that a technician's visit is required to customer premises. Accordingly, it would issue a work order to send someone directly. If none of that were apparent, it would present the case to the human operator for further investigation and decision.""",user-reported incidents,information and communication,no,Autonomy1,Humans were not in the loop and could not override or abort the bot's functioning which was one of the main causes of the adverse outcomes of this incident.,No. Not intentionally designed to perform harm,,incident management,,"10.1 - The AI was intended to address user-reported incidents in a logical way, which it did. The adverse and unintended consequences arose because of human negligence and could have been solved with the observance of best practices."
CSETv1_Annotator-1,204,True,204,005,2. Initial annotation complete,,False,no,no,no,maybe,no,no,no,no,yes,tangible harm definitively occurred,yes,maybe,True,unclear,"3.3 and 3.5 - Zhihu denies using employee monitoring systems developed by Sangfor. Although tangible harm did occur and a worker was fired, it is unclear that this was the result of use of an employee monitoring system.",no,no,no,no,no,none,,no,yes,maybe,True,no,,2022,02,,True,no,no,,,CN,Asia,,,,"Zhihu, Sangfor Technologies, Zhihu employees, Sangfor behavioral perception system",0,0,False,,"The alleged employee monitoring system is intended to predict a worker's likelihood to quit based on several metrics including the frequency of visiting employment websites, the number of job applications they've submitted, and even links to download PDF files of resumes the employees have sent out.","browsing history, conversations with coworkers, internal emails, internal messages, online footprint","professional, scientific and technical activities",no,Autonomy3,,Yes. Intentionally designed to perform harm and did create intended harm,,employee monitoring,,
CSETv1_Annotator-1,208,True,208,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,"Although there are no recorded incidents of crashes, deaths, or injuries due to the phantom braking phenomenon, drivers reported discomfort. For example, one driver said his wife experienced great pressure against her pregnant belly because of the aggressive, automatic braking. Phantom braking also indicates that there is an imminent risk of more severe tangible harm in the future. Many drivers noted crashes were only narrowly avoided because of human attention.",no,no,no,no,no,none,,no,yes,yes,True,no,,2022,05,04,False,no,yes,,,US,North America,,,"6.1-6.3 - May 4, 2022 refers to the date of a letter in which the National Highway Traffic Safety Administration asked Tesla to supply all reports it received of phantom braking. At that point, there had been reports circulating of phantom braking on Teslas for some time. Investigations had begun as early as February 2021.","Tesla, Tesla Autopilot, Tesla vehicles, Tesla drivers , National Highway Traffic Safety Administration",0,0,True,It is unclear how many of the reports resulted in injury of different severities.,"Tesla's Autopilot driver-assistance system is meant to semi-autonomously navigate road conditions and implement actions such as applying the brakes, steering, detecting objects, and more.","geospatial data, video input, sensor data",transportation and storage,no,Autonomy2,,No. Not intentionally designed to perform harm,Tesla vehicle,semi-autonomous navigation,,
CSETv1_Annotator-1,250,True,250,005,2. Initial annotation complete,,False,maybe,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,no,yes,True,none,"3.2 - WOZ property valuation laws ""use clear statistical methods."" While some municipalities experiment with Artificial Intelligence, it is unclear that any such model was used to compute the WOZ values.
3.5 - Because there is no AI involved, this incident does not classify as an AI tangible harm event.",no,yes,no,no,no,none,"4.2 - Under Dutch case law, a public body must be able to provide the details and mechanisms that led to an automated decision. The municipality was unable to answer how the claimant's demand to be told how the valuation of 320,000€ came to be.",maybe,no,yes,True,no,,2016,,,False,no,no,Castricum,,NL,Europe,,,,"Unnamed claimant in Castricum, Castricum municipality government, Amsterdam court, WOZ value calculation algorithm",0,0,False,,"not AI, but the algorithm involved in this incident was developed with the purpose of estimating property values to determine the appropriate level of property tax for Castricum homeowners",unclear,real estate activities,yes,Autonomy3,,,,,,no AI 
CSETv1_Annotator-1,350,True,350,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,"no tangible harm, near-miss, or issue",yes,maybe,False,none,"3.3 - The robot was being monitored at the time of the incident by a human operator. It paused upon encountering the yellow hazard tape. Upon a human at the scene lifting the tape, the operator allowed the robot to continue through the crime scene because they perceived that it was fine to pass. The main cause of the adverse outcome in this incident is a mistake in human judgment.",no,no,no,no,no,none,,no,yes,maybe,False,no,,2022,09,13,False,no,yes,Los Angeles,CA,US,North America,,,,"Serve Robotics, Serve delivery robot",0,0,False,,"Serve delivery robots have Level 4 autonomy and can drive themselves under certain conditions without needing a human to take over. However, human operators are required to remotely monitor and assist each bot at every intersection. The human operator will also remotely take control if teh bot encounters an obstacle such as a construction zone or a fallen tree and cannot figure out how to navigate around it within 30 seconds.","geospatial data, sensor data, video input","transportation and storage, accommodation and food service activities",no,Autonomy2,,No. Not intentionally designed to perform harm,Serve delivery robot,"food delivery, semi-autonomous navigation",,
CSETv1_Annotator-1,351,True,351,005,2. Initial annotation complete,,False,no,yes,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,maybe,yes,race,,maybe,yes,yes,True,maybe,,2022,09,12,False,no,no,,,,Global,,,,"Twitter, Twitter user @TenGazillioinIQ, Twitter users, Black people",0,0,False,,It is unclear which AI application the Twitter user @TenGazillionIQ used to replace Halle Bailey with a white actress in Disney's new trailer for The Little Mermaid.,"images, videos","Arts, entertainment and recreation",no,unclear,9.5 - The AI was used as a tool for nefarious means. ,Yes. Intentionally designed to perform harm and did create intended harm,,"video altering, video editing",,10.1 - The AI was used as a tool for nefarious means. 
CSETv1_Annotator-1,210,True,210,005,2. Initial annotation complete,,False,no,maybe,no,yes,no,no,no,no,yes,"no tangible harm, near-miss, or issue",maybe,yes,True,none,"3.2 - It is unclear that the technology deployed by app Tek Fog contains AI. Its main functions, including targeting inactive accounts to message their contacts or amplifying pro-BJP hashtags, do not necessarily require AI and could be done algorithmically with bots.",no,no,no,yes,yes,ideology,,yes,maybe,yes,True,yes,,2020,04,,True,no,no,,,IN,Asia,,,,"Tek Fog, Bharatiya Janata Party, Twitter, Persistent Systems, Mohalla Tech, Indian Twitter users",0,0,False,,"Tek Fog is allegedly able to 'bypass reCaptcha codes' allowing employees to 'auto-upload texts and hashtag Trends."" It uses ""in-built automation features to 'auto-retweet' or 'auto-share' the tweets and posts of individuals or groups and spam existing hashtags by accounts controlled by the app operatives."" It also takes over inactive WhatsApp accounts to message their contacts. This amplifies right-wing propoganda.","tweets, WhatsApp accounts",information and communication,maybe,Autonomy3,9.4 - The answer to this depends on whether Tek Fog was in fact deployed by the BJP.,Yes. Intentionally designed to perform harm and did create intended harm,,"spread misinformation, amplify propaganda",,
CSETv1_Annotator-1,452,True,452,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,"3.3 - Although ChatGPT did not cause the harm of users submitting auto-generated bug reports to Immunefi, those users did use ChatGPT as a tool to further nefarious ends.",no,no,no,maybe,no,none,4.4 - Chat-GPT-regenerated bug reports are not helpful and require Immunefi to ban users who submit them.,no,yes,yes,False,no,"5.3 - Although ChatGPT did not cause the harm of users submitting auto-generated bug reports to Immunefi, those users did use ChatGPT as a tool to further nefarious ends.",2023,01, ,False,no,no,,,,Global,,,,"Immunefi, OpenAI, ChatGPT, Immunefi submitters who use ChatGPT to generate reports",0,0,False,,ChatGPT is a tool that uses a large-language model called GPT-3 to converse naturally with humans.,,information and communication,no,Autonomy3,,Yes. Intentionally designed to perform harm but created an unintended harm (a different harm may have occurred),,text generation,"deep learning, large-language models","10.1 - ChatGPT was designed with the intention of answering user queries and generating texts, but it was not designed with the purpose of hindering the normal functionings of platforms like Immunefi."
CSETv1_Annotator-1,454,True,454,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,maybe,yes,yes,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,no,yes,race,,yes,yes,yes,True,yes,,2018,12, ,False,no,no,,,US,North America,,,"Date refers to the date of publication of the study that this incident is about, titled ""Racial Influence on Automated Perceptions of Emotions.""","Face++, Microsoft, Microsoft Face API, Lauren Rhue, Black people",0,0,False,,Facial recognition software is used to assign and analyze emotions based on facial images.,"NBA player photos, facial images",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,facial recognition,facial recognition,
CSETv1_Annotator-1,244,True,244,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,maybe,True,AI tangible harm event,"3.3 - The license plate reader software incorrectly matched the vehicle to a stolen vehicle with the same plate information but from a different state. The stolen vehicle in question was a motorcycle, while the one involved in the traffic stop was an automobile. It is important to note that while the AI system may have incorrectly matched the vehicle to the stolen one in question, the human police officers definitely should have exercised less extreme policing practices and should have been more careful about examining the results of the system's match. However, if the license plate matcher hadn't returned the result of a match (which would be correct, considering the differing vehicle types and states of registration), then this harm would not have happened.",no,yes,yes,no,no,none,4.2 and 4.3 - Four of the people apprehended by the police were children between the ages of 6 and 17. Everyone in the vehicle apprehended by the police was subject to extreme and unfair treatment by the police.,yes,yes,maybe,True,yes,5.3 - see 3.3,2020,08,02,False,no,no,Aurora,CO,US,North America,,,,"Aurora Police Department, Aurora Police Department license plate reader system, Family incorrectly apprehended by the police in Aurora, Family incorrectly apprehended by the police in Aurora",0,0,True,"It is unclear if this incident resulted in lasting or severe injuries. However, the physical health and safety of the family apprehended by the police in the traffic stop was threatened.",The license plate matching system apparently matched the license plate of the family's minivan to the license plat of a motorcycle from Montana that had been reported as stolen.,license plate images,law enforcement,yes,Autonomy3,,No. Not intentionally designed to perform harm, ,license plate recognition,,
CSETv1_Annotator-1,239,True,239,005,2. Initial annotation complete,,False,no,no,yes,yes,no,no,no,no,maybe,imminent risk of tangible harm (near miss) did occur,no,yes,True,none,"3.1 - Some teachers were fired because of a negative assessment by the Gates Foundation's Intensive Partnerships for Effective Teaching value-added model. However, it is unclear that all of them would not have otherwise been fired for poor performance. Thus, there is an imminent risk that at least some of those teachers were unfairly fired because of their assessment by the algorithm.",no,no,no,no,no,none,,no,no,yes,True,no,,2018,, ,True,no,no,, ,US,North America,,,,"Bill & Melinda Gates Foundation, Intensive Partnerships for Effective Teaching, Rand Corporation, Teachers assessed by the Intensive Partnerships for Effective Teaching program",0,0,False,,"The Intensive Partnerships for Effective Teaching program sought to ""improve education for low-income minority students... by gathering data and using an algorithm to assess teacher performance. It focused on measures such as test scores, the observations of school principals and evaluations from students and parents to determine whether teachers were adding value.","test scores, school principal assessments, student evaluations",Education,yes,Autonomy3,,,,,,no AI 
CSETv1_Annotator-1,435,True,435,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,no,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,Coupang was fined 3.29 billion won ($2.81 million) after it manipulated search algorithms to prioritize its own products over those of suppliers.,no,no,no,no,no,none,,no,yes,yes,True,no,,2017,,,True,no,no,,,KR,Asia,,,6.1 - The Korea Fair Trade Commission (KFTC) said the e-commerce giant was found to have forced hundreds of sellers from early 2017 to September 2020 to comply with its unlawful sales and marketing policies to maintain its competitive edge over other online retailers amid the fierce battle for market dominance.,"Coupang, Fair Trade Commission of South Korea, LG Household & Health Care, Yuhan Kimberly, Maeil Dairies, Namyang Dairy Products, Cuchen",0,0,False,,"According to the Fair Trade Commission's announcement, Coupang made changes in search algorithms to prioritize the appearance of products and services related to Coupang. It also engaged in unfair business practices with suppliers.","Coupang products, Coupang services, Coupang search results",wholesale and retail trade,no,Autonomy3,9.5 - The choice to push Coupang-affiliated products and services to the top of Coupangsearch results was made by Coupang itself. The AI was a tool Coupang used to achieve its goal of capturing more market share. ,Yes. Intentionally designed to perform harm and did create intended harm,,"product promotion, search result ranking",,10.1 - Coupang successfully used the search AI to promote its own products and services
CSETv1_Annotator-1,281,True,281,005,2. Initial annotation complete,,False,no,maybe,no,yes,no,no,no,no,no,non-imminent risk of tangible harm (an issue) occurred,yes,yes,False,none,"3.1 - There is a non-imminent risk that watchers could be influenced by the self-harm detrimental content that Youtube recommends which could cause tangible harm. However, in this case, the tangible harm would not be directly linked to the AI. ",no,no,yes,yes,no,none,,yes,yes,yes,True,yes,,2019,, ,False,no,no,,,,Global,,,,"Youtube, Youtube search algorithm, Minors watching Youtube",0,0,False,,Youtube has failed to remove inappropriate suicide-themed content before and has offered worrying search term recommendations related to self-harm.,"Youtube videos, Youtube search results",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,"video recommender, search suggestion",,
CSETv1_Annotator-1,445,True,445,005,2. Initial annotation complete,,True,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,no,yes,True,none,"3.3 - The Patriot system identifies targets, but Patriot crews choose to decide whether or not to fire. However, given that the Patriot system misidentified the RAF Tornado and the operators only had one minute to further evaluate the nature of the potentially hostile target, the technology can still be directly linked to the adverse outcome in this incident.",no,no,no,no,no,none,,no,no,yes,True,no,,2003,03,23,False,no,yes,,,IQ,Asia,,,"The Patriot missile shot the RAF Tornado on March 23, 2003. It shot the F-A-18C on April 2, 2003.","Raytheon, Lockheed Martin, United States Air Force, US Patriot Missile, RAF Tornado, RAF Tornado crew members, US Patriot Missile \""identification friend or foe\"" system, F-A-18C crew member, F-A-18C",3,0,False,,"""Patriot is a long-range, high-altitude, all-weather system designed to defeat advanced threats, including aircraft, tactical ballistic missiles, and cruise missiles...Multifunction phased array radar, track-via-missile guidance, and automated operations - including man-in-the-loop (human) override - are the key features of the Patriot system...A Patriot Fire Unit is deployed with an engagement control station, an electronic power plant vehicle, an antenna mast group for communications, and up to sixteen remote launching stations."" Given the time of deployment, it is unlikely that the Patriot Missile System can be characterized as artificial intelligence.",radar input,defense,yes,Autonomy3,"9.5 - The Patriot system identifies targets, but Patriot crews choose to decide whether or not to fire. However, given that the Patriot system misidentified the RAF Tornado and the operators only had one minute to further evaluate the nature of the potentially hostile target, the technology can still be directly linked to the adverse outcome in this incident.",,,,,no AI
CSETv1_Annotator-1,594,True,594,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,no,True,none,,no,no,no,yes,no,none,,yes,yes,yes,True,yes,,2023,08, ,False,no,no,,,NZ,Oceania,,,,"Pak 'n' Save, Savey Meal-bot, Savey Meal-bot users",0,0,False,,The Savey Meal-bot auto-generates meal plans from user-inputted ingredients.,ingredients,"accommodation and food service activities, wholesale and retail trade",no,Autonomy3,,unclear,,"recipe generation, text generation",,"10.1 - The Meal-bot was intended to create recipes from ingredients that users input. However, when customers began experimenting with entering a wider range of household shopping list items into the app, the Meal-bot continued to create recipes with them even if toxic or deadly."
CSETv1_Annotator-1,349,True,349,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,non-imminent risk of tangible harm (an issue) occurred,yes,yes,True,AI tangible harm issue,"3.1 - The rate of false positives caused by Evolv AI's misidentifications cause schools to lower sensitivity settings. This could contribute to lower accuracy in the future. False positives also require manual searches on ""almost every child as they walked through"" monopolizing the attention of safety officers who would otherwise be monitoring the halls and other entrances.",no,no,yes,no,no,none,,no,yes,yes,True,no,,2022,03, ,False,no,yes,Charlotte,NC,US,North America,,,,"Evolv Technology, Mallard Creek High School, Evolv AI-based weapons screening system, Students in the Charlotte Mecklenburg School District (CMS), Schools in the Charlotte Mecklenburg School District",0,0,False,,"Evolv systems scan the bodies of students for weapons like guns as they walk through. The scanning is meant to flag weapons like guns, but not common school items like phones, laptops, and binders. However, there is little statistical evidence that Evolv's scanners make schools safer. During the 2021-22 school year, 30 guns were found on the school's campuses by means other than Evolv scanners. A decline in guns found on campus began months before Evolv scanners were implemented",body scans,Education,yes,unclear,"9.5 - The scanners do not require human oversight, interaction, or intervention to flag a student for what it determines to be a weapon. However, the scanners do not act on this information. It is up to security officers to investigate the flagged students.",No. Not intentionally designed to perform harm,body scanner,weapon detection,,"10.1 - The Evolv system was designed to detect weapons like guns, but turned out to be less effective than suggested."
CSETv1_Annotator-1,385,True,385,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,no,True,none,"3.1 and 3.3 - Tangible harm definitely occurred in this incident. A woman was sexually assaulted in March 2019. However, the incident is mainly about the police department's use of DNA phenotyping to produce a snapshot of the suspect. They removed the image after facing controversy over the potentially racist implications of generating facial profiles and pigmentation predictions from DNA. Thus, the AI is linked to the main harm of this incident, stereotyping, but is not linked to the original crime.",no,no,no,no,yes,race,,maybe,yes,yes,True,yes,,2022,10,,False,no,no,Edmonton,Alberta,CA,North America,,,,"Edmonton Police Service, Parabon NanoLabs, Snapshot DNA Phenotyping Service, Black people in Edmonton",0,0,False,,"Using DNA evidence, Parabon produces trait predictions for the person of interest. Individual predictions are made for the person's ancestry, eye color, hair color, skin color, freckling, and face shape. It then produces a composite image depicting what the person of interest may have looked like at 25 years old and with an average body-mass index of 22. These are scientific approximations of appearance.",DNA evidence,law enforcement,yes,unclear,"9.5 - The system operates independently to produce the ""Snapshot"" composite image. However, it was the choice of the Edmonton Police Service to upload the image to social media in an attempt to find the suspect.",Yes. Intentionally designed to perform harm and did create intended harm,,"facial image generation, facial reconstruction",,10.1 - The phenotyping service is designed to produce a composite image that serves as an approximation of what the person of interest might look like. 
CSETv1_Annotator-1,360,True,360,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,maybe,no,no,no,none,"4.2 - McDonald's was sued by Shannon Carpenter, who claimed that McDonald's voice-recognition drive-through technology violated  Illinois’ Biometric Information Privacy Act (BIPA). However, Carpenter and McDonald's later jointly filed a stipulation in Illinois federal court to have the case dismissed.",no,yes,yes,True,no,,2021,06,,False,no,yes,Chicago,IL,US,North America,,,,"McDonald's, McD Tech Labs, McDonald's voice-recognition drive-through software, McDonald's customers in Chicago, IL",0,0,False,,McDonald's implemented voice recognition technology to automate the drive-through ordering process with AI.,"voice input, McDonald's drive-through orders",accommodation and food service activities,no,Autonomy2,9.5 - Restaurant workers are able to jump in to help the AI.,No. Not intentionally designed to perform harm,,voice recognition,voice recognition,
CSETv1_Annotator-1,490,True,490,005,2. Initial annotation complete,,False,no,yes,maybe,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,maybe,True,none,3.3 - The existence of chatbot AIs like ChatGPT is not directly linked to the adverse outcome of this incident. Human users actively choose to use AI to try and generate submissions that they can get paid for.,no,no,no,no,no,none,,no,yes,maybe,True,no,,2023,02, ,False,no,no,,,,Global,,,February 2023 refers to the date on which Clarkesworld editor Neil Clarke closed story submissions.,"Clarkesworld Magazine, ChatGPT, Clarkesworld Magazine story submitters",0,0,False,,ChatGPT is a chatbot intended to generate text and answer user prompts. It is based on a large language model.,text,"information and communication, Arts, entertainment and recreation",no,Autonomy3,,No. Not intentionally designed to perform harm,,"text generation, chatbot",large language model,"10.1 - ChatGPT was designed to generate text. However, it was not intended to be passed for original work and submitted to publications that do not allow AI submissions."
CSETv1_Annotator-1,309,True,309,005,2. Initial annotation complete,,False,maybe,no,no,yes,no,yes,no,no,yes,non-imminent risk of tangible harm (an issue) occurred,yes,yes,True,AI tangible harm issue,"3.1 - 35 people were falsely matched at the Notting Hill Carnival. There was one correct match, but the person had already been arrested and was no longer wanted at the time that the system flagged them. Thus, no tangible harm occurred at the carnival where the facial recognition technology was deployed. However, there is the possibility that a future misidentification could lead to false arrest. ",no,maybe,no,no,maybe,race,"4.2 - The retention of facial images in police databases may be unlawful according to a 2012 ruling by the High Court. It is also possible that constant real-time surveillance is a rights violation.
4.5-4.6 - The software has yet to be tested for demographic accuracy biases and may perpetuate racial stereotypes, as facial recognition software tends to perform poorly on black people compared to white people.",maybe,yes,yes,True,maybe,,2017,08,,False,no,maybe,London,,GB,Europe,,,,"Metropolitan Police Service, Metropolitan Police's automated facial recognition technology, Notting Hill Carnival goers, British people, British people, Black British people",0,0,False,,"""Forces use facial recognition in two ways: one is after the fact, while cross-checking of images against mugshots held in national databases; the other involves real-time scanning of people's faces in a crowd to compare against a ""watch list"" that is freshly drawn up for each event."" ""The Metropolitan Police's automated facial recognition (AFR) technology has a 98 per cent false positive rate.""","facial images, video input",law enforcement,yes,Autonomy3,,No. Not intentionally designed to perform harm,,"facial recognition, identify criminals",facial recognition,
CSETv1_Annotator-1,476,True,476,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,maybe,tangible harm definitively occurred,yes,no,True,none,"3.3 - Even though Youtube may have helped ISIS recruit members and ""communicate its desired messages,"" it cannot be directly and clearly linked to the adverse tangible outcome of the terrorist attack because it did not force any of the terrorists to act or commit the physical acts. It is unclear that the attack would not have occurred if not for the AI.",no,no,no,yes,no,none,,yes,yes,yes,True,yes,,2015,11,13,False,no,no,Paris, ,FR,Europe,,,,"Nohemi Gonzalez , Paris 2015 terrorist attack victims, Google, Youtube, Youtube content recommender algorithm, Youtube users, ISIS",130,416,False,These deaths and injuries may not be clearly and directly linked to the AI.,Youtube's content recommender algorithm promotes content that users have shown interest in in the past. Someone who shows some interest in terrorist recruitment videos will be shown more recruitment videos based on past viewing habits. This feature may promote misinformation and encourage people to join harmful terrorist organizations.,Youtube videos,information and communication,no,Autonomy1,,Yes. Intentionally designed to perform harm but created an unintended harm (a different harm may have occurred),,content recommendation,,"10.1 - The recommender system was designed to promote content users showed interest in. However, this does not include content related to terrorism or videos being used to radicalize and recruit extremists."
CSETv1_Annotator-1,520,True,520,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,yes,no,non-imminent risk of tangible harm (an issue) occurred,yes,yes,True,AI tangible harm issue,"Because customers cannot pay for stolen items after the fact, it would be possible for shoppers to steal from Amazon Fresh stores either accidentally or intentionally, causing a financial loss to Amazon.",no,no,no,no,no,none,,no,yes,yes,True,no,,2022, ,,False,no,no,,,US,North America,,,,"Amazon, Amazon Fresh stores, Amazon Fresh cashierless checkout algorithm, Amazon Fresh customers",0,0,False,,"Amazon Fresh's computer vision-based checkout enables shoppers to pick up items and leave the store without having a discrete checkout phase to the visit. The shopping experience begins and ends with entry and exit gates requiring you to scan a QR code or credit card. Cameras track shoppers' movements and purchases, recognizing the products that shoppers pick up. A receipt is billed to the shoppers after they leave the store.","video input, camera footage",wholesale and retail trade,no,Autonomy3,"9.5 - There are likely humans in the loop if different cameras have different analyses of footage. According to Sean McGregors hypothesis, it appears Amazon is first checking for machine agreement, then having a human provide definitive labels only when the models are more likely to have failed.",No. Not intentionally designed to perform harm,store security camera,product recognition,computer vision,
CSETv1_Annotator-1,230,True,230,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,no,no,no,no,none,,no,yes,yes,True,no,,2019,03,01,False,no,no,Delray Beach,FL,US,North America,,,,"Tesla, Tesla Model 3 vehicle, Tesla Autopilot, Jeremy Banner, Tractor-trailer truck",1,0,False,,"Tesla's Autopilot system is meant to provide autonomous driving capacities to vehicles, navigating obstacles and reacting to real-time road situations.","sensor data, video input",transportation and storage,no,Autonomy2,,No. Not intentionally designed to perform harm,Tesla Model 3,semi-autonomous navigation,,
CSETv1_Annotator-1,337,True,337,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,yes,yes,tangible harm definitively occurred,yes,maybe,True,AI tangible harm event,"3.3 - Representatives from Tesla claimed that Autosteer was not engaged and was not the cause of the crash. Adaptive cruise control is only engaged with the driver is buckled and above five miles per hour. The driver may have backed out of the driveway, engaged Autosteer, and then switched seats to the back of the car. It is unclear whether or not Autopilot was engaged, as officials and Tesla representatives disagree.",no,no,no,no,no,none,,no,yes,maybe,True,no,,2021,04,17,False,no,yes,Spring,TX,US,North America,,,,"Tesla, Tesla Model S vehicle, Everette Talbot, William Varner",2,0,False,,"Teslas all feature an ""Adaptive Cruise Control"" which does not steer the car, but will keep it moving. The ACC attempts to detect obstacles in front of the car but is far from perfect at detecting stationary objects, including trees. It is most likely that the car was in ACC mode, not that Autopilot was engaged. ","sensor data, camera input",transportation and storage,no,Autonomy2,,No. Not intentionally designed to perform harm,Tesla Model S,"semi-autonomous navigation, obstacle avoidance",,
CSETv1_Annotator-1,368,True,368,005,2. Initial annotation complete,,False,maybe,no,no,yes,no,no,no,no,yes,non-imminent risk of tangible harm (an issue) occurred,yes,yes,True,AI tangible harm issue,"Although it is unclear that Blue Wolf and White Wolf have caused tangible harm, the facial recognition and citizen tracking systems could be used to cause military targeting and tangible harm in the future.",no,yes,no,no,yes,"nation of origin, citizenship, immigrant status",,yes,yes,yes,True,yes,,2021,,,False,no,no,West Bank,,PS,Asia,,,,"Israeli Defense Forces, Blue Wolf, White Wolf, Israeli soldiers, Palestinians in the West Bank, Palestinians in the West Bank, Palestinians in the West Bank",0,0,False,,"""Blue Wolf"" takes photos of Palestinians and stores them in a large-scale database. Once an image is captured, Blue Wolf matches that picture to a person in its database. Soldiers' phones will then flash a specific color that signifies if that individual should be arrested, detained, or left undisturbed. The Israeli military has also set up cameras throughout the city of Hebron that scan Palestinians' faces and identify them for soldiers at checkpoints. CCTV cameras, some of which point into people's homes, provide live monitoring. Israel also uses facial recognition software at West Bank checkpoints.

White Wolf is a desktop application which is also connected to the database with profiles of every Palestinian in the West Bank; their pictures, their family history, their education, and a security rating for each one of them. Israeli soldiers use the system to scan Palestinian ID's before they enter the West Bank for work or for other reasons.","facial images, surveillance camera footage",law enforcement,yes,Autonomy3,,Yes. Intentionally designed to perform harm and did create intended harm,,facial recognition,facial recognition,
CSETv1_Annotator-1,574,True,574,005,2. Initial annotation complete,,False,no,yes,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,maybe,no,none,,no,yes,yes,True,no,,2023,07, ,False,no,no,,,,Global,,,,"G/O Media, Gizmodo, Gizmodo writers, Google, Bard, OpenAI, ChatGPT",0,0,False,,ChatGPT and Bard are text-generation bots.,"text, user prompts","information and communication, Arts, entertainment and recreation",no,Autonomy3,9.5 - Bard and ChatGPT do not operate unless user prompted. The chatbot-written articles would not have been published without the active decision of human executives at G/O Media.,Yes. Intentionally designed to perform harm and did create intended harm,,"text generation, content generation",,10.1 - Bard and ChatGPT were designed to generate text. 
CSETv1_Annotator-1,461,True,461,005,2. Initial annotation complete,,False,no,no,maybe,yes,maybe,no,no,no,yes,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,no,yes,"race, financial means",,yes,yes,yes,True,yes,,2023,01, ,False,no,no,,,US,North America,,,"6.1 and 6.2 - Date refers to the publication of the paper ""Measuring and Mitigating Racial Disparities in Tax Audits""","Black taxpayers, EITC claimants, Internal Revenue Service, Audit selection algorithms, RegLab researchers",0,0,False,,"The IRS's audit selection algorithms automate the process of selecting returns for audit. The algorithms disproportionately flag tax returns with potential errors in the claiming of certain tax credits, like the earned-income tax credit, which supplements low-income workers' incomes in an effort to alleviate poverty. Research suggests that the IRS has focused on audits that are easier to conduct. However, Black Americans claiming the EITC only explained a small part of the audit differences. More than three-quarters of the disparity stems from how much more often Black taxpayers who claim the credit are audited, compared with EITC claimants who are not Black.","taxpayer profile, 148 million tax returns , 780000 audits, taxpayer names, census demographics","public administration, financial and insurance activities",yes,Autonomy3,,No. Not intentionally designed to perform harm,,audit selection,,
CSETv1_Annotator-1,273,True,273,005,2. Initial annotation complete,,False,no,maybe,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,no,yes,sexual orientation or gender identity,,yes,yes,yes,True,yes,,2020,12,24,False,no,no,,,US,North America,,,,"FaceApp, Erin Reed, FaceApp users with dysmorphia or dysphoria",0,0,False,,FaceApp is a photo editing app that generates realistic transformations of human faces based on user uploaded photos.,"facial images, selfies, uploaded images","information and communication, Arts, entertainment and recreation",no,Autonomy1,,unclear,,human facial image transformation,,10.1 - FaceApp was designed and intended to produce realistic transformations of human facial images.
CSETv1_Annotator-1,503,True,503,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,yes,no,none,,yes,yes,yes,True,yes,,2023,02,,False,no,no,,,,Global,,,,"Microsoft, Bing, Bing search chatbot, Martin von Hagen, Seth Lazar, BingBot users",0,0,False,,Microsoft Bing's chatbot is designed to automatically generate text to respond to user queries.,"user queries, text",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,"text generation, chat bot",,
CSETv1_Annotator-1,410,True,410,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,yes,no,none,,yes,yes,yes,True,yes,,2022,11,09,False,no,no, ,,DE,Europe,,,,"KFC, KFC app, KFC app automated messaging system, German KFC app users",0,0,False,,KFC's automated messaging system is designed to detect holidays and other days of significance and write relevant marketing messages. Messages created by the system are supposed to be checked by a human before being sent to users.,"dates of significance, marketing material","accommodation and food service activities, information and communication",no,Autonomy3,9.5 - Messages created by the system are supposed to be checked by a human before being sent to users. This message slipped through the cracks. ,No. Not intentionally designed to perform harm,,marketing material generation,,
CSETv1_Annotator-1,396,True,396,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,no,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,no,no,no,yes,sexual orientation or gender identity,,yes,yes,yes,True,yes,,2018, ,,True,no,no,,,US,North America,,,,"Uber, Uber Real-Time ID Check, Microsoft Cognitive Services, Janey Webb, Janey Webb, Transgender Uber drivers, Transgender Uber drivers",0,0,False,,"Uber's Real-Time ID Check prompts users to pull over and take a selfie. That photo is then compared to the drivers' photo on file. If the photo isn't a match, the driver's account is temporarily suspended while Uber ""looks into the situation.""",facial images,"transportation and storage, information and communication, professional, scientific and technical activities",no,Autonomy1,"9.5 - If the photo isn't a match, the account is deactivated. It is unclear whether a human is involved in this deactivation process.",No. Not intentionally designed to perform harm,,facial recognition,facial recognition,
CSETv1_Annotator-1,616,True,616,005,2. Initial annotation complete,,False,no,yes,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,no,no,none,,no,yes,yes,True,no,,2023,11,,False,no,no,,,US,North America,,,,"The Arena Group, Sports Illustrated, AdVon Commerce, Sports Illustrated readers",0,0,False,,"AdVon Commerce likely used AI to not only generate article content, but also writer profile pictures. It is unclear which AI tools were used or how they were deployed.",,"information and communication, Arts, entertainment and recreation",no,Autonomy3,9.5 - Text generation AIs operate at the behest of human users' commands. These texts also would not be published into articles in Sports Illustrated if not for the will of human operators.,No. Not intentionally designed to perform harm,,"text generation, content generation",,"10.1 - Text generation AIs are designed to answer user queries and generate content. However, no AI was created with the specific purpose of writing articles for Sports Illustrated."
CSETv1_Annotator-1,414,True,414,005,2. Initial annotation complete,,False,no,maybe,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,yes,no,none,,yes,yes,yes,True,yes,,2020,01,18,False,no,no,,,,Global,,,,"Facebook, Suu Kyi's official Facebook page, Facebook's Burmese to English translation algorithm, Xi Jinping",0,0,False,,"Facebook includes a built in translation tool between languages. However, it has faced numerous problems with translation from Burmese in the past.","text, Burmese text",information and communication,no,Autonomy3,,No. Not intentionally designed to perform harm,,"translation, Burmese to English translation",,
CSETv1_Annotator-1,519,True,519,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,imminent risk of tangible harm (near miss) did occur,yes,yes,True,AI tangible harm near-miss,,no,no,no,no,no,none,,no,yes,yes,True,no, ,2022,04,03,False,no,yes,Los Angeles,CA,US,North America,,,,"University of California Los Angeles, Starship Technologies, Starship delivery robot, ",0,0,False,,"The Starship delivery robot is designed to operate fully autonomously on more than 99 percent of deliveries. In the remaining 1 percent of the time, a persona connects remotely to the unit from one of the three countries with operator teams. In this case, the Starship vandalism detectors were triggered by the interference of humans to try and help the robot when it veered off the path. As soon as the unit registered potential vandalism, a human operator connected to the cameras and controls. The task for the human operator is to return the unit to the GPS track so it can continue on its path without human supervision.","video input, sensor data","accommodation and food service activities, transportation and storage",maybe,Autonomy2,,No. Not intentionally designed to perform harm,Starship delivery robot,autonomous food delivery,,
CSETv1_Annotator-1,517,True,517,005,2. Initial annotation complete,,False,maybe,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,yes,no,no,no,none,,yes,yes,yes,True,yes,,2018,02,,False,no,yes,New York,NY,US,North America,,,,"Man arrested for theft of socks from a T.J. Maxx store, Man arrested for theft of socks from a T.J. Maxx store, T.J. Maxx store, New York Police Department, T.J Maxx security guard",0,0,False,,Details about the facial recognition software NYPD used are unclear.,"surveillance footage, video input",law enforcement,yes,Autonomy3,,No. Not intentionally designed to perform harm,,facial recognition,facial recognition,
CSETv1_Annotator-1,501,True,501,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,yes,no,no,no,yes,"age, disability, financial means",,yes,yes,yes,True,yes,,2023, ,,True,no,no,,,US,North America,,,6.1 - Year refers to the date of publication of the investigation published by STAT. It is unclear how long algorithms have been in use for determining how soon patients can be discharged or whether or not patients meet coverage requirements. The source identifies June 2019 as when Frances Walter was wrongfully denied payment for her care.,"Frances Walter, Medicare and Medicaid patients, Medicare and Medicaid patients, Medicare Advantage insurers and healthcare insurance companies, NaviHealth, nH Predict",0,0,False,,"nH Predict uses details such as a person's diagnosis, age, living situation, and physical function to find similar individuals in a database of 6 million patients it compiled over years of working with providers. It then generates an assessment of the patient's mobility and cognitive capacity, along with a down-to-the-minute prediction of their medical needs, estimated length of stay, and target discharge date.","diagnosis, age, living situation, physical function",human health and social work activities,yes,Autonomy3,,No. Not intentionally designed to perform harm,,determine length of stay,,
CSETv1_Annotator-1,290,True,290,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,imminent risk of tangible harm (near miss) did occur,yes,yes,True,AI tangible harm near-miss,"By allowing contaminated beaches to stay open because of measurements taken by AI water quality monitoring systems, the Toronto government put beach-goers directly at risk of contracting E. coli and other bacteria.",no,no,no,no,no,none,,no,yes,yes,True,no,,2022, , ,False,no,yes,Toronto,,CA,North America,,,,"Toronto Public Health (city government), Toronto beachgoers, Cann Forecast, Sunnyside and Marie Curtis beaches, Water quality testing artificial intelligence predictive modeling tool",0,0,False,,"Waters that tested high for E. coli using traditional means were marked safe by the new AIPM system dozens of times. ""Cann Forecast describes its beach water monitoring system as a high-tech ""artificial intelligence algorithm"" that uses ""machine learning"" to provide ""real-time water quality advisories that are 90% accurate on average.""""",water samples,"human health and social work activities, public administration",yes,Autonomy3,,No. Not intentionally designed to perform harm,,water quality testing,machine learning,
CSETv1_Annotator-1,329,True,329,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,maybe,"no tangible harm, near-miss, or issue",yes,no,False,none,"There are no instances of users being influenced by Amazon's ""frequently bought together"" recommendations to build bombs. Even if there were, the harm would not be directly linked to the AI because the AI would not have directly caused the person to make the bomb.",no,no,no,maybe,no,none,4.4 - Exposing users to suggestions that could help them make bombs could be considered detrimental content.,maybe,yes,yes,True,yes,"5.3 - AI is directly linked to the intangible harm of detrimental content, or exposing people to suggestions that might help them make bombs.",2017,, ,True,no,no,,,,Global,,,,"Amazon, Amazon purchasers of black powder, thermite, ball bearings, and other potential bomb ingredients, Amazon recommender algorithm",0,0,False,,Amazon's recommender algorithm provides buyers of a product with suggestions of bundles of other items that other users frequently bought along with it.,"Amazon items, Amazon purchases",wholesale and retail trade,no,Autonomy1,,No. Not intentionally designed to perform harm,,,,
CSETv1_Annotator-1,245,True,245,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,maybe,yes,True,AI tangible harm event,"3.3 - The automated license plate reader did make a mistake in identifying Denise Green's license plate number, 5SOW350, as plate number 5SOW750 which belonged to a stolen vehicle.  However, police officers involved had several chances to verify the plate number or caution the others involved to do so. Sergeant Kim, who was the one that pulled Green over, did not visually identify all seven numbers on Green's license plate. Thus, even though verification protocols may not have been in place at the time of the incident, there were several points at which humans should have reasonably decided not to act on the automated system's misidentification.",no,maybe,no,no,no,none,,no,maybe,yes,True,no,,2009,03,30,False,no,yes,San Francisco,CA,US,North America,,,,"Denise Green, Automated license plate reader software, San Francisco Police Department, Alberto Esparza and Robert Pedersen, Sergeant Kim",0,0,False, ,Automated license plate readers parse passing vehicles and search for matches with license plate numbers in a database of vehicles that are stolen or wanted.,license plate images,law enforcement,yes,Autonomy3,"The ALPR operated by SFPD officers Alberto Esparza and Robert Pedersen misidentified Denise Green's plate as belonging to a stolen vehicle. Esparza reported it over the radio to Sergeant Kim, who apprehended Green. ",No. Not intentionally designed to perform harm,,license plate matching,,
CSETv1_Annotator-1,489,True,489,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,no,yes,"age, disability, race",,yes,yes,yes,True,yes,,2023,02, ,False,no,no,,,US,North America,,,Date refers to when the lawsuit against Workday was launched.,"Workday, Derek Mobley, Black people applying to jobs through Workday, Disabled people applying to jobs through Workday, Older people applying to jobs through Workday",0,0,False,,"Workday is used as a recruitment screening tool. Allegedly, ""the selection tools marketed by Workday to its customers allows these customers to manipulate and configure them in a discriminatory manner to recruit, hire, and onboard employees. Workday's products process and interpret an applicant's qualifications and recommend whether the applicant should be accepted or rejected.""",job application,"professional, scientific and technical activities, information and communication",no,unclear,"9.5 - It is unclear whether the Workday recruitment screening tools completely eliminate certain candidates from the applicant pool before a human ever sees them, or if the tools only provide recommendations to human reviewers about whether or not to hire the candidate.",No. Not intentionally designed to perform harm,,"recruitment screening, job screening",,
CSETv1_Annotator-1,563,True,563,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,no,True,none,"3.3 - The AI is not linked to the incident. The robotaxi Cruise vehicles were accused of blocking ambulance trucks and emergency responders trying to save Sammy Davis. However, it was actually a city bus that fatally struck Davis. Cruise denied that its vehicles had anything to do with Davis's death, claiming that only 90 seconds elapsed between the time when he was put on a stretcher and when the man left the scene. ",no,no,no,no,no,none,,no,yes,no,True,no,,2023,08,14,False,no,yes,San Francisco,CA,US,North America,,,,"Cruise driverless taxis, Cruise, San Francisco Fire Department, SFPD ambulance, Sammy Davis, San Francisco city bus",1,0,False,,Cruise robotaxis are designed to autonomously navigate roads and respond to real-time traffic conditions using sensors and geospatial data.,"sensor input, geospatial data",transportation and storage,no,Autonomy1,,No. Not intentionally designed to perform harm,,autonomous navigation,,The AI did not cause a harm in this incident
CSETv1_Annotator-1,234,True,234,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,non-imminent risk of tangible harm (an issue) occurred,yes,yes,True,AI tangible harm issue,"3.1 - This incident can be classified as an non-imminent risk of tangible harm because harm could happen in the future if Waze did not alter its algorithm to halt the diversion of traffic from Highway, as it would ""amount to a 'death sentence' for people in the Glenridge and Almond Grove neighborhoods in the event of a wildfire."" This incident is about a Los Gatos man, Jeffrey Siegel, who has rallied locals around the cause of Waze modifying its algorithm after Los Gatos ranked very highly on wildfire hazard potential. That is, no wildfire occurred in Los Gatos as of the incident reports. However, considering Los Gatos' wildfire risk, it is reasonable to assume a non-imminent risk of tangible harm.",no,no,no,no,no,none,,no,yes,yes,True,no,,2019,,,False,no,no,Los Gatos,CA,US,North America,,natural disaster - wildfires,,"Los Gatos residents, Google, Waze, Waze users",0,0,False,,Waze uses machine learning to predict traffic patterns based on GPS data and other users' reports in order to optimize routes for the primary user. ,"user traffic reports, route specifications, road data, traffic, GPS input","information and communication, transportation and storage",no,Autonomy3,,No. Not intentionally designed to perform harm,,"navigation, route optimization","shortest-path algorithm, Dijkstra Algorithm",
CSETv1_Annotator-1,571,True,571,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",maybe,no,False,none,"3.2 - There is no AI in this incident. The GitHub repositories that included vulnerabilities were meant to proliferate and share Microsoft's AI products, but no AI were directly involved in this incident. 
3.3 - AI cannot be directly linked to this incident. The data vulnerability resulted from faulty configuration of SAS tokens in Azure by Microsoft employees. ",no,no,no,no,no,none,,no,maybe,no,False,no,,2023,06,22,False,no,no,,,,Global,,,"Dat refers to when Wiz Research found and reported issues to MSRC. See further timeline details below: 
Jul. 20, 2020 – SAS token first committed to GitHub; expiry set to Oct. 5, 2021 
Oct. 6, 2021 – SAS token expiry updated to Oct. 6, 2051 
Jun. 22, 2023 – Wiz Research finds and reports issue to MSRC 
Jun. 24, 2023 – SAS token invalidated by Microsoft 
Jul. 7, 2023 – SAS token replaced on GitHub 
Aug. 16, 2023 – Microsoft completes internal investigation of potential impact 
Sep. 18, 2023 – Public disclosure","Wiz Research, Microsoft, Microsoft AI Research Division",0,0,False,,"Researchers shared their files to GitHub in an effort to open-source AI research using an Azure feature called SAS tokens. In this case, the access level was configured to share the entire storage account which exposed 38 TB of private files.","Azure Storage accounts, private files",information and communication,no,Autonomy3,"9.5 - There is no AI system here. The SAS tokens are not AI. However, they do operate under level 3 autonomy. Configuration is done by human software developers.",,,,,no AI 
CSETv1_Annotator-1,581,True,581,005,2. Initial annotation complete,,False,no,maybe,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,no,no,none,"4.4 - The websites don't necessarily contain detrimental content, just content that is redundant and of poor quality",no,yes,yes,True,no,,2023,06,,True,no,no,,,,Global,,,,"Brands that pay for Google-served ad-placement, Programmatic advertising algorithms, Made for advertising websites, Generative AI , NewsGuard, Google, Google Ads",0,0,False,,"Generative AI can be used to generate text and images that content farms use to churn out articles to attract impressions and ad placements. 

Programmatic ad placement algorithms calculate which websites will be likely to attract the highest number of views to determine where brands should place their ads.","websites, articles, text",information and communication,no,Autonomy3,Generative AI would not be deployed to write articles and generate images for content farms without human intention.,No. Not intentionally designed to perform harm,,content generation,,
CSETv1_Annotator-1,455,True,455,005,2. Initial annotation complete,,False,no,maybe,no,yes,no,yes,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,yes,no,none,"4.4 - The AI chatbots produced misinformation, like miscalculating the compounded interest earnings on a savings account deposit.",yes,yes,yes,True,yes,,2023,01,,False,no,no,,,,Global,,,Date refers to Futurism's report that the prominent technology news site CNET had been quietly publishing articles generated by AI. It is unclear how long before the report CNET was implementing AI.,"Futurism, CNET, ChatGPT, OpenAI, CNET readers",0,0,False,,ChatGPT is a chatbot that uses AI to generate text and content based on user prompts.,"queries, prompts",information and communication,no,Autonomy3,"9.8 - The articles would not have been published without human approval. In addition, Guglielmo promised that every story published under the program had been ""reviewed, fact-checked, and edited by an editor with topical expertise before we hit publish.""",No. Not intentionally designed to perform harm,,"text generation, content generation",large language models,
CSETv1_Annotator-1,596,True,596,005,2. Initial annotation complete,,False,yes,no,no,yes,no,yes,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,no,no,no,no,none,,no,yes,yes,True,no,,2023,10,02,True,no,yes,San Francisco,CA,US,North America,,,"This incident describes the National Highway Traffic Safety Administration's probe into 600 of Cruise's driverless vehicles. Date refers to one of the incidents NHTSA cited from October 2023 when a woman was severely injured in a hit-and-run crash in San Francisco. She was struck by a vehicle, whose driver later fled the scene, and then launched into the path of a driverless Cruise car. The Cruise vehicle came to a stop on top of the pedestrian. Rescue crews had to lift the car off the woman, who was then transported to the hospital.","General Motors, Cruise, National Highway Traffic Safety Administration, Unnamed woman injured in a hit-and-run and stopped on top of by a Cruise vehicle., Cruise vehicles, Unnamed hit-and-run driver, San Francisco pedestrians",0,1,True,There may have been more injuries involved in the probed incidents.,"Cruise autonomous vehicles aim to autonomously navigate roads, respond to obstacles, and react to real-time traffic and condition updates.","geospatial data, sensor data",transportation and storage,no,Autonomy1,,No. Not intentionally designed to perform harm,Cruise AV,autonomous navigation,,
CSETv1_Annotator-1,436,True,436,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,imminent risk of tangible harm (near miss) did occur,yes,yes,True,AI tangible harm near-miss,"Although no harm occurred, the Tesla driver was asleep and had used a steering wheel weight to bypass safeguards. Harm could very nearly have occurred, especially since law enforcement was involved and the sleeping driver did not comply with their instructions to pull over for a traffic stop.",no,no,no,no,no,none,,no,yes,yes,True,no,,2022,12,29,False,no,yes,Bamberg,,DE,Europe,,,,"Tesla vehicle, Tesla, Unnamed Tesla driver, German police",0,0,False,,"Tesla's autonomous vehicles are designed to navigate roads, respond to obstructions, and react to real-time traffic and condition updates.","geospatial data, sensor data",transportation and storage,no,Autonomy2,"9.5 - Semi-autonomous Teslas operate on autonomy level 2. However, in this case, the driver was also asleep. This means that he would not have been able to provide oversight if the vehicle prompted him to.",No. Not intentionally designed to perform harm,Tesla vehicle,semi-autonomous navigation,,
CSETv1_Annotator-1,507,True,507,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,yes,no,none,,yes,yes,yes,True,yes,,2023,04,,False,no,no,,,,Global,,,,"ChatGPT, OpenAI, Brian Hood, ChatGPT users",0,0,False,,ChatGPT is a chatbot that generates text and content based on user queries. ,"user queries, user prompts, text",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,"content generation, text generation",large language models,
CSETv1_Annotator-1,220,True,220,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,no,no,no,maybe,financial means,Primarily small to medium-sized business owners were affected.,maybe,yes,yes,True,maybe,,2020,11, ,False,no,no,,,,Global,,,"Facebook switched to relying more heavily on artificial intelligence to police its platform after the COVID-19 pandemic began in March 2020. However, users mainly started reporting their ads being unjustly taken down in November of 2020.","Facebook (now Meta), Facebook automated spam filters, Small businesses on Facebook, Advertisers on Facebook",0,0,False,,Facebook deploys automated spam filters to moderate content and take down ads/posts that violate its content policies. ,"Facebook ads, Facebook posts","wholesale and retail trade, information and communication",no,Autonomy1,,No. Not intentionally designed to perform harm,,content moderation,,
CSETv1_Annotator-1,254,True,254,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,no,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,maybe,no,no,no,none,"4.2 - Google's agreed to pay $100 million to settle a class-action lawsuit regarding its facial grouping tool, which automatically identifies your face in photos and videos uploaded to Photos. Plaintiffs in Illinois sued for the violation of their privacy rights as outlined by the Illinois Biometric Information Privacy Act.",no,yes,yes,True,no,,2022,, ,True,no,no,,IL,US,North America,,,"Anyone who appeared in a photo on Google Photos between May 1, 2015, and April 25, 2022, while they were an Illinois resident was eligible to submit a claim for their part of the settlement.","Google, Google Photos, Google Photos users in Illinois",0,0,False,,Google Photo's facial grouping tool recognizes and sorts faces on Google Photos by similarity.,"photos in Google photos, photos, facial images",information and communication,no,Autonomy1,,Yes. Intentionally designed to perform harm but created an unintended harm (a different harm may have occurred),,"facial recognition, facial grouping",,"10.1 - Google Photos' facial grouping tool was intended to recognize and sort faces. However, it was not intended to violate any users' rights."
CSETv1_Annotator-1,576,True,576,005,2. Initial annotation complete,,False,no,maybe,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,maybe,yes,no,none,"4.3 and 4.4 - PicSo emphasizes ""girls."" Although the AI images do not specify what age the people in the images are, the AI has harmful applications. ",yes,yes,yes,True,yes,,2023,11, ,False,no,no,,,,Global,,,"Date refers to post made by Patrick Hall on Linkedin, who drew attention to the existence of PicSo AI's ads on Instagram.","PicSo AI, Instagram, PicSo AI users",0,0,False,,PicSo AI is an app that uses generative AI to create images and perform image generation services based on user uploaded images and requests.,images,information and communication,no,Autonomy1,,Yes. Intentionally designed to perform harm and did create intended harm,,image generation,,10.1 - PicSo AI was developed to generate images and could very well be used to generate detrimental and inappropriate content.
CSETv1_Annotator-1,313,True,313,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,yes,no,none,,yes,yes,yes,True,yes,,2022,08,24,False,no,no, ,,,Global,,,,"Marietje Schaake, BlenderBot 3 users, BlenderBot 3, Meta",0,0,False,,"Meta's BlenderBot 3 was a ""state-of-the-art conversational agent"" developed as a research project that generated text responses to user prompts.","user prompts, user queries, text",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,text generation,large language models,
CSETv1_Annotator-1,558,True,558,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,imminent risk of tangible harm (near miss) did occur,yes,no,True,none,"3.1 - NYPD ""sent dozens of officers, including some in riot gear, to the home of the 28-year-old activist Derrick Ingram. A stand-off followed....the NYPD has been criticized for the disproportionate show of force in pursuing Ingram.""
3.2 - NYPD's use of force was not directly related to the facial recognition software used to identify Ingram. The AI did not cause the physical harm.",no,maybe,no,no,yes,"race, ideology",4.2 - It is unclear whether photos from Ingram's personal social media were used in the facial recognition process. NYPD is only supposed to use arrest photos and surveillance video footage. Using social media images would be a breach of NYPD's own policies.,yes,yes,yes,True,yes,,2020,08,07,False,no,no,New York,NY,US,North America,,,,"NYPD, NYPD facial recognition software, Derrick Ingram, Derrick Ingram",0,0,False,,The New York Police Department uses facial recognition software to compare still images with arrest photos or surveillance video footage to assist in their daily operations.,"photos, arrest photos, surveillance footage",law enforcement,yes,Autonomy3,,No. Not intentionally designed to perform harm,,facial recognition,,
CSETv1_Annotator-1,367,True,367,005,2. Initial annotation complete,,False,no,no,maybe,yes,no,yes,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,yes,yes,sex,,yes,yes,yes,True,yes,,2021,01,,True,no,no, ,,,Global,,,,"Ryan Steed and Aylin Caliskan, OpenAI, iGPT, Google, SimCLR, Women",0,0,False,,"Steed and Caliskan examined embeddings within image-generation algorithms, which separate pixels based on how often they co-occur within training images. Those pixel embeddings can then be used to compare how close or far two images are in mathematical space.  AI algorithms like iGPT and SimCLR are used to auto-complete input images.",images,information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,,"unsupervised learning, natural language processing, pixel embeddings",
CSETv1_Annotator-1,387,True,387,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",no,yes,False,none,,no,maybe,no,no,no,,"The substance of the class action  litigation ""hinges on allegations that Oracle collects vast amounts of data from unwitting Internet users, i.e. without their consent, and uses this surveillance intelligence to profile individuals, further enriching profiles via its data marketplace and threatening people's privacy on a vast scale.""",maybe,no,yes,True,no,,2022,08, ,False,no,no,,,US,North America,,,,"Oracle, Internet users surveilled by Oracle, Dr. Johnny Ryan, Michael Katz-Lacabe, Dr. Jennifer Golbeck, Lieff Cabraser, Oracle data collection tools",0,0,False,,Oracle may collect data from Internet users without their consent in order to create more comprehensive user profiles to sell on the marketplace for data.,Internet usage,information and communication,no,unclear,,,,,,no AI
CSETv1_Annotator-1,341,True,341,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,"Nissan said it knew of ""at least 30 allegations of 'minor collisions' stemming from automatic emergency braking incidents, and 10 reports alleging 'minor injuries.'""",no,no,no,no,no,none,,no,yes,yes,True,no,,2017,,,True,no,yes,, ,US,North America,,,"The allegations come from Rogue and Rogue Sport vehicles produced in the 2017 to 2020 model years, and Sentras made in the 2018 and 2019 model years. Other vehicles that may be equipped with faulty Automatic Emergency Braking (AEB) systems include the Nissan Pathfinder, Murano, Altima, Maxima, Armada, Leaf, Sentra, Kicks, and Versa.","Nissan, Nissan Rogue, Rogue Sport, and Sentra vehicles, Nissan drivers",0,10,True,,"Nissan vehicles' Automatic Emergency Braking systems are there to ""alert drivers of a possible imminent frontal collision, braking if the driver doesn't respond to the warning by putting on the brakes themselves. Nissan's AEB systems use radar to determine pedestrians, other vehicles and other potential obstacles ahead of a car."" However, the systems are accused of detecting non-existent obstacles, providing false alarms, or triggering the brakes despite no obstacles being present. This is especially dangerous because the emergency braking systems have falsely engaged while in intersections or on bridges, highways and railroad tracks. The activation of the brakes allegedly makes it difficult for drivers to move out of the way of danger, putting them at an increased risk of side-on or rear-end collisions.",radar input,transportation and storage,no,Autonomy2,,No. Not intentionally designed to perform harm,"Nissan vehicles (Rogue, Rogue Hybrid, Rogue Sport, Sentra)",automatic emergency braking,,
CSETv1_Annotator-1,554,True,554,005,2. Initial annotation complete,,False,no,yes,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,"3.2 - There are two AI systems potentially involved in this incident - first, the AI that was used to generate the Vermeer ""Girl with a Pear Earring"" replica. Second, Google's search algorithm that placed the AI-generated image in the featured card of the Google search result.",no,no,no,yes,no,none,,yes,yes,yes,True,yes,,2023,06, ,False,no,no,,,,Global,,,,"Google , Google's search engine algorithm, Google users interested in art, Julian van Dieken",0,0,False,,"While it is unclear which AI image generation software van Dieken used to generate the replica image, he likely inputted details about the original painting to prompt the AI to generate the image that it did. ","user queries, user prompts","Arts, entertainment and recreation",no,unclear,9.5 - The image-generation AI was operating under Autonomy3 and would not have produced an image without the prompts of van Dieken. Google's search engine algorithm likely operates under Autonomy1.,No. Not intentionally designed to perform harm,,"image generation, search optimization, search engine optimization",,
CSETv1_Annotator-1,339,True,339,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,yes,no,no,none,,no,yes,yes,True,no,,2022,,  ,True,no,no,,,,Global,,,,"Sudowrite, OpenAI, ChatGPT, Teachers, Non-cheating students, Cheating students",0,0,False,,"Sudowrite, ChatGPT, and other tools are used in some instances to facilitate cheating in academic settings. These tools accept user prompts/queries and specifications about output in order to answer essay questions or provide unauthorized assistance with assignments for students.","user queries, user prompts, text","Education, information and communication",no,Autonomy3,,No. Not intentionally designed to perform harm,,text generation,large language models,
CSETv1_Annotator-1,510,True,510,005,2. Initial annotation complete,,False,no,yes,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,maybe,no,none,,yes,yes,yes,True,yes,,2023,03, ,False,no,no,,,,Global,,,,"Twitter user skyferrori, Midjourney Inc., Midjourney v5, Pope Francis, Twitter users",0,0,False,,Midjourney v5 is an image synthesis service that creates artificially-generated photos based on user prompts.,"user prompts, user queries","information and communication, Arts, entertainment and recreation",no,Autonomy3,,No. Not intentionally designed to perform harm,,image generation,,
CSETv1_Annotator-1,474,True,474,005,2. Initial annotation complete,,False,no,yes,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,yes,no,none,"In January of , many Replika users noticed that the interactions with their AI companions were veering increasingly toward the vulgar - even if they didn't initiate it. Many found this sudden change ""unwelcome and disturbing.""",yes,yes,yes,True,yes,,2023,02, ,False,no,no,,,,Global,,,"6.4 - Users noticed unwelcome vulgar responses from the Replika AI in January of 2023. In February, users started noticing that their Replika companions were no longer engaging in erotic roleplay (ERP), a service initially advertised as part of the product.","Luka, Replika, Replika users, Replika users",0,0,False,,Replika's AI chatbot provided sexually-charged conversations as part of a $70-per-year paid tier.  It advertised that users could find sexual fulfillment or emotional support through use of the chatbot.,text,"Arts, entertainment and recreation",no,Autonomy1,,No. Not intentionally designed to perform harm,,chat bot,,
CSETv1_Annotator-1,509,True,509,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,no,no,maybe,no,none,,maybe,yes,yes,True,no,,2023,03,  ,False,no,no,,,VN,Asia,,,,"Deepfake technology, Deepfake scam victims in Vietnam, Deepfake scammers, Deepfaked Facebook users in Vietnam",0,0,False,,"Scammers using deepfake technology began by collecting visual data on victims from Facebook, Zalo, etc. Then, they would collect personal data such as the victims' phone numbers, email addresses, and family relationships. Next, they would make a phone or video call using deepfaked audio and video of the victims in order to convince their family members and acquaintances to transfer money to their compromised accounts.","Facebook accounts, facial images, personal information, family relationships",information and communication,no,Autonomy3,,No. Not intentionally designed to perform harm,,"deepfake video generation, deepfake audio generation",,
CSETv1_Annotator-1,412,True,412,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,yes,yes,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,yes,yes,no,no,none,,yes,yes,yes,True,yes,,2021,04,08,False,no,no, ,,,Global,,,"6.4 - Date refers to the discovery of the incident by Finland's National Bureau of Investigation. However, the tool was presented to Finnish authorities as early as 2019.
6.10 - Buzzfeed discovered that 88 international government-affiliated and taxpayer-funded agencies and organizations around the globe used Clearview AI.","Clearview AI, Clearview AI facial recognition software, Law enforcement agencies and government organizations, Subjects of images scraped from the web by Clearview AI",0,0,False,,ClearView AI distributes a facial recognition tool that law enforcement officers can use to receive matches on photos of suspects or people of interest. It claims its software is more accurate than other facial recognition technologies because it is trained on a database of more than 3 billion images scraped from websites and social media platforms.,"facial images, images from websites, scraped images, images from social media","law enforcement, information and communication",yes,Autonomy3,,No. Not intentionally designed to perform harm,,facial recognition,,
CSETv1_Annotator-1,284,True,284,005,2. Initial annotation complete,,False,no,yes,no,yes,no,no,no,no,no,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,"Teacher Frederic Durand-Baissas sued Facebook for €20,000.",no,maybe,no,maybe,no,none,"4.2 - Facebook's removal of certain advertisements for art was denounced as censorship.
4.4 - Nude artwork may be considered by Facebook as detrimental content.",maybe,yes,yes,True,maybe,,2015,,,True,no,no,,,,Global,,,"2015 refers to the date of French teacher Frederic Durand-Baissas winning in court the right to post a link to Facebook with the image of a painting including nudity.

In 2017, art broker Mossgreen tried to promote a painting by Charles Blackman's including nudity but Facebook rejected it for ""advertising adult products or services.""
Art broker Mossgreen tried to promote it on Facebook, but the social media network rejected it for ""advertising adult products or services"".

In 2018, the Flanders tourist board had their posts featuring artwork of nude women taken down. Also in 2018, the Montreal Museum of Fine Arts' online ads got taken down.

","Meta, Facebook, Frederic Durand-Baissas, Mossgreen, Flanders Tourist Board, Montreal Museum of Fine Arts, Vienna museums",0,0,False,,"Facebook's automated content removal algorithms review advertisements for features that violate its content policies, for example, nudity. Facebook does allow users to post images of nude paintings, as well as photographs of paintings, sculptures and other art that depicts nude figures. The standards for advertisements are currently more stringent and do not allow nudity in paintings in ads, though an exception was made in this instance for fine art.","Facebook advertisements, images","information and communication, Arts, entertainment and recreation",no,Autonomy1,,No. Not intentionally designed to perform harm,,content moderation,,
CSETv1_Annotator-1,447,True,447,005,2. Initial annotation complete,,False,no,yes,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,maybe,no,none,,no,yes,yes,True,no,,2022,12,18,False,no,no,,,,Global,,,,"Alexis Mac Allister, Meta, Instagram, Instagram translation function, Instagram users",0,0,False,,"The Instagram translation function allows users to translate comments and captions in other languages. In this case, it translated a slang phrase in Spanish into English very literally, without the relevant cultural context. The result was a ""controversial X-rated message"" that did not convey what Mac Allister originally intended.",text,"information and communication, Arts, entertainment and recreation",no,Autonomy1,,No. Not intentionally designed to perform harm,,"translation, language translation",natural language processing,
CSETv1_Annotator-1,304,True,304,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,yes,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,no,no,no,no,none,,no,yes,yes,True,no,,2021,11,03,False,no,yes,Brea,CA,US,North America,,,,"Tesla Model Y vehicle, Tesla Full Self-Driving beta mode, Tesla Model Y driver, Tesla, Tesla drivers",0,0,False,,"FSD is not an autonomous driving system. Drivers are required to remain vigilant. FSD is Tesla's driver assist feature, which has functions to navigate road obstacles and react to real time traffic conditions. Tesla made the decision to test its ""Full Self Driving"" driver assistance software with untrained vehicle owners on public roads.","geospatial data, sensor data",transportation and storage,no,Autonomy2,"9.5 - In the case, the driver reported trying but failing to override the system's decisions in real time.",No. Not intentionally designed to perform harm,Tesla Model Y,semi-autonomous navigation,,
CSETv1_Annotator-1,559,True,559,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,maybe,non-imminent risk of tangible harm (an issue) occurred,yes,yes,True,AI tangible harm issue,"3.1 - Assessor reports are used by the Australian Research Council's College of Experts to decide which grant proposals should ultimately receive government funding. For example, in 2022, only 19% of Discovery Projects in the funding round were ultimately successful.",no,no,no,no,no,none,,no,yes,yes,True,no,,2023,07,,False,no,no,,,AU,Oceania,,,,"OpenAI, ChatGPT, Australian Research Council, Australian Research Council grant appliers, Australian Research Council grant peer-reviewers, Australian Research Council grant peer-reviewers",0,0,False,,ChatGPT is a chatbot that generates text according to user prompts and queries.,"text, user prompts, user queries","information and communication, Education",yes,Autonomy3,9.4 - The Australian Research Council is the primary non-medical research funding agency of the Australian Government. ,No. Not intentionally designed to perform harm,,"text generation, chat bot",natural language processing,"10.1 - ChatGPT was designed to generate text. However, it is not intended to be used for academic integrity violations."
CSETv1_Annotator-1,358,True,358,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,maybe,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,no,no,none,"4.2 - ""Under Alberta's Personal Information Privacy Act, people need to be notified their private information is being collected, but as the mall isn't actually saving the recordings, what they're doing is legal.""",no,yes,yes,True,no,,2018,06,,False,no,yes,Calgary,AB,CA,North America,,,"6.1 and 6.2 - Cadillac Fairview, the malls' parent company, said they began using the facial recognition software in June.","Calgary malls, Cadillac Fairview, Calgary mall shoppers, MappedIn facial recognition software, MappedIn",0,0,False,,"The software was described to be able to approximate, for example, how many men in their 60s used the directory, but did not store images of their faces or collect any other biometric data. Cadillac Fairview described that the data was ""used in aggregate to understand directory usage patterns to 'create a better shopper experience.'""",facial images,wholesale and retail trade,no,Autonomy1,,No. Not intentionally designed to perform harm,,facial recognition,,
CSETv1_Annotator-1,456,True,456,005,2. Initial annotation complete,,False,no,yes,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,yes,yes,no,none,,yes,yes,yes,True,yes,,2021,,,True,no,no, ,,,Global,,,6.1 - There are instances of Replika AI being overly sexual since as early as 2021.,"Luka, Replika, Replika users, Eugenia Kuyda",0,0,False,,Replika AI is a chatbot that uses Luka's own GPT-3 model and scripted dialogue content in order to customize conversations with users.,text,"Arts, entertainment and recreation, information and communication",no,Autonomy1,,unclear,,chat bot,natural language processing,"10.1 - Replika AI was designed to initiate and reciprocate sexual conversations. However, this incident includes instances in which it was overly violent or sent sexual messages to users who didn't request it."
CSETv1_Annotator-1,294,True,294,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,no,no,no,no,none,,no,yes,yes,True,no,,2018,05,,False,no,yes,Thessaloniki, ,GR,Europe,,,,"Tesla, Tesla Model 3, You You Xue, Tesla Autopilot",0,0,False,,Tesla's Autopilot is designed to assist drivers by semi-autonomously navigating road obstacles and responding to real-time traffic conditions.,"geospatial data, sensor data",transportation and storage,no,Autonomy2,,No. Not intentionally designed to perform harm,Tesla Model 3,semi-autonomous navigation,,
CSETv1_Annotator-1,354,True,354,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,maybe,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,"3.1 - Uber lost in an appeals court in the Netherlands and was ordered to pay a fine of €10,000 every day it continued to violate data protection laws. Uber was withholding details about its batch matching and upfront pricing systems, as well as ""information about the existence of automated decision-making... including assigning rides, calculating prices, rating drivers, calculating 'fraud probability scores', deactivating drivers' accounts,"" etc. This, especially wrongful termination of accounts, could cause drivers financial loss. In this instance, the company Uber experienced tangible AI harm while drivers experienced a non-imminent risk of financial loss.",no,yes,no,no,no,none,"4.2 - an appeals court in the Netherlands ""found largely in favor of platform workers litigating against ride-hailing giants... judging the platforms violated the drivers' rights in a number of instances, including when algorithms were involved in terminating driver accounts.""",yes,yes,yes,True,yes,,2019, ,,True,no,no,,,,Europe,,,6.1 - it is unclear how long Uber has been using algorithmic decision making.,"Uber, European Uber drivers, European Uber drivers, Uber app",0,0,False,,"Uber automates decision-making for management functions such as driver termination, account deactivation, upfront pricing, batch matching, fraud probability scores, profiling, assigning riders, calculating pricing, rating drivers, and more",Uber accounts,transportation and storage,no,Autonomy1,,No. Not intentionally designed to perform harm,,,,
CSETv1_Annotator-1,214,True,214,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,imminent risk of tangible harm (near miss) did occur,yes,yes,True,AI tangible harm near-miss,,no,no,yes,no,yes,race,,yes,yes,yes,True,yes,,2020,01, ,False,no,yes,New York,NY,US,North America,,,,"Lockport City School District, SN Technologies, AEGIS face and weapons detection system, Lockport City School District students, id3 Technologies",0,0,False,,SN Technologies' weapons and facial recognition software uses facial recognition to surveil students and identify objects within the school to see if they are guns or not. It was found that these systems reported a lot of false alarms.,"video input, camera footage","Education, law enforcement, public administration",yes,Autonomy3,,No. Not intentionally designed to perform harm,,"facial recognition, object detection, weapons detection",facial recognition,
CSETv1_Annotator-1,547,True,547,005,2. Initial annotation complete,,False,no,maybe,no,yes,no,no,no,no,maybe,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,yes,no,none,,yes,yes,yes,True,yes,,2023,06,05,False,no,no, ,,US,North America,,,,"Ron DeSantis's campaign, Donald Trump, People who viewed the DeSantis campaign's AI-generated images",0,0,False,,"It is unclear which tool was used. However, DeSantis's campaign used some technology to generate fake images of Donald Trump hugging Anthony Fauci.",images,other,no,Autonomy3,9.3 - political advertising,No. Not intentionally designed to perform harm,,image generation,,
CSETv1_Annotator-1,526,True,526,005,2. Initial annotation complete,,False,no,yes,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,maybe,no,no,no,none,4.2 - there are no established legal standards on whether or not deepfake AI of artist's voices violates copyright laws,no,yes,yes,True,no,,2023,04, ,False,no,no,,,,Global,,,,"Drake and The Weeknd, @ghostwriter, Universal Music Group",0,0,False,,"It is unclear which deepfake AI technology TikTok user @ghostwriter used to create the viral song ""Heart On My Sleeve."" However, it was likely trained with catalogs of Drake's and The Weeknd's music. Then, @ghostwriter likely inputted lyrics and prompted the AI to output a likeness of Drake and The Weekend singing them.","songs, Drake songs, Drake voice, The Weeknd songs, The Weeknd voice","Arts, entertainment and recreation",no,Autonomy3,,unclear,,deepfake audio generation,,"10.1 - The technology used was designed to deepfake voices. However, it was likely not intended to infringe on copyrights, as UMG alleges it does."
CSETv1_Annotator-1,619,True,619,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,non-imminent risk of tangible harm (an issue) occurred,yes,yes,True,AI tangible harm issue,"3.1 - People flagged as shoplifters by Rite Aid's facial recognition technology could be approached, asked to leave without finishing their purchases, searched, humiliated, or reported to the police. ",no,no,no,no,yes,race,,yes,yes,yes,True,yes,,2012, ,,True,no,yes,,,US,North America,,,6.1 - The FTC alleged that Rite Aid deployed facial recognition technology in hundreds of retail pharmacies and stores between 2012 and 2020.,"Federal Trade Commission, Rite Aid, Rite Aid customers, Rite Aid customers, DeepCam, FaceFirst, Rite Aid pharmacies and stores",0,0,False,,"Rite Aid supervised the creation of a ""watchlist database"" of images of people the company claimed had engaged in actual or attempted criminal activity at one of its stores. These entries included ""first and last names, years of birth, and a description of behavior Rite Aid claimed the person in the photo had engaged in... According to the complaint, Rite Aid directed store security to ""push for as many enrollments as possible."" If someone who entered the store matched an image in the database, employees received an alert and could choose to follow, apprehend, report, or otherwise engage with the customer. However, Rite Aid's technology was found to disproportionately misidentify black, Asian, Latino, and female consumers as matching an image in the database.","store camera footage, camera footage, surveillance footage",wholesale and retail trade,no,Autonomy3,,No. Not intentionally designed to perform harm,,facial recognition,facial recognition,
CSETv1_Annotator-1,564,True,564,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,imminent risk of tangible harm (near miss) did occur,yes,yes,True,AI tangible harm near-miss,,no,no,no,no,no,none,,no,yes,yes,False,no,,2023, ,,False,no,no,,,,Global,,,,"Clive Kabatznik, Unknown deepfake technology developers, Unnamed deepfake scammers, Unknown deepfake voice technology",0,0,False,,"Although it is unclear who the scammers were, what technology they used, and who developed that technology, it is clear that there was fraud involved with Kabatznik's account. The scammer likely used publicly available recordings of Kabatznik's voice to train a deepfake voice AI, and then inputted text when calling the Bank of America representative to attempt to get Kabatznik's money transferred without his consent.","audio inputs, voice recordings",financial and insurance activities,no,Autonomy3,,No. Not intentionally designed to perform harm,,deepfake audio generation,,"10.1 - deepfake voice technology was designed to output audio based on recording/voice input. However, it was not designed with the goal of implementing financial scams in mind."
CSETv1_Annotator-1,323,True,323,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,maybe,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,no,no,no,no,none,,no,yes,yes,True,no,,2018,05,29,False,no,yes,Laguna Beach,CA,US,North America,,,,"Tesla sedan, Tesla driver, Tesla, Laguna Beach Police Department vehicle, Tesla Autopilot",0,1,False,,Tesla Autopilot is designed to assist drivers in semi-autonomously navigating road obstacles and reacting to real-time traffic conditions.,"geospatial data, sensor input, camera input",transportation and storage,no,Autonomy2,,No. Not intentionally designed to perform harm,Tesla sedan,semi-autonomous navigation,,
CSETv1_Annotator-1,409,True,409,005,2. Initial annotation complete,,False,no,yes,yes,maybe,no,no,no,no,no,"no tangible harm, near-miss, or issue",maybe,no,True,none,,no,no,maybe,no,yes,sexual orientation or gender identity,,yes,maybe,no,True,no,,2013, ,,True,no,no,,,,Global,,,"6.1 - Ricanek was researching as early as 2013. However, investigation of the dataset he compiled didn't happen until 2017.","Karl Ricanek, Trans people who uploaded videos of their hormone therapies on Youtube",0,0,False,,"Ricaneck built a biometric dataset of 10,000 images of 38 trans people, scraped from their YouTube videos documenting their hormone therapies in order to improve the accuracy of facial recognition systems in identifying people pre and post hormone therapy. This ""HRT Transgender Dataset"" was still available as a Dropbox URL as late as April 2021 and also included the videos.","Youtube videos, facial images","professional, scientific and technical activities",no,Autonomy3,"9.5 - Ricanek initiated and facilitated the scraping of the YouTube videos. The dataset would not have been built without his involvement. However, there is no technology or AI explicitly involved in this incident.",,,,,no AI
CSETv1_Annotator-1,614,True,614,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,maybe,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,yes,no,none,,yes,yes,yes,True,yes,,2023,10, ,False,no,no,,,AU,Oceania,,,,"Australian academics urging parliamentary inquiry into Big 4 Accounting firms, Google, BardAI, KPMG, Deloitte, Readers of parliamentary inquiry report",0,0,False,,"Google's Bard AI, now known as Gemini, is a generative artificial intelligence chatbot that responds to user prompts by generating text to answer their questions.","text, user queries, user prompts","law enforcement, information and communication",maybe,Autonomy3,9.4 - Bard AI was used in a report submitted by academics to the Australian Parliament.,No. Not intentionally designed to perform harm,,"chatbot, content generation",large language models,
CSETv1_Annotator-1,535,True,535,005,2. Initial annotation complete,,False,no,no,yes,no,yes,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,"3.1 and 3.4 - Because the machine learning models in the research papers submitted to journals were not deployed in real medical settings, it is unlikely that they created tangible harm or affected any specific entities.",no,no,no,maybe,no,none,,no,yes,yes,False,no,,2020,01,01,False,no,no,,,,Global,,,"The review conducted by the University of Cambridge researchers encompassed ""all published papers and preprints, for the period from 1 January 2020 to 3 October 2020., which describe new machine learning models for the diagnosis or prognosis of COVID-19 from CXR or CT images.""","University of Cambridge researchers, COVID-19 diagnosis/prognosis model developers and researchers, COVID-19 machine learning models",0,0,False,,"Researchers reviewed articles describing machine learning models developed for ""fast and accurate detection and prognostication of coronavirus disease 2019 (COVID-19) from standard-of-care chest radiographs (CXR) and chest computed tomography (CT) images. None of the models identified were of potential clinical use due to methodological flaws and/or underlying biases. "" ""The algorithms were often trained on small, single-origin data samples with limited diversity; some even reused the same data for training and testing."" ""Many studies not only lacked external validation, but also neglected to specify the data sources used or details on how their AI models were trained... [others] were found to be at high risk of bias due to a variety of problems, including reliance on public datasets where many images suspected to represent COVID-19 are not confirmed to be positive cases. A few AI models trained to diagnose adult COVID-19 cases on chest X-rays were tested on images of pediatric patients with pneumonia.""","CXR radiographs, CT images, research papers",human health and social work activities,no,Autonomy3,,No. Not intentionally designed to perform harm,,"COVID-19 prognosis, COVID-19 diagnosis",machine learning,
CSETv1_Annotator-1,393,True,393,005,2. Initial annotation complete,,False,no,maybe,no,yes,no,no,yes,no,no,"no tangible harm, near-miss, or issue",maybe,yes,True,none,"3.2 - It is unclear whether Facebook's failure to reject the ads containing harmful content was attributable to human content moderators or content moderation algorithms. Facebook does use ""proactive detection technology.""",no,no,no,yes,yes,"nation of origin, citizenship, immigrant status, race","4.4 - In Kenya, Global Witness submitted test ads that ""spoke of beheadings, rape and bloodshed. They compared people to donkeys and goats. Some also included profanity and grammatical errors.""
4.6 - Test ads submitted in Ethiopia used dehumanizing hate speech to call for the murder of people belonging to each of Ethiopia's three main ethnic groups - the Amhara, the Oromo and the Tigrayans.",yes,maybe,yes,True,yes,,2022,07, ,False,no,no,,,,Africa,,,"Global Witness submitted ads in Kenya, Ethiopia, and Myanmar.","Facebook, Meta, Foxglove, Global Witness, Facebook users, Facebook content moderation algorithms",0,0,False,,"Facebook utilizes content moderation algorithms that are developed to review ad submissions and reject those that contain content that violates its guidelines. These algorithms work in tandem with human content moderators. Some of the English ads submitted by Global Witness were rejected at first, but only because they contained profanities and mistakes in addition to hate speech. Once the profanities were removed and grammar errors fixed, however, the ads - still calling for killings and containing obvious hate speech - went through without a hitch.","Facebook ads, Facebook posts","Arts, entertainment and recreation",no,Autonomy1,"9.5 - Either the human reviewers allowed ads with blatantly hateful content, or the content moderation algorithms approved them without a human in the loop.",No. Not intentionally designed to perform harm,,content moderation,,
CSETv1_Annotator-1,583,True,583,005,2. Initial annotation complete,,False,no,maybe,yes,yes,no,no,no,no,yes,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,yes,yes,yes,no,none,4.2 - Child sexual abuse content is illegal,yes,yes,yes,True,yes,,2023,06, ,True,no,no,,, ,Global,,,,"Instagram, Meta, Instagram recommender algorithms, The Wall Street Journal, Researchers at Stanford University's Internet Observatory Cyber Policy Center and the University of Massachusetts Amherst, Instagram users, Children",0,0,False,,"""Instagram's recommendation algorithms have been connecting and promoting accounts that facilitate and sell child sexual abuse content...Meta's photo-sharing service stands out from other social media platforms and 'appears to have a particularly severe problem' with accounts showing self-generated child sexual abuse material.""","Instagram accounts, Instagram posts","Arts, entertainment and recreation",no,Autonomy1,"9.5 - ""Due to the widespread use of hashtags, relatively long life of seller accounts and, especially, the effective recommendation algorithm, Instagram serves as the key discovery mechanism for this specific community of buyers and sellers... researchers discovered Instagram's recommendation algorithms also promoted them 'to users viewing an account in the network, allowing for account discovery without keyword searches.'""",No. Not intentionally designed to perform harm,,content recommendation,,
CSETv1_Annotator-1,205,True,205,005,2. Initial annotation complete,,False,no,maybe,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",no,yes,False,none,,no,no,no,yes,yes,"nation of origin, citizenship, immigrant status",,yes,no,yes,True,no,5.5 - no AI was involved. Hackers gained access to Facebook and Instagram accounts through phishing. ,2022,02,  ,False,no,no,,,,Europe,,,6.10 - Russia and Ukraine,"Facebook, Instagram, Meta, Ghostwriter, Hacked Facebook and Instagram users, Facebook, Instagram, Twitter, Youtube, Telegram, Odnoklassniki, and VK users",0,0,False,,"Hacking group Ghostwriter used Facebook to target public figures in Ukraine. Hackers successfully gained access to targets' social media accounts and attempted to post YouTube videos from them portraying Ukrainian troops as weakened. In a separate influence campaign, individuals used a number of fictitious personas to run websites masquerading as independent news outlets to publish claims about the West betraying Ukraine and Ukraine being a failed state.","social media accounts, Facebook accounts, Instagram accounts","Arts, entertainment and recreation, information and communication",no,Autonomy3,,,,,,"no AI - AI was only used by the hackers to generate fake profile pictures, which is not the main harm in this incident"
CSETv1_Annotator-1,466,True,466,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,no,no,none,,no,yes,yes,True,no,,2023,01,31,False,no,no,,,,Global,,,,"OpenAI, OpenAI Text Classifier",0,0,False,,OpenAI's Text Classifier was developed to detect AI-written text. It is only about 26% accurate.,"human-written text passages, AI-written text passages, user prompts, user queries, text",information and communication,no,Autonomy3,,No. Not intentionally designed to perform harm,,AI text detection,"supervised learning, binary classification",
CSETv1_Annotator-1,603,True,603,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,yes,yes,no,no,yes,"disability, financial means, age",4.2 - The algorithm that cut Seiler's care in 2008 was declared unconstitutional by the court in 2016.,yes,yes,yes,True,yes,,2008, , ,True,no,no,,,US,North America,,,"6.1 - Idaho created an algorithm to apportion home care assistance for people with disabilities as early as 2008. These algorithms continued to be used in different states after 2008. These include Pennsylvania, Iowa, New York, Maryland, New Jersey, Arkansas, Missouri, Washington, D.C., and more. ","Larkin Seiler, People receiving state-determined home care, People receiving state-determined home care, Tammy Dobbs, State governments, Home-care allocation algorithms, Brant Fries",0,0,True,"It is unclear how many injuries, hospitalizations, or deaths were caused because of the hour cuts mandated by the algorithm.","The algorithm included a computerized assessment with 286 questions covering everything from mental health to how much help patients need with daily activities like eating or doing their personal finances. Then, an algorithmic tool sorted patients into various levels of need. Each level was assigned a standard numbers of hours of care.","286 questions, health measures, patient information",human health and social work activities,yes,Autonomy3,,No. Not intentionally designed to perform harm,,"welfare determination, benefits allocation",,
CSETv1_Annotator-1,218,True,218,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,no,no,no,no,none,,no,yes,yes,False,no,,2020,06,01,False,no,yes,,,TW,Asia,,,,"Tesla, Tesla Model 3, Tesla Autopilot, Unnamed Tesla driver, Flipped truck",0,0,False,,Tesla's Autopilot is a driver assistance technology meant to help drivers semi-autonomously navigate obstacles and respond to traffic and road conditions in real time.,"radar input, camera input, sensor data",transportation and storage,no,Autonomy2,,No. Not intentionally designed to perform harm,Tesla Model 3,semi-autonomous navigation,,
CSETv1_Annotator-1,355,True,355,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,imminent risk of tangible harm (near miss) did occur,yes,yes,True,AI tangible harm near-miss,"3.1 - Drivers were falsely accused of ""fraudulent activity"" by Uber's automated systems and were subsequently let go without appeal. This would very likely cause tangible harm to the drivers' financial statuses and ability to earn money. Uber also used its algorithms to allocate jobs from the available pool, impacting drivers' earnings potential.",no,yes,no,no,no,none,"4.2 - An appeals court in the Netherlands judged that ride-hailing giants Uber and Ola violated driver rights in a number of instances, including when algorithms were involved in terminating driver accounts. The companies violated the European Union's General Data Protection Regulation which provides individuals with rights to data held on them and information about algorithmic decision making applied to them.",yes,yes,yes,True,yes,,2020,07,,False,no,no, ,,,Europe,,,6.1 - The legal challenges were originally lodged in July and September of 2020 in the United Kingdom.,"Ola, Uber, Ola and Uber drivers, Ola and Uber drivers, App Drivers and Couriers Union, International Alliance of App-based Transport, Worker Info Exchange, Uber algorithmic management systems, Amsterdam courts",0,0,False,,"Uber uses algorithms to detect fraud, such as strategically logging out to await higher surge pricing or declining work offered, in driver accounts. These algorithms have the ability to dismiss drivers without the right of appeal. Uber also uses algorithms to determine the earnings potential of a driver by assigning or withholding jobs from the available pool.",Uber driver account information,transportation and storage,no,Autonomy1,9.5 - There was no significant evidence of humans in the loop.,No. Not intentionally designed to perform harm,,worker management,,
CSETv1_Annotator-1,405,True,405,005,2. Initial annotation complete,,False,no,no,maybe,yes,no,no,no,no,no,non-imminent risk of tangible harm (an issue) occurred,no,yes,True,none,"3.1 - German credit card users could be denied financial services or have their financial freedom limited because of flawed Schufa scores.
3.2 - Schufa scores are calculated formulaically. The Schufa calculates a value between 0 and 10,000 points for a person. How exactly which feature is included in the calculation is secret, the weighting differs from industry to industry and from version to version. The score is used to determine probability of fulfillment, as well as other metrics.
3.5 - There is no AI in this incident",maybe,maybe,no,no,yes,"age, sex","4.2 - Schufa scores' lack of transparency may violate Europe's General Data Privacy Regulations.
4.6 - Young people and men were generally more likely to receive lower Schufa scores.",yes,no,yes,True,no,5.5 - There is no AI in this incident.,2001,,,True,no,no,,,DE,Europe,,,"Schufa scores have been in place since as early as 2001, which is when version 1 was introduced. Version 1 was used at least up until June of 2018.","Sven Drewert, Schufa Holding AG, German credit card users, Young, male, German credit card users",0,0,False,,"According to the Schufa, it has information on more than 67 million consumers. This includes information about the existence of a consumer's accounts and contracts. Surprisingly, Schufa has stored a maximum of three items of information from economic life for almost a quarter of people in the data set - for example the establishment of a current account and the conclusion of a credit card and mobile phone contract. Otherwise, it only has general data such as addresses or gender.","consumer gender, consumer address, consumer account details, consumer contract details",financial and insurance activities,no,Autonomy3,"9.4 - Schufa is a private credit agency.
9.5 - Schufa scores provide information to other vendors, who may use it to restrict or vet consumers.",,,,,no AI 
CSETv1_Annotator-1,314,True,314,005,2. Initial annotation complete,,False,no,yes,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,maybe,no,yes,yes,sex,,yes,yes,yes,True,yes,,2022,08,,False,no,no,,,,Global,,,,"Stability AI, Stable Diffusion, Art generator services, Women, Female celebrities",0,0,False,,Stability AI's Stable Diffusion is an open source AI image generator capable of producing realistic pictures from any text prompt.,"text prompts, user queries","information and communication, Arts, entertainment and recreation",no,Autonomy3,9.5 - Image generation AIs do not independently produce images. They rely on user inputted queries and text prompts.,No. Not intentionally designed to perform harm,,image generator,,
CSETv1_Annotator-1,579,True,579,005,2. Initial annotation complete,,False,no,maybe,yes,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,no,yes,sexual orientation or gender identity,"Adding gender identity terms like ""trans,"" ""nonbinary,"" or ""queer"" to an image generation prompt leads to images that are less human looking, more stereotypical, and more sexualized than images from prompts without these terms.",yes,yes,yes,True,yes,,2023,07,03,True,no,no,,,,Global,,,6.1-6.3 - Date is of the publication date of the article written by Sabine Weber that this incident refers to.,"OpenAI, DALL-E, Transgender, nonbinary, and queer people, Eddie Ugless",0,0,False,,DALL-E is an AI text-to-image generator that can create realistic images and art from a description in natural language.,"text queries, user prompts","information and communication, Arts, entertainment and recreation",no,Autonomy3,9.5 - DALL-E does not generate any images without human prompt input.,No. Not intentionally designed to perform harm,,"image generation, text-to-image",,
CSETv1_Annotator-1,235,True,235,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,maybe,"no tangible harm, near-miss, or issue",yes,yes,True,none,,maybe,no,no,no,maybe,"financial means, nation of origin, citizenship, immigrant status","4.5 - Ping An may be using its new facial recognition technology to identify which types of people are making the most insurance claims in order to reject them and save money. ""The poor and downtrodden - people living precarious, overworked lives - tend to run into more problems, and hence have more insurance claims. And in China, human discrimination makes certain ethnic groups - such as Uyghurs... more likely to be poor and downtrodden... So an algorithm trained to identify potential claimants will also discriminate against these people.",maybe,yes,yes,True,maybe,"It is unclear whether or not Ping An's facial recognition claims are actually biased against insurance claimants and ethnic minorities. The author of this article mostly posits that such algorithms may have ramifications for minorities, but there are not enough details to conclude that AI special interest intangible harm has actually occurred.",2019,,,True,no,no,,,CN,Asia,,,,"Ping An, Ping An facial recognition software, Ping An insurance claimants",0,0,False,,"Ping An apparently uses facial recognition software to search for ""micro-expressions"" on people's faces to help decide whether they're being truthful, whether to insure them, and presumably what the service should be. Secondarily, the software will gauge people's body-mass index and well-being to determine health insurance premiums.","facial images, facial videos","human health and social work activities, public administration",no,Autonomy3,,No. Not intentionally designed to perform harm,,"fraud detection, facial recognition, insurance",facial recognition,
CSETv1_Annotator-1,506,True,506,005,2. Initial annotation complete,,False,no,maybe,no,yes,no,yes,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,maybe,no,yes,no,none,4.2 - False claims could be characterized as libel.,yes,yes,yes,True,yes,,2023,03,,False,no,no,,,,Global,,,,"OpenAI, ChatGPT, Eugene Volokh, ChatGPT users, Jonathan Turley, People ChatGPT makes false claims about",0,0,False,,ChatGPT is a natural language processing chatbot driven by generative AI technology that outputs text in response to user prompts/queries.,"text, user prompts, user queries",information and communication,no,unclear,"9.5 - ChatGPT  requires user prompts/queries to output text. After a question or statement is provided, ChatGPT independently generates an answer without a human in-the-loop. However, a human is initially needed to provide a prompt.",No. Not intentionally designed to perform harm,,text generation,large language models,
CSETv1_Annotator-1,292,True,292,005,2. Initial annotation complete,,False,yes,no,no,yes,no,yes,no,no,yes,imminent risk of tangible harm (near miss) did occur,yes,yes,True,AI tangible harm near-miss,"In initial tests, Apple's autonomous vehicle allegedly ""nearly took out a jogger who was crossing the street.""",no,no,no,no,no,none,,no,yes,yes,True,no,,2022,,,True,no,yes,Cupertino,CA,US,North America,,,6.4 - Apple sent several of its prototype self-driving cars on a roughly 40-mile trek through Montana in August 2021. It is unclear when the test that almost injured a jogger occurred.,"Apple, Apple self-driving vehicles, Unnamed jogger",0,0,False,,"Apple's self-driving car is designed to autonomously navigate and drive passengers, avoid obstacles, and react to real-time traffic and road conditions. Compared to other self-driving vehicles, Apple's car does not feature any windows or a steering wheel.","geospatial data, sensor data, camera input",transportation and storage,no,Autonomy2,,No. Not intentionally designed to perform harm,modified Lexus SUV,autonomous navigation,,
CSETv1_Annotator-1,427,True,427,005,2. Initial annotation complete,,False,yes,no,no,yes,no,yes,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,no,no,no,no,none,,no,yes,yes,True,no,,2022,12,12,False,no,yes,San Francisco,CA,US,North America,,,6.1-6.3 - Date refers to when the NHTSA's investigation into Cruise's vehicles was opened.,"National Highway Traffic Safety Administration, General Motors, Cruise, Cruise vehicles, Cars that struck Cruise vehicles, People in cars that struck Cruise vehicles, People in Cruise vehicles",0,3,False,,"Cruise equips vehicles with an Automated Driving System (ADS), which is designed to semi-autonomously navigate obstacles and react to real-time traffic and weather conditions. NHTSA was notified of multiple reports involving Cruise ADS equipped vehicles, operating without onboard human supervision, becoming immobilized. The vehicle may strand passengers in unsafe locations and become an obstacle to other road users. NHTSA also received reports of hard braking incidents.","geospatial data, sensor data, campera input",transportation and storage,no,unclear,"9.5 - The NHTSA report detailed that during the incidents of vehicle immobilization, the ADS equipped vehicles were operating without onboard human supervision. It is unclear whether there were human operators in the hard braking incidents.",No. Not intentionally designed to perform harm,Cruise vehicle,semi-autonomous navigation,,
CSETv1_Annotator-1,610,True,610,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,yes,yes,yes,yes,sex,,yes,yes,yes,True,yes,,2023,09,,False,no,no,Almendralejo,,ES,Europe,,,,"Girls in Spain targeted by deepfake images, Girls in Spain targeted by deepfake images, Girls in Spain targeted by deepfake images, Boys who used AI to generate naked images of girls in Spain, ClothOff",0,0,False,,ClothOff was used to alter images of girls to remove their clothes. It is described to be readily available to use on smartphones. More than 20 girls in Spain reported receiving AI-generated naked images of themselves.,images,information and communication,no,Autonomy3,9.5 - The app did not create the CASM independently. The perpetrators uploaded images stolen from the girls' Instagram accounts and prompted the AI to generate a new image with their clothing removed.,Yes. Intentionally designed to perform harm and did create intended harm,,"image generation, image modification",,10.1 - ClothOff is designed to produce nude versions of images where the subject is clothed.
CSETv1_Annotator-1,213,True,213,005,2. Initial annotation complete,,False,no,maybe,maybe,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,maybe,yes,geography,"4.4 - This incident is not explicitly about misinformation. Instead, it is about Facebook's inability to correctly identify political ads. This could lead to harmful actors being able to spread misinformation or manipulate political events through ads on Facebook. However, Facebook's inability to identify political ads itself does not constitute misinformation or detrimental content.
4.5 and 4.6 - Facebook's ad detection was worse in non-English-speaking countries like Malaysia.",yes,yes,yes,True,yes,,2020,07,,False,no,no, ,, ,Global,,,6.1 and 6.2 - Date refers to the researchers examining 33.8 million Facebook ads that ran between July 2020 and February 2021 - a timeframe that included elections in both the U.S. and Brazil.,"imec-DistriNet researchers, NYU Cybersecurity for Democracy researchers, Facebook, Facebook users outside of the U.S., Facebook users, Political advertisers on Facebook, Facebook political ad detection and policy enforcement systems",0,0,False,,"Facebook's political ad detection and policy enforcement systems are ineffective. Globally, Facebook made the wrong decision for 83% of the ads that had not been declared as political by their advertisers and that Facebook or the researchers deemed political. That is, Facebook missed political ads just because the advertisers had said they were not political. In addition, Facebook missed a higher proportion of political ads outside the U.S. Because not all advertisers self-declare political ads, Facebook conducts additional reviews to ensure all political ads are captured. Undeclared political ads are taken down. Facebook's enforcement relies heavily on detecting keywords in ads under an automated system, although staff also play a role in moderating content.","Facebook advertisements, political advertisements",information and communication,no,Autonomy2,"Facebook's enforcement of the policy relies heavily on detecting keywords in ads under an automated system, although staff may also play a role in moderating the content. There is a human in the loop.",No. Not intentionally designed to perform harm,,"content detection, political content detection, advertisement classification, content moderation",,
CSETv1_Annotator-1,448,True,448,005,2. Initial annotation complete,,False,no,yes,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,yes,yes,"sex, other","4.6 - The AI VTuber Neuro-sama not only said she's not sure if she believes in the Holocaust, but also that women's rights don't exist and that throwing a fat person on the tracks would solve philosophy's famous trolley ethical conundrum.",yes,yes,yes,True,yes,,2022,12,,False,no,no,,,,Global,,,,"Neuro-sama, Neuro-sama Twitch stream viewers, Women, Fat people, Vedal",0,0,False,,"Neuro-sama is a VTuber who streams Minecraft and the rhythm game Osu! on Twitch. Unlike most anime avatars, Neuro-sama is controlled by an artificial intelligence program rather than a human being. The AI is used to respond to questions and stream the games.",chat questions,"Arts, entertainment and recreation",no,Autonomy2,"9.5 - Although Neuro-sama is controlled by an artificial intelligence program, it is likely that a human operator is overseeing the livestream and could override the system in real time. An AI cannot independently set up a Twitch stream.",No. Not intentionally designed to perform harm,,"livestream, game streaming, answer chat questions",,
CSETv1_Annotator-1,264,True,264,005,2. Initial annotation complete,,False,yes,no,no,maybe,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,no,no,none,,no,yes,yes,False,no,,2022,03,,False,no,no,,,,Global,,,,"Speedcam Anywhere, Speedcam Anywhere developers, Speedcam Anywhere potential users",0,0,False,,"Users of the app open Speedcam Anywhere when they hear a speeding car approaching and film the car passing. The app uses the number plate of the passing car to search the DVLA's public registration database to find the make and model of the car. From there, it determines the distance between the axles of the car, and compares it with the footage to calculate the speed. The user then has the option of saving the video, or generating a report to share with the authorities. Because the algorithm has not been vetted by the Home Office, it is not legally a speed camera and cannot be used as evidence to issue speeding tickets.","video input, car footage, camera footage, speeding video","transportation and storage, information and communication",no,Autonomy3,,Yes. Intentionally designed to perform harm but created an unintended harm (a different harm may have occurred),,"speed detection, speeding detection",,"10.1 - The app was intentionally designed to track car speeds, but it had the unintended side effect of making potential users unhappy"
CSETv1_Annotator-1,529,True,529,005,2. Initial annotation complete,,False,no,maybe,no,yes,no,yes,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,,no,no,no,no,yes,"race, sex",,yes,yes,yes,True,yes,,2022,10,31,True,no,no,,,,Global,,,"6.4 - This date refers to when Sasha Luccioni, AI researcher for Hugging Face, tweeted about creating a simple tool to explore biases ingrained in the Stable Diffusion AI image generator model. Stable Diffusion was released in August 2022 and was likely displaying the same biases since its inception.","Stable Diffusion, Sasha Luccioni, Stability AI, Women, People of color",0,0,False,,Stable Diffusion is a text-to-image AI that gets its raw data from LAION-5B (the world's largest openly accessible image-text dataset with more than 5 billion images and captions found on the Internet). Users input text prompts and receive images as output.,"images scraped from the Internet, images","Arts, entertainment and recreation, information and communication",no,Autonomy3,9.5 - Stable Diffusion requires user prompts in order to output images.,No. Not intentionally designed to perform harm,,"image generation, text-to-image",,
CSETv1_Annotator-1,437,True,437,005,2. Initial annotation complete,,False,yes,no,maybe,yes,no,no,no,no,maybe,imminent risk of tangible harm (near miss) did occur,yes,yes,True,AI tangible harm near-miss,"3.1 - Non-Amazon brands may be negatively financially affected if their products are copied or artificially deprioritized in search results.
3.2 - Amazon's search systems most likely deploy AI to rank products and vendors in search results.
3.3 - The search systems did not perpetuate the harm. Employees were able to artificial seed searches with Amazon-branded results. However, the search system is still linked to the chain of harm in this incident.",no,no,no,no,no,none,,no,yes,yes,True,no,,2021,10,,True,no,no,,,IN,Asia,,,"6.4 - Date refers to the allegations of search seeding and product copying against Amazon. However, Amazon India was likely engaging in these practices before October 2021. In 2016, a report was done on the in-house brand Solimo, whose strategy was 'to use information from Amazon.in to develop products and then leverage the Amazon.in platform to market these products to our customers.'"" A 2020 Wall Street Journal report found that Amazon employees had studied detailed internal sales data to help it crush independent sellers with competing products.","Amazon, Indian vendors that sell products on Amazon, Amazon India employees, Amazon search systems",0,0,False,,"Amazon's search systems list results for products matching user search queries. In this incident, results were artificially manipulated to prioritize products associated with Amazon brands. ",Amazon products,"wholesale and retail trade, information and communication",no,unclear,"9.5 - The search system should operate independently. However, in this case, Amazon India employees used ""search seeding"" to make sure Amazon brand products placed in the first two to three search results.",No. Not intentionally designed to perform harm,,search result ranking,,
CSETv1_Annotator-1,465,True,465,005,2. Initial annotation complete,,False,no,maybe,yes,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,no,True,none,"3.2 and 3.3 - LAION is a nonprofit that aims to make datasets available to the general public. While its data can be used in various AI projects, the dataset itself is not AI. It may have used AI to scrape the web for images, but the AI is not clearly linked to the adverse outcome of the incident. The adverse outcome of the incident is linked to whichever entity originally stole the images from Lapine's doctor and uploaded them to the Internet.",no,yes,no,no,no,none,4.2 - The images of Lapine were private medical records that she did not consent to being used by anyone except her doctor.,no,yes,no,False,no,,2022,09,,True,no,no,,,,Global,,,6.4 - Date refers to when Lapine discovered her face was in the LAION dataset. The images were taken in 2013.,"Lapine, LAION-5B dataset, LAION",0,0,False,,"LAION datasets are ""indexes to the Internet, i.e. lists of URLs to the original images together with the ALT texts found linked to those images."" LAION downloaded and calculated CLIP embeddings of the pictures do compute similarity scores between pictures and texts.",images,information and communication,no,Autonomy3,"9.5 - LAION deployed the web scraping technology to find image and text links for the dataset. The dataset also does not make decisions independently, but is used by researchers as training data for AI image synthesis models.",,,,,no AI linked to the harm 
CSETv1_Annotator-1,439,True,439,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,yes,no,no,yes,race,,yes,yes,yes,True,yes,,2019,07,,False,no,no,Detroit,MI,US,North America,,,"6.4 - The crime was committed on May 15, 2019. The facial recognition software mistakenly led the Detroit Police Department to Michael Oliver in July 2019. Michael Oliver was handcuffed and driven to jail on July 31, 2019. His car was impounded and he was forced to wait behind bars for 2.5 days.","Michael Oliver, Michael Oliver, People of color, Detroit Police Department, Michael Oliver, DPD facial recognition software, DataWorks Plus",0,0,False,,"The  facial recognition technology that the Detroit Police Department deployed sent back a shot of Michael Oliver and detective Donald Bussa assumed that he was the one who had snatched Stephen Cassini's phone. Bussa showed Cassini a photo lineup of suspects and Cassini identified Oliver. The software measures various points on a person's face - the space between their eyes, the slope of their nose - to generate a unique ""face print."" The Detroit Police Department then checks for a possible match in a database of photos; the system can access thousands of mugshots as well as the Michigan state database of driver's license photos.",facial images,law enforcement,yes,Autonomy3,9.5 - The technology provided a match but Cassini identified Oliver out of a photo lineup of suspects before detective Donald Bussa got a warrant for Oliver's arrest.,No. Not intentionally designed to perform harm,,facial recognition,,
CSETv1_Annotator-1,449,True,449,005,2. Initial annotation complete,,False,no,no,no,yes,no,yes,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,no,no,none,,no,yes,yes,True,no,,2023,01,,False,no,no,,,,Global,,,,"Koko, Rob Morris, Koko users, OpenAI, Chat GPT-3, Koko users",0,0,False,,"Koko is a mental health nonprofit that aims to provide support to people seeking counseling. Koko uses Discord to provide peer-to-peer support to people experiencing mental health crises and those seeking counseling.It tested the use of GPT-3 in assisting humans in writing messages. The ""'messages composed by AI (and supervised by humans) were rated significantly higher than those written by humans on their own... Response times went down 50%, to well under a minute... [but] once people learned the messages were co-created by a machine, it didn't work. Simulated empathy feels weird, empty.'""","messages, user text prompts","human health and social work activities, information and communication",no,Autonomy3,,No. Not intentionally designed to perform harm,,"text generation, content generation, peer-to-peer support, mental health support",,
CSETv1_Annotator-1,492,True,492,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,no,no,no,maybe,age,4.5 - Scammers may target elderly people because they are perceived to be more vulnerable to voice cloning scams.,no,yes,yes,True,no,,2023,01,10,False,,,,,CA,North America,,,,"Benjamin Perkin, Benjamin Perkin's parents, Voice scammers, Voice synthesizing tools",0,0,False,,It is unclear which tools the voice scammers who targeted Benjamin Perkin's parents used. It may have been ElevenLabs software. ElevenLabs is an AI voice synthesizing start-up that transforms a short vocal sample into a synthetically generated voice through a text-to-speech tool.,,"other, information and communication",no,Autonomy3,,No. Not intentionally designed to perform harm,,"text-to-speech, voice synthesis",,"10.1 - Voice synthesizing tools were not intentionally designed to be used in financial scams. However, they are used to achieve such goals by nefarious actors."
CSETv1_Annotator-1,382,True,382,005,2. Initial annotation complete,,False,no,maybe,no,yes,no,no,no,no,no,tangible harm definitively occurred,maybe,no,True,none,"3.2 - Molly likely was likely exposed to more and more detrimental content about suicide because of the platforms' recommender systems.
3.3 - The adverse outcome in this incident, Molly's death, cannot be directly linked to AI. However, it undoubtedly contributed to her worsening mental health.",no,no,yes,yes,no,none,,yes,maybe,yes,True,yes,"5.3 - In the case of detrimental content, the technology can be linked to the adverse outcome. Social media platforms like Pinterest and Instagram permitted and even recommended graphic images and depressive material.",2017,11,,False,no,no,,,GB,Global,,,,"Molly Russell, Molly Russell, Meta, Instagram, Pinterest",1,0,False,,"The internet ""affected her [Molly Russell's] mental health in a negative way and contributed to her death in a more than minimal way."" Social media platforms like Instagram and Pinterest, which Molly used, likely recommended her graphic images of self-harm and depressive material based on her previous likes and engagement.",user engagement,information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,content recommendation,,
CSETv1_Annotator-1,543,True,543,005,2. Initial annotation complete,,False,no,maybe,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,False,none,3.1 - The dip in the markets was brief and temporary.,no,no,no,yes,no,none,,yes,yes,yes,True,yes,,2023,05,22,False,no,no,,,US,Global,,,,"Twitter account @BloombergFeed, Twitter, Twitter users",0,0,False,,It is unclear who posted the AI-generated image or what tool they used. The tool they used like was designed to output images based on user prompts.,"user prompts, user queries",information and communication,no,Autonomy3,,No. Not intentionally designed to perform harm,,image generation,,
CSETv1_Annotator-1,340,True,340,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,,no,no,no,no,no,none,,no,yes,yes,True,no,,2020,,,True,no,yes,,,US,North America,,,6.1 - AI systems like the Collision Mitigation Braking System (CMBS) was present in Honda models as early as 2020.,"Honda, Honda vehicles, Honda drivers, Honda Collision Mitigation Braking System",0,0,True,8.3 - It is unclear how many people were injured by the braking system.,"Honda's CMBS is part of the car's overall collision avoidance system. The CMBS uses a millimeter wave radar unit mounted near the car's front bumper along with a camera mounted near the rearview mirror. The radar and camera scan ahead in the range of 300 feet, searching for risks of potential collision with people or other things. Information from these devices feeds into a computer. If an obstacle is detected, the CMBS will alert the driver and potentially apply light or strong brakes automatically. However, sometimes the CMBS responds even when there is no real collision threat.","radar input, camera input",transportation and storage,no,Autonomy1,"9.5 - It seems that the CMBS was operating unbeknownst to drivers. Thus, it did not require simultaneous human oversight, interaction, or intervention for operation.",No. Not intentionally designed to perform harm,Honda sedans,"automatic braking, collision avoidance, collision mitigation",,
CSETv1_Annotator-1,301,True,301,005,2. Initial annotation complete,,False,maybe,no,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,"3.1 - The student received a 0 on the exam and a ""warning on her record"" as a result of being flagged as engaging in academically dishonest behavior.",no,no,yes,no,yes,race,4.5 - The student was a black woman who felt that her race played a role in her being flagged in part because of studies and media coverage of facial analysis technology's struggles with people who have darker skin.,yes,yes,yes,True,yes,,2022,02,,False,no,no,,FL,US,North America,,,,"unnamed Florida student, unnamed Florida student, People with dark skin, Honorlock, Amazon, Rekognition, Jonelle Orridge",0,0,False,,"Rekognition is an image analysis tool that Amazon started selling in 2016. It looks for facial landmarks - nose, eyes, eyebrows, mouth - and returns a confidence score that what is onscreen is a face. It can also infer the emotional state, gender, and angle of the face. Honorlock will flag a test taker as suspicious if it detects multiple faces in the room, or if the test taker's face disappears. ","facial images, camera input, facial video",Education,maybe,Autonomy3,9.4 - Broward College is a public university.,No. Not intentionally designed to perform harm,,"facial recognition, exam proctoring, detect cheating",,
CSETv1_Annotator-1,207,True,207,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,"no tangible harm, near-miss, or issue",yes,yes,False,none,"3.1 - The adverse outcome in this incident is public outrage over the Honolulu Police Department using federal CARES funding to purchase the ""Spot"" robot. There are no recorded incidents in which the robot caused tangible harm to citizens.",no,no,no,no,no,none,,no,yes,yes,True,no,,2020,,,True,no,yes,Honolulu,HI,US,North America,,,,"Honolulu Police Department, Boston Dynamics, \""Spot\"" robot dog, Honolulu homeless people",0,0,False,,"""According to Boston Dynamics, Spot is a “stable, dynamically balanced quadruped robot” that can do what other robots and drones cannot, like climb stairs, work around obstructions and operate in “constrained environments.” The quadrupedal robots move like animals and can even pick themselves back up if they’re knocked over."" The Honolulu Police Department purchased the robot dog to mitigate the spread of COVID-19 by taking homeless peoples' temperatures, conducting touchless field screening, providing telemedicine, and delivering medical supplies and food. ","sensor data, camera input","law enforcement, human health and social work activities",yes,Autonomy2,,No. Not intentionally designed to perform harm,robotic dog,administer telehealth,,
CSETv1_Annotator-1,257,True,257,005,2. Initial annotation complete,,False,yes,no,no,yes,no,no,no,no,yes,tangible harm definitively occurred,yes,yes,True,AI tangible harm event,"In March 2021, a false ShotSpotter alert eventually led to the killing of 13-year-old Adam Toledo.",no,maybe,yes,no,yes,"race, geography","4.2 - One of the criticisms of ShotSpotter is that the constant recording/surveillance may be an invasion of privacy.
4.6 - Data shows that ShotSpotter sensors are placed almost exclusively in majority Black and brown neighborhoods.",yes,yes,yes,True,yes,,2017,,,True,no,yes,,,US,North America,,,"6.1 and 6.4 - ShotSpotter was installed as early as 2017 (in Syracuse). As of March 2022, the technology was used in at least 130 U.S. cities and towns.
6.9 - ShotSpotter has been deployed in a variety of cities across the country. These include Chicago, IL; Kansas City, Missouri; Cleveland, Ohio; Syracuse, New York; and Atlanta, Georgia","ShotSpotter, MacArthur Justice Center, Predominantly Black and brown neighborhoods, Black and brown people, Black and brown people, Chicago Police Department, Surveillance Technology Oversight Project, Syracuse Police Department, Adam Toledo, Adam Toledo, Kansas City Police Department, Atlanta Police Department, Cleveland Division of Police",1,0,True,8.3 - It is unclear whether other arrests or deaths were caused by false Shotspotter reports.,"ShtSpotter uses hidden microphone sensors to detect the sound of gunshots, generate real-time alerts, and trigger armed police responses to the location. However, a study conducted by MacArthur Justice Center at Northwestern Pritzker School of Law, found that 89% of ShotSpotter deployments were dead ends. That is, they turned up no gun-related crime. 86% led to no report of any crime at all. In less than two years, there were more than 40,000 dead-end ShotSpotter deployments.","microphone input, audio input, audio recordings",law enforcement,yes,Autonomy3,,No. Not intentionally designed to perform harm,microphones,"detect gunshots, audio classification, audio detection",acoustic triangulation,
CSETv1_Annotator-1,316,True,316,005,2. Initial annotation complete,,False,no,maybe,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,maybe,no,none,,no,yes,yes,True,no,,2016,06,02,True,no,no,,,,Global,,,6.4 - Date refers to the publication of the Medium article that this incident refers to detailing the investigation into Facebook's advertisement-approval algorithms.,"Facebook, Facebook false advertisers, Facebook ad-approval algorithm, Facebook users",0,0,False,,"Facebook's ad approval algorithm stands between advertisers and them getting their ads posted on Facebook. Supposedly, this algorithm should block ads that violate Facebook's Terms of Service from being posted.",Facebook advertisements,information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,"content moderation, advertisement moderation, advertisement approval",,
CSETv1_Annotator-1,331,True,331,005,2. Initial annotation complete,,False,no,maybe,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,yes,no,none,"4.4 - Instagram shielded hashtags about Donald Trump from displaying related hashtags, including ones with negative connotations. However, similar Biden hashtags were displayed alongside related hashtags, which at times steered users to insults and disinformation about Joe Biden.",yes,yes,yes,True,yes,,2020,08,,False,no,no,,,US,North America,,,,"Meta, Instagram, Instagram users, Joe Biden, Instagram content suggestion algorithm",0,0,False,,"Instagram suggests related content to users when they search or post with hashtags. However, Instagram experienced a bug that turned off related hashtags for Trump but not Biden.","hashtags, Instagram posts",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,content recommendation,,
CSETv1_Annotator-1,631,True,631,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,maybe,no,none,4.4 - the chatbot used foul language and criticized DPD.,no,yes,yes,True,no,,2024,01,18,False,no,no,,,GB,Europe,,,,"Dynamic Parcel Distribution (DPD), DPD online support chatbot, Ashley Beauchamp, DPD chatbot users",0,0,False,,DPD implemented an AI chatbot service to perform online customer support. ,"customer queries, customer concerns, customer messages, text","wholesale and retail trade, information and communication",no,Autonomy1,,No. Not intentionally designed to perform harm,,"chatbot, customer service",large language model,
CSETv1_Annotator-1,633,True,633,005,2. Initial annotation complete,,False,no,maybe,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,maybe,yes,sex,,yes,yes,yes,True,yes,,2024,01,28,False,no,no,Melbourne,VI,AU,Oceania,,,,"Georgie Purcell, 9News Melbourne, Photoshop, Adobe",0,0,False,,"9News Melbourne blamed 'automation by Photoshop' for the editing of an image of Georgie Purcell to make her breasts look bigger and expose her midriff. 9News Melbourne used Photoshop to resize the image to fit the outlet's specs. It alleged that during the process, the automation by Photoshop created an image that was not consistent with the original. However, a spokesperson for Adobe said use of its generative AI features would have required human intervention and approval.",images,information and communication,maybe,Autonomy3,"9.4 - the AI system was deployed by a public media news outlet on a public figure (governmental official: upper house MP Georgia Purcell).
9.5 - Adobe purports that human intervention is necessary to activate Photoshop's generative AI features. In addition, human reviewers, editors, and producers were involved in the broadcasting process.",No. Not intentionally designed to perform harm,,image alteration,,
CSETv1_Annotator-1,667,True,667,005,2. Initial annotation complete,,False,no,maybe,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,yes,yes,"nation of origin, citizenship, immigrant status, ideology",,yes,yes,yes,True,yes,,2023,11,,False,no,no,,,TW,Asia,,,,"Lai Ching-te, Taiwanese voters, Chinese officials, MyGoPen, Tsai Ing-wen, Cofacts, Doublethink Lab",0,0,False,,"It is unclear which technologies were used to create the deepfake footage of Taiwanese public figures. However, the systems were used to create videos of the figures saying things that they had not. For example, a video of Lai Ching-te was created where he endorsed his two rivals in the presidential election campaign.",videos,information and communication,yes,Autonomy3,9.4 - The deepfake technology was allegedly deployed by Chinese government officials in order to influence Taiwanese election results.,No. Not intentionally designed to perform harm,,deepfake video generation,,
CSETv1_Annotator-1,676,True,676,005,2. Initial annotation complete,,False,no,maybe,no,yes,no,no,no,no,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,yes,no,none,,yes,yes,yes,True,yes,,2024,04,,False,no,no,,,PH,Asia,,,,"President Ferdinand Marcos Jr., Filipino citizens",0,0,False,,"It is unclear which technology was used to create the deepfakes of Marcos. However, it  made it seem like President Ferdinand Marcos Jr. was urging military action against China, despite him repeatedly asserting that he is not trying to provoke Beijing regarding disputes over the South China Sea.",audio inputs,information and communication,maybe,Autonomy3,"9.4 - The deepfake technology was applied on a government official. It is unclear who deployed the technology, but it is likely that foreign governmental actors were involved.",No. Not intentionally designed to perform harm,,deepfake audio generation,,
CSETv1_Annotator-1,651,True,651,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,no,yes,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,yes,yes,yes,yes,sex,,yes,yes,yes,True,yes,,2024,02,,False,no,no,Beverly Hills,CA,US,North America,,,,"Beverly Vista Middle School students who created and distributed fake nude images of their peers, Beverly Vista Middle School students, Beverly Vista Middle School students who were victims of deepfake nude image generation, Beverly Vista Middle School students who were victims of deepfake nude image generation",0,0,False,,It is unclear which AI image generation technologies/systems were deployed by the Beverly Vista middle schoolers to create and distribute fake nude photos of their peers. ,images,information and communication,no,Autonomy3,,unclear,,"image generation, image modification",,
CSETv1_Annotator-1,642,True,642,005,2. Initial annotation complete,,False,no,no,no,yes,no,no,no,yes,no,"no tangible harm, near-miss, or issue",yes,yes,True,none,,no,no,no,maybe,no,none,"4.4 - The temporary glitch caused ChatGPT to output nonsensical/gibberish content, but it was not necessarily detrimental.",no,yes,yes,True,no,,2024,02,20,False,no,no,,,,Global,,,,"OpenAI, ChatGPT, ChatGPT users",0,0,False,,ChatGPT is a natural language processing chatbot driven by generative AI technology that outputs text in response to user prompts/queries.,"text, user prompts, user queries",information and communication,no,Autonomy1,,No. Not intentionally designed to perform harm,,"chat bot, text generation",,
